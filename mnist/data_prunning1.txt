nohup: ignoring input
Running with pruning_method=0, pruning_rate=-0.3, wandb_name=avg_loss, on GPU=0
Running with pruning_method=0, pruning_rate=-0.5, wandb_name=avg_loss, on GPU=1
Running with pruning_method=0, pruning_rate=-0.7, wandb_name=avg_loss, on GPU=2
Running with pruning_method=0, pruning_rate=-0.9, wandb_name=avg_loss, on GPU=3
Running with pruning_method=0, pruning_rate=0.3, wandb_name=avg_loss, on GPU=0
Running with pruning_method=0, pruning_rate=0.5, wandb_name=avg_loss, on GPU=1
Running with pruning_method=0, pruning_rate=0.7, wandb_name=avg_loss, on GPU=2
Running with pruning_method=0, pruning_rate=0.9, wandb_name=avg_loss, on GPU=3
Running with pruning_method=2, pruning_rate=-0.3, wandb_name=TTDS, on GPU=0
Running with pruning_method=2, pruning_rate=-0.5, wandb_name=TTDS, on GPU=1
Running with pruning_method=2, pruning_rate=-0.7, wandb_name=TTDS, on GPU=2
Running with pruning_method=2, pruning_rate=-0.9, wandb_name=TTDS, on GPU=3
Running with pruning_method=2, pruning_rate=0.3, wandb_name=TTDS, on GPU=0
Running with pruning_method=2, pruning_rate=0.5, wandb_name=TTDS, on GPU=1
Running with pruning_method=2, pruning_rate=0.7, wandb_name=TTDS, on GPU=2
Running with pruning_method=2, pruning_rate=0.9, wandb_name=TTDS, on GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/mnist/wandb/run-20250125_150623-lqs2yl70
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avg_loss_prune0.9_seeds10
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/california_housing_pruning
wandb: ğŸš€ View run at https://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/lqs2yl70
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/mnist/wandb/run-20250125_150623-a6k7h7vc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avg_loss_prune0.3_seeds10
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/california_housing_pruning
wandb: ğŸš€ View run at https://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/a6k7h7vc
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/mnist/wandb/run-20250125_150624-e6x0e4t1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avg_loss_prune-0.9_seeds10
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/california_housing_pruning
wandb: ğŸš€ View run at https://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/e6x0e4t1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/mnist/wandb/run-20250125_150625-m23c7bia
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avg_loss_prune-0.3_seeds10
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/california_housing_pruning
wandb: ğŸš€ View run at https://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/m23c7bia
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/mnist/wandb/run-20250125_150625-s7xvtzlb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avg_loss_prune0.5_seeds10
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/california_housing_pruning
wandb: ğŸš€ View run at https://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/s7xvtzlb
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/mnist/wandb/run-20250125_150625-ri28k2df
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TTDS_prune-0.3_seeds10
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/california_housing_pruning
wandb: ğŸš€ View run at https://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/ri28k2df
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/mnist/wandb/run-20250125_150625-yjl7i154
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avg_loss_prune0.7_seeds10
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/california_housing_pruning
wandb: ğŸš€ View run at https://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/yjl7i154
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/mnist/wandb/run-20250125_150626-e0py2dus
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avg_loss_prune-0.5_seeds10
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/california_housing_pruning
wandb: ğŸš€ View run at https://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/e0py2dus
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/mnist/wandb/run-20250125_150626-v7v6mw3u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TTDS_prune0.3_seeds10
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/california_housing_pruning
wandb: ğŸš€ View run at https://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/v7v6mw3u
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/mnist/wandb/run-20250125_150626-wiwwwtcb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TTDS_prune-0.9_seeds10
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/california_housing_pruning
wandb: ğŸš€ View run at https://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/wiwwwtcb
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/mnist/wandb/run-20250125_150626-b1x74fm3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avg_loss_prune-0.7_seeds10
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/california_housing_pruning
wandb: ğŸš€ View run at https://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/b1x74fm3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/mnist/wandb/run-20250125_150626-f3vqlvh6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TTDS_prune0.5_seeds10
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/california_housing_pruning
wandb: ğŸš€ View run at https://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/f3vqlvh6
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/mnist/wandb/run-20250125_150626-vnq4w4x6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TTDS_prune-0.5_seeds10
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/california_housing_pruning
wandb: ğŸš€ View run at https://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/vnq4w4x6
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/mnist/wandb/run-20250125_150626-goqm7639
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TTDS_prune0.9_seeds10
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/california_housing_pruning
wandb: ğŸš€ View run at https://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/goqm7639
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/mnist/wandb/run-20250125_150626-qh44ngwb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TTDS_prune0.7_seeds10
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/california_housing_pruning
wandb: ğŸš€ View run at https://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/qh44ngwb
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/mnist/wandb/run-20250125_150626-a5901bn8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run TTDS_prune-0.7_seeds10
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/california_housing_pruning
wandb: ğŸš€ View run at https://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/a5901bn8
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
start training with Seed 0, pruning rate: 0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 1, pruning rate: 0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 2, pruning rate: 0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 3, pruning rate: 0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 4, pruning rate: 0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 5, pruning rate: 0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 6, pruning rate: 0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 7, pruning rate: 0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 8, pruning rate: 0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 9, pruning rate: 0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
start training with Seed 0, pruning rate: 0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 1, pruning rate: 0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 2, pruning rate: 0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 3, pruning rate: 0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 4, pruning rate: 0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 5, pruning rate: 0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 6, pruning rate: 0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 7, pruning rate: 0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 8, pruning rate: 0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 9, pruning rate: 0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: ğŸš€ View run [33mavg_loss_prune0.7_seeds10[0m at: [34mhttps://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/yjl7i154[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250125_150625-yjl7i154/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
start training with Seed 0, pruning rate: -0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 1, pruning rate: -0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 2, pruning rate: -0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 3, pruning rate: -0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 4, pruning rate: -0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 5, pruning rate: -0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 6, pruning rate: -0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 7, pruning rate: -0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 8, pruning rate: -0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 9, pruning rate: -0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
start training with Seed 0, pruning rate: -0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 1, pruning rate: -0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 2, pruning rate: -0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 3, pruning rate: -0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 4, pruning rate: -0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 5, pruning rate: -0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 6, pruning rate: -0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 7, pruning rate: -0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 8, pruning rate: -0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 9, pruning rate: -0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ğŸš€ View run [33mTTDS_prune0.7_seeds10[0m at: [34mhttps://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/qh44ngwb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250125_150626-qh44ngwb/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ğŸš€ View run [33mTTDS_prune-0.7_seeds10[0m at: [34mhttps://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/a5901bn8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250125_150626-a5901bn8/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
start training with Seed 0, pruning rate: -0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 1, pruning rate: -0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 2, pruning rate: -0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 3, pruning rate: -0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 4, pruning rate: -0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 5, pruning rate: -0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 6, pruning rate: -0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 7, pruning rate: -0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 8, pruning rate: -0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 9, pruning rate: -0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ğŸš€ View run [33mTTDS_prune-0.9_seeds10[0m at: [34mhttps://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/wiwwwtcb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250125_150626-wiwwwtcb/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
start training with Seed 0, pruning rate: 0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 1, pruning rate: 0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 2, pruning rate: 0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 3, pruning rate: 0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 4, pruning rate: 0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 5, pruning rate: 0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 6, pruning rate: 0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 7, pruning rate: 0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 8, pruning rate: 0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 9, pruning rate: 0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ğŸš€ View run [33mavg_loss_prune-0.9_seeds10[0m at: [34mhttps://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/e6x0e4t1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250125_150624-e6x0e4t1/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
start training with Seed 0, pruning rate: -0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 1, pruning rate: -0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 2, pruning rate: -0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 3, pruning rate: -0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 4, pruning rate: -0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 5, pruning rate: -0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 6, pruning rate: -0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 7, pruning rate: -0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 8, pruning rate: -0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
start training with Seed 9, pruning rate: -0.7, len_all_dataset: 60000, len_train_dataset: 18000, removed_dataset: 0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: ğŸš€ View run [33mTTDS_prune0.9_seeds10[0m at: [34mhttps://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/goqm7639[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250125_150626-goqm7639/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
start training with Seed 0, pruning rate: 0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 1, pruning rate: 0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 2, pruning rate: 0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 3, pruning rate: 0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 4, pruning rate: 0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 5, pruning rate: 0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 6, pruning rate: 0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 7, pruning rate: 0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 8, pruning rate: 0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
start training with Seed 9, pruning rate: 0.9, len_all_dataset: 60000, len_train_dataset: 6000, removed_dataset: 0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ğŸš€ View run [33mavg_loss_prune-0.7_seeds10[0m at: [34mhttps://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/b1x74fm3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250125_150626-b1x74fm3/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ğŸš€ View run [33mavg_loss_prune0.9_seeds10[0m at: [34mhttps://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/lqs2yl70[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250125_150623-lqs2yl70/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
start training with Seed 0, pruning rate: -0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 1, pruning rate: -0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 2, pruning rate: -0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 3, pruning rate: -0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 4, pruning rate: -0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 5, pruning rate: -0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 6, pruning rate: -0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 7, pruning rate: -0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 8, pruning rate: -0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 9, pruning rate: -0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: ğŸš€ View run [33mavg_loss_prune-0.3_seeds10[0m at: [34mhttps://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/m23c7bia[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250125_150625-m23c7bia/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
start training with Seed 0, pruning rate: 0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 1, pruning rate: 0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 2, pruning rate: 0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 3, pruning rate: 0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 4, pruning rate: 0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 5, pruning rate: 0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 6, pruning rate: 0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 7, pruning rate: 0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 8, pruning rate: 0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 9, pruning rate: 0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
start training with Seed 0, pruning rate: -0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 1, pruning rate: -0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 2, pruning rate: -0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 3, pruning rate: -0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 4, pruning rate: -0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 5, pruning rate: -0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 6, pruning rate: -0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 7, pruning rate: -0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 8, pruning rate: -0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 9, pruning rate: -0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
start training with Seed 0, pruning rate: 0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 1, pruning rate: 0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 2, pruning rate: 0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 3, pruning rate: 0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 4, pruning rate: 0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 5, pruning rate: 0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 6, pruning rate: 0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 7, pruning rate: 0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 8, pruning rate: 0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
start training with Seed 9, pruning rate: 0.3, len_all_dataset: 60000, len_train_dataset: 42000, removed_dataset: 0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: ğŸš€ View run [33mavg_loss_prune0.3_seeds10[0m at: [34mhttps://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/a6k7h7vc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250125_150623-a6k7h7vc/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ğŸš€ View run [33mTTDS_prune-0.3_seeds10[0m at: [34mhttps://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/ri28k2df[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250125_150625-ri28k2df/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ğŸš€ View run [33mTTDS_prune0.3_seeds10[0m at: [34mhttps://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/v7v6mw3u[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250125_150626-v7v6mw3u/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
start training with Seed 0, pruning rate: -0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 1, pruning rate: -0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 2, pruning rate: -0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 3, pruning rate: -0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 4, pruning rate: -0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 5, pruning rate: -0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 6, pruning rate: -0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 7, pruning rate: -0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 8, pruning rate: -0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 9, pruning rate: -0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
start training with Seed 0, pruning rate: 0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 1, pruning rate: 0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 2, pruning rate: 0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 3, pruning rate: 0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 4, pruning rate: 0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 5, pruning rate: 0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 6, pruning rate: 0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 7, pruning rate: 0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 8, pruning rate: 0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 9, pruning rate: 0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: ğŸš€ View run [33mTTDS_prune-0.5_seeds10[0m at: [34mhttps://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/vnq4w4x6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250125_150626-vnq4w4x6/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ğŸš€ View run [33mavg_loss_prune0.5_seeds10[0m at: [34mhttps://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/s7xvtzlb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250125_150625-s7xvtzlb/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
start training with Seed 0, pruning rate: -0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 1, pruning rate: -0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 2, pruning rate: -0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 3, pruning rate: -0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 4, pruning rate: -0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 5, pruning rate: -0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 6, pruning rate: -0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 7, pruning rate: -0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 8, pruning rate: -0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 9, pruning rate: -0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: ğŸš€ View run [33mavg_loss_prune-0.5_seeds10[0m at: [34mhttps://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/e0py2dus[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250125_150626-e0py2dus/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
start training with Seed 0, pruning rate: 0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 1, pruning rate: 0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 2, pruning rate: 0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 3, pruning rate: 0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 4, pruning rate: 0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 5, pruning rate: 0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 6, pruning rate: 0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 7, pruning rate: 0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 8, pruning rate: 0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
start training with Seed 9, pruning rate: 0.5, len_all_dataset: 60000, len_train_dataset: 30000, removed_dataset: 0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: ğŸš€ View run [33mTTDS_prune0.5_seeds10[0m at: [34mhttps://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/f3vqlvh6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250125_150626-f3vqlvh6/logs[0m
All tasks completed.
