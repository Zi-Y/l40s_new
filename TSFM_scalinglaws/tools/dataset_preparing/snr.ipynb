{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_info_path='./meta_info'\n",
    "snr_info = {\n",
    "    'snr30': {},\n",
    "    'snr20': {},\n",
    "    'snr10': {},\n",
    "    'snr0': {}\n",
    "}\n",
    "\n",
    "def categorize_snr(vn, dataset_info):\n",
    "    categories = {'snr30': [], 'snr20': [], 'snr10': [], 'snr0': []}\n",
    "    for i in range(vn):\n",
    "        snr = dataset_info[f'var{i}']['snr']\n",
    "        if snr >= 30:\n",
    "            categories['snr30'].append(i)\n",
    "        elif snr >= 20:\n",
    "            categories['snr20'].append(i)\n",
    "        elif snr >= 10:\n",
    "            categories['snr10'].append(i)\n",
    "        else:\n",
    "            categories['snr0'].append(i)\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fp in os.listdir(meta_info_path):\n",
    "    name = fp.split('.')[0]\n",
    "    with open(os.path.join(meta_info_path, fp), 'r') as file:\n",
    "        dataset_info = json.load(file)\n",
    "    \n",
    "    vn = dataset_info['variance_num']\n",
    "    categories = categorize_snr(vn, dataset_info)\n",
    "    \n",
    "    for snr_level, indices in categories.items():\n",
    "        if indices:\n",
    "            snr_info[snr_level].update({name: indices})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dicts(dict1, dict2):\n",
    "    merged_dict = {**dict1, **dict2}\n",
    "    for key in set(dict1) & set(dict2):\n",
    "        merged_dict[key] = dict1[key] + dict2[key]\n",
    "    return merged_dict\n",
    "\n",
    "snr_greater_20 = merge_dicts(snr_info['snr20'], snr_info['snr30'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_greater_20 = OrderedDict(sorted(snr_greater_20.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition(k):\n",
    "    if k.startswith('cmip6') or k.startswith('era5'):\n",
    "        if k in ('cmip6_1850', 'cmip6_1855') or k in ('era5_1989', 'era5_1990'):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    if 'missing' in k:\n",
    "        return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOOP_SEATTLE': [0],\n",
       " 'M_DENSE': [0],\n",
       " 'PEMS04': [2],\n",
       " 'PEMS07': [0],\n",
       " 'PEMS08': [0, 2],\n",
       " 'PEMS_BAY': [0],\n",
       " 'Q-TRAFFIC': [0],\n",
       " 'alibaba_cluster_trace_2018': [1],\n",
       " 'australian_electricity_demand': [0],\n",
       " 'bdg-2_bear': [0],\n",
       " 'bdg-2_fox': [0],\n",
       " 'bdg-2_panther': [0],\n",
       " 'beijing_air_quality': [7],\n",
       " 'borg_cluster_data_2011': [1],\n",
       " 'cif_2016_12': [0],\n",
       " 'cif_2016_6': [0],\n",
       " 'cmip6_1850': [11,\n",
       "  13,\n",
       "  14,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38],\n",
       " 'cmip6_1855': [11,\n",
       "  13,\n",
       "  14,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38],\n",
       " 'covid19_energy': [0],\n",
       " 'covid_deaths': [0],\n",
       " 'elecdemand': [0],\n",
       " 'elf': [0],\n",
       " 'era5_1989': [9, 0, 3, 4, 5, 6, 7, 8, 17, 24, 25, 26, 27, 28, 29, 30],\n",
       " 'era5_1990': [9, 0, 3, 4, 5, 6, 7, 8, 17, 24, 25, 26, 27, 28, 29, 30],\n",
       " 'favorita_transactions': [0],\n",
       " 'fred_md': [0],\n",
       " 'gfc14_load': [0],\n",
       " 'gfc17_load': [0],\n",
       " 'godaddy': [0, 1],\n",
       " 'largest_2017': [0],\n",
       " 'largest_2018': [0],\n",
       " 'largest_2019': [0],\n",
       " 'largest_2020': [0],\n",
       " 'largest_2021': [0],\n",
       " 'm1_monthly': [0],\n",
       " 'm1_quarterly': [0],\n",
       " 'm1_yearly': [0],\n",
       " 'm4_daily': [0],\n",
       " 'm4_hourly': [0],\n",
       " 'm4_monthly': [0],\n",
       " 'm4_quarterly': [0],\n",
       " 'm4_weekly': [0],\n",
       " 'm4_yearly': [0],\n",
       " 'monash_m3_monthly': [0],\n",
       " 'monash_m3_other': [0],\n",
       " 'monash_m3_quarterly': [0],\n",
       " 'monash_m3_yearly': [0],\n",
       " 'nn5_weekly': [0],\n",
       " 'pdb': [0],\n",
       " 'sceaux': [0],\n",
       " 'solar_power': [0],\n",
       " 'spain': [0],\n",
       " 'subseasonal': [3],\n",
       " 'tourism_yearly': [0],\n",
       " 'traffic_weekly': [0],\n",
       " 'us_births': [0]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_datasets = {k: v for k, v in snr_greater_20.items() if condition(k)}\n",
    "filtered_datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('filtered_datasets.json', 'w') as f:\n",
    "    json.dump(filtered_datasets, f, separators=(',', ':'), indent=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
