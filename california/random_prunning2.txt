nohup: ignoring input
Running with pruning_rate=0.0 on GPU=0
Running with pruning_rate=0.1 on GPU=1
Running with pruning_rate=0.2 on GPU=2
Running with pruning_rate=0.3 on GPU=3
Running with pruning_rate=0.4 on GPU=0
Running with pruning_rate=0.5 on GPU=1
Running with pruning_rate=0.7 on GPU=2
Running with pruning_rate=0.9 on GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/california/wandb/run-20250123_215206-auto5q20
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/california_housing_pruning
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/auto5q20
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/california/wandb/run-20250123_215208-jp368x1k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/california_housing_pruning
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/jp368x1k
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/california/wandb/run-20250123_215208-5fyw766k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/california_housing_pruning
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/5fyw766k
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/california/wandb/run-20250123_215208-u0vt1fz8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.4_lr0.01_bs1024_dr0.1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/california_housing_pruning
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/u0vt1fz8
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/california/wandb/run-20250123_215209-ow1pivop
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.1_lr0.01_bs1024_dr0.1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/california_housing_pruning
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/ow1pivop
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/california/wandb/run-20250123_215209-t4cbgboz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/california_housing_pruning
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/t4cbgboz
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/california/wandb/run-20250123_215209-wsl91jvj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/california_housing_pruning
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/wsl91jvj
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/california/wandb/run-20250123_215209-f0p1gbul
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.2_lr0.01_bs1024_dr0.1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/california_housing_pruning
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/f0p1gbul
Loading dataset ...
Starting hyperparameter optimization...
[lr=0.01, bs=1024, dr=0.1] -> best_test_loss = 0.257515
Best parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1} with Test Loss: 0.2575152019724099
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/auto5q20[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250123_215206-auto5q20/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
[lr=0.01, bs=1024, dr=0.1] -> best_test_loss = 0.213532
Best parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1} with Test Loss: 0.21353169977265096
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/jp368x1k[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250123_215208-jp368x1k/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
[lr=0.01, bs=1024, dr=0.1] -> best_test_loss = 0.204044
Best parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1} with Test Loss: 0.2040443071825613
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/5fyw766k[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250123_215208-5fyw766k/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
[lr=0.01, bs=1024, dr=0.1] -> best_test_loss = 0.209937
Best parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1} with Test Loss: 0.2099370322155238
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/wsl91jvj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250123_215209-wsl91jvj/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
[lr=0.01, bs=1024, dr=0.1] -> best_test_loss = 0.204571
Best parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1} with Test Loss: 0.20457101854260792
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.4_lr0.01_bs1024_dr0.1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/u0vt1fz8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250123_215208-u0vt1fz8/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
[lr=0.01, bs=1024, dr=0.1] -> best_test_loss = 0.205565
Best parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1} with Test Loss: 0.2055649458820008
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/t4cbgboz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250123_215209-t4cbgboz/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
[lr=0.01, bs=1024, dr=0.1] -> best_test_loss = 0.201759
Best parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1} with Test Loss: 0.20175911452516815
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.1_lr0.01_bs1024_dr0.1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/ow1pivop[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250123_215209-ow1pivop/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
[lr=0.01, bs=1024, dr=0.1] -> best_test_loss = 0.203127
Best parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1} with Test Loss: 0.2031267842985401
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.2_lr0.01_bs1024_dr0.1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/f0p1gbul[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250123_215209-f0p1gbul/logs[0m
All tasks completed.
