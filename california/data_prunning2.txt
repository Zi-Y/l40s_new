nohup: ignoring input
Running with pruning_rate=0.0 on GPU=0
Running with pruning_rate=0.1 on GPU=1
Running with pruning_rate=0.2 on GPU=2
Running with pruning_rate=0.3 on GPU=3
Running with pruning_rate=0.4 on GPU=0
Running with pruning_rate=0.5 on GPU=1
Running with pruning_rate=0.7 on GPU=2
Running with pruning_rate=0.9 on GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/california/wandb/run-20250124_091815-zfdtn1n2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fix_random_prune0.9_lr0.01_bs1024_dr0.1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/california_housing_pruning
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/zfdtn1n2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/california/wandb/run-20250124_091817-pyqswdbb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fix_random_prune0.5_lr0.01_bs1024_dr0.1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/california_housing_pruning
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/pyqswdbb
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/california/wandb/run-20250124_091818-nl07idln
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fix_random_prune0.3_lr0.01_bs1024_dr0.1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/california_housing_pruning
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/nl07idln
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/california/wandb/run-20250124_091818-lcmicmfn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fix_random_prune0.0_lr0.01_bs1024_dr0.1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/california_housing_pruning
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/lcmicmfn
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/california/wandb/run-20250124_091818-vg6j4zql
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fix_random_prune0.1_lr0.01_bs1024_dr0.1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/california_housing_pruning
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/vg6j4zql
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/california/wandb/run-20250124_091818-ifhz6l4n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fix_random_prune0.4_lr0.01_bs1024_dr0.1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/california_housing_pruning
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/ifhz6l4n
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/california/wandb/run-20250124_091818-kx1i1er8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fix_random_prune0.7_lr0.01_bs1024_dr0.1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/california_housing_pruning
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/kx1i1er8
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/california/wandb/run-20250124_091818-uduhjr3u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fix_random_prune0.2_lr0.01_bs1024_dr0.1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/california_housing_pruning
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/uduhjr3u
Loading dataset ...
Starting hyperparameter optimization...
[lr=0.01, bs=1024, dr=0.1] -> best_test_loss = 0.257515
Best parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1} with Test Loss: 0.2575152019724099
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mfix_random_prune0.9_lr0.01_bs1024_dr0.1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/zfdtn1n2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250124_091815-zfdtn1n2/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
[lr=0.01, bs=1024, dr=0.1] -> best_test_loss = 0.213532
Best parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1} with Test Loss: 0.21353169977265096
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mfix_random_prune0.5_lr0.01_bs1024_dr0.1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/pyqswdbb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250124_091817-pyqswdbb/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
[lr=0.01, bs=1024, dr=0.1] -> best_test_loss = 0.204044
Best parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1} with Test Loss: 0.2040443071825613
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mfix_random_prune0.0_lr0.01_bs1024_dr0.1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/lcmicmfn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250124_091818-lcmicmfn/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
[lr=0.01, bs=1024, dr=0.1] -> best_test_loss = 0.205565
Best parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1} with Test Loss: 0.2055649458820008
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mfix_random_prune0.3_lr0.01_bs1024_dr0.1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/nl07idln[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250124_091818-nl07idln/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
[lr=0.01, bs=1024, dr=0.1] -> best_test_loss = 0.204571
Best parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1} with Test Loss: 0.20457101854260792
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mfix_random_prune0.4_lr0.01_bs1024_dr0.1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/ifhz6l4n[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250124_091818-ifhz6l4n/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
[lr=0.01, bs=1024, dr=0.1] -> best_test_loss = 0.201759
Best parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1} with Test Loss: 0.20175911452516815
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mfix_random_prune0.1_lr0.01_bs1024_dr0.1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/vg6j4zql[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250124_091818-vg6j4zql/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
[lr=0.01, bs=1024, dr=0.1] -> best_test_loss = 0.209937
Best parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1} with Test Loss: 0.2099370322155238
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mfix_random_prune0.7_lr0.01_bs1024_dr0.1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/kx1i1er8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250124_091818-kx1i1er8/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
[lr=0.01, bs=1024, dr=0.1] -> best_test_loss = 0.203127
Best parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1} with Test Loss: 0.2031267842985401
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mfix_random_prune0.2_lr0.01_bs1024_dr0.1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/california_housing_pruning/runs/uduhjr3u[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250124_091818-uduhjr3u/logs[0m
All tasks completed.
