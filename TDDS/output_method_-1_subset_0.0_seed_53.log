wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/TDDS/wandb/run-20250203_101753-oc56zx1a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ranodom_pr0.0_resnet18_cifar100_seed53
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/c-class-iterations-full
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/c-class-iterations-full/runs/oc56zx1a
./checkpoint/pruned-dataset
save path : ./checkpoint/pruned-dataset
{'data_path': './data', 'dataset': 'cifar100', 'arch': 'resnet18', 'epochs': 200, 'batch_size': 128, 'learning_rate': 0.1, 'momentum': 0.9, 'decay': 0.0005, 'print_freq': 200, 'save_path': './checkpoint/pruned-dataset', 'evaluate': False, 'subset_rate': 0.0, 'mask_path': './checkpoint/generated_mask/data_mask_win10_ep30.npy', 'score_path': './checkpoint/generated_mask/score_win10_ep30.npy', 'ngpu': 1, 'workers': 2, 'manualSeed': 53, 'pruning_methods': -1, 'use_cuda': True}
Random Seed: 53
python version : 3.12.8 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:31:09) [GCC 11.2.0]
torch  version : 2.5.1
cudnn  version : 90100
Dataset: cifar100
Data Path: ./data
Network: resnet18
Batchsize: 128
Learning Rate: 0.1
Momentum: 0.9
Weight Decay: 0.0005
Loading CIFAR100... Files already downloaded and verified
Files already downloaded and verified
=> creating model 'resnet18'
=> network :
 ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=100, bias=True)
)

==>>[2025-02-03 18:17:55] [Epoch=000/200] [Need: 00:00:00] [learning_rate=0.1000] [Best : Accuracy=0.00, Error=100.00]
  Epoch: [000][000/128]   Time 0.798 (0.798)   Data 0.000 (0.000)   Loss 4.6291 (4.6291)   Prec@1 2.344 (2.344)   Prec@5 10.156 (10.156)   [2025-02-03 18:17:56]
  Epoch: [000][200/128]   Time 0.015 (0.019)   Data 0.000 (0.000)   Loss 3.7144 (4.1189)   Prec@1 9.375 (7.575)   Prec@5 36.719 (25.086)   [2025-02-03 18:17:59]
  **Train** Prec@1 10.408 Prec@5 31.392 Error@1 89.592
  **Test** Prec@1 17.040 Prec@5 43.290 Error@1 82.960
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:18:03] [Epoch=001/200] [Need: 00:24:32] [learning_rate=0.1000] [Best : Accuracy=17.04, Error=82.96]
  Epoch: [001][000/128]   Time 0.118 (0.118)   Data 0.000 (0.000)   Loss 3.4885 (3.4885)   Prec@1 13.281 (13.281)   Prec@5 39.062 (39.062)   [2025-02-03 18:18:03]
  Epoch: [001][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 3.1843 (3.2878)   Prec@1 20.312 (19.450)   Prec@5 55.469 (47.889)   [2025-02-03 18:18:06]
  **Train** Prec@1 21.690 Prec@5 51.066 Error@1 78.310
  **Test** Prec@1 24.470 Prec@5 55.830 Error@1 75.530
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:18:09] [Epoch=002/200] [Need: 00:22:02] [learning_rate=0.1000] [Best : Accuracy=24.47, Error=75.53]
  Epoch: [002][000/128]   Time 0.108 (0.108)   Data 0.000 (0.000)   Loss 2.9050 (2.9050)   Prec@1 27.344 (27.344)   Prec@5 59.375 (59.375)   [2025-02-03 18:18:09]
  Epoch: [002][200/128]   Time 0.014 (0.015)   Data 0.000 (0.000)   Loss 2.6349 (2.7277)   Prec@1 28.906 (29.831)   Prec@5 62.500 (62.080)   [2025-02-03 18:18:12]
  **Train** Prec@1 32.176 Prec@5 65.146 Error@1 67.824
  **Test** Prec@1 36.420 Prec@5 69.880 Error@1 63.580
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:18:15] [Epoch=003/200] [Need: 00:21:39] [learning_rate=0.0999] [Best : Accuracy=36.42, Error=63.58]
  Epoch: [003][000/128]   Time 0.157 (0.157)   Data 0.000 (0.000)   Loss 2.4186 (2.4186)   Prec@1 37.500 (37.500)   Prec@5 68.750 (68.750)   [2025-02-03 18:18:16]
  Epoch: [003][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 2.0683 (2.2260)   Prec@1 40.625 (40.151)   Prec@5 71.094 (73.305)   [2025-02-03 18:18:18]
  **Train** Prec@1 41.598 Prec@5 74.676 Error@1 58.402
  **Test** Prec@1 40.060 Prec@5 74.030 Error@1 59.940
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:18:21] [Epoch=004/200] [Need: 00:21:03] [learning_rate=0.0999] [Best : Accuracy=40.06, Error=59.94]
  Epoch: [004][000/128]   Time 0.110 (0.110)   Data 0.000 (0.000)   Loss 2.0877 (2.0877)   Prec@1 37.500 (37.500)   Prec@5 78.125 (78.125)   [2025-02-03 18:18:21]
  Epoch: [004][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 2.2334 (1.9093)   Prec@1 37.500 (47.423)   Prec@5 75.000 (79.691)   [2025-02-03 18:18:24]
  **Train** Prec@1 48.024 Prec@5 80.236 Error@1 51.976
  **Test** Prec@1 46.850 Prec@5 78.740 Error@1 53.150
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:18:27] [Epoch=005/200] [Need: 00:20:45] [learning_rate=0.0998] [Best : Accuracy=46.85, Error=53.15]
  Epoch: [005][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 1.7059 (1.7059)   Prec@1 59.375 (59.375)   Prec@5 83.594 (83.594)   [2025-02-03 18:18:28]
  Epoch: [005][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 1.7232 (1.7074)   Prec@1 54.688 (52.542)   Prec@5 79.688 (83.353)   [2025-02-03 18:18:30]
  **Train** Prec@1 52.586 Prec@5 83.144 Error@1 47.414
  **Test** Prec@1 49.730 Prec@5 81.050 Error@1 50.270
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:18:34] [Epoch=006/200] [Need: 00:20:33] [learning_rate=0.0998] [Best : Accuracy=49.73, Error=50.27]
  Epoch: [006][000/128]   Time 0.117 (0.117)   Data 0.000 (0.000)   Loss 1.5920 (1.5920)   Prec@1 55.469 (55.469)   Prec@5 85.156 (85.156)   [2025-02-03 18:18:34]
  Epoch: [006][200/128]   Time 0.015 (0.014)   Data 0.000 (0.000)   Loss 1.6254 (1.5875)   Prec@1 57.812 (55.247)   Prec@5 88.281 (85.230)   [2025-02-03 18:18:37]
  **Train** Prec@1 54.924 Prec@5 85.136 Error@1 45.076
  **Test** Prec@1 50.440 Prec@5 80.040 Error@1 49.560
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:18:40] [Epoch=007/200] [Need: 00:20:17] [learning_rate=0.0997] [Best : Accuracy=50.44, Error=49.56]
  Epoch: [007][000/128]   Time 0.127 (0.127)   Data 0.000 (0.000)   Loss 1.1208 (1.1208)   Prec@1 69.531 (69.531)   Prec@5 91.406 (91.406)   [2025-02-03 18:18:40]
  Epoch: [007][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.5611 (1.5016)   Prec@1 53.125 (57.156)   Prec@5 86.719 (86.629)   [2025-02-03 18:18:42]
  **Train** Prec@1 57.094 Prec@5 86.384 Error@1 42.906
  **Test** Prec@1 52.770 Prec@5 83.280 Error@1 47.230
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:18:46] [Epoch=008/200] [Need: 00:20:10] [learning_rate=0.0996] [Best : Accuracy=52.77, Error=47.23]
  Epoch: [008][000/128]   Time 0.119 (0.119)   Data 0.000 (0.000)   Loss 1.3180 (1.3180)   Prec@1 64.062 (64.062)   Prec@5 85.156 (85.156)   [2025-02-03 18:18:46]
  Epoch: [008][200/128]   Time 0.015 (0.013)   Data 0.000 (0.000)   Loss 1.3234 (1.4282)   Prec@1 61.719 (59.336)   Prec@5 89.844 (87.527)   [2025-02-03 18:18:49]
  **Train** Prec@1 58.954 Prec@5 87.312 Error@1 41.046
  **Test** Prec@1 48.350 Prec@5 78.130 Error@1 51.650
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:18:52] [Epoch=009/200] [Need: 00:19:57] [learning_rate=0.0995] [Best : Accuracy=52.77, Error=47.23]
  Epoch: [009][000/128]   Time 0.140 (0.140)   Data 0.000 (0.000)   Loss 1.2441 (1.2441)   Prec@1 64.844 (64.844)   Prec@5 92.969 (92.969)   [2025-02-03 18:18:52]
  Epoch: [009][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 1.3485 (1.3641)   Prec@1 58.594 (61.081)   Prec@5 89.062 (88.433)   [2025-02-03 18:18:55]
  **Train** Prec@1 60.470 Prec@5 88.314 Error@1 39.530
  **Test** Prec@1 51.180 Prec@5 82.060 Error@1 48.820
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:18:58] [Epoch=010/200] [Need: 00:19:45] [learning_rate=0.0994] [Best : Accuracy=52.77, Error=47.23]
  Epoch: [010][000/128]   Time 0.116 (0.116)   Data 0.000 (0.000)   Loss 1.1936 (1.1936)   Prec@1 64.062 (64.062)   Prec@5 92.969 (92.969)   [2025-02-03 18:18:58]
  Epoch: [010][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.3315 (1.3145)   Prec@1 64.062 (62.131)   Prec@5 87.500 (89.226)   [2025-02-03 18:19:01]
  **Train** Prec@1 61.812 Prec@5 88.974 Error@1 38.188
  **Test** Prec@1 52.480 Prec@5 82.750 Error@1 47.520
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:19:04] [Epoch=011/200] [Need: 00:19:37] [learning_rate=0.0993] [Best : Accuracy=52.77, Error=47.23]
  Epoch: [011][000/128]   Time 0.117 (0.117)   Data 0.000 (0.000)   Loss 1.3003 (1.3003)   Prec@1 66.406 (66.406)   Prec@5 89.844 (89.844)   [2025-02-03 18:19:04]
  Epoch: [011][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 1.3321 (1.2963)   Prec@1 67.188 (62.815)   Prec@5 85.938 (89.490)   [2025-02-03 18:19:07]
  **Train** Prec@1 62.468 Prec@5 89.304 Error@1 37.532
  **Test** Prec@1 52.320 Prec@5 81.260 Error@1 47.680
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:19:10] [Epoch=012/200] [Need: 00:19:28] [learning_rate=0.0991] [Best : Accuracy=52.77, Error=47.23]
  Epoch: [012][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 1.1011 (1.1011)   Prec@1 69.531 (69.531)   Prec@5 96.875 (96.875)   [2025-02-03 18:19:10]
  Epoch: [012][200/128]   Time 0.015 (0.013)   Data 0.000 (0.000)   Loss 1.3025 (1.2369)   Prec@1 62.500 (64.517)   Prec@5 89.062 (90.431)   [2025-02-03 18:19:13]
  **Train** Prec@1 63.630 Prec@5 89.942 Error@1 36.370
  **Test** Prec@1 52.970 Prec@5 81.540 Error@1 47.030
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:19:16] [Epoch=013/200] [Need: 00:19:23] [learning_rate=0.0990] [Best : Accuracy=52.97, Error=47.03]
  Epoch: [013][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 1.3988 (1.3988)   Prec@1 56.250 (56.250)   Prec@5 90.625 (90.625)   [2025-02-03 18:19:17]
  Epoch: [013][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.3322 (1.2062)   Prec@1 59.375 (65.108)   Prec@5 89.062 (90.520)   [2025-02-03 18:19:19]
  **Train** Prec@1 64.006 Prec@5 90.272 Error@1 35.994
  **Test** Prec@1 53.400 Prec@5 83.710 Error@1 46.600
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:19:22] [Epoch=014/200] [Need: 00:19:14] [learning_rate=0.0988] [Best : Accuracy=53.40, Error=46.60]
  Epoch: [014][000/128]   Time 0.111 (0.111)   Data 0.000 (0.000)   Loss 1.2459 (1.2459)   Prec@1 60.156 (60.156)   Prec@5 92.969 (92.969)   [2025-02-03 18:19:23]
  Epoch: [014][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 1.1021 (1.1816)   Prec@1 65.625 (65.431)   Prec@5 92.188 (91.181)   [2025-02-03 18:19:25]
  **Train** Prec@1 64.806 Prec@5 90.756 Error@1 35.194
  **Test** Prec@1 55.440 Prec@5 83.350 Error@1 44.560
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:19:29] [Epoch=015/200] [Need: 00:19:06] [learning_rate=0.0986] [Best : Accuracy=55.44, Error=44.56]
  Epoch: [015][000/128]   Time 0.124 (0.124)   Data 0.000 (0.000)   Loss 1.2637 (1.2637)   Prec@1 66.406 (66.406)   Prec@5 90.625 (90.625)   [2025-02-03 18:19:29]
  Epoch: [015][200/128]   Time 0.015 (0.014)   Data 0.000 (0.000)   Loss 1.0129 (1.1493)   Prec@1 71.094 (66.569)   Prec@5 89.062 (91.682)   [2025-02-03 18:19:31]
  **Train** Prec@1 65.636 Prec@5 91.028 Error@1 34.364
  **Test** Prec@1 55.740 Prec@5 84.120 Error@1 44.260
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:19:35] [Epoch=016/200] [Need: 00:19:02] [learning_rate=0.0984] [Best : Accuracy=55.74, Error=44.26]
  Epoch: [016][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 1.2560 (1.2560)   Prec@1 66.406 (66.406)   Prec@5 89.844 (89.844)   [2025-02-03 18:19:35]
  Epoch: [016][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.1633 (1.1390)   Prec@1 68.750 (66.671)   Prec@5 86.719 (91.923)   [2025-02-03 18:19:38]
  **Train** Prec@1 66.062 Prec@5 91.386 Error@1 33.938
  **Test** Prec@1 54.840 Prec@5 83.940 Error@1 45.160
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:19:41] [Epoch=017/200] [Need: 00:18:54] [learning_rate=0.0982] [Best : Accuracy=55.74, Error=44.26]
  Epoch: [017][000/128]   Time 0.119 (0.119)   Data 0.000 (0.000)   Loss 1.2482 (1.2482)   Prec@1 64.062 (64.062)   Prec@5 90.625 (90.625)   [2025-02-03 18:19:41]
  Epoch: [017][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 1.1580 (1.1015)   Prec@1 69.531 (67.833)   Prec@5 91.406 (92.086)   [2025-02-03 18:19:44]
  **Train** Prec@1 66.700 Prec@5 91.512 Error@1 33.300
  **Test** Prec@1 54.680 Prec@5 83.850 Error@1 45.320
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:19:47] [Epoch=018/200] [Need: 00:18:48] [learning_rate=0.0980] [Best : Accuracy=55.74, Error=44.26]
  Epoch: [018][000/128]   Time 0.145 (0.145)   Data 0.000 (0.000)   Loss 1.1452 (1.1452)   Prec@1 68.750 (68.750)   Prec@5 92.188 (92.188)   [2025-02-03 18:19:47]
  Epoch: [018][200/128]   Time 0.011 (0.014)   Data 0.000 (0.000)   Loss 1.2256 (1.1131)   Prec@1 67.969 (67.634)   Prec@5 90.625 (92.145)   [2025-02-03 18:19:50]
  **Train** Prec@1 67.180 Prec@5 91.828 Error@1 32.820
  **Test** Prec@1 55.820 Prec@5 84.120 Error@1 44.180
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:19:53] [Epoch=019/200] [Need: 00:18:40] [learning_rate=0.0978] [Best : Accuracy=55.82, Error=44.18]
  Epoch: [019][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 1.0812 (1.0812)   Prec@1 76.562 (76.562)   Prec@5 92.969 (92.969)   [2025-02-03 18:19:53]
  Epoch: [019][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.8547 (1.0963)   Prec@1 73.438 (68.043)   Prec@5 96.875 (92.234)   [2025-02-03 18:19:56]
  **Train** Prec@1 67.514 Prec@5 92.036 Error@1 32.486
  **Test** Prec@1 57.830 Prec@5 86.050 Error@1 42.170
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:19:59] [Epoch=020/200] [Need: 00:18:33] [learning_rate=0.0976] [Best : Accuracy=57.83, Error=42.17]
  Epoch: [020][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.8418 (0.8418)   Prec@1 75.000 (75.000)   Prec@5 96.875 (96.875)   [2025-02-03 18:19:59]
  Epoch: [020][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.1781 (1.0713)   Prec@1 68.750 (68.633)   Prec@5 89.844 (92.631)   [2025-02-03 18:20:02]
  **Train** Prec@1 67.726 Prec@5 92.332 Error@1 32.274
  **Test** Prec@1 53.720 Prec@5 83.290 Error@1 46.280
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:20:05] [Epoch=021/200] [Need: 00:18:26] [learning_rate=0.0973] [Best : Accuracy=57.83, Error=42.17]
  Epoch: [021][000/128]   Time 0.116 (0.116)   Data 0.000 (0.000)   Loss 0.9326 (0.9326)   Prec@1 72.656 (72.656)   Prec@5 94.531 (94.531)   [2025-02-03 18:20:06]
  Epoch: [021][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.9108 (1.0540)   Prec@1 73.438 (68.719)   Prec@5 94.531 (92.879)   [2025-02-03 18:20:08]
  **Train** Prec@1 67.802 Prec@5 92.294 Error@1 32.198
  **Test** Prec@1 56.560 Prec@5 84.260 Error@1 43.440
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:20:12] [Epoch=022/200] [Need: 00:18:20] [learning_rate=0.0970] [Best : Accuracy=57.83, Error=42.17]
  Epoch: [022][000/128]   Time 0.131 (0.131)   Data 0.000 (0.000)   Loss 0.8622 (0.8622)   Prec@1 76.562 (76.562)   Prec@5 96.094 (96.094)   [2025-02-03 18:20:12]
  Epoch: [022][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.2384 (1.0402)   Prec@1 60.156 (69.570)   Prec@5 90.625 (93.206)   [2025-02-03 18:20:14]
  **Train** Prec@1 68.492 Prec@5 92.586 Error@1 31.508
  **Test** Prec@1 59.630 Prec@5 86.910 Error@1 40.370
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:20:18] [Epoch=023/200] [Need: 00:18:13] [learning_rate=0.0968] [Best : Accuracy=59.63, Error=40.37]
  Epoch: [023][000/128]   Time 0.129 (0.129)   Data 0.000 (0.000)   Loss 0.9074 (0.9074)   Prec@1 74.219 (74.219)   Prec@5 94.531 (94.531)   [2025-02-03 18:20:18]
  Epoch: [023][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.3436 (1.0257)   Prec@1 60.938 (69.978)   Prec@5 90.625 (92.984)   [2025-02-03 18:20:21]
  **Train** Prec@1 68.836 Prec@5 92.666 Error@1 31.164
  **Test** Prec@1 55.640 Prec@5 84.440 Error@1 44.360
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:20:24] [Epoch=024/200] [Need: 00:18:07] [learning_rate=0.0965] [Best : Accuracy=59.63, Error=40.37]
  Epoch: [024][000/128]   Time 0.137 (0.137)   Data 0.000 (0.000)   Loss 1.0372 (1.0372)   Prec@1 67.188 (67.188)   Prec@5 93.750 (93.750)   [2025-02-03 18:20:24]
  Epoch: [024][200/128]   Time 0.012 (0.013)   Data 0.000 (0.000)   Loss 1.0406 (1.0006)   Prec@1 71.094 (70.274)   Prec@5 91.406 (93.637)   [2025-02-03 18:20:26]
  **Train** Prec@1 69.176 Prec@5 92.856 Error@1 30.824
  **Test** Prec@1 58.130 Prec@5 85.820 Error@1 41.870
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:20:30] [Epoch=025/200] [Need: 00:17:58] [learning_rate=0.0962] [Best : Accuracy=59.63, Error=40.37]
  Epoch: [025][000/128]   Time 0.130 (0.130)   Data 0.000 (0.000)   Loss 0.8778 (0.8778)   Prec@1 76.562 (76.562)   Prec@5 93.750 (93.750)   [2025-02-03 18:20:30]
  Epoch: [025][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 1.1973 (1.0058)   Prec@1 65.625 (70.425)   Prec@5 92.969 (93.462)   [2025-02-03 18:20:32]
  **Train** Prec@1 69.396 Prec@5 92.892 Error@1 30.604
  **Test** Prec@1 60.220 Prec@5 87.160 Error@1 39.780
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:20:36] [Epoch=026/200] [Need: 00:17:51] [learning_rate=0.0959] [Best : Accuracy=60.22, Error=39.78]
  Epoch: [026][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.7937 (0.7937)   Prec@1 78.125 (78.125)   Prec@5 95.312 (95.312)   [2025-02-03 18:20:36]
  Epoch: [026][200/128]   Time 0.012 (0.013)   Data 0.000 (0.000)   Loss 0.9231 (1.0041)   Prec@1 71.875 (70.118)   Prec@5 96.875 (93.591)   [2025-02-03 18:20:38]
  **Train** Prec@1 69.232 Prec@5 93.184 Error@1 30.768
  **Test** Prec@1 60.020 Prec@5 87.110 Error@1 39.980
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:20:42] [Epoch=027/200] [Need: 00:17:43] [learning_rate=0.0956] [Best : Accuracy=60.22, Error=39.78]
  Epoch: [027][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 1.0110 (1.0110)   Prec@1 68.750 (68.750)   Prec@5 92.188 (92.188)   [2025-02-03 18:20:42]
  Epoch: [027][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.1760 (0.9972)   Prec@1 68.750 (70.892)   Prec@5 87.500 (93.478)   [2025-02-03 18:20:44]
  **Train** Prec@1 69.932 Prec@5 93.160 Error@1 30.068
  **Test** Prec@1 57.290 Prec@5 85.220 Error@1 42.710
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:20:48] [Epoch=028/200] [Need: 00:17:37] [learning_rate=0.0952] [Best : Accuracy=60.22, Error=39.78]
  Epoch: [028][000/128]   Time 0.139 (0.139)   Data 0.000 (0.000)   Loss 1.0277 (1.0277)   Prec@1 66.406 (66.406)   Prec@5 94.531 (94.531)   [2025-02-03 18:20:48]
  Epoch: [028][200/128]   Time 0.014 (0.015)   Data 0.000 (0.000)   Loss 1.0241 (0.9658)   Prec@1 70.312 (71.482)   Prec@5 93.750 (93.940)   [2025-02-03 18:20:51]
  **Train** Prec@1 70.446 Prec@5 93.426 Error@1 29.554
  **Test** Prec@1 58.400 Prec@5 85.740 Error@1 41.600
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:20:54] [Epoch=029/200] [Need: 00:17:33] [learning_rate=0.0949] [Best : Accuracy=60.22, Error=39.78]
  Epoch: [029][000/128]   Time 0.127 (0.127)   Data 0.000 (0.000)   Loss 0.9134 (0.9134)   Prec@1 77.344 (77.344)   Prec@5 91.406 (91.406)   [2025-02-03 18:20:54]
  Epoch: [029][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.9334 (0.9625)   Prec@1 69.531 (71.626)   Prec@5 95.312 (93.952)   [2025-02-03 18:20:57]
  **Train** Prec@1 70.298 Prec@5 93.300 Error@1 29.702
  **Test** Prec@1 60.250 Prec@5 87.330 Error@1 39.750
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:21:00] [Epoch=030/200] [Need: 00:17:27] [learning_rate=0.0946] [Best : Accuracy=60.25, Error=39.75]
  Epoch: [030][000/128]   Time 0.133 (0.133)   Data 0.000 (0.000)   Loss 0.8259 (0.8259)   Prec@1 73.438 (73.438)   Prec@5 97.656 (97.656)   [2025-02-03 18:21:01]
  Epoch: [030][200/128]   Time 0.014 (0.016)   Data 0.000 (0.000)   Loss 0.8989 (0.9624)   Prec@1 71.875 (71.580)   Prec@5 95.312 (94.053)   [2025-02-03 18:21:04]
  **Train** Prec@1 70.520 Prec@5 93.472 Error@1 29.480
  **Test** Prec@1 58.060 Prec@5 86.130 Error@1 41.940
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:21:07] [Epoch=031/200] [Need: 00:17:24] [learning_rate=0.0942] [Best : Accuracy=60.25, Error=39.75]
  Epoch: [031][000/128]   Time 0.125 (0.125)   Data 0.000 (0.000)   Loss 0.7485 (0.7485)   Prec@1 75.781 (75.781)   Prec@5 97.656 (97.656)   [2025-02-03 18:21:08]
  Epoch: [031][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.7100 (0.9386)   Prec@1 73.438 (72.330)   Prec@5 96.875 (94.282)   [2025-02-03 18:21:10]
  **Train** Prec@1 71.098 Prec@5 93.786 Error@1 28.902
  **Test** Prec@1 55.460 Prec@5 83.830 Error@1 44.540
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:21:13] [Epoch=032/200] [Need: 00:17:19] [learning_rate=0.0938] [Best : Accuracy=60.25, Error=39.75]
  Epoch: [032][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.7366 (0.7366)   Prec@1 75.781 (75.781)   Prec@5 95.312 (95.312)   [2025-02-03 18:21:14]
  Epoch: [032][200/128]   Time 0.015 (0.014)   Data 0.000 (0.000)   Loss 1.0742 (0.9484)   Prec@1 68.750 (72.065)   Prec@5 93.750 (94.053)   [2025-02-03 18:21:16]
  **Train** Prec@1 71.052 Prec@5 93.700 Error@1 28.948
  **Test** Prec@1 58.090 Prec@5 84.990 Error@1 41.910
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:21:20] [Epoch=033/200] [Need: 00:17:12] [learning_rate=0.0934] [Best : Accuracy=60.25, Error=39.75]
  Epoch: [033][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 0.9770 (0.9770)   Prec@1 70.312 (70.312)   Prec@5 94.531 (94.531)   [2025-02-03 18:21:20]
  Epoch: [033][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.0885 (0.9439)   Prec@1 66.406 (71.945)   Prec@5 89.844 (94.100)   [2025-02-03 18:21:22]
  **Train** Prec@1 71.062 Prec@5 93.748 Error@1 28.938
  **Test** Prec@1 57.850 Prec@5 84.720 Error@1 42.150
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:21:26] [Epoch=034/200] [Need: 00:17:05] [learning_rate=0.0930] [Best : Accuracy=60.25, Error=39.75]
  Epoch: [034][000/128]   Time 0.138 (0.138)   Data 0.000 (0.000)   Loss 0.7830 (0.7830)   Prec@1 75.781 (75.781)   Prec@5 94.531 (94.531)   [2025-02-03 18:21:26]
  Epoch: [034][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.1885 (0.9351)   Prec@1 64.062 (72.338)   Prec@5 92.969 (94.096)   [2025-02-03 18:21:29]
  **Train** Prec@1 71.504 Prec@5 93.812 Error@1 28.496
  **Test** Prec@1 57.260 Prec@5 85.180 Error@1 42.740
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:21:32] [Epoch=035/200] [Need: 00:16:59] [learning_rate=0.0926] [Best : Accuracy=60.25, Error=39.75]
  Epoch: [035][000/128]   Time 0.124 (0.124)   Data 0.000 (0.000)   Loss 0.8860 (0.8860)   Prec@1 71.094 (71.094)   Prec@5 94.531 (94.531)   [2025-02-03 18:21:32]
  Epoch: [035][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.8706 (0.9151)   Prec@1 70.312 (72.905)   Prec@5 97.656 (94.691)   [2025-02-03 18:21:34]
  **Train** Prec@1 71.686 Prec@5 94.096 Error@1 28.314
  **Test** Prec@1 57.340 Prec@5 84.750 Error@1 42.660
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:21:38] [Epoch=036/200] [Need: 00:16:52] [learning_rate=0.0922] [Best : Accuracy=60.25, Error=39.75]
  Epoch: [036][000/128]   Time 0.132 (0.132)   Data 0.000 (0.000)   Loss 0.9531 (0.9531)   Prec@1 74.219 (74.219)   Prec@5 94.531 (94.531)   [2025-02-03 18:21:38]
  Epoch: [036][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.9116 (0.9192)   Prec@1 72.656 (72.633)   Prec@5 93.750 (94.500)   [2025-02-03 18:21:41]
  **Train** Prec@1 71.624 Prec@5 93.970 Error@1 28.376
  **Test** Prec@1 58.520 Prec@5 86.070 Error@1 41.480
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:21:44] [Epoch=037/200] [Need: 00:16:46] [learning_rate=0.0918] [Best : Accuracy=60.25, Error=39.75]
  Epoch: [037][000/128]   Time 0.125 (0.125)   Data 0.000 (0.000)   Loss 1.0540 (1.0540)   Prec@1 64.844 (64.844)   Prec@5 92.188 (92.188)   [2025-02-03 18:21:44]
  Epoch: [037][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 1.2675 (0.9044)   Prec@1 65.625 (73.084)   Prec@5 93.750 (94.450)   [2025-02-03 18:21:47]
  **Train** Prec@1 71.956 Prec@5 94.038 Error@1 28.044
  **Test** Prec@1 59.010 Prec@5 86.550 Error@1 40.990
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:21:50] [Epoch=038/200] [Need: 00:16:40] [learning_rate=0.0914] [Best : Accuracy=60.25, Error=39.75]
  Epoch: [038][000/128]   Time 0.147 (0.147)   Data 0.000 (0.000)   Loss 0.9370 (0.9370)   Prec@1 67.969 (67.969)   Prec@5 92.969 (92.969)   [2025-02-03 18:21:50]
  Epoch: [038][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.9236 (0.9212)   Prec@1 74.219 (72.427)   Prec@5 92.188 (94.368)   [2025-02-03 18:21:53]
  **Train** Prec@1 71.834 Prec@5 94.054 Error@1 28.166
  **Test** Prec@1 59.150 Prec@5 86.780 Error@1 40.850
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:21:56] [Epoch=039/200] [Need: 00:16:34] [learning_rate=0.0909] [Best : Accuracy=60.25, Error=39.75]
  Epoch: [039][000/128]   Time 0.118 (0.118)   Data 0.000 (0.000)   Loss 0.8517 (0.8517)   Prec@1 76.562 (76.562)   Prec@5 92.969 (92.969)   [2025-02-03 18:21:57]
  Epoch: [039][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.8011 (0.8883)   Prec@1 77.344 (73.675)   Prec@5 94.531 (94.807)   [2025-02-03 18:21:59]
  **Train** Prec@1 72.192 Prec@5 94.234 Error@1 27.808
  **Test** Prec@1 60.900 Prec@5 87.360 Error@1 39.100
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:22:03] [Epoch=040/200] [Need: 00:16:27] [learning_rate=0.0905] [Best : Accuracy=60.90, Error=39.10]
  Epoch: [040][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.8669 (0.8669)   Prec@1 75.781 (75.781)   Prec@5 96.094 (96.094)   [2025-02-03 18:22:03]
  Epoch: [040][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.9815 (0.8918)   Prec@1 71.094 (73.368)   Prec@5 92.969 (94.780)   [2025-02-03 18:22:05]
  **Train** Prec@1 72.406 Prec@5 94.356 Error@1 27.594
  **Test** Prec@1 60.690 Prec@5 85.780 Error@1 39.310
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:22:09] [Epoch=041/200] [Need: 00:16:22] [learning_rate=0.0900] [Best : Accuracy=60.90, Error=39.10]
  Epoch: [041][000/128]   Time 0.131 (0.131)   Data 0.000 (0.000)   Loss 0.7068 (0.7068)   Prec@1 78.125 (78.125)   Prec@5 96.094 (96.094)   [2025-02-03 18:22:09]
  Epoch: [041][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.0010 (0.8670)   Prec@1 75.781 (74.413)   Prec@5 96.094 (95.021)   [2025-02-03 18:22:12]
  **Train** Prec@1 73.104 Prec@5 94.526 Error@1 26.896
  **Test** Prec@1 62.630 Prec@5 87.820 Error@1 37.370
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:22:15] [Epoch=042/200] [Need: 00:16:15] [learning_rate=0.0895] [Best : Accuracy=62.63, Error=37.37]
  Epoch: [042][000/128]   Time 0.127 (0.127)   Data 0.000 (0.000)   Loss 0.9026 (0.9026)   Prec@1 77.344 (77.344)   Prec@5 94.531 (94.531)   [2025-02-03 18:22:15]
  Epoch: [042][200/128]   Time 0.015 (0.015)   Data 0.000 (0.000)   Loss 1.0027 (0.8729)   Prec@1 67.188 (74.129)   Prec@5 96.875 (95.017)   [2025-02-03 18:22:18]
  **Train** Prec@1 72.992 Prec@5 94.558 Error@1 27.008
  **Test** Prec@1 61.000 Prec@5 87.220 Error@1 39.000
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:22:21] [Epoch=043/200] [Need: 00:16:10] [learning_rate=0.0890] [Best : Accuracy=62.63, Error=37.37]
  Epoch: [043][000/128]   Time 0.136 (0.136)   Data 0.000 (0.000)   Loss 0.8795 (0.8795)   Prec@1 72.656 (72.656)   Prec@5 94.531 (94.531)   [2025-02-03 18:22:22]
  Epoch: [043][200/128]   Time 0.012 (0.014)   Data 0.000 (0.000)   Loss 0.9571 (0.8612)   Prec@1 71.094 (74.658)   Prec@5 96.094 (95.114)   [2025-02-03 18:22:24]
  **Train** Prec@1 73.250 Prec@5 94.406 Error@1 26.750
  **Test** Prec@1 59.860 Prec@5 86.340 Error@1 40.140
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:22:27] [Epoch=044/200] [Need: 00:16:03] [learning_rate=0.0885] [Best : Accuracy=62.63, Error=37.37]
  Epoch: [044][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.7582 (0.7582)   Prec@1 73.438 (73.438)   Prec@5 95.312 (95.312)   [2025-02-03 18:22:28]
  Epoch: [044][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.7341 (0.8603)   Prec@1 75.000 (74.265)   Prec@5 96.875 (95.099)   [2025-02-03 18:22:30]
  **Train** Prec@1 73.234 Prec@5 94.756 Error@1 26.766
  **Test** Prec@1 59.560 Prec@5 86.790 Error@1 40.440
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:22:33] [Epoch=045/200] [Need: 00:15:56] [learning_rate=0.0880] [Best : Accuracy=62.63, Error=37.37]
  Epoch: [045][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.9140 (0.9140)   Prec@1 74.219 (74.219)   Prec@5 94.531 (94.531)   [2025-02-03 18:22:33]
  Epoch: [045][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.1086 (0.8607)   Prec@1 67.188 (73.939)   Prec@5 90.625 (95.091)   [2025-02-03 18:22:36]
  **Train** Prec@1 72.796 Prec@5 94.544 Error@1 27.204
  **Test** Prec@1 59.550 Prec@5 85.760 Error@1 40.450
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:22:39] [Epoch=046/200] [Need: 00:15:49] [learning_rate=0.0875] [Best : Accuracy=62.63, Error=37.37]
  Epoch: [046][000/128]   Time 0.119 (0.119)   Data 0.000 (0.000)   Loss 0.7695 (0.7695)   Prec@1 79.688 (79.688)   Prec@5 93.750 (93.750)   [2025-02-03 18:22:39]
  Epoch: [046][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.9553 (0.8425)   Prec@1 73.438 (74.829)   Prec@5 96.094 (95.468)   [2025-02-03 18:22:42]
  **Train** Prec@1 73.738 Prec@5 94.928 Error@1 26.262
  **Test** Prec@1 59.430 Prec@5 86.880 Error@1 40.570
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:22:46] [Epoch=047/200] [Need: 00:15:44] [learning_rate=0.0870] [Best : Accuracy=62.63, Error=37.37]
  Epoch: [047][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.9078 (0.9078)   Prec@1 75.781 (75.781)   Prec@5 95.312 (95.312)   [2025-02-03 18:22:46]
  Epoch: [047][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.8733 (0.8446)   Prec@1 74.219 (74.600)   Prec@5 93.750 (95.452)   [2025-02-03 18:22:49]
  **Train** Prec@1 73.432 Prec@5 94.958 Error@1 26.568
  **Test** Prec@1 60.980 Prec@5 87.760 Error@1 39.020
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:22:52] [Epoch=048/200] [Need: 00:15:38] [learning_rate=0.0864] [Best : Accuracy=62.63, Error=37.37]
  Epoch: [048][000/128]   Time 0.128 (0.128)   Data 0.000 (0.000)   Loss 0.8380 (0.8380)   Prec@1 75.000 (75.000)   Prec@5 95.312 (95.312)   [2025-02-03 18:22:52]
  Epoch: [048][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.9584 (0.8250)   Prec@1 69.531 (75.288)   Prec@5 95.312 (95.519)   [2025-02-03 18:22:55]
  **Train** Prec@1 73.832 Prec@5 94.942 Error@1 26.168
  **Test** Prec@1 58.060 Prec@5 85.050 Error@1 41.940
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:22:58] [Epoch=049/200] [Need: 00:15:32] [learning_rate=0.0859] [Best : Accuracy=62.63, Error=37.37]
  Epoch: [049][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.7957 (0.7957)   Prec@1 77.344 (77.344)   Prec@5 96.094 (96.094)   [2025-02-03 18:22:58]
  Epoch: [049][200/128]   Time 0.012 (0.014)   Data 0.000 (0.000)   Loss 0.7881 (0.8459)   Prec@1 75.000 (74.813)   Prec@5 97.656 (95.421)   [2025-02-03 18:23:01]
  **Train** Prec@1 73.912 Prec@5 95.072 Error@1 26.088
  **Test** Prec@1 59.370 Prec@5 86.290 Error@1 40.630
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:23:04] [Epoch=050/200] [Need: 00:15:26] [learning_rate=0.0854] [Best : Accuracy=62.63, Error=37.37]
  Epoch: [050][000/128]   Time 0.116 (0.116)   Data 0.000 (0.000)   Loss 0.7011 (0.7011)   Prec@1 77.344 (77.344)   Prec@5 96.094 (96.094)   [2025-02-03 18:23:04]
  Epoch: [050][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.0037 (0.8085)   Prec@1 67.188 (76.100)   Prec@5 94.531 (95.616)   [2025-02-03 18:23:07]
  **Train** Prec@1 74.578 Prec@5 95.180 Error@1 25.422
  **Test** Prec@1 60.980 Prec@5 86.690 Error@1 39.020
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:23:10] [Epoch=051/200] [Need: 00:15:19] [learning_rate=0.0848] [Best : Accuracy=62.63, Error=37.37]
  Epoch: [051][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.8895 (0.8895)   Prec@1 72.656 (72.656)   Prec@5 94.531 (94.531)   [2025-02-03 18:23:10]
  Epoch: [051][200/128]   Time 0.012 (0.014)   Data 0.000 (0.000)   Loss 0.9518 (0.8165)   Prec@1 69.531 (75.377)   Prec@5 96.094 (95.682)   [2025-02-03 18:23:13]
  **Train** Prec@1 74.320 Prec@5 95.114 Error@1 25.680
  **Test** Prec@1 61.970 Prec@5 87.870 Error@1 38.030
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:23:16] [Epoch=052/200] [Need: 00:15:12] [learning_rate=0.0842] [Best : Accuracy=62.63, Error=37.37]
  Epoch: [052][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.8371 (0.8371)   Prec@1 77.344 (77.344)   Prec@5 96.094 (96.094)   [2025-02-03 18:23:16]
  Epoch: [052][200/128]   Time 0.012 (0.013)   Data 0.000 (0.000)   Loss 0.6477 (0.8013)   Prec@1 82.812 (76.131)   Prec@5 96.875 (95.736)   [2025-02-03 18:23:19]
  **Train** Prec@1 74.780 Prec@5 95.290 Error@1 25.220
  **Test** Prec@1 61.610 Prec@5 87.840 Error@1 38.390
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:23:22] [Epoch=053/200] [Need: 00:15:05] [learning_rate=0.0837] [Best : Accuracy=62.63, Error=37.37]
  Epoch: [053][000/128]   Time 0.118 (0.118)   Data 0.000 (0.000)   Loss 0.8814 (0.8814)   Prec@1 71.094 (71.094)   Prec@5 95.312 (95.312)   [2025-02-03 18:23:22]
  Epoch: [053][200/128]   Time 0.012 (0.014)   Data 0.000 (0.000)   Loss 0.7685 (0.8005)   Prec@1 72.656 (76.061)   Prec@5 97.656 (95.802)   [2025-02-03 18:23:25]
  **Train** Prec@1 74.748 Prec@5 95.260 Error@1 25.252
  **Test** Prec@1 60.510 Prec@5 87.010 Error@1 39.490
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:23:28] [Epoch=054/200] [Need: 00:14:59] [learning_rate=0.0831] [Best : Accuracy=62.63, Error=37.37]
  Epoch: [054][000/128]   Time 0.119 (0.119)   Data 0.000 (0.000)   Loss 0.7495 (0.7495)   Prec@1 81.250 (81.250)   Prec@5 96.875 (96.875)   [2025-02-03 18:23:28]
  Epoch: [054][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.8225 (0.8196)   Prec@1 76.562 (75.610)   Prec@5 96.094 (95.616)   [2025-02-03 18:23:31]
  **Train** Prec@1 74.796 Prec@5 95.334 Error@1 25.204
  **Test** Prec@1 58.940 Prec@5 86.210 Error@1 41.060
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:23:34] [Epoch=055/200] [Need: 00:14:52] [learning_rate=0.0825] [Best : Accuracy=62.63, Error=37.37]
  Epoch: [055][000/128]   Time 0.108 (0.108)   Data 0.000 (0.000)   Loss 0.8649 (0.8649)   Prec@1 73.438 (73.438)   Prec@5 96.875 (96.875)   [2025-02-03 18:23:34]
  Epoch: [055][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.8498 (0.7932)   Prec@1 75.000 (76.434)   Prec@5 94.531 (95.950)   [2025-02-03 18:23:37]
  **Train** Prec@1 74.974 Prec@5 95.432 Error@1 25.026
  **Test** Prec@1 60.990 Prec@5 86.950 Error@1 39.010
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:23:40] [Epoch=056/200] [Need: 00:14:46] [learning_rate=0.0819] [Best : Accuracy=62.63, Error=37.37]
  Epoch: [056][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.8401 (0.8401)   Prec@1 72.656 (72.656)   Prec@5 95.312 (95.312)   [2025-02-03 18:23:40]
  Epoch: [056][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.7756 (0.7889)   Prec@1 81.250 (76.275)   Prec@5 93.750 (96.051)   [2025-02-03 18:23:43]
  **Train** Prec@1 75.120 Prec@5 95.488 Error@1 24.880
  **Test** Prec@1 59.910 Prec@5 86.230 Error@1 40.090
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:23:46] [Epoch=057/200] [Need: 00:14:39] [learning_rate=0.0813] [Best : Accuracy=62.63, Error=37.37]
  Epoch: [057][000/128]   Time 0.113 (0.113)   Data 0.000 (0.000)   Loss 0.7540 (0.7540)   Prec@1 82.812 (82.812)   Prec@5 98.438 (98.438)   [2025-02-03 18:23:46]
  Epoch: [057][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.6765 (0.7801)   Prec@1 80.469 (76.726)   Prec@5 96.875 (96.086)   [2025-02-03 18:23:49]
  **Train** Prec@1 75.722 Prec@5 95.670 Error@1 24.278
  **Test** Prec@1 61.320 Prec@5 86.640 Error@1 38.680
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:23:52] [Epoch=058/200] [Need: 00:14:33] [learning_rate=0.0806] [Best : Accuracy=62.63, Error=37.37]
  Epoch: [058][000/128]   Time 0.117 (0.117)   Data 0.000 (0.000)   Loss 0.5663 (0.5663)   Prec@1 85.938 (85.938)   Prec@5 97.656 (97.656)   [2025-02-03 18:23:52]
  Epoch: [058][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 0.8421 (0.7685)   Prec@1 71.875 (76.870)   Prec@5 97.656 (96.117)   [2025-02-03 18:23:55]
  **Train** Prec@1 75.558 Prec@5 95.618 Error@1 24.442
  **Test** Prec@1 59.920 Prec@5 87.250 Error@1 40.080
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:23:58] [Epoch=059/200] [Need: 00:14:27] [learning_rate=0.0800] [Best : Accuracy=62.63, Error=37.37]
  Epoch: [059][000/128]   Time 0.127 (0.127)   Data 0.000 (0.000)   Loss 0.8168 (0.8168)   Prec@1 72.656 (72.656)   Prec@5 96.094 (96.094)   [2025-02-03 18:23:59]
  Epoch: [059][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.7696 (0.7637)   Prec@1 75.781 (77.184)   Prec@5 96.875 (96.269)   [2025-02-03 18:24:02]
  **Train** Prec@1 75.828 Prec@5 95.752 Error@1 24.172
  **Test** Prec@1 57.450 Prec@5 85.930 Error@1 42.550
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:24:05] [Epoch=060/200] [Need: 00:14:21] [learning_rate=0.0794] [Best : Accuracy=62.63, Error=37.37]
  Epoch: [060][000/128]   Time 0.146 (0.146)   Data 0.000 (0.000)   Loss 0.5961 (0.5961)   Prec@1 81.250 (81.250)   Prec@5 99.219 (99.219)   [2025-02-03 18:24:05]
  Epoch: [060][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.7744 (0.7638)   Prec@1 78.906 (76.912)   Prec@5 96.094 (96.113)   [2025-02-03 18:24:08]
  **Train** Prec@1 75.792 Prec@5 95.736 Error@1 24.208
  **Test** Prec@1 63.070 Prec@5 88.010 Error@1 36.930
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:24:11] [Epoch=061/200] [Need: 00:14:15] [learning_rate=0.0788] [Best : Accuracy=63.07, Error=36.93]
  Epoch: [061][000/128]   Time 0.118 (0.118)   Data 0.000 (0.000)   Loss 0.6678 (0.6678)   Prec@1 80.469 (80.469)   Prec@5 96.875 (96.875)   [2025-02-03 18:24:11]
  Epoch: [061][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.8075 (0.7474)   Prec@1 77.344 (77.515)   Prec@5 95.312 (96.346)   [2025-02-03 18:24:14]
  **Train** Prec@1 76.168 Prec@5 95.938 Error@1 23.832
  **Test** Prec@1 59.500 Prec@5 85.980 Error@1 40.500
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:24:17] [Epoch=062/200] [Need: 00:14:09] [learning_rate=0.0781] [Best : Accuracy=63.07, Error=36.93]
  Epoch: [062][000/128]   Time 0.116 (0.116)   Data 0.000 (0.000)   Loss 0.8658 (0.8658)   Prec@1 74.219 (74.219)   Prec@5 95.312 (95.312)   [2025-02-03 18:24:17]
  Epoch: [062][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.7726 (0.7400)   Prec@1 80.469 (77.604)   Prec@5 95.312 (96.304)   [2025-02-03 18:24:20]
  **Train** Prec@1 76.240 Prec@5 95.862 Error@1 23.760
  **Test** Prec@1 61.560 Prec@5 87.090 Error@1 38.440
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:24:23] [Epoch=063/200] [Need: 00:14:02] [learning_rate=0.0775] [Best : Accuracy=63.07, Error=36.93]
  Epoch: [063][000/128]   Time 0.133 (0.133)   Data 0.000 (0.000)   Loss 0.7936 (0.7936)   Prec@1 77.344 (77.344)   Prec@5 95.312 (95.312)   [2025-02-03 18:24:23]
  Epoch: [063][200/128]   Time 0.014 (0.013)   Data 0.000 (0.000)   Loss 0.7367 (0.7316)   Prec@1 73.438 (77.818)   Prec@5 96.875 (96.447)   [2025-02-03 18:24:26]
  **Train** Prec@1 76.354 Prec@5 95.972 Error@1 23.646
  **Test** Prec@1 62.380 Prec@5 87.950 Error@1 37.620
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:24:29] [Epoch=064/200] [Need: 00:13:56] [learning_rate=0.0768] [Best : Accuracy=63.07, Error=36.93]
  Epoch: [064][000/128]   Time 0.118 (0.118)   Data 0.000 (0.000)   Loss 0.5255 (0.5255)   Prec@1 85.156 (85.156)   Prec@5 96.875 (96.875)   [2025-02-03 18:24:29]
  Epoch: [064][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.9638 (0.7224)   Prec@1 71.875 (78.164)   Prec@5 92.969 (96.583)   [2025-02-03 18:24:32]
  **Train** Prec@1 76.658 Prec@5 96.048 Error@1 23.342
  **Test** Prec@1 60.460 Prec@5 87.040 Error@1 39.540
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:24:36] [Epoch=065/200] [Need: 00:13:50] [learning_rate=0.0761] [Best : Accuracy=63.07, Error=36.93]
  Epoch: [065][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.7500 (0.7500)   Prec@1 76.562 (76.562)   Prec@5 95.312 (95.312)   [2025-02-03 18:24:36]
  Epoch: [065][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.8245 (0.7097)   Prec@1 77.344 (78.354)   Prec@5 96.094 (96.685)   [2025-02-03 18:24:38]
  **Train** Prec@1 76.868 Prec@5 96.200 Error@1 23.132
  **Test** Prec@1 61.870 Prec@5 87.820 Error@1 38.130
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:24:42] [Epoch=066/200] [Need: 00:13:44] [learning_rate=0.0755] [Best : Accuracy=63.07, Error=36.93]
  Epoch: [066][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 1.0112 (1.0112)   Prec@1 71.094 (71.094)   Prec@5 94.531 (94.531)   [2025-02-03 18:24:42]
  Epoch: [066][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.6404 (0.7348)   Prec@1 77.344 (77.795)   Prec@5 98.438 (96.525)   [2025-02-03 18:24:45]
  **Train** Prec@1 76.858 Prec@5 96.272 Error@1 23.142
  **Test** Prec@1 60.130 Prec@5 86.850 Error@1 39.870
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:24:48] [Epoch=067/200] [Need: 00:13:38] [learning_rate=0.0748] [Best : Accuracy=63.07, Error=36.93]
  Epoch: [067][000/128]   Time 0.133 (0.133)   Data 0.000 (0.000)   Loss 0.6442 (0.6442)   Prec@1 80.469 (80.469)   Prec@5 96.094 (96.094)   [2025-02-03 18:24:48]
  Epoch: [067][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.6716 (0.7042)   Prec@1 80.469 (78.642)   Prec@5 97.656 (96.723)   [2025-02-03 18:24:51]
  **Train** Prec@1 77.112 Prec@5 96.316 Error@1 22.888
  **Test** Prec@1 60.750 Prec@5 87.350 Error@1 39.250
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:24:54] [Epoch=068/200] [Need: 00:13:32] [learning_rate=0.0741] [Best : Accuracy=63.07, Error=36.93]
  Epoch: [068][000/128]   Time 0.124 (0.124)   Data 0.000 (0.000)   Loss 0.7532 (0.7532)   Prec@1 75.000 (75.000)   Prec@5 98.438 (98.438)   [2025-02-03 18:24:54]
  Epoch: [068][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.7352 (0.6963)   Prec@1 77.344 (78.692)   Prec@5 97.656 (96.922)   [2025-02-03 18:24:57]
  **Train** Prec@1 77.302 Prec@5 96.368 Error@1 22.698
  **Test** Prec@1 62.670 Prec@5 88.400 Error@1 37.330
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:25:00] [Epoch=069/200] [Need: 00:13:26] [learning_rate=0.0734] [Best : Accuracy=63.07, Error=36.93]
  Epoch: [069][000/128]   Time 0.142 (0.142)   Data 0.000 (0.000)   Loss 0.5042 (0.5042)   Prec@1 82.031 (82.031)   Prec@5 97.656 (97.656)   [2025-02-03 18:25:00]
  Epoch: [069][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.7735 (0.6942)   Prec@1 76.562 (78.941)   Prec@5 97.656 (96.898)   [2025-02-03 18:25:03]
  **Train** Prec@1 77.640 Prec@5 96.394 Error@1 22.360
  **Test** Prec@1 61.500 Prec@5 87.850 Error@1 38.500
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:25:06] [Epoch=070/200] [Need: 00:13:19] [learning_rate=0.0727] [Best : Accuracy=63.07, Error=36.93]
  Epoch: [070][000/128]   Time 0.124 (0.124)   Data 0.000 (0.000)   Loss 0.7380 (0.7380)   Prec@1 81.250 (81.250)   Prec@5 97.656 (97.656)   [2025-02-03 18:25:06]
  Epoch: [070][200/128]   Time 0.012 (0.015)   Data 0.000 (0.000)   Loss 0.8022 (0.6757)   Prec@1 79.688 (79.501)   Prec@5 93.750 (97.065)   [2025-02-03 18:25:09]
  **Train** Prec@1 77.938 Prec@5 96.480 Error@1 22.062
  **Test** Prec@1 61.330 Prec@5 87.650 Error@1 38.670
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:25:12] [Epoch=071/200] [Need: 00:13:13] [learning_rate=0.0720] [Best : Accuracy=63.07, Error=36.93]
  Epoch: [071][000/128]   Time 0.116 (0.116)   Data 0.000 (0.000)   Loss 0.6932 (0.6932)   Prec@1 78.906 (78.906)   Prec@5 99.219 (99.219)   [2025-02-03 18:25:13]
  Epoch: [071][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.5719 (0.6780)   Prec@1 80.469 (79.233)   Prec@5 98.438 (97.085)   [2025-02-03 18:25:15]
  **Train** Prec@1 77.804 Prec@5 96.564 Error@1 22.196
  **Test** Prec@1 59.760 Prec@5 86.760 Error@1 40.240
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:25:18] [Epoch=072/200] [Need: 00:13:07] [learning_rate=0.0713] [Best : Accuracy=63.07, Error=36.93]
  Epoch: [072][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.7901 (0.7901)   Prec@1 73.438 (73.438)   Prec@5 96.094 (96.094)   [2025-02-03 18:25:18]
  Epoch: [072][200/128]   Time 0.008 (0.014)   Data 0.000 (0.000)   Loss 0.7597 (0.6651)   Prec@1 82.812 (79.792)   Prec@5 93.750 (97.097)   [2025-02-03 18:25:21]
  **Train** Prec@1 78.442 Prec@5 96.652 Error@1 21.558
  **Test** Prec@1 62.640 Prec@5 88.400 Error@1 37.360
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:25:25] [Epoch=073/200] [Need: 00:13:01] [learning_rate=0.0706] [Best : Accuracy=63.07, Error=36.93]
  Epoch: [073][000/128]   Time 0.125 (0.125)   Data 0.000 (0.000)   Loss 0.6842 (0.6842)   Prec@1 82.031 (82.031)   Prec@5 96.094 (96.094)   [2025-02-03 18:25:25]
  Epoch: [073][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.8008 (0.6648)   Prec@1 73.438 (79.769)   Prec@5 94.531 (97.194)   [2025-02-03 18:25:27]
  **Train** Prec@1 78.676 Prec@5 96.822 Error@1 21.324
  **Test** Prec@1 64.220 Prec@5 88.470 Error@1 35.780
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:25:31] [Epoch=074/200] [Need: 00:12:54] [learning_rate=0.0699] [Best : Accuracy=64.22, Error=35.78]
  Epoch: [074][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.7031 (0.7031)   Prec@1 76.562 (76.562)   Prec@5 98.438 (98.438)   [2025-02-03 18:25:31]
  Epoch: [074][200/128]   Time 0.012 (0.014)   Data 0.000 (0.000)   Loss 0.7440 (0.6614)   Prec@1 76.562 (79.606)   Prec@5 97.656 (97.299)   [2025-02-03 18:25:33]
  **Train** Prec@1 78.462 Prec@5 96.808 Error@1 21.538
  **Test** Prec@1 61.740 Prec@5 87.290 Error@1 38.260
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:25:37] [Epoch=075/200] [Need: 00:12:48] [learning_rate=0.0691] [Best : Accuracy=64.22, Error=35.78]
  Epoch: [075][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.5416 (0.5416)   Prec@1 85.156 (85.156)   Prec@5 99.219 (99.219)   [2025-02-03 18:25:37]
  Epoch: [075][200/128]   Time 0.010 (0.014)   Data 0.000 (0.000)   Loss 0.9633 (0.6647)   Prec@1 69.531 (79.769)   Prec@5 93.750 (97.170)   [2025-02-03 18:25:40]
  **Train** Prec@1 78.776 Prec@5 96.750 Error@1 21.224
  **Test** Prec@1 64.580 Prec@5 89.480 Error@1 35.420
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:25:43] [Epoch=076/200] [Need: 00:12:42] [learning_rate=0.0684] [Best : Accuracy=64.58, Error=35.42]
  Epoch: [076][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.6611 (0.6611)   Prec@1 81.250 (81.250)   Prec@5 97.656 (97.656)   [2025-02-03 18:25:43]
  Epoch: [076][200/128]   Time 0.012 (0.013)   Data 0.000 (0.000)   Loss 0.6296 (0.6450)   Prec@1 81.250 (80.496)   Prec@5 97.656 (97.306)   [2025-02-03 18:25:45]
  **Train** Prec@1 79.214 Prec@5 97.024 Error@1 20.786
  **Test** Prec@1 63.560 Prec@5 88.730 Error@1 36.440
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:25:49] [Epoch=077/200] [Need: 00:12:36] [learning_rate=0.0677] [Best : Accuracy=64.58, Error=35.42]
  Epoch: [077][000/128]   Time 0.147 (0.147)   Data 0.000 (0.000)   Loss 0.5361 (0.5361)   Prec@1 82.031 (82.031)   Prec@5 96.875 (96.875)   [2025-02-03 18:25:49]
  Epoch: [077][200/128]   Time 0.015 (0.015)   Data 0.000 (0.000)   Loss 0.5560 (0.6369)   Prec@1 83.594 (80.791)   Prec@5 98.438 (97.555)   [2025-02-03 18:25:52]
  **Train** Prec@1 79.486 Prec@5 97.050 Error@1 20.514
  **Test** Prec@1 62.720 Prec@5 87.180 Error@1 37.280
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:25:56] [Epoch=078/200] [Need: 00:12:30] [learning_rate=0.0669] [Best : Accuracy=64.58, Error=35.42]
  Epoch: [078][000/128]   Time 0.150 (0.150)   Data 0.000 (0.000)   Loss 0.6018 (0.6018)   Prec@1 79.688 (79.688)   Prec@5 99.219 (99.219)   [2025-02-03 18:25:56]
  Epoch: [078][200/128]   Time 0.015 (0.016)   Data 0.000 (0.000)   Loss 0.6243 (0.6279)   Prec@1 77.344 (80.857)   Prec@5 99.219 (97.621)   [2025-02-03 18:25:59]
  **Train** Prec@1 79.350 Prec@5 97.052 Error@1 20.650
  **Test** Prec@1 63.230 Prec@5 88.960 Error@1 36.770
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:26:02] [Epoch=079/200] [Need: 00:12:25] [learning_rate=0.0662] [Best : Accuracy=64.58, Error=35.42]
  Epoch: [079][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.6103 (0.6103)   Prec@1 82.031 (82.031)   Prec@5 96.875 (96.875)   [2025-02-03 18:26:02]
  Epoch: [079][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.7590 (0.6034)   Prec@1 76.562 (81.720)   Prec@5 98.438 (97.594)   [2025-02-03 18:26:05]
  **Train** Prec@1 80.046 Prec@5 97.248 Error@1 19.954
  **Test** Prec@1 63.680 Prec@5 88.430 Error@1 36.320
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:26:08] [Epoch=080/200] [Need: 00:12:19] [learning_rate=0.0655] [Best : Accuracy=64.58, Error=35.42]
  Epoch: [080][000/128]   Time 0.114 (0.114)   Data 0.000 (0.000)   Loss 0.5541 (0.5541)   Prec@1 81.250 (81.250)   Prec@5 97.656 (97.656)   [2025-02-03 18:26:08]
  Epoch: [080][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.7366 (0.6172)   Prec@1 76.562 (81.060)   Prec@5 96.094 (97.668)   [2025-02-03 18:26:11]
  **Train** Prec@1 79.714 Prec@5 97.192 Error@1 20.286
  **Test** Prec@1 62.730 Prec@5 88.140 Error@1 37.270
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:26:14] [Epoch=081/200] [Need: 00:12:12] [learning_rate=0.0647] [Best : Accuracy=64.58, Error=35.42]
  Epoch: [081][000/128]   Time 0.118 (0.118)   Data 0.000 (0.000)   Loss 0.6921 (0.6921)   Prec@1 82.031 (82.031)   Prec@5 96.875 (96.875)   [2025-02-03 18:26:15]
  Epoch: [081][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.8820 (0.6119)   Prec@1 74.219 (81.604)   Prec@5 94.531 (97.695)   [2025-02-03 18:26:17]
  **Train** Prec@1 80.562 Prec@5 97.432 Error@1 19.438
  **Test** Prec@1 66.590 Prec@5 90.420 Error@1 33.410
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:26:20] [Epoch=082/200] [Need: 00:12:06] [learning_rate=0.0639] [Best : Accuracy=66.59, Error=33.41]
  Epoch: [082][000/128]   Time 0.119 (0.119)   Data 0.000 (0.000)   Loss 0.5667 (0.5667)   Prec@1 80.469 (80.469)   Prec@5 99.219 (99.219)   [2025-02-03 18:26:21]
  Epoch: [082][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.8656 (0.5992)   Prec@1 71.875 (81.732)   Prec@5 93.750 (97.843)   [2025-02-03 18:26:23]
  **Train** Prec@1 80.328 Prec@5 97.338 Error@1 19.672
  **Test** Prec@1 61.260 Prec@5 86.630 Error@1 38.740
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:26:27] [Epoch=083/200] [Need: 00:12:00] [learning_rate=0.0632] [Best : Accuracy=66.59, Error=33.41]
  Epoch: [083][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.4569 (0.4569)   Prec@1 85.938 (85.938)   Prec@5 98.438 (98.438)   [2025-02-03 18:26:27]
  Epoch: [083][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.6916 (0.5919)   Prec@1 77.344 (81.849)   Prec@5 96.094 (97.707)   [2025-02-03 18:26:30]
  **Train** Prec@1 80.606 Prec@5 97.388 Error@1 19.394
  **Test** Prec@1 65.000 Prec@5 89.220 Error@1 35.000
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:26:33] [Epoch=084/200] [Need: 00:11:54] [learning_rate=0.0624] [Best : Accuracy=66.59, Error=33.41]
  Epoch: [084][000/128]   Time 0.126 (0.126)   Data 0.000 (0.000)   Loss 0.4376 (0.4376)   Prec@1 88.281 (88.281)   Prec@5 99.219 (99.219)   [2025-02-03 18:26:33]
  Epoch: [084][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.5909 (0.5849)   Prec@1 84.375 (81.887)   Prec@5 98.438 (97.851)   [2025-02-03 18:26:36]
  **Train** Prec@1 80.808 Prec@5 97.510 Error@1 19.192
  **Test** Prec@1 64.210 Prec@5 88.430 Error@1 35.790
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:26:39] [Epoch=085/200] [Need: 00:11:48] [learning_rate=0.0617] [Best : Accuracy=66.59, Error=33.41]
  Epoch: [085][000/128]   Time 0.145 (0.145)   Data 0.000 (0.000)   Loss 0.5873 (0.5873)   Prec@1 82.031 (82.031)   Prec@5 96.094 (96.094)   [2025-02-03 18:26:39]
  Epoch: [085][200/128]   Time 0.012 (0.017)   Data 0.000 (0.000)   Loss 0.6147 (0.5760)   Prec@1 85.156 (82.175)   Prec@5 95.312 (98.080)   [2025-02-03 18:26:42]
  **Train** Prec@1 81.002 Prec@5 97.650 Error@1 18.998
  **Test** Prec@1 63.630 Prec@5 88.570 Error@1 36.370
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:26:46] [Epoch=086/200] [Need: 00:11:42] [learning_rate=0.0609] [Best : Accuracy=66.59, Error=33.41]
  Epoch: [086][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 0.3926 (0.3926)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2025-02-03 18:26:46]
  Epoch: [086][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.8725 (0.5688)   Prec@1 74.219 (82.801)   Prec@5 93.750 (97.952)   [2025-02-03 18:26:48]
  **Train** Prec@1 81.586 Prec@5 97.672 Error@1 18.414
  **Test** Prec@1 64.680 Prec@5 88.580 Error@1 35.320
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:26:52] [Epoch=087/200] [Need: 00:11:36] [learning_rate=0.0601] [Best : Accuracy=66.59, Error=33.41]
  Epoch: [087][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.4744 (0.4744)   Prec@1 84.375 (84.375)   Prec@5 97.656 (97.656)   [2025-02-03 18:26:52]
  Epoch: [087][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.6770 (0.5554)   Prec@1 78.906 (83.061)   Prec@5 100.000 (98.119)   [2025-02-03 18:26:55]
  **Train** Prec@1 81.564 Prec@5 97.682 Error@1 18.436
  **Test** Prec@1 64.870 Prec@5 88.960 Error@1 35.130
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:26:58] [Epoch=088/200] [Need: 00:11:30] [learning_rate=0.0594] [Best : Accuracy=66.59, Error=33.41]
  Epoch: [088][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.4307 (0.4307)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2025-02-03 18:26:58]
  Epoch: [088][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.7671 (0.5598)   Prec@1 78.125 (82.711)   Prec@5 96.875 (98.111)   [2025-02-03 18:27:01]
  **Train** Prec@1 82.092 Prec@5 97.806 Error@1 17.908
  **Test** Prec@1 61.030 Prec@5 86.610 Error@1 38.970
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:27:04] [Epoch=089/200] [Need: 00:11:23] [learning_rate=0.0586] [Best : Accuracy=66.59, Error=33.41]
  Epoch: [089][000/128]   Time 0.124 (0.124)   Data 0.000 (0.000)   Loss 0.5036 (0.5036)   Prec@1 85.156 (85.156)   Prec@5 99.219 (99.219)   [2025-02-03 18:27:04]
  Epoch: [089][200/128]   Time 0.056 (0.015)   Data 0.000 (0.000)   Loss 0.5946 (0.5324)   Prec@1 82.031 (83.500)   Prec@5 97.656 (98.309)   [2025-02-03 18:27:07]
  **Train** Prec@1 82.238 Prec@5 97.930 Error@1 17.762
  **Test** Prec@1 62.940 Prec@5 88.390 Error@1 37.060
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:27:10] [Epoch=090/200] [Need: 00:11:17] [learning_rate=0.0578] [Best : Accuracy=66.59, Error=33.41]
  Epoch: [090][000/128]   Time 0.124 (0.124)   Data 0.000 (0.000)   Loss 0.4214 (0.4214)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2025-02-03 18:27:10]
  Epoch: [090][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.6090 (0.5378)   Prec@1 85.156 (83.392)   Prec@5 98.438 (98.336)   [2025-02-03 18:27:13]
  **Train** Prec@1 82.102 Prec@5 97.920 Error@1 17.898
  **Test** Prec@1 64.760 Prec@5 89.420 Error@1 35.240
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:27:16] [Epoch=091/200] [Need: 00:11:11] [learning_rate=0.0570] [Best : Accuracy=66.59, Error=33.41]
  Epoch: [091][000/128]   Time 0.119 (0.119)   Data 0.000 (0.000)   Loss 0.4522 (0.4522)   Prec@1 85.938 (85.938)   Prec@5 98.438 (98.438)   [2025-02-03 18:27:16]
  Epoch: [091][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.5302 (0.5217)   Prec@1 83.594 (84.010)   Prec@5 100.000 (98.368)   [2025-02-03 18:27:19]
  **Train** Prec@1 82.956 Prec@5 98.062 Error@1 17.044
  **Test** Prec@1 61.000 Prec@5 87.030 Error@1 39.000
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:27:22] [Epoch=092/200] [Need: 00:11:05] [learning_rate=0.0563] [Best : Accuracy=66.59, Error=33.41]
  Epoch: [092][000/128]   Time 0.113 (0.113)   Data 0.000 (0.000)   Loss 0.6335 (0.6335)   Prec@1 83.594 (83.594)   Prec@5 98.438 (98.438)   [2025-02-03 18:27:22]
  Epoch: [092][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.7091 (0.5113)   Prec@1 81.250 (83.963)   Prec@5 96.875 (98.449)   [2025-02-03 18:27:25]
  **Train** Prec@1 82.444 Prec@5 97.990 Error@1 17.556
  **Test** Prec@1 63.180 Prec@5 88.270 Error@1 36.820
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:27:28] [Epoch=093/200] [Need: 00:10:58] [learning_rate=0.0555] [Best : Accuracy=66.59, Error=33.41]
  Epoch: [093][000/128]   Time 0.115 (0.115)   Data 0.000 (0.000)   Loss 0.3710 (0.3710)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2025-02-03 18:27:28]
  Epoch: [093][200/128]   Time 0.011 (0.013)   Data 0.000 (0.000)   Loss 0.5414 (0.4989)   Prec@1 82.812 (84.593)   Prec@5 100.000 (98.558)   [2025-02-03 18:27:31]
  **Train** Prec@1 83.382 Prec@5 98.262 Error@1 16.618
  **Test** Prec@1 62.390 Prec@5 87.460 Error@1 37.610
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:27:34] [Epoch=094/200] [Need: 00:10:52] [learning_rate=0.0547] [Best : Accuracy=66.59, Error=33.41]
  Epoch: [094][000/128]   Time 0.141 (0.141)   Data 0.000 (0.000)   Loss 0.5298 (0.5298)   Prec@1 84.375 (84.375)   Prec@5 99.219 (99.219)   [2025-02-03 18:27:34]
  Epoch: [094][200/128]   Time 0.011 (0.014)   Data 0.000 (0.000)   Loss 0.4070 (0.4957)   Prec@1 88.281 (84.729)   Prec@5 100.000 (98.527)   [2025-02-03 18:27:37]
  **Train** Prec@1 83.616 Prec@5 98.240 Error@1 16.384
  **Test** Prec@1 64.840 Prec@5 88.370 Error@1 35.160
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:27:40] [Epoch=095/200] [Need: 00:10:46] [learning_rate=0.0539] [Best : Accuracy=66.59, Error=33.41]
  Epoch: [095][000/128]   Time 0.116 (0.116)   Data 0.000 (0.000)   Loss 0.4748 (0.4748)   Prec@1 83.594 (83.594)   Prec@5 100.000 (100.000)   [2025-02-03 18:27:40]
  Epoch: [095][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.6814 (0.4783)   Prec@1 78.906 (85.242)   Prec@5 96.875 (98.593)   [2025-02-03 18:27:43]
  **Train** Prec@1 83.650 Prec@5 98.228 Error@1 16.350
  **Test** Prec@1 65.030 Prec@5 89.830 Error@1 34.970
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:27:47] [Epoch=096/200] [Need: 00:10:40] [learning_rate=0.0531] [Best : Accuracy=66.59, Error=33.41]
  Epoch: [096][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.5732 (0.5732)   Prec@1 79.688 (79.688)   Prec@5 100.000 (100.000)   [2025-02-03 18:27:47]
  Epoch: [096][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.3553 (0.4829)   Prec@1 87.500 (84.939)   Prec@5 100.000 (98.667)   [2025-02-03 18:27:50]
  **Train** Prec@1 83.890 Prec@5 98.366 Error@1 16.110
  **Test** Prec@1 65.250 Prec@5 89.280 Error@1 34.750
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:27:53] [Epoch=097/200] [Need: 00:10:34] [learning_rate=0.0524] [Best : Accuracy=66.59, Error=33.41]
  Epoch: [097][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.4399 (0.4399)   Prec@1 85.156 (85.156)   Prec@5 98.438 (98.438)   [2025-02-03 18:27:53]
  Epoch: [097][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.4538 (0.4648)   Prec@1 86.719 (85.681)   Prec@5 98.438 (98.702)   [2025-02-03 18:27:56]
  **Train** Prec@1 84.340 Prec@5 98.320 Error@1 15.660
  **Test** Prec@1 63.060 Prec@5 88.310 Error@1 36.940
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:27:59] [Epoch=098/200] [Need: 00:10:28] [learning_rate=0.0516] [Best : Accuracy=66.59, Error=33.41]
  Epoch: [098][000/128]   Time 0.137 (0.137)   Data 0.000 (0.000)   Loss 0.4401 (0.4401)   Prec@1 87.500 (87.500)   Prec@5 98.438 (98.438)   [2025-02-03 18:27:59]
  Epoch: [098][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.5329 (0.4643)   Prec@1 82.031 (85.743)   Prec@5 96.875 (98.803)   [2025-02-03 18:28:02]
  **Train** Prec@1 84.584 Prec@5 98.574 Error@1 15.416
  **Test** Prec@1 64.940 Prec@5 89.210 Error@1 35.060
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:28:05] [Epoch=099/200] [Need: 00:10:21] [learning_rate=0.0508] [Best : Accuracy=66.59, Error=33.41]
  Epoch: [099][000/128]   Time 0.113 (0.113)   Data 0.000 (0.000)   Loss 0.4266 (0.4266)   Prec@1 85.938 (85.938)   Prec@5 99.219 (99.219)   [2025-02-03 18:28:05]
  Epoch: [099][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.4203 (0.4420)   Prec@1 85.156 (86.470)   Prec@5 100.000 (98.869)   [2025-02-03 18:28:08]
  **Train** Prec@1 84.988 Prec@5 98.592 Error@1 15.012
  **Test** Prec@1 66.490 Prec@5 89.820 Error@1 33.510
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:28:11] [Epoch=100/200] [Need: 00:10:15] [learning_rate=0.0500] [Best : Accuracy=66.59, Error=33.41]
  Epoch: [100][000/128]   Time 0.116 (0.116)   Data 0.000 (0.000)   Loss 0.3509 (0.3509)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2025-02-03 18:28:11]
  Epoch: [100][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.4798 (0.4602)   Prec@1 86.719 (85.891)   Prec@5 96.094 (98.624)   [2025-02-03 18:28:14]
  **Train** Prec@1 84.976 Prec@5 98.574 Error@1 15.024
  **Test** Prec@1 66.740 Prec@5 89.460 Error@1 33.260
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:28:17] [Epoch=101/200] [Need: 00:10:09] [learning_rate=0.0492] [Best : Accuracy=66.74, Error=33.26]
  Epoch: [101][000/128]   Time 0.117 (0.117)   Data 0.000 (0.000)   Loss 0.4960 (0.4960)   Prec@1 82.812 (82.812)   Prec@5 99.219 (99.219)   [2025-02-03 18:28:17]
  Epoch: [101][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.3889 (0.4272)   Prec@1 89.844 (86.789)   Prec@5 97.656 (98.927)   [2025-02-03 18:28:20]
  **Train** Prec@1 85.300 Prec@5 98.586 Error@1 14.700
  **Test** Prec@1 66.420 Prec@5 89.750 Error@1 33.580
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:28:23] [Epoch=102/200] [Need: 00:10:02] [learning_rate=0.0484] [Best : Accuracy=66.74, Error=33.26]
  Epoch: [102][000/128]   Time 0.115 (0.115)   Data 0.000 (0.000)   Loss 0.4186 (0.4186)   Prec@1 86.719 (86.719)   Prec@5 97.656 (97.656)   [2025-02-03 18:28:23]
  Epoch: [102][200/128]   Time 0.014 (0.015)   Data 0.000 (0.000)   Loss 0.5725 (0.4311)   Prec@1 82.812 (86.602)   Prec@5 97.656 (98.947)   [2025-02-03 18:28:26]
  **Train** Prec@1 85.208 Prec@5 98.682 Error@1 14.792
  **Test** Prec@1 66.040 Prec@5 89.540 Error@1 33.960
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:28:30] [Epoch=103/200] [Need: 00:09:57] [learning_rate=0.0476] [Best : Accuracy=66.74, Error=33.26]
  Epoch: [103][000/128]   Time 0.349 (0.349)   Data 0.000 (0.000)   Loss 0.3976 (0.3976)   Prec@1 87.500 (87.500)   Prec@5 100.000 (100.000)   [2025-02-03 18:28:30]
  Epoch: [103][200/128]   Time 0.012 (0.015)   Data 0.000 (0.000)   Loss 0.4787 (0.4080)   Prec@1 84.375 (87.325)   Prec@5 100.000 (99.048)   [2025-02-03 18:28:33]
  **Train** Prec@1 85.938 Prec@5 98.858 Error@1 14.062
  **Test** Prec@1 64.990 Prec@5 88.960 Error@1 35.010
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:28:36] [Epoch=104/200] [Need: 00:09:51] [learning_rate=0.0469] [Best : Accuracy=66.74, Error=33.26]
  Epoch: [104][000/128]   Time 0.124 (0.124)   Data 0.000 (0.000)   Loss 0.4311 (0.4311)   Prec@1 89.844 (89.844)   Prec@5 98.438 (98.438)   [2025-02-03 18:28:37]
  Epoch: [104][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.4369 (0.3988)   Prec@1 87.500 (87.737)   Prec@5 100.000 (99.114)   [2025-02-03 18:28:39]
  **Train** Prec@1 86.136 Prec@5 98.820 Error@1 13.864
  **Test** Prec@1 65.570 Prec@5 89.490 Error@1 34.430
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:28:43] [Epoch=105/200] [Need: 00:09:45] [learning_rate=0.0461] [Best : Accuracy=66.74, Error=33.26]
  Epoch: [105][000/128]   Time 0.134 (0.134)   Data 0.000 (0.000)   Loss 0.3012 (0.3012)   Prec@1 93.750 (93.750)   Prec@5 97.656 (97.656)   [2025-02-03 18:28:43]
  Epoch: [105][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.4194 (0.3983)   Prec@1 85.938 (87.741)   Prec@5 99.219 (99.133)   [2025-02-03 18:28:46]
  **Train** Prec@1 86.514 Prec@5 98.900 Error@1 13.486
  **Test** Prec@1 63.620 Prec@5 88.250 Error@1 36.380
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:28:49] [Epoch=106/200] [Need: 00:09:39] [learning_rate=0.0453] [Best : Accuracy=66.74, Error=33.26]
  Epoch: [106][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 0.4934 (0.4934)   Prec@1 84.375 (84.375)   Prec@5 98.438 (98.438)   [2025-02-03 18:28:49]
  Epoch: [106][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.4013 (0.4104)   Prec@1 86.719 (87.407)   Prec@5 99.219 (99.075)   [2025-02-03 18:28:52]
  **Train** Prec@1 86.288 Prec@5 98.948 Error@1 13.712
  **Test** Prec@1 65.740 Prec@5 89.700 Error@1 34.260
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:28:55] [Epoch=107/200] [Need: 00:09:33] [learning_rate=0.0445] [Best : Accuracy=66.74, Error=33.26]
  Epoch: [107][000/128]   Time 0.128 (0.128)   Data 0.000 (0.000)   Loss 0.3901 (0.3901)   Prec@1 87.500 (87.500)   Prec@5 99.219 (99.219)   [2025-02-03 18:28:55]
  Epoch: [107][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.3325 (0.3776)   Prec@1 89.844 (88.472)   Prec@5 100.000 (99.304)   [2025-02-03 18:28:58]
  **Train** Prec@1 87.132 Prec@5 99.094 Error@1 12.868
  **Test** Prec@1 66.110 Prec@5 89.100 Error@1 33.890
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:29:01] [Epoch=108/200] [Need: 00:09:26] [learning_rate=0.0437] [Best : Accuracy=66.74, Error=33.26]
  Epoch: [108][000/128]   Time 0.119 (0.119)   Data 0.000 (0.000)   Loss 0.2996 (0.2996)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2025-02-03 18:29:01]
  Epoch: [108][200/128]   Time 0.014 (0.013)   Data 0.000 (0.000)   Loss 0.2990 (0.3669)   Prec@1 91.406 (88.717)   Prec@5 99.219 (99.262)   [2025-02-03 18:29:04]
  **Train** Prec@1 87.706 Prec@5 99.060 Error@1 12.294
  **Test** Prec@1 66.570 Prec@5 89.990 Error@1 33.430
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:29:07] [Epoch=109/200] [Need: 00:09:20] [learning_rate=0.0430] [Best : Accuracy=66.74, Error=33.26]
  Epoch: [109][000/128]   Time 0.112 (0.112)   Data 0.000 (0.000)   Loss 0.2407 (0.2407)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2025-02-03 18:29:07]
  Epoch: [109][200/128]   Time 0.015 (0.013)   Data 0.000 (0.000)   Loss 0.4857 (0.3698)   Prec@1 86.719 (88.394)   Prec@5 99.219 (99.246)   [2025-02-03 18:29:10]
  **Train** Prec@1 87.298 Prec@5 99.074 Error@1 12.702
  **Test** Prec@1 67.370 Prec@5 89.960 Error@1 32.630
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:29:13] [Epoch=110/200] [Need: 00:09:14] [learning_rate=0.0422] [Best : Accuracy=67.37, Error=32.63]
  Epoch: [110][000/128]   Time 0.130 (0.130)   Data 0.000 (0.000)   Loss 0.3222 (0.3222)   Prec@1 90.625 (90.625)   Prec@5 99.219 (99.219)   [2025-02-03 18:29:13]
  Epoch: [110][200/128]   Time 0.011 (0.014)   Data 0.000 (0.000)   Loss 0.3165 (0.3705)   Prec@1 89.062 (88.464)   Prec@5 100.000 (99.304)   [2025-02-03 18:29:16]
  **Train** Prec@1 87.458 Prec@5 99.158 Error@1 12.542
  **Test** Prec@1 66.260 Prec@5 88.780 Error@1 33.740
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:29:19] [Epoch=111/200] [Need: 00:09:08] [learning_rate=0.0414] [Best : Accuracy=67.37, Error=32.63]
  Epoch: [111][000/128]   Time 0.119 (0.119)   Data 0.000 (0.000)   Loss 0.4081 (0.4081)   Prec@1 85.938 (85.938)   Prec@5 99.219 (99.219)   [2025-02-03 18:29:19]
  Epoch: [111][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.4976 (0.3455)   Prec@1 85.156 (89.533)   Prec@5 98.438 (99.328)   [2025-02-03 18:29:22]
  **Train** Prec@1 88.508 Prec@5 99.256 Error@1 11.492
  **Test** Prec@1 65.740 Prec@5 88.740 Error@1 34.260
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:29:25] [Epoch=112/200] [Need: 00:09:01] [learning_rate=0.0406] [Best : Accuracy=67.37, Error=32.63]
  Epoch: [112][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 0.2864 (0.2864)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2025-02-03 18:29:25]
  Epoch: [112][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.3299 (0.3202)   Prec@1 91.406 (90.326)   Prec@5 99.219 (99.572)   [2025-02-03 18:29:28]
  **Train** Prec@1 88.738 Prec@5 99.290 Error@1 11.262
  **Test** Prec@1 66.060 Prec@5 89.560 Error@1 33.940
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:29:31] [Epoch=113/200] [Need: 00:08:55] [learning_rate=0.0399] [Best : Accuracy=67.37, Error=32.63]
  Epoch: [113][000/128]   Time 0.118 (0.118)   Data 0.000 (0.000)   Loss 0.1949 (0.1949)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2025-02-03 18:29:32]
  Epoch: [113][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.4486 (0.3335)   Prec@1 87.500 (89.750)   Prec@5 100.000 (99.436)   [2025-02-03 18:29:34]
  **Train** Prec@1 88.690 Prec@5 99.282 Error@1 11.310
  **Test** Prec@1 65.750 Prec@5 89.200 Error@1 34.250
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:29:38] [Epoch=114/200] [Need: 00:08:49] [learning_rate=0.0391] [Best : Accuracy=67.37, Error=32.63]
  Epoch: [114][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.3590 (0.3590)   Prec@1 88.281 (88.281)   Prec@5 99.219 (99.219)   [2025-02-03 18:29:38]
  Epoch: [114][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.2638 (0.3392)   Prec@1 90.625 (89.447)   Prec@5 100.000 (99.413)   [2025-02-03 18:29:40]
  **Train** Prec@1 88.630 Prec@5 99.282 Error@1 11.370
  **Test** Prec@1 66.760 Prec@5 89.270 Error@1 33.240
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:29:44] [Epoch=115/200] [Need: 00:08:43] [learning_rate=0.0383] [Best : Accuracy=67.37, Error=32.63]
  Epoch: [115][000/128]   Time 0.132 (0.132)   Data 0.000 (0.000)   Loss 0.3502 (0.3502)   Prec@1 87.500 (87.500)   Prec@5 99.219 (99.219)   [2025-02-03 18:29:44]
  Epoch: [115][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.2342 (0.2995)   Prec@1 92.188 (90.979)   Prec@5 99.219 (99.475)   [2025-02-03 18:29:46]
  **Train** Prec@1 89.674 Prec@5 99.360 Error@1 10.326
  **Test** Prec@1 67.310 Prec@5 90.020 Error@1 32.690
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:29:50] [Epoch=116/200] [Need: 00:08:37] [learning_rate=0.0376] [Best : Accuracy=67.37, Error=32.63]
  Epoch: [116][000/128]   Time 0.118 (0.118)   Data 0.000 (0.000)   Loss 0.2192 (0.2192)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2025-02-03 18:29:50]
  Epoch: [116][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.2992 (0.3029)   Prec@1 89.844 (90.582)   Prec@5 100.000 (99.580)   [2025-02-03 18:29:52]
  **Train** Prec@1 89.312 Prec@5 99.406 Error@1 10.688
  **Test** Prec@1 66.670 Prec@5 89.610 Error@1 33.330
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:29:56] [Epoch=117/200] [Need: 00:08:31] [learning_rate=0.0368] [Best : Accuracy=67.37, Error=32.63]
  Epoch: [117][000/128]   Time 0.126 (0.126)   Data 0.000 (0.000)   Loss 0.2738 (0.2738)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2025-02-03 18:29:56]
  Epoch: [117][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.3236 (0.2873)   Prec@1 88.281 (91.375)   Prec@5 100.000 (99.646)   [2025-02-03 18:29:59]
  **Train** Prec@1 90.244 Prec@5 99.500 Error@1 9.756
  **Test** Prec@1 68.130 Prec@5 90.010 Error@1 31.870
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:30:02] [Epoch=118/200] [Need: 00:08:24] [learning_rate=0.0361] [Best : Accuracy=68.13, Error=31.87]
  Epoch: [118][000/128]   Time 0.135 (0.135)   Data 0.000 (0.000)   Loss 0.4706 (0.4706)   Prec@1 89.844 (89.844)   Prec@5 99.219 (99.219)   [2025-02-03 18:30:02]
  Epoch: [118][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.2175 (0.2955)   Prec@1 92.969 (91.006)   Prec@5 100.000 (99.600)   [2025-02-03 18:30:05]
  **Train** Prec@1 90.312 Prec@5 99.496 Error@1 9.688
  **Test** Prec@1 66.910 Prec@5 89.440 Error@1 33.090
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:30:08] [Epoch=119/200] [Need: 00:08:18] [learning_rate=0.0353] [Best : Accuracy=68.13, Error=31.87]
  Epoch: [119][000/128]   Time 0.133 (0.133)   Data 0.000 (0.000)   Loss 0.1793 (0.1793)   Prec@1 96.875 (96.875)   Prec@5 99.219 (99.219)   [2025-02-03 18:30:08]
  Epoch: [119][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.3708 (0.2716)   Prec@1 86.719 (91.647)   Prec@5 98.438 (99.607)   [2025-02-03 18:30:11]
  **Train** Prec@1 90.886 Prec@5 99.564 Error@1 9.114
  **Test** Prec@1 67.840 Prec@5 90.240 Error@1 32.160
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:30:14] [Epoch=120/200] [Need: 00:08:12] [learning_rate=0.0345] [Best : Accuracy=68.13, Error=31.87]
  Epoch: [120][000/128]   Time 0.130 (0.130)   Data 0.000 (0.000)   Loss 0.2270 (0.2270)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2025-02-03 18:30:14]
  Epoch: [120][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.2033 (0.2792)   Prec@1 96.875 (91.643)   Prec@5 100.000 (99.619)   [2025-02-03 18:30:17]
  **Train** Prec@1 91.072 Prec@5 99.550 Error@1 8.928
  **Test** Prec@1 68.180 Prec@5 89.850 Error@1 31.820
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:30:20] [Epoch=121/200] [Need: 00:08:06] [learning_rate=0.0338] [Best : Accuracy=68.18, Error=31.82]
  Epoch: [121][000/128]   Time 0.129 (0.129)   Data 0.000 (0.000)   Loss 0.2232 (0.2232)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2025-02-03 18:30:20]
  Epoch: [121][200/128]   Time 0.013 (0.016)   Data 0.000 (0.000)   Loss 0.2463 (0.2630)   Prec@1 93.750 (91.849)   Prec@5 99.219 (99.693)   [2025-02-03 18:30:23]
  **Train** Prec@1 90.886 Prec@5 99.600 Error@1 9.114
  **Test** Prec@1 67.590 Prec@5 90.420 Error@1 32.410
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:30:27] [Epoch=122/200] [Need: 00:08:00] [learning_rate=0.0331] [Best : Accuracy=68.18, Error=31.82]
  Epoch: [122][000/128]   Time 0.126 (0.126)   Data 0.000 (0.000)   Loss 0.2573 (0.2573)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2025-02-03 18:30:27]
  Epoch: [122][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.3206 (0.2544)   Prec@1 87.500 (92.149)   Prec@5 100.000 (99.701)   [2025-02-03 18:30:30]
  **Train** Prec@1 91.504 Prec@5 99.618 Error@1 8.496
  **Test** Prec@1 68.520 Prec@5 90.520 Error@1 31.480
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:30:34] [Epoch=123/200] [Need: 00:07:54] [learning_rate=0.0323] [Best : Accuracy=68.52, Error=31.48]
  Epoch: [123][000/128]   Time 0.124 (0.124)   Data 0.000 (0.000)   Loss 0.2296 (0.2296)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2025-02-03 18:30:34]
  Epoch: [123][200/128]   Time 0.012 (0.014)   Data 0.000 (0.000)   Loss 0.2276 (0.2352)   Prec@1 93.750 (93.023)   Prec@5 100.000 (99.693)   [2025-02-03 18:30:36]
  **Train** Prec@1 92.000 Prec@5 99.652 Error@1 8.000
  **Test** Prec@1 67.760 Prec@5 89.920 Error@1 32.240
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:30:40] [Epoch=124/200] [Need: 00:07:48] [learning_rate=0.0316] [Best : Accuracy=68.52, Error=31.48]
  Epoch: [124][000/128]   Time 0.125 (0.125)   Data 0.000 (0.000)   Loss 0.2419 (0.2419)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2025-02-03 18:30:40]
  Epoch: [124][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.2834 (0.2306)   Prec@1 89.844 (93.148)   Prec@5 100.000 (99.786)   [2025-02-03 18:30:42]
  **Train** Prec@1 92.170 Prec@5 99.696 Error@1 7.830
  **Test** Prec@1 67.550 Prec@5 89.660 Error@1 32.450
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:30:46] [Epoch=125/200] [Need: 00:07:42] [learning_rate=0.0309] [Best : Accuracy=68.52, Error=31.48]
  Epoch: [125][000/128]   Time 0.126 (0.126)   Data 0.000 (0.000)   Loss 0.3023 (0.3023)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2025-02-03 18:30:46]
  Epoch: [125][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.1999 (0.2283)   Prec@1 93.750 (93.113)   Prec@5 99.219 (99.747)   [2025-02-03 18:30:48]
  **Train** Prec@1 92.528 Prec@5 99.700 Error@1 7.472
  **Test** Prec@1 68.170 Prec@5 90.690 Error@1 31.830
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:30:52] [Epoch=126/200] [Need: 00:07:35] [learning_rate=0.0301] [Best : Accuracy=68.52, Error=31.48]
  Epoch: [126][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.1709 (0.1709)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2025-02-03 18:30:52]
  Epoch: [126][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.2013 (0.2233)   Prec@1 94.531 (93.346)   Prec@5 99.219 (99.775)   [2025-02-03 18:30:54]
  **Train** Prec@1 92.970 Prec@5 99.738 Error@1 7.030
  **Test** Prec@1 69.910 Prec@5 90.970 Error@1 30.090
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:30:58] [Epoch=127/200] [Need: 00:07:29] [learning_rate=0.0294] [Best : Accuracy=69.91, Error=30.09]
  Epoch: [127][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.2037 (0.2037)   Prec@1 95.312 (95.312)   Prec@5 99.219 (99.219)   [2025-02-03 18:30:58]
  Epoch: [127][200/128]   Time 0.012 (0.014)   Data 0.000 (0.000)   Loss 0.3597 (0.2167)   Prec@1 88.281 (93.416)   Prec@5 100.000 (99.841)   [2025-02-03 18:31:00]
  **Train** Prec@1 92.998 Prec@5 99.760 Error@1 7.002
  **Test** Prec@1 68.480 Prec@5 90.710 Error@1 31.520
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:31:04] [Epoch=128/200] [Need: 00:07:23] [learning_rate=0.0287] [Best : Accuracy=69.91, Error=30.09]
  Epoch: [128][000/128]   Time 0.130 (0.130)   Data 0.000 (0.000)   Loss 0.1584 (0.1584)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2025-02-03 18:31:04]
  Epoch: [128][200/128]   Time 0.014 (0.015)   Data 0.000 (0.000)   Loss 0.1932 (0.1958)   Prec@1 93.750 (94.073)   Prec@5 100.000 (99.810)   [2025-02-03 18:31:07]
  **Train** Prec@1 93.260 Prec@5 99.770 Error@1 6.740
  **Test** Prec@1 68.270 Prec@5 90.270 Error@1 31.730
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:31:11] [Epoch=129/200] [Need: 00:07:17] [learning_rate=0.0280] [Best : Accuracy=69.91, Error=30.09]
  Epoch: [129][000/128]   Time 0.139 (0.139)   Data 0.000 (0.000)   Loss 0.1970 (0.1970)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2025-02-03 18:31:11]
  Epoch: [129][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.1419 (0.1983)   Prec@1 96.875 (94.251)   Prec@5 100.000 (99.841)   [2025-02-03 18:31:13]
  **Train** Prec@1 93.848 Prec@5 99.820 Error@1 6.152
  **Test** Prec@1 68.440 Prec@5 89.760 Error@1 31.560
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:31:17] [Epoch=130/200] [Need: 00:07:11] [learning_rate=0.0273] [Best : Accuracy=69.91, Error=30.09]
  Epoch: [130][000/128]   Time 0.119 (0.119)   Data 0.000 (0.000)   Loss 0.1761 (0.1761)   Prec@1 92.969 (92.969)   Prec@5 99.219 (99.219)   [2025-02-03 18:31:17]
  Epoch: [130][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 0.1478 (0.1859)   Prec@1 95.312 (94.593)   Prec@5 100.000 (99.856)   [2025-02-03 18:31:20]
  **Train** Prec@1 94.016 Prec@5 99.814 Error@1 5.984
  **Test** Prec@1 69.400 Prec@5 90.750 Error@1 30.600
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:31:23] [Epoch=131/200] [Need: 00:07:05] [learning_rate=0.0266] [Best : Accuracy=69.91, Error=30.09]
  Epoch: [131][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 0.1964 (0.1964)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2025-02-03 18:31:23]
  Epoch: [131][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.2125 (0.1724)   Prec@1 93.750 (95.122)   Prec@5 99.219 (99.895)   [2025-02-03 18:31:26]
  **Train** Prec@1 94.500 Prec@5 99.884 Error@1 5.500
  **Test** Prec@1 67.760 Prec@5 89.490 Error@1 32.240
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:31:29] [Epoch=132/200] [Need: 00:06:59] [learning_rate=0.0259] [Best : Accuracy=69.91, Error=30.09]
  Epoch: [132][000/128]   Time 0.127 (0.127)   Data 0.000 (0.000)   Loss 0.1966 (0.1966)   Prec@1 93.750 (93.750)   Prec@5 99.219 (99.219)   [2025-02-03 18:31:30]
  Epoch: [132][200/128]   Time 0.015 (0.015)   Data 0.000 (0.000)   Loss 0.2255 (0.1848)   Prec@1 93.750 (94.691)   Prec@5 100.000 (99.880)   [2025-02-03 18:31:32]
  **Train** Prec@1 94.254 Prec@5 99.868 Error@1 5.746
  **Test** Prec@1 70.080 Prec@5 90.830 Error@1 29.920
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:31:36] [Epoch=133/200] [Need: 00:06:53] [learning_rate=0.0252] [Best : Accuracy=70.08, Error=29.92]
  Epoch: [133][000/128]   Time 0.143 (0.143)   Data 0.000 (0.000)   Loss 0.1719 (0.1719)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2025-02-03 18:31:36]
  Epoch: [133][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.2028 (0.1628)   Prec@1 94.531 (95.149)   Prec@5 100.000 (99.911)   [2025-02-03 18:31:39]
  **Train** Prec@1 94.762 Prec@5 99.892 Error@1 5.238
  **Test** Prec@1 69.130 Prec@5 90.700 Error@1 30.870
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:31:42] [Epoch=134/200] [Need: 00:06:47] [learning_rate=0.0245] [Best : Accuracy=70.08, Error=29.92]
  Epoch: [134][000/128]   Time 0.118 (0.118)   Data 0.000 (0.000)   Loss 0.1470 (0.1470)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2025-02-03 18:31:42]
  Epoch: [134][200/128]   Time 0.012 (0.014)   Data 0.000 (0.000)   Loss 0.1622 (0.1583)   Prec@1 92.188 (95.429)   Prec@5 100.000 (99.914)   [2025-02-03 18:31:45]
  **Train** Prec@1 94.970 Prec@5 99.902 Error@1 5.030
  **Test** Prec@1 70.470 Prec@5 90.830 Error@1 29.530
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:31:48] [Epoch=135/200] [Need: 00:06:40] [learning_rate=0.0239] [Best : Accuracy=70.47, Error=29.53]
  Epoch: [135][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.0796 (0.0796)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2025-02-03 18:31:48]
  Epoch: [135][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.1504 (0.1459)   Prec@1 94.531 (96.000)   Prec@5 100.000 (99.883)   [2025-02-03 18:31:51]
  **Train** Prec@1 95.566 Prec@5 99.888 Error@1 4.434
  **Test** Prec@1 69.850 Prec@5 91.240 Error@1 30.150
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:31:55] [Epoch=136/200] [Need: 00:06:34] [learning_rate=0.0232] [Best : Accuracy=70.47, Error=29.53]
  Epoch: [136][000/128]   Time 0.116 (0.116)   Data 0.000 (0.000)   Loss 0.1534 (0.1534)   Prec@1 96.094 (96.094)   Prec@5 99.219 (99.219)   [2025-02-03 18:31:55]
  Epoch: [136][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.1071 (0.1350)   Prec@1 97.656 (96.140)   Prec@5 100.000 (99.965)   [2025-02-03 18:31:58]
  **Train** Prec@1 95.628 Prec@5 99.932 Error@1 4.372
  **Test** Prec@1 69.710 Prec@5 90.640 Error@1 30.290
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:32:01] [Epoch=137/200] [Need: 00:06:28] [learning_rate=0.0225] [Best : Accuracy=70.47, Error=29.53]
  Epoch: [137][000/128]   Time 0.126 (0.126)   Data 0.000 (0.000)   Loss 0.1793 (0.1793)   Prec@1 94.531 (94.531)   Prec@5 99.219 (99.219)   [2025-02-03 18:32:01]
  Epoch: [137][200/128]   Time 0.011 (0.013)   Data 0.000 (0.000)   Loss 0.2184 (0.1372)   Prec@1 94.531 (96.171)   Prec@5 100.000 (99.934)   [2025-02-03 18:32:04]
  **Train** Prec@1 95.878 Prec@5 99.924 Error@1 4.122
  **Test** Prec@1 69.320 Prec@5 90.730 Error@1 30.680
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:32:07] [Epoch=138/200] [Need: 00:06:22] [learning_rate=0.0219] [Best : Accuracy=70.47, Error=29.53]
  Epoch: [138][000/128]   Time 0.118 (0.118)   Data 0.000 (0.000)   Loss 0.1149 (0.1149)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2025-02-03 18:32:07]
  Epoch: [138][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0981 (0.1249)   Prec@1 97.656 (96.618)   Prec@5 100.000 (99.949)   [2025-02-03 18:32:10]
  **Train** Prec@1 96.280 Prec@5 99.938 Error@1 3.720
  **Test** Prec@1 71.050 Prec@5 90.660 Error@1 28.950
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:32:13] [Epoch=139/200] [Need: 00:06:16] [learning_rate=0.0212] [Best : Accuracy=71.05, Error=28.95]
  Epoch: [139][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.0549 (0.0549)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2025-02-03 18:32:13]
  Epoch: [139][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0817 (0.1151)   Prec@1 98.438 (96.902)   Prec@5 100.000 (99.961)   [2025-02-03 18:32:16]
  **Train** Prec@1 96.660 Prec@5 99.952 Error@1 3.340
  **Test** Prec@1 71.530 Prec@5 91.680 Error@1 28.470
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:32:19] [Epoch=140/200] [Need: 00:06:10] [learning_rate=0.0206] [Best : Accuracy=71.53, Error=28.47]
  Epoch: [140][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.1381 (0.1381)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2025-02-03 18:32:19]
  Epoch: [140][200/128]   Time 0.012 (0.015)   Data 0.000 (0.000)   Loss 0.0696 (0.0977)   Prec@1 100.000 (97.505)   Prec@5 100.000 (99.981)   [2025-02-03 18:32:22]
  **Train** Prec@1 97.138 Prec@5 99.962 Error@1 2.862
  **Test** Prec@1 71.270 Prec@5 91.290 Error@1 28.730
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:32:25] [Epoch=141/200] [Need: 00:06:03] [learning_rate=0.0200] [Best : Accuracy=71.53, Error=28.47]
  Epoch: [141][000/128]   Time 0.128 (0.128)   Data 0.000 (0.000)   Loss 0.0895 (0.0895)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2025-02-03 18:32:25]
  Epoch: [141][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0602 (0.0910)   Prec@1 98.438 (97.847)   Prec@5 100.000 (99.984)   [2025-02-03 18:32:28]
  **Train** Prec@1 97.548 Prec@5 99.972 Error@1 2.452
  **Test** Prec@1 72.020 Prec@5 91.540 Error@1 27.980
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:32:31] [Epoch=142/200] [Need: 00:05:57] [learning_rate=0.0194] [Best : Accuracy=72.02, Error=27.98]
  Epoch: [142][000/128]   Time 0.134 (0.134)   Data 0.000 (0.000)   Loss 0.0725 (0.0725)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2025-02-03 18:32:31]
  Epoch: [142][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 0.0484 (0.0865)   Prec@1 100.000 (97.843)   Prec@5 100.000 (99.988)   [2025-02-03 18:32:34]
  **Train** Prec@1 97.570 Prec@5 99.976 Error@1 2.430
  **Test** Prec@1 71.030 Prec@5 91.280 Error@1 28.970
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:32:38] [Epoch=143/200] [Need: 00:05:51] [learning_rate=0.0187] [Best : Accuracy=72.02, Error=27.98]
  Epoch: [143][000/128]   Time 0.146 (0.146)   Data 0.000 (0.000)   Loss 0.0415 (0.0415)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2025-02-03 18:32:38]
  Epoch: [143][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.1138 (0.0859)   Prec@1 97.656 (97.847)   Prec@5 100.000 (99.996)   [2025-02-03 18:32:40]
  **Train** Prec@1 97.704 Prec@5 99.990 Error@1 2.296
  **Test** Prec@1 71.910 Prec@5 91.530 Error@1 28.090
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:32:43] [Epoch=144/200] [Need: 00:05:45] [learning_rate=0.0181] [Best : Accuracy=72.02, Error=27.98]
  Epoch: [144][000/128]   Time 0.124 (0.124)   Data 0.000 (0.000)   Loss 0.0900 (0.0900)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2025-02-03 18:32:44]
  Epoch: [144][200/128]   Time 0.011 (0.013)   Data 0.000 (0.000)   Loss 0.0659 (0.0878)   Prec@1 99.219 (97.862)   Prec@5 100.000 (99.969)   [2025-02-03 18:32:46]
  **Train** Prec@1 97.804 Prec@5 99.976 Error@1 2.196
  **Test** Prec@1 72.320 Prec@5 91.550 Error@1 27.680
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:32:50] [Epoch=145/200] [Need: 00:05:39] [learning_rate=0.0175] [Best : Accuracy=72.32, Error=27.68]
  Epoch: [145][000/128]   Time 0.128 (0.128)   Data 0.000 (0.000)   Loss 0.0479 (0.0479)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2025-02-03 18:32:50]
  Epoch: [145][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.1058 (0.0805)   Prec@1 96.875 (97.998)   Prec@5 100.000 (99.988)   [2025-02-03 18:32:52]
  **Train** Prec@1 98.024 Prec@5 99.988 Error@1 1.976
  **Test** Prec@1 72.140 Prec@5 91.370 Error@1 27.860
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:32:56] [Epoch=146/200] [Need: 00:05:32] [learning_rate=0.0169] [Best : Accuracy=72.32, Error=27.68]
  Epoch: [146][000/128]   Time 0.141 (0.141)   Data 0.000 (0.000)   Loss 0.0539 (0.0539)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2025-02-03 18:32:56]
  Epoch: [146][200/128]   Time 0.012 (0.014)   Data 0.000 (0.000)   Loss 0.0589 (0.0634)   Prec@1 98.438 (98.616)   Prec@5 100.000 (99.996)   [2025-02-03 18:32:58]
  **Train** Prec@1 98.612 Prec@5 99.998 Error@1 1.388
  **Test** Prec@1 73.130 Prec@5 92.160 Error@1 26.870
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:33:02] [Epoch=147/200] [Need: 00:05:26] [learning_rate=0.0163] [Best : Accuracy=73.13, Error=26.87]
  Epoch: [147][000/128]   Time 0.126 (0.126)   Data 0.000 (0.000)   Loss 0.0665 (0.0665)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:02]
  Epoch: [147][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0534 (0.0526)   Prec@1 99.219 (98.935)   Prec@5 100.000 (99.996)   [2025-02-03 18:33:04]
  **Train** Prec@1 98.694 Prec@5 99.992 Error@1 1.306
  **Test** Prec@1 73.950 Prec@5 92.360 Error@1 26.050
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:33:08] [Epoch=148/200] [Need: 00:05:20] [learning_rate=0.0158] [Best : Accuracy=73.95, Error=26.05]
  Epoch: [148][000/128]   Time 0.118 (0.118)   Data 0.000 (0.000)   Loss 0.0221 (0.0221)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:08]
  Epoch: [148][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.0698 (0.0451)   Prec@1 97.656 (99.168)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:11]
  **Train** Prec@1 99.046 Prec@5 99.996 Error@1 0.954
  **Test** Prec@1 74.250 Prec@5 92.210 Error@1 25.750
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:33:14] [Epoch=149/200] [Need: 00:05:14] [learning_rate=0.0152] [Best : Accuracy=74.25, Error=25.75]
  Epoch: [149][000/128]   Time 0.129 (0.129)   Data 0.000 (0.000)   Loss 0.0210 (0.0210)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:14]
  Epoch: [149][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.0454 (0.0488)   Prec@1 100.000 (99.013)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:17]
  **Train** Prec@1 99.014 Prec@5 100.000 Error@1 0.986
  **Test** Prec@1 73.740 Prec@5 92.500 Error@1 26.260
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:33:20] [Epoch=150/200] [Need: 00:05:08] [learning_rate=0.0146] [Best : Accuracy=74.25, Error=25.75]
  Epoch: [150][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.0272 (0.0272)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:20]
  Epoch: [150][200/128]   Time 0.012 (0.014)   Data 0.000 (0.000)   Loss 0.0404 (0.0400)   Prec@1 98.438 (99.351)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:23]
  **Train** Prec@1 99.268 Prec@5 100.000 Error@1 0.732
  **Test** Prec@1 74.790 Prec@5 92.290 Error@1 25.210
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:33:26] [Epoch=151/200] [Need: 00:05:01] [learning_rate=0.0141] [Best : Accuracy=74.79, Error=25.21]
  Epoch: [151][000/128]   Time 0.145 (0.145)   Data 0.000 (0.000)   Loss 0.0436 (0.0436)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:26]
  Epoch: [151][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.0291 (0.0342)   Prec@1 99.219 (99.339)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:29]
  **Train** Prec@1 99.352 Prec@5 100.000 Error@1 0.648
  **Test** Prec@1 75.240 Prec@5 92.310 Error@1 24.760
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:33:32] [Epoch=152/200] [Need: 00:04:55] [learning_rate=0.0136] [Best : Accuracy=75.24, Error=24.76]
  Epoch: [152][000/128]   Time 0.117 (0.117)   Data 0.000 (0.000)   Loss 0.0362 (0.0362)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:32]
  Epoch: [152][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0365 (0.0311)   Prec@1 98.438 (99.537)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:35]
  **Train** Prec@1 99.462 Prec@5 100.000 Error@1 0.538
  **Test** Prec@1 75.400 Prec@5 92.860 Error@1 24.600
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:33:38] [Epoch=153/200] [Need: 00:04:49] [learning_rate=0.0130] [Best : Accuracy=75.40, Error=24.60]
  Epoch: [153][000/128]   Time 0.140 (0.140)   Data 0.000 (0.000)   Loss 0.0280 (0.0280)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:38]
  Epoch: [153][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0251 (0.0261)   Prec@1 100.000 (99.674)   Prec@5 100.000 (99.996)   [2025-02-03 18:33:41]
  **Train** Prec@1 99.636 Prec@5 99.998 Error@1 0.364
  **Test** Prec@1 76.020 Prec@5 93.090 Error@1 23.980
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:33:44] [Epoch=154/200] [Need: 00:04:43] [learning_rate=0.0125] [Best : Accuracy=76.02, Error=23.98]
  Epoch: [154][000/128]   Time 0.139 (0.139)   Data 0.000 (0.000)   Loss 0.0244 (0.0244)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:45]
  Epoch: [154][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0175 (0.0218)   Prec@1 100.000 (99.708)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:47]
  **Train** Prec@1 99.716 Prec@5 99.998 Error@1 0.284
  **Test** Prec@1 76.690 Prec@5 93.160 Error@1 23.310
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:33:51] [Epoch=155/200] [Need: 00:04:37] [learning_rate=0.0120] [Best : Accuracy=76.69, Error=23.31]
  Epoch: [155][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.0126 (0.0126)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:51]
  Epoch: [155][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0126 (0.0175)   Prec@1 100.000 (99.841)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:54]
  **Train** Prec@1 99.828 Prec@5 100.000 Error@1 0.172
  **Test** Prec@1 76.190 Prec@5 93.300 Error@1 23.810
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:33:57] [Epoch=156/200] [Need: 00:04:31] [learning_rate=0.0115] [Best : Accuracy=76.69, Error=23.31]
  Epoch: [156][000/128]   Time 0.124 (0.124)   Data 0.000 (0.000)   Loss 0.0135 (0.0135)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:57]
  Epoch: [156][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0223 (0.0168)   Prec@1 99.219 (99.841)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:00]
  **Train** Prec@1 99.794 Prec@5 100.000 Error@1 0.206
  **Test** Prec@1 76.470 Prec@5 93.130 Error@1 23.530
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:34:03] [Epoch=157/200] [Need: 00:04:24] [learning_rate=0.0110] [Best : Accuracy=76.69, Error=23.31]
  Epoch: [157][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.0340 (0.0340)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:03]
  Epoch: [157][200/128]   Time 0.012 (0.013)   Data 0.000 (0.000)   Loss 0.0117 (0.0176)   Prec@1 100.000 (99.848)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:06]
  **Train** Prec@1 99.854 Prec@5 100.000 Error@1 0.146
  **Test** Prec@1 77.070 Prec@5 93.690 Error@1 22.930
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:34:09] [Epoch=158/200] [Need: 00:04:18] [learning_rate=0.0105] [Best : Accuracy=77.07, Error=22.93]
  Epoch: [158][000/128]   Time 0.126 (0.126)   Data 0.000 (0.000)   Loss 0.0113 (0.0113)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:09]
  Epoch: [158][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 0.0367 (0.0125)   Prec@1 99.219 (99.938)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:12]
  **Train** Prec@1 99.924 Prec@5 100.000 Error@1 0.076
  **Test** Prec@1 77.470 Prec@5 93.570 Error@1 22.530
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:34:15] [Epoch=159/200] [Need: 00:04:12] [learning_rate=0.0100] [Best : Accuracy=77.47, Error=22.53]
  Epoch: [159][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.0081 (0.0081)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:15]
  Epoch: [159][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0191 (0.0104)   Prec@1 99.219 (99.938)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:18]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 77.710 Prec@5 93.880 Error@1 22.290
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:34:22] [Epoch=160/200] [Need: 00:04:06] [learning_rate=0.0095] [Best : Accuracy=77.71, Error=22.29]
  Epoch: [160][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 0.0127 (0.0127)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:22]
  Epoch: [160][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0236 (0.0106)   Prec@1 99.219 (99.946)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:24]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 77.850 Prec@5 93.640 Error@1 22.150
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:34:28] [Epoch=161/200] [Need: 00:04:00] [learning_rate=0.0091] [Best : Accuracy=77.85, Error=22.15]
  Epoch: [161][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 0.0137 (0.0137)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:28]
  Epoch: [161][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0129 (0.0114)   Prec@1 99.219 (99.942)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:30]
  **Train** Prec@1 99.924 Prec@5 100.000 Error@1 0.076
  **Test** Prec@1 77.800 Prec@5 93.850 Error@1 22.200
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:34:34] [Epoch=162/200] [Need: 00:03:54] [learning_rate=0.0086] [Best : Accuracy=77.85, Error=22.15]
  Epoch: [162][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.0099 (0.0099)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:34]
  Epoch: [162][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0183 (0.0110)   Prec@1 99.219 (99.942)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:36]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 77.810 Prec@5 93.840 Error@1 22.190
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:34:40] [Epoch=163/200] [Need: 00:03:47] [learning_rate=0.0082] [Best : Accuracy=77.85, Error=22.15]
  Epoch: [163][000/128]   Time 0.124 (0.124)   Data 0.000 (0.000)   Loss 0.0091 (0.0091)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:40]
  Epoch: [163][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 0.0074 (0.0106)   Prec@1 100.000 (99.949)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:43]
  **Train** Prec@1 99.948 Prec@5 100.000 Error@1 0.052
  **Test** Prec@1 78.250 Prec@5 93.930 Error@1 21.750
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:34:46] [Epoch=164/200] [Need: 00:03:41] [learning_rate=0.0078] [Best : Accuracy=78.25, Error=21.75]
  Epoch: [164][000/128]   Time 0.113 (0.113)   Data 0.000 (0.000)   Loss 0.0113 (0.0113)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:46]
  Epoch: [164][200/128]   Time 0.014 (0.013)   Data 0.000 (0.000)   Loss 0.0055 (0.0103)   Prec@1 100.000 (99.961)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:49]
  **Train** Prec@1 99.938 Prec@5 100.000 Error@1 0.062
  **Test** Prec@1 78.080 Prec@5 94.070 Error@1 21.920
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:34:52] [Epoch=165/200] [Need: 00:03:35] [learning_rate=0.0074] [Best : Accuracy=78.25, Error=21.75]
  Epoch: [165][000/128]   Time 0.118 (0.118)   Data 0.000 (0.000)   Loss 0.0088 (0.0088)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:52]
  Epoch: [165][200/128]   Time 0.012 (0.013)   Data 0.000 (0.000)   Loss 0.0059 (0.0100)   Prec@1 100.000 (99.957)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:55]
  **Train** Prec@1 99.956 Prec@5 100.000 Error@1 0.044
  **Test** Prec@1 78.220 Prec@5 93.910 Error@1 21.780
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:34:58] [Epoch=166/200] [Need: 00:03:29] [learning_rate=0.0070] [Best : Accuracy=78.25, Error=21.75]
  Epoch: [166][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.0091 (0.0091)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:58]
  Epoch: [166][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0094 (0.0096)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:01]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 78.030 Prec@5 93.880 Error@1 21.970
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:35:04] [Epoch=167/200] [Need: 00:03:23] [learning_rate=0.0066] [Best : Accuracy=78.25, Error=21.75]
  Epoch: [167][000/128]   Time 0.146 (0.146)   Data 0.000 (0.000)   Loss 0.0106 (0.0106)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:04]
  Epoch: [167][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0182 (0.0105)   Prec@1 99.219 (99.953)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:07]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 78.590 Prec@5 94.040 Error@1 21.410
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:35:10] [Epoch=168/200] [Need: 00:03:17] [learning_rate=0.0062] [Best : Accuracy=78.59, Error=21.41]
  Epoch: [168][000/128]   Time 0.137 (0.137)   Data 0.000 (0.000)   Loss 0.0106 (0.0106)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:10]
  Epoch: [168][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0080 (0.0096)   Prec@1 100.000 (99.969)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:13]
  **Train** Prec@1 99.966 Prec@5 100.000 Error@1 0.034
  **Test** Prec@1 78.450 Prec@5 94.040 Error@1 21.550
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:35:16] [Epoch=169/200] [Need: 00:03:10] [learning_rate=0.0058] [Best : Accuracy=78.59, Error=21.41]
  Epoch: [169][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 0.0079 (0.0079)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:16]
  Epoch: [169][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0056 (0.0098)   Prec@1 100.000 (99.961)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:19]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 78.600 Prec@5 94.020 Error@1 21.400
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:35:22] [Epoch=170/200] [Need: 00:03:04] [learning_rate=0.0054] [Best : Accuracy=78.60, Error=21.40]
  Epoch: [170][000/128]   Time 0.126 (0.126)   Data 0.000 (0.000)   Loss 0.0091 (0.0091)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:23]
  Epoch: [170][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.0066 (0.0096)   Prec@1 100.000 (99.973)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:25]
  **Train** Prec@1 99.968 Prec@5 100.000 Error@1 0.032
  **Test** Prec@1 78.480 Prec@5 94.060 Error@1 21.520
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:35:29] [Epoch=171/200] [Need: 00:02:58] [learning_rate=0.0051] [Best : Accuracy=78.60, Error=21.40]
  Epoch: [171][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.0064 (0.0064)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:29]
  Epoch: [171][200/128]   Time 0.015 (0.015)   Data 0.000 (0.000)   Loss 0.0072 (0.0097)   Prec@1 100.000 (99.969)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:32]
  **Train** Prec@1 99.956 Prec@5 100.000 Error@1 0.044
  **Test** Prec@1 78.580 Prec@5 94.130 Error@1 21.420
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:35:35] [Epoch=172/200] [Need: 00:02:52] [learning_rate=0.0048] [Best : Accuracy=78.60, Error=21.40]
  Epoch: [172][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.0084 (0.0084)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:35]
  Epoch: [172][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0090 (0.0098)   Prec@1 100.000 (99.973)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:38]
  **Train** Prec@1 99.966 Prec@5 100.000 Error@1 0.034
  **Test** Prec@1 78.470 Prec@5 94.090 Error@1 21.530
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:35:41] [Epoch=173/200] [Need: 00:02:46] [learning_rate=0.0044] [Best : Accuracy=78.60, Error=21.40]
  Epoch: [173][000/128]   Time 0.113 (0.113)   Data 0.000 (0.000)   Loss 0.0067 (0.0067)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:41]
  Epoch: [173][200/128]   Time 0.014 (0.013)   Data 0.000 (0.000)   Loss 0.0079 (0.0091)   Prec@1 100.000 (99.973)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:44]
  **Train** Prec@1 99.968 Prec@5 100.000 Error@1 0.032
  **Test** Prec@1 78.540 Prec@5 94.070 Error@1 21.460
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:35:47] [Epoch=174/200] [Need: 00:02:40] [learning_rate=0.0041] [Best : Accuracy=78.60, Error=21.40]
  Epoch: [174][000/128]   Time 0.113 (0.113)   Data 0.000 (0.000)   Loss 0.0108 (0.0108)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:47]
  Epoch: [174][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.0080 (0.0095)   Prec@1 100.000 (99.957)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:50]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 78.790 Prec@5 94.200 Error@1 21.210
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:35:53] [Epoch=175/200] [Need: 00:02:33] [learning_rate=0.0038] [Best : Accuracy=78.79, Error=21.21]
  Epoch: [175][000/128]   Time 0.119 (0.119)   Data 0.000 (0.000)   Loss 0.0081 (0.0081)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:53]
  Epoch: [175][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0087 (0.0096)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:56]
  **Train** Prec@1 99.962 Prec@5 100.000 Error@1 0.038
  **Test** Prec@1 78.500 Prec@5 94.120 Error@1 21.500
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:35:59] [Epoch=176/200] [Need: 00:02:27] [learning_rate=0.0035] [Best : Accuracy=78.79, Error=21.21]
  Epoch: [176][000/128]   Time 0.114 (0.114)   Data 0.000 (0.000)   Loss 0.0075 (0.0075)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:59]
  Epoch: [176][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0076 (0.0101)   Prec@1 100.000 (99.949)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:02]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 78.660 Prec@5 94.100 Error@1 21.340
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:36:06] [Epoch=177/200] [Need: 00:02:21] [learning_rate=0.0032] [Best : Accuracy=78.79, Error=21.21]
  Epoch: [177][000/128]   Time 0.372 (0.372)   Data 0.000 (0.000)   Loss 0.0080 (0.0080)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:06]
  Epoch: [177][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.0070 (0.0094)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:08]
  **Train** Prec@1 99.956 Prec@5 100.000 Error@1 0.044
  **Test** Prec@1 78.660 Prec@5 94.160 Error@1 21.340
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:36:12] [Epoch=178/200] [Need: 00:02:15] [learning_rate=0.0030] [Best : Accuracy=78.79, Error=21.21]
  Epoch: [178][000/128]   Time 0.126 (0.126)   Data 0.000 (0.000)   Loss 0.0071 (0.0071)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:13]
  Epoch: [178][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0087 (0.0091)   Prec@1 100.000 (99.984)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:15]
  **Train** Prec@1 99.982 Prec@5 100.000 Error@1 0.018
  **Test** Prec@1 78.720 Prec@5 94.160 Error@1 21.280
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:36:19] [Epoch=179/200] [Need: 00:02:09] [learning_rate=0.0027] [Best : Accuracy=78.79, Error=21.21]
  Epoch: [179][000/128]   Time 0.142 (0.142)   Data 0.000 (0.000)   Loss 0.0069 (0.0069)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:19]
  Epoch: [179][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0092 (0.0090)   Prec@1 100.000 (99.981)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:22]
  **Train** Prec@1 99.976 Prec@5 100.000 Error@1 0.024
  **Test** Prec@1 78.610 Prec@5 94.120 Error@1 21.390
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:36:25] [Epoch=180/200] [Need: 00:02:03] [learning_rate=0.0024] [Best : Accuracy=78.79, Error=21.21]
  Epoch: [180][000/128]   Time 0.127 (0.127)   Data 0.000 (0.000)   Loss 0.0075 (0.0075)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:25]
  Epoch: [180][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0081 (0.0092)   Prec@1 100.000 (99.969)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:28]
  **Train** Prec@1 99.970 Prec@5 100.000 Error@1 0.030
  **Test** Prec@1 78.560 Prec@5 94.150 Error@1 21.440
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:36:31] [Epoch=181/200] [Need: 00:01:57] [learning_rate=0.0022] [Best : Accuracy=78.79, Error=21.21]
  Epoch: [181][000/128]   Time 0.131 (0.131)   Data 0.000 (0.000)   Loss 0.0085 (0.0085)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:31]
  Epoch: [181][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.0074 (0.0089)   Prec@1 100.000 (99.981)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:34]
  **Train** Prec@1 99.976 Prec@5 100.000 Error@1 0.024
  **Test** Prec@1 78.810 Prec@5 94.160 Error@1 21.190
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:36:37] [Epoch=182/200] [Need: 00:01:50] [learning_rate=0.0020] [Best : Accuracy=78.81, Error=21.19]
  Epoch: [182][000/128]   Time 0.116 (0.116)   Data 0.000 (0.000)   Loss 0.0108 (0.0108)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:38]
  Epoch: [182][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.0063 (0.0091)   Prec@1 100.000 (99.984)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:40]
  **Train** Prec@1 99.976 Prec@5 100.000 Error@1 0.024
  **Test** Prec@1 78.850 Prec@5 94.140 Error@1 21.150
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:36:43] [Epoch=183/200] [Need: 00:01:44] [learning_rate=0.0018] [Best : Accuracy=78.85, Error=21.15]
  Epoch: [183][000/128]   Time 0.118 (0.118)   Data 0.000 (0.000)   Loss 0.0100 (0.0100)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:44]
  Epoch: [183][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0061 (0.0093)   Prec@1 100.000 (99.984)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:46]
  **Train** Prec@1 99.976 Prec@5 100.000 Error@1 0.024
  **Test** Prec@1 79.070 Prec@5 94.130 Error@1 20.930
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:36:49] [Epoch=184/200] [Need: 00:01:38] [learning_rate=0.0016] [Best : Accuracy=79.07, Error=20.93]
  Epoch: [184][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.0088 (0.0088)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:50]
  Epoch: [184][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0072 (0.0089)   Prec@1 100.000 (99.977)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:52]
  **Train** Prec@1 99.964 Prec@5 100.000 Error@1 0.036
  **Test** Prec@1 78.710 Prec@5 94.000 Error@1 21.290
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:36:55] [Epoch=185/200] [Need: 00:01:32] [learning_rate=0.0014] [Best : Accuracy=79.07, Error=20.93]
  Epoch: [185][000/128]   Time 0.115 (0.115)   Data 0.000 (0.000)   Loss 0.0099 (0.0099)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:55]
  Epoch: [185][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0084 (0.0091)   Prec@1 100.000 (99.977)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:58]
  **Train** Prec@1 99.972 Prec@5 100.000 Error@1 0.028
  **Test** Prec@1 78.860 Prec@5 94.220 Error@1 21.140
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:37:01] [Epoch=186/200] [Need: 00:01:26] [learning_rate=0.0012] [Best : Accuracy=79.07, Error=20.93]
  Epoch: [186][000/128]   Time 0.108 (0.108)   Data 0.000 (0.000)   Loss 0.0075 (0.0075)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:02]
  Epoch: [186][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0071 (0.0090)   Prec@1 100.000 (99.977)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:04]
  **Train** Prec@1 99.974 Prec@5 100.000 Error@1 0.026
  **Test** Prec@1 78.810 Prec@5 94.170 Error@1 21.190
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:37:07] [Epoch=187/200] [Need: 00:01:20] [learning_rate=0.0010] [Best : Accuracy=79.07, Error=20.93]
  Epoch: [187][000/128]   Time 0.147 (0.147)   Data 0.000 (0.000)   Loss 0.0089 (0.0089)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:08]
  Epoch: [187][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.0069 (0.0090)   Prec@1 100.000 (99.969)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:10]
  **Train** Prec@1 99.972 Prec@5 100.000 Error@1 0.028
  **Test** Prec@1 79.020 Prec@5 94.120 Error@1 20.980
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:37:14] [Epoch=188/200] [Need: 00:01:13] [learning_rate=0.0009] [Best : Accuracy=79.07, Error=20.93]
  Epoch: [188][000/128]   Time 0.113 (0.113)   Data 0.000 (0.000)   Loss 0.0108 (0.0108)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:14]
  Epoch: [188][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.0118 (0.0090)   Prec@1 100.000 (99.981)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:16]
  **Train** Prec@1 99.978 Prec@5 100.000 Error@1 0.022
  **Test** Prec@1 78.950 Prec@5 94.060 Error@1 21.050
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:37:20] [Epoch=189/200] [Need: 00:01:07] [learning_rate=0.0007] [Best : Accuracy=79.07, Error=20.93]
  Epoch: [189][000/128]   Time 0.113 (0.113)   Data 0.000 (0.000)   Loss 0.0064 (0.0064)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:20]
  Epoch: [189][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.0083 (0.0087)   Prec@1 100.000 (99.984)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:23]
  **Train** Prec@1 99.980 Prec@5 100.000 Error@1 0.020
  **Test** Prec@1 78.850 Prec@5 94.090 Error@1 21.150
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:37:26] [Epoch=190/200] [Need: 00:01:01] [learning_rate=0.0006] [Best : Accuracy=79.07, Error=20.93]
  Epoch: [190][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.0083 (0.0083)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:26]
  Epoch: [190][200/128]   Time 0.012 (0.014)   Data 0.000 (0.000)   Loss 0.0076 (0.0089)   Prec@1 100.000 (99.984)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:29]
  **Train** Prec@1 99.978 Prec@5 100.000 Error@1 0.022
  **Test** Prec@1 78.970 Prec@5 94.220 Error@1 21.030
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:37:32] [Epoch=191/200] [Need: 00:00:55] [learning_rate=0.0005] [Best : Accuracy=79.07, Error=20.93]
  Epoch: [191][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.0064 (0.0064)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:32]
  Epoch: [191][200/128]   Time 0.015 (0.015)   Data 0.000 (0.000)   Loss 0.0111 (0.0087)   Prec@1 100.000 (99.969)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:35]
  **Train** Prec@1 99.980 Prec@5 100.000 Error@1 0.020
  **Test** Prec@1 78.880 Prec@5 94.230 Error@1 21.120
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:37:39] [Epoch=192/200] [Need: 00:00:49] [learning_rate=0.0004] [Best : Accuracy=79.07, Error=20.93]
  Epoch: [192][000/128]   Time 0.116 (0.116)   Data 0.000 (0.000)   Loss 0.0085 (0.0085)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:39]
  Epoch: [192][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 0.0088 (0.0089)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:41]
  **Train** Prec@1 99.972 Prec@5 100.000 Error@1 0.028
  **Test** Prec@1 79.050 Prec@5 94.010 Error@1 20.950
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:37:45] [Epoch=193/200] [Need: 00:00:43] [learning_rate=0.0003] [Best : Accuracy=79.07, Error=20.93]
  Epoch: [193][000/128]   Time 0.127 (0.127)   Data 0.000 (0.000)   Loss 0.0087 (0.0087)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:45]
  Epoch: [193][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0079 (0.0089)   Prec@1 100.000 (99.961)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:47]
  **Train** Prec@1 99.972 Prec@5 100.000 Error@1 0.028
  **Test** Prec@1 78.950 Prec@5 94.190 Error@1 21.050
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:37:51] [Epoch=194/200] [Need: 00:00:36] [learning_rate=0.0002] [Best : Accuracy=79.07, Error=20.93]
  Epoch: [194][000/128]   Time 0.129 (0.129)   Data 0.000 (0.000)   Loss 0.0088 (0.0088)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:51]
  Epoch: [194][200/128]   Time 0.014 (0.015)   Data 0.000 (0.000)   Loss 0.0079 (0.0085)   Prec@1 100.000 (99.981)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:54]
  **Train** Prec@1 99.978 Prec@5 100.000 Error@1 0.022
  **Test** Prec@1 78.800 Prec@5 94.140 Error@1 21.200
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:37:57] [Epoch=195/200] [Need: 00:00:30] [learning_rate=0.0002] [Best : Accuracy=79.07, Error=20.93]
  Epoch: [195][000/128]   Time 0.382 (0.382)   Data 0.000 (0.000)   Loss 0.0088 (0.0088)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:57]
  Epoch: [195][200/128]   Time 0.013 (0.017)   Data 0.000 (0.000)   Loss 0.0125 (0.0090)   Prec@1 100.000 (99.973)   Prec@5 100.000 (100.000)   [2025-02-03 18:38:00]
  **Train** Prec@1 99.982 Prec@5 100.000 Error@1 0.018
  **Test** Prec@1 78.840 Prec@5 94.080 Error@1 21.160
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:38:04] [Epoch=196/200] [Need: 00:00:24] [learning_rate=0.0001] [Best : Accuracy=79.07, Error=20.93]
  Epoch: [196][000/128]   Time 0.125 (0.125)   Data 0.000 (0.000)   Loss 0.0068 (0.0068)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:38:04]
  Epoch: [196][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0112 (0.0087)   Prec@1 100.000 (99.977)   Prec@5 100.000 (100.000)   [2025-02-03 18:38:07]
  **Train** Prec@1 99.976 Prec@5 100.000 Error@1 0.024
  **Test** Prec@1 78.910 Prec@5 94.060 Error@1 21.090
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:38:10] [Epoch=197/200] [Need: 00:00:18] [learning_rate=0.0001] [Best : Accuracy=79.07, Error=20.93]
  Epoch: [197][000/128]   Time 0.116 (0.116)   Data 0.000 (0.000)   Loss 0.0094 (0.0094)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:38:10]
  Epoch: [197][200/128]   Time 0.014 (0.013)   Data 0.000 (0.000)   Loss 0.0059 (0.0090)   Prec@1 100.000 (99.973)   Prec@5 100.000 (100.000)   [2025-02-03 18:38:13]
  **Train** Prec@1 99.970 Prec@5 100.000 Error@1 0.030
  **Test** Prec@1 78.800 Prec@5 94.160 Error@1 21.200
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:38:16] [Epoch=198/200] [Need: 00:00:12] [learning_rate=0.0000] [Best : Accuracy=79.07, Error=20.93]
  Epoch: [198][000/128]   Time 0.125 (0.125)   Data 0.000 (0.000)   Loss 0.0065 (0.0065)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:38:16]
  Epoch: [198][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0075 (0.0090)   Prec@1 100.000 (99.973)   Prec@5 100.000 (100.000)   [2025-02-03 18:38:19]
  **Train** Prec@1 99.978 Prec@5 100.000 Error@1 0.022
  **Test** Prec@1 79.050 Prec@5 94.250 Error@1 20.950
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:38:22] [Epoch=199/200] [Need: 00:00:06] [learning_rate=0.0000] [Best : Accuracy=79.07, Error=20.93]
  Epoch: [199][000/128]   Time 0.106 (0.106)   Data 0.000 (0.000)   Loss 0.0091 (0.0091)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:38:22]
  Epoch: [199][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0088 (0.0088)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2025-02-03 18:38:25]
  **Train** Prec@1 99.972 Prec@5 100.000 Error@1 0.028
  **Test** Prec@1 78.890 Prec@5 94.200 Error@1 21.110
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mranodom_pr0.0_resnet18_cifar100_seed53[0m at: [34mhttps://wandb.ai/hpi-deep-learning/c-class-iterations-full/runs/oc56zx1a[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250203_101753-oc56zx1a/logs[0m
