wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/TDDS/wandb/run-20250203_101753-vgwkmbit
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ranodom_pr0.0_resnet18_cifar100_seed55
wandb: ⭐️ View project at https://wandb.ai/hpi-deep-learning/c-class-iterations-full
wandb: 🚀 View run at https://wandb.ai/hpi-deep-learning/c-class-iterations-full/runs/vgwkmbit
./checkpoint/pruned-dataset
save path : ./checkpoint/pruned-dataset
{'data_path': './data', 'dataset': 'cifar100', 'arch': 'resnet18', 'epochs': 200, 'batch_size': 128, 'learning_rate': 0.1, 'momentum': 0.9, 'decay': 0.0005, 'print_freq': 200, 'save_path': './checkpoint/pruned-dataset', 'evaluate': False, 'subset_rate': 0.0, 'mask_path': './checkpoint/generated_mask/data_mask_win10_ep30.npy', 'score_path': './checkpoint/generated_mask/score_win10_ep30.npy', 'ngpu': 1, 'workers': 2, 'manualSeed': 55, 'pruning_methods': -1, 'use_cuda': True}
Random Seed: 55
python version : 3.12.8 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:31:09) [GCC 11.2.0]
torch  version : 2.5.1
cudnn  version : 90100
Dataset: cifar100
Data Path: ./data
Network: resnet18
Batchsize: 128
Learning Rate: 0.1
Momentum: 0.9
Weight Decay: 0.0005
Loading CIFAR100... Files already downloaded and verified
Files already downloaded and verified
=> creating model 'resnet18'
=> network :
 ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=100, bias=True)
)

==>>[2025-02-03 18:17:56] [Epoch=000/200] [Need: 00:00:00] [learning_rate=0.1000] [Best : Accuracy=0.00, Error=100.00]
  Epoch: [000][000/128]   Time 0.803 (0.803)   Data 0.000 (0.000)   Loss 4.7455 (4.7455)   Prec@1 1.562 (1.562)   Prec@5 5.469 (5.469)   [2025-02-03 18:17:56]
  Epoch: [000][200/128]   Time 0.013 (0.019)   Data 0.000 (0.000)   Loss 3.7722 (4.0195)   Prec@1 10.156 (8.535)   Prec@5 33.594 (27.387)   [2025-02-03 18:17:59]
  **Train** Prec@1 12.022 Prec@5 34.572 Error@1 87.978
  **Test** Prec@1 19.580 Prec@5 45.660 Error@1 80.420
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:18:03] [Epoch=001/200] [Need: 00:23:51] [learning_rate=0.1000] [Best : Accuracy=19.58, Error=80.42]
  Epoch: [001][000/128]   Time 0.114 (0.114)   Data 0.000 (0.000)   Loss 3.3259 (3.3259)   Prec@1 22.656 (22.656)   Prec@5 49.219 (49.219)   [2025-02-03 18:18:03]
  Epoch: [001][200/128]   Time 0.012 (0.013)   Data 0.000 (0.000)   Loss 2.9260 (3.1573)   Prec@1 29.688 (21.914)   Prec@5 56.250 (51.442)   [2025-02-03 18:18:05]
  **Train** Prec@1 24.772 Prec@5 55.518 Error@1 75.228
  **Test** Prec@1 28.940 Prec@5 61.470 Error@1 71.060
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:18:09] [Epoch=002/200] [Need: 00:21:15] [learning_rate=0.1000] [Best : Accuracy=28.94, Error=71.06]
  Epoch: [002][000/128]   Time 0.112 (0.112)   Data 0.000 (0.000)   Loss 2.6534 (2.6534)   Prec@1 29.688 (29.688)   Prec@5 66.406 (66.406)   [2025-02-03 18:18:09]
  Epoch: [002][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 2.2612 (2.5481)   Prec@1 41.406 (33.625)   Prec@5 74.219 (66.134)   [2025-02-03 18:18:12]
  **Train** Prec@1 35.596 Prec@5 68.628 Error@1 64.404
  **Test** Prec@1 37.770 Prec@5 70.830 Error@1 62.230
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:18:15] [Epoch=003/200] [Need: 00:20:57] [learning_rate=0.0999] [Best : Accuracy=37.77, Error=62.23]
  Epoch: [003][000/128]   Time 0.114 (0.114)   Data 0.000 (0.000)   Loss 2.1684 (2.1684)   Prec@1 39.062 (39.062)   Prec@5 77.344 (77.344)   [2025-02-03 18:18:15]
  Epoch: [003][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 2.2393 (2.1259)   Prec@1 38.281 (42.386)   Prec@5 70.312 (75.548)   [2025-02-03 18:18:18]
  **Train** Prec@1 43.568 Prec@5 76.528 Error@1 56.432
  **Test** Prec@1 42.570 Prec@5 74.600 Error@1 57.430
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:18:21] [Epoch=004/200] [Need: 00:20:29] [learning_rate=0.0999] [Best : Accuracy=42.57, Error=57.43]
  Epoch: [004][000/128]   Time 0.113 (0.113)   Data 0.000 (0.000)   Loss 2.0577 (2.0577)   Prec@1 41.406 (41.406)   Prec@5 79.688 (79.688)   [2025-02-03 18:18:21]
  Epoch: [004][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 2.0783 (1.8521)   Prec@1 46.875 (48.632)   Prec@5 75.000 (80.655)   [2025-02-03 18:18:24]
  **Train** Prec@1 49.120 Prec@5 80.802 Error@1 50.880
  **Test** Prec@1 47.030 Prec@5 78.770 Error@1 52.970
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:18:27] [Epoch=005/200] [Need: 00:20:14] [learning_rate=0.0998] [Best : Accuracy=47.03, Error=52.97]
  Epoch: [005][000/128]   Time 0.141 (0.141)   Data 0.000 (0.000)   Loss 1.8056 (1.8056)   Prec@1 49.219 (49.219)   Prec@5 83.594 (83.594)   [2025-02-03 18:18:27]
  Epoch: [005][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.5305 (1.6757)   Prec@1 60.938 (53.059)   Prec@5 85.938 (83.741)   [2025-02-03 18:18:30]
  **Train** Prec@1 53.010 Prec@5 83.618 Error@1 46.990
  **Test** Prec@1 48.910 Prec@5 79.440 Error@1 51.090
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:18:33] [Epoch=006/200] [Need: 00:20:05] [learning_rate=0.0998] [Best : Accuracy=48.91, Error=51.09]
  Epoch: [006][000/128]   Time 0.127 (0.127)   Data 0.000 (0.000)   Loss 1.5113 (1.5113)   Prec@1 53.906 (53.906)   Prec@5 92.188 (92.188)   [2025-02-03 18:18:33]
  Epoch: [006][200/128]   Time 0.012 (0.014)   Data 0.000 (0.000)   Loss 1.7292 (1.5773)   Prec@1 52.344 (55.111)   Prec@5 80.469 (85.269)   [2025-02-03 18:18:36]
  **Train** Prec@1 55.498 Prec@5 85.272 Error@1 44.502
  **Test** Prec@1 46.300 Prec@5 77.440 Error@1 53.700
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:18:39] [Epoch=007/200] [Need: 00:19:51] [learning_rate=0.0997] [Best : Accuracy=48.91, Error=51.09]
  Epoch: [007][000/128]   Time 0.142 (0.142)   Data 0.000 (0.000)   Loss 1.4440 (1.4440)   Prec@1 60.156 (60.156)   Prec@5 89.844 (89.844)   [2025-02-03 18:18:39]
  Epoch: [007][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.5323 (1.4863)   Prec@1 57.031 (57.676)   Prec@5 85.156 (86.684)   [2025-02-03 18:18:42]
  **Train** Prec@1 57.540 Prec@5 86.392 Error@1 42.460
  **Test** Prec@1 49.040 Prec@5 79.170 Error@1 50.960
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:18:45] [Epoch=008/200] [Need: 00:19:46] [learning_rate=0.0996] [Best : Accuracy=49.04, Error=50.96]
  Epoch: [008][000/128]   Time 0.114 (0.114)   Data 0.000 (0.000)   Loss 1.4441 (1.4441)   Prec@1 62.500 (62.500)   Prec@5 86.719 (86.719)   [2025-02-03 18:18:45]
  Epoch: [008][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.4878 (1.4065)   Prec@1 58.594 (59.690)   Prec@5 87.500 (87.861)   [2025-02-03 18:18:48]
  **Train** Prec@1 59.152 Prec@5 87.490 Error@1 40.848
  **Test** Prec@1 52.000 Prec@5 81.870 Error@1 48.000
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:18:51] [Epoch=009/200] [Need: 00:19:40] [learning_rate=0.0995] [Best : Accuracy=52.00, Error=48.00]
  Epoch: [009][000/128]   Time 0.130 (0.130)   Data 0.000 (0.000)   Loss 1.5011 (1.5011)   Prec@1 56.250 (56.250)   Prec@5 85.156 (85.156)   [2025-02-03 18:18:51]
  Epoch: [009][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 1.3906 (1.3633)   Prec@1 64.844 (61.120)   Prec@5 84.375 (88.650)   [2025-02-03 18:18:54]
  **Train** Prec@1 60.370 Prec@5 88.334 Error@1 39.630
  **Test** Prec@1 53.570 Prec@5 83.270 Error@1 46.430
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:18:57] [Epoch=010/200] [Need: 00:19:32] [learning_rate=0.0994] [Best : Accuracy=53.57, Error=46.43]
  Epoch: [010][000/128]   Time 0.159 (0.159)   Data 0.000 (0.000)   Loss 1.2839 (1.2839)   Prec@1 63.281 (63.281)   Prec@5 89.062 (89.062)   [2025-02-03 18:18:58]
  Epoch: [010][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.4334 (1.3079)   Prec@1 58.594 (62.356)   Prec@5 89.062 (89.319)   [2025-02-03 18:19:00]
  **Train** Prec@1 61.406 Prec@5 89.000 Error@1 38.594
  **Test** Prec@1 54.420 Prec@5 83.220 Error@1 45.580
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:19:04] [Epoch=011/200] [Need: 00:19:30] [learning_rate=0.0993] [Best : Accuracy=54.42, Error=45.58]
  Epoch: [011][000/128]   Time 0.119 (0.119)   Data 0.000 (0.000)   Loss 1.0876 (1.0876)   Prec@1 66.406 (66.406)   Prec@5 92.188 (92.188)   [2025-02-03 18:19:04]
  Epoch: [011][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 1.4807 (1.2578)   Prec@1 57.031 (63.872)   Prec@5 87.500 (90.112)   [2025-02-03 18:19:06]
  **Train** Prec@1 62.880 Prec@5 89.548 Error@1 37.120
  **Test** Prec@1 57.750 Prec@5 86.420 Error@1 42.250
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:19:10] [Epoch=012/200] [Need: 00:19:18] [learning_rate=0.0991] [Best : Accuracy=57.75, Error=42.25]
  Epoch: [012][000/128]   Time 0.126 (0.126)   Data 0.000 (0.000)   Loss 1.1224 (1.1224)   Prec@1 66.406 (66.406)   Prec@5 92.969 (92.969)   [2025-02-03 18:19:10]
  Epoch: [012][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.1930 (1.2455)   Prec@1 64.844 (63.899)   Prec@5 90.625 (90.345)   [2025-02-03 18:19:13]
  **Train** Prec@1 63.360 Prec@5 89.972 Error@1 36.640
  **Test** Prec@1 52.390 Prec@5 81.550 Error@1 47.610
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:19:16] [Epoch=013/200] [Need: 00:19:16] [learning_rate=0.0990] [Best : Accuracy=57.75, Error=42.25]
  Epoch: [013][000/128]   Time 0.117 (0.117)   Data 0.000 (0.000)   Loss 1.2945 (1.2945)   Prec@1 66.406 (66.406)   Prec@5 90.625 (90.625)   [2025-02-03 18:19:16]
  Epoch: [013][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.1028 (1.2262)   Prec@1 64.844 (64.331)   Prec@5 93.750 (90.547)   [2025-02-03 18:19:19]
  **Train** Prec@1 64.066 Prec@5 90.304 Error@1 35.934
  **Test** Prec@1 55.350 Prec@5 84.220 Error@1 44.650
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:19:22] [Epoch=014/200] [Need: 00:19:07] [learning_rate=0.0988] [Best : Accuracy=57.75, Error=42.25]
  Epoch: [014][000/128]   Time 0.128 (0.128)   Data 0.000 (0.000)   Loss 1.3267 (1.3267)   Prec@1 64.844 (64.844)   Prec@5 92.969 (92.969)   [2025-02-03 18:19:22]
  Epoch: [014][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.2105 (1.1707)   Prec@1 65.625 (66.099)   Prec@5 90.625 (91.297)   [2025-02-03 18:19:25]
  **Train** Prec@1 65.126 Prec@5 90.804 Error@1 34.874
  **Test** Prec@1 56.100 Prec@5 84.310 Error@1 43.900
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:19:28] [Epoch=015/200] [Need: 00:19:01] [learning_rate=0.0986] [Best : Accuracy=57.75, Error=42.25]
  Epoch: [015][000/128]   Time 0.141 (0.141)   Data 0.000 (0.000)   Loss 0.9792 (0.9792)   Prec@1 68.750 (68.750)   Prec@5 93.750 (93.750)   [2025-02-03 18:19:28]
  Epoch: [015][200/128]   Time 0.015 (0.015)   Data 0.000 (0.000)   Loss 1.0778 (1.1543)   Prec@1 68.750 (66.363)   Prec@5 89.844 (91.612)   [2025-02-03 18:19:31]
  **Train** Prec@1 65.640 Prec@5 91.050 Error@1 34.360
  **Test** Prec@1 53.570 Prec@5 82.350 Error@1 46.430
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:19:35] [Epoch=016/200] [Need: 00:18:59] [learning_rate=0.0984] [Best : Accuracy=57.75, Error=42.25]
  Epoch: [016][000/128]   Time 0.117 (0.117)   Data 0.000 (0.000)   Loss 0.9459 (0.9459)   Prec@1 74.219 (74.219)   Prec@5 92.188 (92.188)   [2025-02-03 18:19:35]
  Epoch: [016][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.2571 (1.1396)   Prec@1 64.844 (66.694)   Prec@5 92.188 (91.834)   [2025-02-03 18:19:37]
  **Train** Prec@1 65.902 Prec@5 91.442 Error@1 34.098
  **Test** Prec@1 57.030 Prec@5 85.300 Error@1 42.970
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:19:41] [Epoch=017/200] [Need: 00:18:51] [learning_rate=0.0982] [Best : Accuracy=57.75, Error=42.25]
  Epoch: [017][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.9154 (0.9154)   Prec@1 73.438 (73.438)   Prec@5 94.531 (94.531)   [2025-02-03 18:19:41]
  Epoch: [017][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 1.0614 (1.1181)   Prec@1 66.406 (67.312)   Prec@5 91.406 (91.970)   [2025-02-03 18:19:44]
  **Train** Prec@1 66.598 Prec@5 91.614 Error@1 33.402
  **Test** Prec@1 56.690 Prec@5 84.620 Error@1 43.310
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:19:47] [Epoch=018/200] [Need: 00:18:47] [learning_rate=0.0980] [Best : Accuracy=57.75, Error=42.25]
  Epoch: [018][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 1.2346 (1.2346)   Prec@1 64.844 (64.844)   Prec@5 92.188 (92.188)   [2025-02-03 18:19:47]
  Epoch: [018][200/128]   Time 0.015 (0.014)   Data 0.000 (0.000)   Loss 1.2650 (1.0952)   Prec@1 61.719 (68.136)   Prec@5 91.406 (92.281)   [2025-02-03 18:19:50]
  **Train** Prec@1 67.142 Prec@5 91.732 Error@1 32.858
  **Test** Prec@1 58.090 Prec@5 85.610 Error@1 41.910
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:19:53] [Epoch=019/200] [Need: 00:18:39] [learning_rate=0.0978] [Best : Accuracy=58.09, Error=41.91]
  Epoch: [019][000/128]   Time 0.133 (0.133)   Data 0.000 (0.000)   Loss 0.9940 (0.9940)   Prec@1 69.531 (69.531)   Prec@5 94.531 (94.531)   [2025-02-03 18:19:53]
  Epoch: [019][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.3235 (1.0809)   Prec@1 64.844 (68.214)   Prec@5 91.406 (92.568)   [2025-02-03 18:19:56]
  **Train** Prec@1 67.428 Prec@5 92.080 Error@1 32.572
  **Test** Prec@1 56.030 Prec@5 84.320 Error@1 43.970
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:19:59] [Epoch=020/200] [Need: 00:18:33] [learning_rate=0.0976] [Best : Accuracy=58.09, Error=41.91]
  Epoch: [020][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 0.9574 (0.9574)   Prec@1 71.875 (71.875)   Prec@5 92.969 (92.969)   [2025-02-03 18:20:00]
  Epoch: [020][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.1646 (1.0757)   Prec@1 67.188 (68.412)   Prec@5 91.406 (92.631)   [2025-02-03 18:20:02]
  **Train** Prec@1 67.758 Prec@5 92.128 Error@1 32.242
  **Test** Prec@1 58.250 Prec@5 86.200 Error@1 41.750
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:20:05] [Epoch=021/200] [Need: 00:18:25] [learning_rate=0.0973] [Best : Accuracy=58.25, Error=41.75]
  Epoch: [021][000/128]   Time 0.125 (0.125)   Data 0.000 (0.000)   Loss 0.9745 (0.9745)   Prec@1 67.188 (67.188)   Prec@5 95.312 (95.312)   [2025-02-03 18:20:05]
  Epoch: [021][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 1.2137 (1.0661)   Prec@1 62.500 (68.614)   Prec@5 91.406 (92.638)   [2025-02-03 18:20:08]
  **Train** Prec@1 68.176 Prec@5 92.352 Error@1 31.824
  **Test** Prec@1 49.290 Prec@5 78.260 Error@1 50.710
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:20:12] [Epoch=022/200] [Need: 00:18:20] [learning_rate=0.0970] [Best : Accuracy=58.25, Error=41.75]
  Epoch: [022][000/128]   Time 0.135 (0.135)   Data 0.000 (0.000)   Loss 0.9628 (0.9628)   Prec@1 71.875 (71.875)   Prec@5 95.312 (95.312)   [2025-02-03 18:20:12]
  Epoch: [022][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.3347 (1.0452)   Prec@1 63.281 (69.454)   Prec@5 89.062 (92.821)   [2025-02-03 18:20:14]
  **Train** Prec@1 68.734 Prec@5 92.462 Error@1 31.266
  **Test** Prec@1 59.450 Prec@5 86.380 Error@1 40.550
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:20:18] [Epoch=023/200] [Need: 00:18:12] [learning_rate=0.0968] [Best : Accuracy=59.45, Error=40.55]
  Epoch: [023][000/128]   Time 0.128 (0.128)   Data 0.000 (0.000)   Loss 1.2008 (1.2008)   Prec@1 67.188 (67.188)   Prec@5 90.625 (90.625)   [2025-02-03 18:20:18]
  Epoch: [023][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.9402 (1.0166)   Prec@1 72.656 (70.075)   Prec@5 91.406 (93.400)   [2025-02-03 18:20:21]
  **Train** Prec@1 68.918 Prec@5 92.654 Error@1 31.082
  **Test** Prec@1 56.060 Prec@5 84.800 Error@1 43.940
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:20:24] [Epoch=024/200] [Need: 00:18:07] [learning_rate=0.0965] [Best : Accuracy=59.45, Error=40.55]
  Epoch: [024][000/128]   Time 0.132 (0.132)   Data 0.000 (0.000)   Loss 0.9336 (0.9336)   Prec@1 71.094 (71.094)   Prec@5 96.875 (96.875)   [2025-02-03 18:20:24]
  Epoch: [024][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.0477 (1.0107)   Prec@1 67.969 (70.344)   Prec@5 93.750 (93.513)   [2025-02-03 18:20:27]
  **Train** Prec@1 69.112 Prec@5 92.872 Error@1 30.888
  **Test** Prec@1 60.520 Prec@5 87.150 Error@1 39.480
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:20:30] [Epoch=025/200] [Need: 00:17:59] [learning_rate=0.0962] [Best : Accuracy=60.52, Error=39.48]
  Epoch: [025][000/128]   Time 0.126 (0.126)   Data 0.000 (0.000)   Loss 0.8733 (0.8733)   Prec@1 76.562 (76.562)   Prec@5 95.312 (95.312)   [2025-02-03 18:20:30]
  Epoch: [025][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.9783 (1.0007)   Prec@1 69.531 (70.876)   Prec@5 96.875 (93.536)   [2025-02-03 18:20:33]
  **Train** Prec@1 69.462 Prec@5 93.054 Error@1 30.538
  **Test** Prec@1 58.940 Prec@5 85.540 Error@1 41.060
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:20:36] [Epoch=026/200] [Need: 00:17:53] [learning_rate=0.0959] [Best : Accuracy=60.52, Error=39.48]
  Epoch: [026][000/128]   Time 0.118 (0.118)   Data 0.000 (0.000)   Loss 0.8596 (0.8596)   Prec@1 77.344 (77.344)   Prec@5 97.656 (97.656)   [2025-02-03 18:20:36]
  Epoch: [026][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.8607 (0.9888)   Prec@1 72.656 (71.059)   Prec@5 93.750 (93.571)   [2025-02-03 18:20:39]
  **Train** Prec@1 69.592 Prec@5 92.996 Error@1 30.408
  **Test** Prec@1 61.780 Prec@5 88.140 Error@1 38.220
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:20:42] [Epoch=027/200] [Need: 00:17:46] [learning_rate=0.0956] [Best : Accuracy=61.78, Error=38.22]
  Epoch: [027][000/128]   Time 0.143 (0.143)   Data 0.000 (0.000)   Loss 0.9725 (0.9725)   Prec@1 73.438 (73.438)   Prec@5 94.531 (94.531)   [2025-02-03 18:20:42]
  Epoch: [027][200/128]   Time 0.015 (0.015)   Data 0.000 (0.000)   Loss 0.9230 (0.9804)   Prec@1 74.219 (71.012)   Prec@5 91.406 (93.801)   [2025-02-03 18:20:45]
  **Train** Prec@1 69.896 Prec@5 93.134 Error@1 30.104
  **Test** Prec@1 58.190 Prec@5 86.130 Error@1 41.810
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:20:49] [Epoch=028/200] [Need: 00:17:43] [learning_rate=0.0952] [Best : Accuracy=61.78, Error=38.22]
  Epoch: [028][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.8097 (0.8097)   Prec@1 76.562 (76.562)   Prec@5 96.094 (96.094)   [2025-02-03 18:20:49]
  Epoch: [028][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.9572 (0.9887)   Prec@1 70.312 (70.927)   Prec@5 92.969 (93.793)   [2025-02-03 18:20:52]
  **Train** Prec@1 69.980 Prec@5 93.296 Error@1 30.020
  **Test** Prec@1 59.440 Prec@5 86.890 Error@1 40.560
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:20:55] [Epoch=029/200] [Need: 00:17:37] [learning_rate=0.0949] [Best : Accuracy=61.78, Error=38.22]
  Epoch: [029][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.8782 (0.8782)   Prec@1 71.875 (71.875)   Prec@5 97.656 (97.656)   [2025-02-03 18:20:55]
  Epoch: [029][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.0814 (0.9815)   Prec@1 64.844 (70.985)   Prec@5 92.969 (93.851)   [2025-02-03 18:20:58]
  **Train** Prec@1 70.124 Prec@5 93.318 Error@1 29.876
  **Test** Prec@1 59.650 Prec@5 86.850 Error@1 40.350
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:21:01] [Epoch=030/200] [Need: 00:17:31] [learning_rate=0.0946] [Best : Accuracy=61.78, Error=38.22]
  Epoch: [030][000/128]   Time 0.114 (0.114)   Data 0.000 (0.000)   Loss 0.8036 (0.8036)   Prec@1 71.094 (71.094)   Prec@5 96.875 (96.875)   [2025-02-03 18:21:01]
  Epoch: [030][200/128]   Time 0.013 (0.016)   Data 0.000 (0.000)   Loss 0.7835 (0.9622)   Prec@1 78.906 (71.517)   Prec@5 94.531 (93.937)   [2025-02-03 18:21:04]
  **Train** Prec@1 70.680 Prec@5 93.552 Error@1 29.320
  **Test** Prec@1 58.020 Prec@5 85.200 Error@1 41.980
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:21:08] [Epoch=031/200] [Need: 00:17:27] [learning_rate=0.0942] [Best : Accuracy=61.78, Error=38.22]
  Epoch: [031][000/128]   Time 0.128 (0.128)   Data 0.000 (0.000)   Loss 0.9365 (0.9365)   Prec@1 71.875 (71.875)   Prec@5 95.312 (95.312)   [2025-02-03 18:21:08]
  Epoch: [031][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.1192 (0.9687)   Prec@1 63.281 (71.385)   Prec@5 92.969 (94.088)   [2025-02-03 18:21:11]
  **Train** Prec@1 70.598 Prec@5 93.504 Error@1 29.402
  **Test** Prec@1 60.000 Prec@5 86.590 Error@1 40.000
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:21:14] [Epoch=032/200] [Need: 00:17:22] [learning_rate=0.0938] [Best : Accuracy=61.78, Error=38.22]
  Epoch: [032][000/128]   Time 0.126 (0.126)   Data 0.000 (0.000)   Loss 0.9222 (0.9222)   Prec@1 74.219 (74.219)   Prec@5 92.188 (92.188)   [2025-02-03 18:21:14]
  Epoch: [032][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.0817 (0.9366)   Prec@1 66.406 (72.260)   Prec@5 92.969 (94.349)   [2025-02-03 18:21:17]
  **Train** Prec@1 71.016 Prec@5 93.766 Error@1 28.984
  **Test** Prec@1 59.750 Prec@5 86.680 Error@1 40.250
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:21:20] [Epoch=033/200] [Need: 00:17:15] [learning_rate=0.0934] [Best : Accuracy=61.78, Error=38.22]
  Epoch: [033][000/128]   Time 0.128 (0.128)   Data 0.000 (0.000)   Loss 0.8511 (0.8511)   Prec@1 75.781 (75.781)   Prec@5 93.750 (93.750)   [2025-02-03 18:21:20]
  Epoch: [033][200/128]   Time 0.015 (0.015)   Data 0.000 (0.000)   Loss 0.9122 (0.9338)   Prec@1 75.000 (72.252)   Prec@5 92.188 (94.422)   [2025-02-03 18:21:23]
  **Train** Prec@1 71.218 Prec@5 93.878 Error@1 28.782
  **Test** Prec@1 56.640 Prec@5 84.470 Error@1 43.360
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:21:27] [Epoch=034/200] [Need: 00:17:11] [learning_rate=0.0930] [Best : Accuracy=61.78, Error=38.22]
  Epoch: [034][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 0.7181 (0.7181)   Prec@1 78.906 (78.906)   Prec@5 96.094 (96.094)   [2025-02-03 18:21:27]
  Epoch: [034][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.9152 (0.9204)   Prec@1 69.531 (72.610)   Prec@5 92.188 (94.512)   [2025-02-03 18:21:30]
  **Train** Prec@1 71.250 Prec@5 94.004 Error@1 28.750
  **Test** Prec@1 56.180 Prec@5 84.410 Error@1 43.820
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:21:33] [Epoch=035/200] [Need: 00:17:05] [learning_rate=0.0926] [Best : Accuracy=61.78, Error=38.22]
  Epoch: [035][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 1.0229 (1.0229)   Prec@1 71.094 (71.094)   Prec@5 92.969 (92.969)   [2025-02-03 18:21:33]
  Epoch: [035][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.9681 (0.9377)   Prec@1 70.312 (72.201)   Prec@5 96.094 (94.395)   [2025-02-03 18:21:36]
  **Train** Prec@1 71.388 Prec@5 93.984 Error@1 28.612
  **Test** Prec@1 58.350 Prec@5 85.730 Error@1 41.650
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:21:39] [Epoch=036/200] [Need: 00:16:58] [learning_rate=0.0922] [Best : Accuracy=61.78, Error=38.22]
  Epoch: [036][000/128]   Time 0.155 (0.155)   Data 0.000 (0.000)   Loss 0.8623 (0.8623)   Prec@1 73.438 (73.438)   Prec@5 93.750 (93.750)   [2025-02-03 18:21:39]
  Epoch: [036][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.0808 (0.9199)   Prec@1 66.406 (72.707)   Prec@5 93.750 (94.341)   [2025-02-03 18:21:42]
  **Train** Prec@1 71.748 Prec@5 93.898 Error@1 28.252
  **Test** Prec@1 60.580 Prec@5 86.550 Error@1 39.420
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:21:45] [Epoch=037/200] [Need: 00:16:51] [learning_rate=0.0918] [Best : Accuracy=61.78, Error=38.22]
  Epoch: [037][000/128]   Time 0.119 (0.119)   Data 0.000 (0.000)   Loss 0.6773 (0.6773)   Prec@1 80.469 (80.469)   Prec@5 96.875 (96.875)   [2025-02-03 18:21:45]
  Epoch: [037][200/128]   Time 0.014 (0.015)   Data 0.000 (0.000)   Loss 0.8115 (0.8981)   Prec@1 75.000 (73.103)   Prec@5 93.750 (94.869)   [2025-02-03 18:21:48]
  **Train** Prec@1 71.860 Prec@5 94.214 Error@1 28.140
  **Test** Prec@1 57.750 Prec@5 85.040 Error@1 42.250
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:21:52] [Epoch=038/200] [Need: 00:16:46] [learning_rate=0.0914] [Best : Accuracy=61.78, Error=38.22]
  Epoch: [038][000/128]   Time 0.135 (0.135)   Data 0.000 (0.000)   Loss 0.8577 (0.8577)   Prec@1 74.219 (74.219)   Prec@5 93.750 (93.750)   [2025-02-03 18:21:52]
  Epoch: [038][200/128]   Time 0.013 (0.016)   Data 0.000 (0.000)   Loss 0.9348 (0.9080)   Prec@1 74.219 (73.088)   Prec@5 93.750 (94.687)   [2025-02-03 18:21:55]
  **Train** Prec@1 72.086 Prec@5 94.182 Error@1 27.914
  **Test** Prec@1 58.100 Prec@5 85.450 Error@1 41.900
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:21:58] [Epoch=039/200] [Need: 00:16:40] [learning_rate=0.0909] [Best : Accuracy=61.78, Error=38.22]
  Epoch: [039][000/128]   Time 0.118 (0.118)   Data 0.000 (0.000)   Loss 0.8610 (0.8610)   Prec@1 74.219 (74.219)   Prec@5 92.969 (92.969)   [2025-02-03 18:21:58]
  Epoch: [039][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.0375 (0.8952)   Prec@1 72.656 (73.546)   Prec@5 91.406 (94.838)   [2025-02-03 18:22:01]
  **Train** Prec@1 72.450 Prec@5 94.384 Error@1 27.550
  **Test** Prec@1 57.810 Prec@5 85.300 Error@1 42.190
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:22:04] [Epoch=040/200] [Need: 00:16:34] [learning_rate=0.0905] [Best : Accuracy=61.78, Error=38.22]
  Epoch: [040][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.8594 (0.8594)   Prec@1 76.562 (76.562)   Prec@5 93.750 (93.750)   [2025-02-03 18:22:04]
  Epoch: [040][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 1.0639 (0.9006)   Prec@1 71.094 (73.286)   Prec@5 91.406 (94.671)   [2025-02-03 18:22:07]
  **Train** Prec@1 72.420 Prec@5 94.428 Error@1 27.580
  **Test** Prec@1 56.180 Prec@5 83.040 Error@1 43.820
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:22:11] [Epoch=041/200] [Need: 00:16:28] [learning_rate=0.0900] [Best : Accuracy=61.78, Error=38.22]
  Epoch: [041][000/128]   Time 0.113 (0.113)   Data 0.000 (0.000)   Loss 0.9831 (0.9831)   Prec@1 71.875 (71.875)   Prec@5 93.750 (93.750)   [2025-02-03 18:22:11]
  Epoch: [041][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 0.8859 (0.8756)   Prec@1 74.219 (73.651)   Prec@5 94.531 (94.967)   [2025-02-03 18:22:13]
  **Train** Prec@1 72.510 Prec@5 94.492 Error@1 27.490
  **Test** Prec@1 58.690 Prec@5 85.890 Error@1 41.310
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:22:17] [Epoch=042/200] [Need: 00:16:21] [learning_rate=0.0895] [Best : Accuracy=61.78, Error=38.22]
  Epoch: [042][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.7848 (0.7848)   Prec@1 75.000 (75.000)   Prec@5 96.875 (96.875)   [2025-02-03 18:22:17]
  Epoch: [042][200/128]   Time 0.014 (0.015)   Data 0.000 (0.000)   Loss 1.1431 (0.8757)   Prec@1 70.312 (73.951)   Prec@5 90.625 (95.176)   [2025-02-03 18:22:20]
  **Train** Prec@1 72.786 Prec@5 94.588 Error@1 27.214
  **Test** Prec@1 56.780 Prec@5 82.990 Error@1 43.220
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:22:23] [Epoch=043/200] [Need: 00:16:16] [learning_rate=0.0890] [Best : Accuracy=61.78, Error=38.22]
  Epoch: [043][000/128]   Time 0.124 (0.124)   Data 0.000 (0.000)   Loss 0.9341 (0.9341)   Prec@1 74.219 (74.219)   Prec@5 92.969 (92.969)   [2025-02-03 18:22:23]
  Epoch: [043][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 0.9577 (0.8690)   Prec@1 70.312 (73.803)   Prec@5 93.750 (95.355)   [2025-02-03 18:22:26]
  **Train** Prec@1 72.944 Prec@5 94.714 Error@1 27.056
  **Test** Prec@1 59.620 Prec@5 86.390 Error@1 40.380
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:22:29] [Epoch=044/200] [Need: 00:16:10] [learning_rate=0.0885] [Best : Accuracy=61.78, Error=38.22]
  Epoch: [044][000/128]   Time 0.125 (0.125)   Data 0.000 (0.000)   Loss 0.6929 (0.6929)   Prec@1 81.250 (81.250)   Prec@5 96.875 (96.875)   [2025-02-03 18:22:29]
  Epoch: [044][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.8529 (0.8530)   Prec@1 72.656 (74.607)   Prec@5 94.531 (95.176)   [2025-02-03 18:22:32]
  **Train** Prec@1 73.120 Prec@5 94.658 Error@1 26.880
  **Test** Prec@1 59.590 Prec@5 86.680 Error@1 40.410
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:22:36] [Epoch=045/200] [Need: 00:16:04] [learning_rate=0.0880] [Best : Accuracy=61.78, Error=38.22]
  Epoch: [045][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.7246 (0.7246)   Prec@1 76.562 (76.562)   Prec@5 96.875 (96.875)   [2025-02-03 18:22:36]
  Epoch: [045][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 0.8976 (0.8612)   Prec@1 70.312 (74.495)   Prec@5 94.531 (94.978)   [2025-02-03 18:22:39]
  **Train** Prec@1 73.604 Prec@5 94.596 Error@1 26.396
  **Test** Prec@1 58.710 Prec@5 85.700 Error@1 41.290
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:22:42] [Epoch=046/200] [Need: 00:15:58] [learning_rate=0.0875] [Best : Accuracy=61.78, Error=38.22]
  Epoch: [046][000/128]   Time 0.124 (0.124)   Data 0.000 (0.000)   Loss 0.7443 (0.7443)   Prec@1 75.781 (75.781)   Prec@5 97.656 (97.656)   [2025-02-03 18:22:42]
  Epoch: [046][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.7785 (0.8533)   Prec@1 77.344 (74.689)   Prec@5 95.312 (95.336)   [2025-02-03 18:22:45]
  **Train** Prec@1 73.514 Prec@5 94.874 Error@1 26.486
  **Test** Prec@1 58.760 Prec@5 84.950 Error@1 41.240
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:22:48] [Epoch=047/200] [Need: 00:15:52] [learning_rate=0.0870] [Best : Accuracy=61.78, Error=38.22]
  Epoch: [047][000/128]   Time 0.112 (0.112)   Data 0.000 (0.000)   Loss 0.8404 (0.8404)   Prec@1 74.219 (74.219)   Prec@5 98.438 (98.438)   [2025-02-03 18:22:48]
  Epoch: [047][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.7684 (0.8418)   Prec@1 78.125 (74.880)   Prec@5 96.094 (95.371)   [2025-02-03 18:22:51]
  **Train** Prec@1 73.692 Prec@5 94.894 Error@1 26.308
  **Test** Prec@1 59.570 Prec@5 86.580 Error@1 40.430
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:22:54] [Epoch=048/200] [Need: 00:15:45] [learning_rate=0.0864] [Best : Accuracy=61.78, Error=38.22]
  Epoch: [048][000/128]   Time 0.113 (0.113)   Data 0.000 (0.000)   Loss 0.8263 (0.8263)   Prec@1 75.000 (75.000)   Prec@5 95.312 (95.312)   [2025-02-03 18:22:54]
  Epoch: [048][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 1.1116 (0.8256)   Prec@1 70.312 (75.249)   Prec@5 94.531 (95.414)   [2025-02-03 18:22:57]
  **Train** Prec@1 73.670 Prec@5 94.898 Error@1 26.330
  **Test** Prec@1 60.570 Prec@5 87.680 Error@1 39.430
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:23:00] [Epoch=049/200] [Need: 00:15:39] [learning_rate=0.0859] [Best : Accuracy=61.78, Error=38.22]
  Epoch: [049][000/128]   Time 0.136 (0.136)   Data 0.000 (0.000)   Loss 0.8022 (0.8022)   Prec@1 78.906 (78.906)   Prec@5 95.312 (95.312)   [2025-02-03 18:23:01]
  Epoch: [049][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.9668 (0.8244)   Prec@1 73.438 (75.404)   Prec@5 93.750 (95.429)   [2025-02-03 18:23:03]
  **Train** Prec@1 74.064 Prec@5 94.908 Error@1 25.936
  **Test** Prec@1 60.380 Prec@5 87.020 Error@1 39.620
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:23:07] [Epoch=050/200] [Need: 00:15:32] [learning_rate=0.0854] [Best : Accuracy=61.78, Error=38.22]
  Epoch: [050][000/128]   Time 0.118 (0.118)   Data 0.000 (0.000)   Loss 0.6761 (0.6761)   Prec@1 78.125 (78.125)   Prec@5 96.875 (96.875)   [2025-02-03 18:23:07]
  Epoch: [050][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.8160 (0.8053)   Prec@1 71.875 (75.851)   Prec@5 97.656 (95.713)   [2025-02-03 18:23:09]
  **Train** Prec@1 74.350 Prec@5 95.122 Error@1 25.650
  **Test** Prec@1 58.140 Prec@5 84.640 Error@1 41.860
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:23:12] [Epoch=051/200] [Need: 00:15:25] [learning_rate=0.0848] [Best : Accuracy=61.78, Error=38.22]
  Epoch: [051][000/128]   Time 0.119 (0.119)   Data 0.000 (0.000)   Loss 0.8521 (0.8521)   Prec@1 75.000 (75.000)   Prec@5 93.750 (93.750)   [2025-02-03 18:23:13]
  Epoch: [051][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.8862 (0.8335)   Prec@1 73.438 (74.992)   Prec@5 96.094 (95.725)   [2025-02-03 18:23:15]
  **Train** Prec@1 73.778 Prec@5 95.146 Error@1 26.222
  **Test** Prec@1 62.840 Prec@5 88.290 Error@1 37.160
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:23:19] [Epoch=052/200] [Need: 00:15:19] [learning_rate=0.0842] [Best : Accuracy=62.84, Error=37.16]
  Epoch: [052][000/128]   Time 0.115 (0.115)   Data 0.000 (0.000)   Loss 0.5775 (0.5775)   Prec@1 83.594 (83.594)   Prec@5 97.656 (97.656)   [2025-02-03 18:23:19]
  Epoch: [052][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 0.8522 (0.8110)   Prec@1 74.219 (75.820)   Prec@5 95.312 (95.721)   [2025-02-03 18:23:22]
  **Train** Prec@1 74.878 Prec@5 95.186 Error@1 25.122
  **Test** Prec@1 60.420 Prec@5 86.920 Error@1 39.580
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:23:25] [Epoch=053/200] [Need: 00:15:13] [learning_rate=0.0837] [Best : Accuracy=62.84, Error=37.16]
  Epoch: [053][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 0.7978 (0.7978)   Prec@1 74.219 (74.219)   Prec@5 96.094 (96.094)   [2025-02-03 18:23:25]
  Epoch: [053][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.7798 (0.8079)   Prec@1 76.562 (75.987)   Prec@5 94.531 (95.775)   [2025-02-03 18:23:28]
  **Train** Prec@1 74.760 Prec@5 95.276 Error@1 25.240
  **Test** Prec@1 61.550 Prec@5 87.480 Error@1 38.450
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:23:31] [Epoch=054/200] [Need: 00:15:06] [learning_rate=0.0831] [Best : Accuracy=62.84, Error=37.16]
  Epoch: [054][000/128]   Time 0.128 (0.128)   Data 0.000 (0.000)   Loss 1.0059 (1.0059)   Prec@1 70.312 (70.312)   Prec@5 93.750 (93.750)   [2025-02-03 18:23:31]
  Epoch: [054][200/128]   Time 0.011 (0.014)   Data 0.000 (0.000)   Loss 0.8423 (0.8007)   Prec@1 78.906 (75.933)   Prec@5 92.969 (95.740)   [2025-02-03 18:23:34]
  **Train** Prec@1 74.646 Prec@5 95.258 Error@1 25.354
  **Test** Prec@1 63.180 Prec@5 88.480 Error@1 36.820
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:23:37] [Epoch=055/200] [Need: 00:15:00] [learning_rate=0.0825] [Best : Accuracy=63.18, Error=36.82]
  Epoch: [055][000/128]   Time 0.138 (0.138)   Data 0.000 (0.000)   Loss 0.7163 (0.7163)   Prec@1 80.469 (80.469)   Prec@5 96.094 (96.094)   [2025-02-03 18:23:37]
  Epoch: [055][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.6299 (0.7852)   Prec@1 79.688 (76.232)   Prec@5 98.438 (95.907)   [2025-02-03 18:23:40]
  **Train** Prec@1 74.980 Prec@5 95.424 Error@1 25.020
  **Test** Prec@1 57.770 Prec@5 84.930 Error@1 42.230
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:23:43] [Epoch=056/200] [Need: 00:14:54] [learning_rate=0.0819] [Best : Accuracy=63.18, Error=36.82]
  Epoch: [056][000/128]   Time 0.127 (0.127)   Data 0.000 (0.000)   Loss 0.8463 (0.8463)   Prec@1 78.906 (78.906)   Prec@5 92.188 (92.188)   [2025-02-03 18:23:44]
  Epoch: [056][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.5968 (0.7775)   Prec@1 82.812 (76.718)   Prec@5 95.312 (96.070)   [2025-02-03 18:23:46]
  **Train** Prec@1 75.360 Prec@5 95.586 Error@1 24.640
  **Test** Prec@1 60.170 Prec@5 86.670 Error@1 39.830
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:23:50] [Epoch=057/200] [Need: 00:14:47] [learning_rate=0.0813] [Best : Accuracy=63.18, Error=36.82]
  Epoch: [057][000/128]   Time 0.142 (0.142)   Data 0.000 (0.000)   Loss 0.6419 (0.6419)   Prec@1 81.250 (81.250)   Prec@5 97.656 (97.656)   [2025-02-03 18:23:50]
  Epoch: [057][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.8353 (0.7841)   Prec@1 73.438 (76.399)   Prec@5 94.531 (96.109)   [2025-02-03 18:23:52]
  **Train** Prec@1 75.268 Prec@5 95.584 Error@1 24.732
  **Test** Prec@1 62.600 Prec@5 87.980 Error@1 37.400
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:23:56] [Epoch=058/200] [Need: 00:14:41] [learning_rate=0.0806] [Best : Accuracy=63.18, Error=36.82]
  Epoch: [058][000/128]   Time 0.134 (0.134)   Data 0.000 (0.000)   Loss 0.8393 (0.8393)   Prec@1 75.781 (75.781)   Prec@5 93.750 (93.750)   [2025-02-03 18:23:56]
  Epoch: [058][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.7590 (0.7770)   Prec@1 77.344 (76.753)   Prec@5 96.875 (96.113)   [2025-02-03 18:23:59]
  **Train** Prec@1 75.702 Prec@5 95.650 Error@1 24.298
  **Test** Prec@1 62.400 Prec@5 87.800 Error@1 37.600
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:24:02] [Epoch=059/200] [Need: 00:14:35] [learning_rate=0.0800] [Best : Accuracy=63.18, Error=36.82]
  Epoch: [059][000/128]   Time 0.119 (0.119)   Data 0.000 (0.000)   Loss 0.6575 (0.6575)   Prec@1 79.688 (79.688)   Prec@5 96.094 (96.094)   [2025-02-03 18:24:02]
  Epoch: [059][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.8196 (0.7652)   Prec@1 77.344 (77.262)   Prec@5 96.875 (96.156)   [2025-02-03 18:24:05]
  **Train** Prec@1 75.542 Prec@5 95.736 Error@1 24.458
  **Test** Prec@1 59.980 Prec@5 86.500 Error@1 40.020
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:24:08] [Epoch=060/200] [Need: 00:14:29] [learning_rate=0.0794] [Best : Accuracy=63.18, Error=36.82]
  Epoch: [060][000/128]   Time 0.135 (0.135)   Data 0.000 (0.000)   Loss 0.6471 (0.6471)   Prec@1 78.125 (78.125)   Prec@5 100.000 (100.000)   [2025-02-03 18:24:09]
  Epoch: [060][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.8802 (0.7628)   Prec@1 73.438 (77.076)   Prec@5 95.312 (96.113)   [2025-02-03 18:24:11]
  **Train** Prec@1 75.922 Prec@5 95.704 Error@1 24.078
  **Test** Prec@1 61.070 Prec@5 87.640 Error@1 38.930
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:24:14] [Epoch=061/200] [Need: 00:14:23] [learning_rate=0.0788] [Best : Accuracy=63.18, Error=36.82]
  Epoch: [061][000/128]   Time 0.119 (0.119)   Data 0.000 (0.000)   Loss 0.7838 (0.7838)   Prec@1 78.125 (78.125)   Prec@5 94.531 (94.531)   [2025-02-03 18:24:15]
  Epoch: [061][200/128]   Time 0.016 (0.014)   Data 0.000 (0.000)   Loss 0.8606 (0.7582)   Prec@1 76.562 (77.146)   Prec@5 92.969 (96.140)   [2025-02-03 18:24:17]
  **Train** Prec@1 76.202 Prec@5 95.906 Error@1 23.798
  **Test** Prec@1 62.720 Prec@5 88.320 Error@1 37.280
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:24:21] [Epoch=062/200] [Need: 00:14:16] [learning_rate=0.0781] [Best : Accuracy=63.18, Error=36.82]
  Epoch: [062][000/128]   Time 0.126 (0.126)   Data 0.000 (0.000)   Loss 0.6276 (0.6276)   Prec@1 81.250 (81.250)   Prec@5 96.094 (96.094)   [2025-02-03 18:24:21]
  Epoch: [062][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 0.8544 (0.7422)   Prec@1 75.000 (77.767)   Prec@5 96.094 (96.389)   [2025-02-03 18:24:24]
  **Train** Prec@1 76.268 Prec@5 95.878 Error@1 23.732
  **Test** Prec@1 58.870 Prec@5 85.540 Error@1 41.130
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:24:27] [Epoch=063/200] [Need: 00:14:10] [learning_rate=0.0775] [Best : Accuracy=63.18, Error=36.82]
  Epoch: [063][000/128]   Time 0.128 (0.128)   Data 0.000 (0.000)   Loss 0.5596 (0.5596)   Prec@1 81.250 (81.250)   Prec@5 97.656 (97.656)   [2025-02-03 18:24:27]
  Epoch: [063][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.8486 (0.7487)   Prec@1 73.438 (77.721)   Prec@5 96.094 (96.397)   [2025-02-03 18:24:30]
  **Train** Prec@1 76.602 Prec@5 95.992 Error@1 23.398
  **Test** Prec@1 62.400 Prec@5 88.040 Error@1 37.600
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:24:33] [Epoch=064/200] [Need: 00:14:04] [learning_rate=0.0768] [Best : Accuracy=63.18, Error=36.82]
  Epoch: [064][000/128]   Time 0.114 (0.114)   Data 0.000 (0.000)   Loss 0.7060 (0.7060)   Prec@1 77.344 (77.344)   Prec@5 94.531 (94.531)   [2025-02-03 18:24:33]
  Epoch: [064][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.8639 (0.7306)   Prec@1 72.656 (77.787)   Prec@5 95.312 (96.455)   [2025-02-03 18:24:36]
  **Train** Prec@1 76.570 Prec@5 96.018 Error@1 23.430
  **Test** Prec@1 61.590 Prec@5 86.860 Error@1 38.410
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:24:39] [Epoch=065/200] [Need: 00:13:58] [learning_rate=0.0761] [Best : Accuracy=63.18, Error=36.82]
  Epoch: [065][000/128]   Time 0.140 (0.140)   Data 0.000 (0.000)   Loss 0.6756 (0.6756)   Prec@1 81.250 (81.250)   Prec@5 99.219 (99.219)   [2025-02-03 18:24:40]
  Epoch: [065][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 0.8182 (0.7291)   Prec@1 77.344 (77.865)   Prec@5 93.750 (96.552)   [2025-02-03 18:24:42]
  **Train** Prec@1 77.038 Prec@5 96.198 Error@1 22.962
  **Test** Prec@1 60.880 Prec@5 86.540 Error@1 39.120
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:24:46] [Epoch=066/200] [Need: 00:13:52] [learning_rate=0.0755] [Best : Accuracy=63.18, Error=36.82]
  Epoch: [066][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.5767 (0.5767)   Prec@1 80.469 (80.469)   Prec@5 97.656 (97.656)   [2025-02-03 18:24:46]
  Epoch: [066][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.7668 (0.7191)   Prec@1 75.000 (78.144)   Prec@5 98.438 (96.673)   [2025-02-03 18:24:48]
  **Train** Prec@1 76.784 Prec@5 96.116 Error@1 23.216
  **Test** Prec@1 63.240 Prec@5 87.820 Error@1 36.760
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:24:52] [Epoch=067/200] [Need: 00:13:45] [learning_rate=0.0748] [Best : Accuracy=63.24, Error=36.76]
  Epoch: [067][000/128]   Time 0.117 (0.117)   Data 0.000 (0.000)   Loss 0.6955 (0.6955)   Prec@1 77.344 (77.344)   Prec@5 97.656 (97.656)   [2025-02-03 18:24:52]
  Epoch: [067][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.7564 (0.7040)   Prec@1 76.562 (78.646)   Prec@5 96.094 (96.824)   [2025-02-03 18:24:54]
  **Train** Prec@1 77.176 Prec@5 96.288 Error@1 22.824
  **Test** Prec@1 61.630 Prec@5 87.710 Error@1 38.370
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:24:58] [Epoch=068/200] [Need: 00:13:39] [learning_rate=0.0741] [Best : Accuracy=63.24, Error=36.76]
  Epoch: [068][000/128]   Time 0.128 (0.128)   Data 0.000 (0.000)   Loss 0.7233 (0.7233)   Prec@1 77.344 (77.344)   Prec@5 97.656 (97.656)   [2025-02-03 18:24:58]
  Epoch: [068][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.7807 (0.7078)   Prec@1 75.000 (78.626)   Prec@5 93.750 (96.789)   [2025-02-03 18:25:01]
  **Train** Prec@1 77.552 Prec@5 96.396 Error@1 22.448
  **Test** Prec@1 64.190 Prec@5 88.900 Error@1 35.810
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:25:04] [Epoch=069/200] [Need: 00:13:33] [learning_rate=0.0734] [Best : Accuracy=64.19, Error=35.81]
  Epoch: [069][000/128]   Time 0.149 (0.149)   Data 0.000 (0.000)   Loss 0.7124 (0.7124)   Prec@1 79.688 (79.688)   Prec@5 96.094 (96.094)   [2025-02-03 18:25:04]
  Epoch: [069][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 0.8486 (0.7027)   Prec@1 73.438 (78.642)   Prec@5 95.312 (96.988)   [2025-02-03 18:25:07]
  **Train** Prec@1 77.506 Prec@5 96.400 Error@1 22.494
  **Test** Prec@1 63.660 Prec@5 88.440 Error@1 36.340
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:25:10] [Epoch=070/200] [Need: 00:13:26] [learning_rate=0.0727] [Best : Accuracy=64.19, Error=35.81]
  Epoch: [070][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.6428 (0.6428)   Prec@1 78.125 (78.125)   Prec@5 96.094 (96.094)   [2025-02-03 18:25:10]
  Epoch: [070][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.7522 (0.7015)   Prec@1 80.469 (78.599)   Prec@5 94.531 (96.898)   [2025-02-03 18:25:13]
  **Train** Prec@1 77.654 Prec@5 96.460 Error@1 22.346
  **Test** Prec@1 62.240 Prec@5 88.210 Error@1 37.760
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:25:16] [Epoch=071/200] [Need: 00:13:20] [learning_rate=0.0720] [Best : Accuracy=64.19, Error=35.81]
  Epoch: [071][000/128]   Time 0.147 (0.147)   Data 0.000 (0.000)   Loss 0.4873 (0.4873)   Prec@1 84.375 (84.375)   Prec@5 98.438 (98.438)   [2025-02-03 18:25:16]
  Epoch: [071][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.7621 (0.6778)   Prec@1 76.562 (79.555)   Prec@5 96.094 (96.972)   [2025-02-03 18:25:19]
  **Train** Prec@1 78.046 Prec@5 96.488 Error@1 21.954
  **Test** Prec@1 63.510 Prec@5 88.440 Error@1 36.490
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:25:22] [Epoch=072/200] [Need: 00:13:14] [learning_rate=0.0713] [Best : Accuracy=64.19, Error=35.81]
  Epoch: [072][000/128]   Time 0.137 (0.137)   Data 0.000 (0.000)   Loss 0.9403 (0.9403)   Prec@1 71.875 (71.875)   Prec@5 95.312 (95.312)   [2025-02-03 18:25:23]
  Epoch: [072][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.8053 (0.6843)   Prec@1 76.562 (79.384)   Prec@5 95.312 (96.836)   [2025-02-03 18:25:25]
  **Train** Prec@1 78.304 Prec@5 96.564 Error@1 21.696
  **Test** Prec@1 61.370 Prec@5 87.480 Error@1 38.630
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:25:29] [Epoch=073/200] [Need: 00:13:07] [learning_rate=0.0706] [Best : Accuracy=64.19, Error=35.81]
  Epoch: [073][000/128]   Time 0.119 (0.119)   Data 0.000 (0.000)   Loss 0.6588 (0.6588)   Prec@1 73.438 (73.438)   Prec@5 98.438 (98.438)   [2025-02-03 18:25:29]
  Epoch: [073][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.5653 (0.6908)   Prec@1 84.375 (79.069)   Prec@5 98.438 (96.995)   [2025-02-03 18:25:31]
  **Train** Prec@1 77.918 Prec@5 96.686 Error@1 22.082
  **Test** Prec@1 63.540 Prec@5 88.410 Error@1 36.460
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:25:35] [Epoch=074/200] [Need: 00:13:01] [learning_rate=0.0699] [Best : Accuracy=64.19, Error=35.81]
  Epoch: [074][000/128]   Time 0.119 (0.119)   Data 0.000 (0.000)   Loss 0.6854 (0.6854)   Prec@1 83.594 (83.594)   Prec@5 96.875 (96.875)   [2025-02-03 18:25:35]
  Epoch: [074][200/128]   Time 0.012 (0.014)   Data 0.000 (0.000)   Loss 0.7432 (0.6545)   Prec@1 78.906 (80.181)   Prec@5 96.094 (97.287)   [2025-02-03 18:25:37]
  **Train** Prec@1 78.822 Prec@5 96.798 Error@1 21.178
  **Test** Prec@1 61.540 Prec@5 86.850 Error@1 38.460
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:25:41] [Epoch=075/200] [Need: 00:12:55] [learning_rate=0.0691] [Best : Accuracy=64.19, Error=35.81]
  Epoch: [075][000/128]   Time 0.129 (0.129)   Data 0.000 (0.000)   Loss 0.7258 (0.7258)   Prec@1 78.906 (78.906)   Prec@5 97.656 (97.656)   [2025-02-03 18:25:41]
  Epoch: [075][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.5467 (0.6453)   Prec@1 82.031 (80.255)   Prec@5 99.219 (97.551)   [2025-02-03 18:25:44]
  **Train** Prec@1 78.816 Prec@5 96.998 Error@1 21.184
  **Test** Prec@1 63.450 Prec@5 88.490 Error@1 36.550
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:25:47] [Epoch=076/200] [Need: 00:12:49] [learning_rate=0.0684] [Best : Accuracy=64.19, Error=35.81]
  Epoch: [076][000/128]   Time 0.113 (0.113)   Data 0.000 (0.000)   Loss 0.5569 (0.5569)   Prec@1 84.375 (84.375)   Prec@5 99.219 (99.219)   [2025-02-03 18:25:47]
  Epoch: [076][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.5402 (0.6522)   Prec@1 84.375 (80.348)   Prec@5 99.219 (97.279)   [2025-02-03 18:25:50]
  **Train** Prec@1 79.110 Prec@5 96.956 Error@1 20.890
  **Test** Prec@1 63.280 Prec@5 88.090 Error@1 36.720
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:25:53] [Epoch=077/200] [Need: 00:12:43] [learning_rate=0.0677] [Best : Accuracy=64.19, Error=35.81]
  Epoch: [077][000/128]   Time 0.125 (0.125)   Data 0.000 (0.000)   Loss 0.6846 (0.6846)   Prec@1 80.469 (80.469)   Prec@5 96.875 (96.875)   [2025-02-03 18:25:53]
  Epoch: [077][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.5239 (0.6201)   Prec@1 80.469 (80.912)   Prec@5 100.000 (97.559)   [2025-02-03 18:25:56]
  **Train** Prec@1 79.246 Prec@5 96.986 Error@1 20.754
  **Test** Prec@1 61.760 Prec@5 88.140 Error@1 38.240
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:25:59] [Epoch=078/200] [Need: 00:12:36] [learning_rate=0.0669] [Best : Accuracy=64.19, Error=35.81]
  Epoch: [078][000/128]   Time 0.117 (0.117)   Data 0.000 (0.000)   Loss 0.5880 (0.5880)   Prec@1 82.031 (82.031)   Prec@5 99.219 (99.219)   [2025-02-03 18:26:00]
  Epoch: [078][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.5619 (0.6171)   Prec@1 83.594 (81.145)   Prec@5 96.094 (97.551)   [2025-02-03 18:26:02]
  **Train** Prec@1 79.456 Prec@5 97.032 Error@1 20.544
  **Test** Prec@1 61.660 Prec@5 87.900 Error@1 38.340
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:26:06] [Epoch=079/200] [Need: 00:12:30] [learning_rate=0.0662] [Best : Accuracy=64.19, Error=35.81]
  Epoch: [079][000/128]   Time 0.132 (0.132)   Data 0.000 (0.000)   Loss 0.6051 (0.6051)   Prec@1 78.906 (78.906)   Prec@5 99.219 (99.219)   [2025-02-03 18:26:06]
  Epoch: [079][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.6435 (0.6371)   Prec@1 79.688 (80.663)   Prec@5 97.656 (97.396)   [2025-02-03 18:26:08]
  **Train** Prec@1 79.346 Prec@5 97.146 Error@1 20.654
  **Test** Prec@1 64.090 Prec@5 88.840 Error@1 35.910
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:26:12] [Epoch=080/200] [Need: 00:12:24] [learning_rate=0.0655] [Best : Accuracy=64.19, Error=35.81]
  Epoch: [080][000/128]   Time 0.115 (0.115)   Data 0.000 (0.000)   Loss 0.5886 (0.5886)   Prec@1 83.594 (83.594)   Prec@5 99.219 (99.219)   [2025-02-03 18:26:12]
  Epoch: [080][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.7741 (0.6305)   Prec@1 77.344 (80.854)   Prec@5 96.094 (97.446)   [2025-02-03 18:26:15]
  **Train** Prec@1 79.866 Prec@5 97.152 Error@1 20.134
  **Test** Prec@1 63.980 Prec@5 88.640 Error@1 36.020
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:26:18] [Epoch=081/200] [Need: 00:12:17] [learning_rate=0.0647] [Best : Accuracy=64.19, Error=35.81]
  Epoch: [081][000/128]   Time 0.109 (0.109)   Data 0.000 (0.000)   Loss 0.9707 (0.9707)   Prec@1 71.875 (71.875)   Prec@5 96.094 (96.094)   [2025-02-03 18:26:18]
  Epoch: [081][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.7425 (0.5941)   Prec@1 77.344 (81.666)   Prec@5 96.875 (97.676)   [2025-02-03 18:26:21]
  **Train** Prec@1 80.084 Prec@5 97.316 Error@1 19.916
  **Test** Prec@1 64.010 Prec@5 88.440 Error@1 35.990
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:26:24] [Epoch=082/200] [Need: 00:12:11] [learning_rate=0.0639] [Best : Accuracy=64.19, Error=35.81]
  Epoch: [082][000/128]   Time 0.148 (0.148)   Data 0.000 (0.000)   Loss 0.4900 (0.4900)   Prec@1 82.031 (82.031)   Prec@5 99.219 (99.219)   [2025-02-03 18:26:24]
  Epoch: [082][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.6656 (0.6000)   Prec@1 79.688 (81.794)   Prec@5 95.312 (97.641)   [2025-02-03 18:26:27]
  **Train** Prec@1 80.436 Prec@5 97.274 Error@1 19.564
  **Test** Prec@1 62.480 Prec@5 87.880 Error@1 37.520
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:26:30] [Epoch=083/200] [Need: 00:12:05] [learning_rate=0.0632] [Best : Accuracy=64.19, Error=35.81]
  Epoch: [083][000/128]   Time 0.124 (0.124)   Data 0.000 (0.000)   Loss 0.6448 (0.6448)   Prec@1 79.688 (79.688)   Prec@5 96.875 (96.875)   [2025-02-03 18:26:30]
  Epoch: [083][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 0.6441 (0.5971)   Prec@1 80.469 (81.499)   Prec@5 98.438 (97.897)   [2025-02-03 18:26:33]
  **Train** Prec@1 80.328 Prec@5 97.414 Error@1 19.672
  **Test** Prec@1 60.850 Prec@5 87.060 Error@1 39.150
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:26:36] [Epoch=084/200] [Need: 00:11:59] [learning_rate=0.0624] [Best : Accuracy=64.19, Error=35.81]
  Epoch: [084][000/128]   Time 0.117 (0.117)   Data 0.000 (0.000)   Loss 0.4465 (0.4465)   Prec@1 85.156 (85.156)   Prec@5 99.219 (99.219)   [2025-02-03 18:26:37]
  Epoch: [084][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.6443 (0.5850)   Prec@1 76.562 (82.055)   Prec@5 97.656 (97.882)   [2025-02-03 18:26:39]
  **Train** Prec@1 80.822 Prec@5 97.482 Error@1 19.178
  **Test** Prec@1 62.600 Prec@5 88.080 Error@1 37.400
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:26:43] [Epoch=085/200] [Need: 00:11:52] [learning_rate=0.0617] [Best : Accuracy=64.19, Error=35.81]
  Epoch: [085][000/128]   Time 0.132 (0.132)   Data 0.000 (0.000)   Loss 0.4709 (0.4709)   Prec@1 84.375 (84.375)   Prec@5 99.219 (99.219)   [2025-02-03 18:26:43]
  Epoch: [085][200/128]   Time 0.015 (0.017)   Data 0.000 (0.000)   Loss 0.6728 (0.5875)   Prec@1 83.594 (81.825)   Prec@5 95.312 (97.827)   [2025-02-03 18:26:46]
  **Train** Prec@1 80.952 Prec@5 97.602 Error@1 19.048
  **Test** Prec@1 60.520 Prec@5 87.250 Error@1 39.480
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:26:49] [Epoch=086/200] [Need: 00:11:47] [learning_rate=0.0609] [Best : Accuracy=64.19, Error=35.81]
  Epoch: [086][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.5449 (0.5449)   Prec@1 85.156 (85.156)   Prec@5 97.656 (97.656)   [2025-02-03 18:26:49]
  Epoch: [086][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.8420 (0.5706)   Prec@1 70.312 (82.459)   Prec@5 96.094 (97.956)   [2025-02-03 18:26:52]
  **Train** Prec@1 81.122 Prec@5 97.602 Error@1 18.878
  **Test** Prec@1 64.360 Prec@5 88.510 Error@1 35.640
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:26:55] [Epoch=087/200] [Need: 00:11:40] [learning_rate=0.0601] [Best : Accuracy=64.36, Error=35.64]
  Epoch: [087][000/128]   Time 0.119 (0.119)   Data 0.000 (0.000)   Loss 0.4864 (0.4864)   Prec@1 89.844 (89.844)   Prec@5 98.438 (98.438)   [2025-02-03 18:26:55]
  Epoch: [087][200/128]   Time 0.011 (0.014)   Data 0.000 (0.000)   Loss 0.5800 (0.5426)   Prec@1 81.250 (83.469)   Prec@5 98.438 (98.317)   [2025-02-03 18:26:58]
  **Train** Prec@1 81.860 Prec@5 97.880 Error@1 18.140
  **Test** Prec@1 63.360 Prec@5 87.750 Error@1 36.640
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:27:01] [Epoch=088/200] [Need: 00:11:34] [learning_rate=0.0594] [Best : Accuracy=64.36, Error=35.64]
  Epoch: [088][000/128]   Time 0.111 (0.111)   Data 0.000 (0.000)   Loss 0.4756 (0.4756)   Prec@1 82.031 (82.031)   Prec@5 97.656 (97.656)   [2025-02-03 18:27:01]
  Epoch: [088][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.7346 (0.5417)   Prec@1 75.000 (83.306)   Prec@5 97.656 (98.208)   [2025-02-03 18:27:04]
  **Train** Prec@1 81.834 Prec@5 97.766 Error@1 18.166
  **Test** Prec@1 62.710 Prec@5 87.810 Error@1 37.290
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:27:07] [Epoch=089/200] [Need: 00:11:28] [learning_rate=0.0586] [Best : Accuracy=64.36, Error=35.64]
  Epoch: [089][000/128]   Time 0.118 (0.118)   Data 0.000 (0.000)   Loss 0.5200 (0.5200)   Prec@1 84.375 (84.375)   Prec@5 97.656 (97.656)   [2025-02-03 18:27:08]
  Epoch: [089][200/128]   Time 0.058 (0.014)   Data 0.000 (0.000)   Loss 0.5469 (0.5244)   Prec@1 85.938 (83.738)   Prec@5 99.219 (98.375)   [2025-02-03 18:27:10]
  **Train** Prec@1 82.014 Prec@5 97.872 Error@1 17.986
  **Test** Prec@1 65.070 Prec@5 89.260 Error@1 34.930
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:27:14] [Epoch=090/200] [Need: 00:11:21] [learning_rate=0.0578] [Best : Accuracy=65.07, Error=34.93]
  Epoch: [090][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 0.4680 (0.4680)   Prec@1 84.375 (84.375)   Prec@5 97.656 (97.656)   [2025-02-03 18:27:14]
  Epoch: [090][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.6356 (0.5369)   Prec@1 79.688 (83.462)   Prec@5 97.656 (98.197)   [2025-02-03 18:27:16]
  **Train** Prec@1 82.170 Prec@5 97.888 Error@1 17.830
  **Test** Prec@1 62.610 Prec@5 88.080 Error@1 37.390
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:27:20] [Epoch=091/200] [Need: 00:11:15] [learning_rate=0.0570] [Best : Accuracy=65.07, Error=34.93]
  Epoch: [091][000/128]   Time 0.151 (0.151)   Data 0.000 (0.000)   Loss 0.5718 (0.5718)   Prec@1 78.906 (78.906)   Prec@5 100.000 (100.000)   [2025-02-03 18:27:20]
  Epoch: [091][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.6214 (0.5086)   Prec@1 82.812 (84.332)   Prec@5 97.656 (98.465)   [2025-02-03 18:27:22]
  **Train** Prec@1 82.730 Prec@5 97.990 Error@1 17.270
  **Test** Prec@1 65.510 Prec@5 89.280 Error@1 34.490
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:27:26] [Epoch=092/200] [Need: 00:11:09] [learning_rate=0.0563] [Best : Accuracy=65.51, Error=34.49]
  Epoch: [092][000/128]   Time 0.115 (0.115)   Data 0.000 (0.000)   Loss 0.6572 (0.6572)   Prec@1 80.469 (80.469)   Prec@5 97.656 (97.656)   [2025-02-03 18:27:26]
  Epoch: [092][200/128]   Time 0.014 (0.015)   Data 0.000 (0.000)   Loss 0.6333 (0.5079)   Prec@1 78.125 (84.519)   Prec@5 98.438 (98.414)   [2025-02-03 18:27:29]
  **Train** Prec@1 83.390 Prec@5 98.098 Error@1 16.610
  **Test** Prec@1 64.640 Prec@5 89.150 Error@1 35.360
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:27:32] [Epoch=093/200] [Need: 00:11:03] [learning_rate=0.0555] [Best : Accuracy=65.51, Error=34.49]
  Epoch: [093][000/128]   Time 0.116 (0.116)   Data 0.000 (0.000)   Loss 0.3107 (0.3107)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2025-02-03 18:27:32]
  Epoch: [093][200/128]   Time 0.015 (0.014)   Data 0.000 (0.000)   Loss 0.5262 (0.5240)   Prec@1 82.031 (83.773)   Prec@5 98.438 (98.395)   [2025-02-03 18:27:35]
  **Train** Prec@1 82.742 Prec@5 98.090 Error@1 17.258
  **Test** Prec@1 61.570 Prec@5 86.800 Error@1 38.430
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:27:38] [Epoch=094/200] [Need: 00:10:57] [learning_rate=0.0547] [Best : Accuracy=65.51, Error=34.49]
  Epoch: [094][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 0.6093 (0.6093)   Prec@1 84.375 (84.375)   Prec@5 97.656 (97.656)   [2025-02-03 18:27:38]
  Epoch: [094][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.6115 (0.5018)   Prec@1 82.031 (84.527)   Prec@5 97.656 (98.511)   [2025-02-03 18:27:41]
  **Train** Prec@1 83.104 Prec@5 98.156 Error@1 16.896
  **Test** Prec@1 65.640 Prec@5 89.400 Error@1 34.360
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:27:44] [Epoch=095/200] [Need: 00:10:50] [learning_rate=0.0539] [Best : Accuracy=65.64, Error=34.36]
  Epoch: [095][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.6188 (0.6188)   Prec@1 85.156 (85.156)   Prec@5 97.656 (97.656)   [2025-02-03 18:27:45]
  Epoch: [095][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.5294 (0.4881)   Prec@1 83.594 (84.861)   Prec@5 99.219 (98.663)   [2025-02-03 18:27:47]
  **Train** Prec@1 83.674 Prec@5 98.294 Error@1 16.326
  **Test** Prec@1 65.660 Prec@5 90.140 Error@1 34.340
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:27:51] [Epoch=096/200] [Need: 00:10:44] [learning_rate=0.0531] [Best : Accuracy=65.66, Error=34.34]
  Epoch: [096][000/128]   Time 0.118 (0.118)   Data 0.000 (0.000)   Loss 0.4112 (0.4112)   Prec@1 87.500 (87.500)   Prec@5 97.656 (97.656)   [2025-02-03 18:27:51]
  Epoch: [096][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.5698 (0.4730)   Prec@1 82.812 (85.491)   Prec@5 98.438 (98.702)   [2025-02-03 18:27:53]
  **Train** Prec@1 84.168 Prec@5 98.444 Error@1 15.832
  **Test** Prec@1 62.590 Prec@5 87.550 Error@1 37.410
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:27:57] [Epoch=097/200] [Need: 00:10:38] [learning_rate=0.0524] [Best : Accuracy=65.66, Error=34.34]
  Epoch: [097][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 0.4128 (0.4128)   Prec@1 87.500 (87.500)   Prec@5 99.219 (99.219)   [2025-02-03 18:27:57]
  Epoch: [097][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.4699 (0.4696)   Prec@1 85.156 (85.580)   Prec@5 100.000 (98.725)   [2025-02-03 18:28:00]
  **Train** Prec@1 84.124 Prec@5 98.432 Error@1 15.876
  **Test** Prec@1 64.250 Prec@5 89.030 Error@1 35.750
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:28:03] [Epoch=098/200] [Need: 00:10:32] [learning_rate=0.0516] [Best : Accuracy=65.66, Error=34.34]
  Epoch: [098][000/128]   Time 0.125 (0.125)   Data 0.000 (0.000)   Loss 0.3673 (0.3673)   Prec@1 87.500 (87.500)   Prec@5 99.219 (99.219)   [2025-02-03 18:28:03]
  Epoch: [098][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.5595 (0.4604)   Prec@1 82.812 (85.673)   Prec@5 98.438 (98.764)   [2025-02-03 18:28:06]
  **Train** Prec@1 84.534 Prec@5 98.518 Error@1 15.466
  **Test** Prec@1 65.260 Prec@5 88.620 Error@1 34.740
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:28:09] [Epoch=099/200] [Need: 00:10:25] [learning_rate=0.0508] [Best : Accuracy=65.66, Error=34.34]
  Epoch: [099][000/128]   Time 0.128 (0.128)   Data 0.000 (0.000)   Loss 0.3950 (0.3950)   Prec@1 86.719 (86.719)   Prec@5 97.656 (97.656)   [2025-02-03 18:28:09]
  Epoch: [099][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.4873 (0.4624)   Prec@1 85.156 (85.689)   Prec@5 99.219 (98.826)   [2025-02-03 18:28:12]
  **Train** Prec@1 84.544 Prec@5 98.572 Error@1 15.456
  **Test** Prec@1 66.340 Prec@5 89.620 Error@1 33.660
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:28:16] [Epoch=100/200] [Need: 00:10:19] [learning_rate=0.0500] [Best : Accuracy=66.34, Error=33.66]
  Epoch: [100][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.4005 (0.4005)   Prec@1 88.281 (88.281)   Prec@5 100.000 (100.000)   [2025-02-03 18:28:16]
  Epoch: [100][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.7143 (0.4366)   Prec@1 79.688 (86.427)   Prec@5 96.875 (98.888)   [2025-02-03 18:28:18]
  **Train** Prec@1 85.378 Prec@5 98.614 Error@1 14.622
  **Test** Prec@1 66.280 Prec@5 89.170 Error@1 33.720
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:28:22] [Epoch=101/200] [Need: 00:10:13] [learning_rate=0.0492] [Best : Accuracy=66.34, Error=33.66]
  Epoch: [101][000/128]   Time 0.139 (0.139)   Data 0.000 (0.000)   Loss 0.4199 (0.4199)   Prec@1 85.938 (85.938)   Prec@5 99.219 (99.219)   [2025-02-03 18:28:22]
  Epoch: [101][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.5246 (0.4360)   Prec@1 81.250 (86.501)   Prec@5 97.656 (99.013)   [2025-02-03 18:28:24]
  **Train** Prec@1 85.104 Prec@5 98.654 Error@1 14.896
  **Test** Prec@1 63.680 Prec@5 88.390 Error@1 36.320
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:28:28] [Epoch=102/200] [Need: 00:10:07] [learning_rate=0.0484] [Best : Accuracy=66.34, Error=33.66]
  Epoch: [102][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.5209 (0.5209)   Prec@1 83.594 (83.594)   Prec@5 98.438 (98.438)   [2025-02-03 18:28:28]
  Epoch: [102][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.4051 (0.4307)   Prec@1 85.938 (86.859)   Prec@5 98.438 (98.986)   [2025-02-03 18:28:31]
  **Train** Prec@1 85.868 Prec@5 98.732 Error@1 14.132
  **Test** Prec@1 64.210 Prec@5 87.610 Error@1 35.790
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:28:34] [Epoch=103/200] [Need: 00:10:01] [learning_rate=0.0476] [Best : Accuracy=66.34, Error=33.66]
  Epoch: [103][000/128]   Time 0.372 (0.372)   Data 0.000 (0.000)   Loss 0.3855 (0.3855)   Prec@1 85.938 (85.938)   Prec@5 98.438 (98.438)   [2025-02-03 18:28:34]
  Epoch: [103][200/128]   Time 0.013 (0.016)   Data 0.000 (0.000)   Loss 0.4965 (0.4185)   Prec@1 83.594 (87.158)   Prec@5 99.219 (99.001)   [2025-02-03 18:28:37]
  **Train** Prec@1 85.858 Prec@5 98.748 Error@1 14.142
  **Test** Prec@1 63.310 Prec@5 87.240 Error@1 36.690
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:28:41] [Epoch=104/200] [Need: 00:09:55] [learning_rate=0.0469] [Best : Accuracy=66.34, Error=33.66]
  Epoch: [104][000/128]   Time 0.155 (0.155)   Data 0.000 (0.000)   Loss 0.4601 (0.4601)   Prec@1 85.938 (85.938)   Prec@5 100.000 (100.000)   [2025-02-03 18:28:41]
  Epoch: [104][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.4515 (0.3986)   Prec@1 86.719 (87.815)   Prec@5 97.656 (99.071)   [2025-02-03 18:28:44]
  **Train** Prec@1 86.392 Prec@5 98.842 Error@1 13.608
  **Test** Prec@1 62.250 Prec@5 87.840 Error@1 37.750
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:28:47] [Epoch=105/200] [Need: 00:09:49] [learning_rate=0.0461] [Best : Accuracy=66.34, Error=33.66]
  Epoch: [105][000/128]   Time 0.126 (0.126)   Data 0.000 (0.000)   Loss 0.3961 (0.3961)   Prec@1 86.719 (86.719)   Prec@5 99.219 (99.219)   [2025-02-03 18:28:47]
  Epoch: [105][200/128]   Time 0.011 (0.014)   Data 0.000 (0.000)   Loss 0.4253 (0.4139)   Prec@1 89.062 (86.960)   Prec@5 98.438 (99.059)   [2025-02-03 18:28:50]
  **Train** Prec@1 85.876 Prec@5 98.790 Error@1 14.124
  **Test** Prec@1 65.970 Prec@5 89.010 Error@1 34.030
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:28:53] [Epoch=106/200] [Need: 00:09:43] [learning_rate=0.0453] [Best : Accuracy=66.34, Error=33.66]
  Epoch: [106][000/128]   Time 0.116 (0.116)   Data 0.000 (0.000)   Loss 0.4932 (0.4932)   Prec@1 85.938 (85.938)   Prec@5 95.312 (95.312)   [2025-02-03 18:28:53]
  Epoch: [106][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.4802 (0.4038)   Prec@1 83.594 (87.496)   Prec@5 100.000 (99.075)   [2025-02-03 18:28:56]
  **Train** Prec@1 86.586 Prec@5 98.910 Error@1 13.414
  **Test** Prec@1 66.850 Prec@5 89.960 Error@1 33.150
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:28:59] [Epoch=107/200] [Need: 00:09:36] [learning_rate=0.0445] [Best : Accuracy=66.85, Error=33.15]
  Epoch: [107][000/128]   Time 0.118 (0.118)   Data 0.000 (0.000)   Loss 0.4309 (0.4309)   Prec@1 91.406 (91.406)   Prec@5 96.875 (96.875)   [2025-02-03 18:29:00]
  Epoch: [107][200/128]   Time 0.015 (0.014)   Data 0.000 (0.000)   Loss 0.4263 (0.3808)   Prec@1 89.844 (88.507)   Prec@5 98.438 (99.219)   [2025-02-03 18:29:02]
  **Train** Prec@1 87.198 Prec@5 99.022 Error@1 12.802
  **Test** Prec@1 63.580 Prec@5 87.760 Error@1 36.420
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:29:05] [Epoch=108/200] [Need: 00:09:30] [learning_rate=0.0437] [Best : Accuracy=66.85, Error=33.15]
  Epoch: [108][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.3191 (0.3191)   Prec@1 91.406 (91.406)   Prec@5 98.438 (98.438)   [2025-02-03 18:29:06]
  Epoch: [108][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.4532 (0.3769)   Prec@1 87.500 (88.246)   Prec@5 97.656 (99.227)   [2025-02-03 18:29:08]
  **Train** Prec@1 87.426 Prec@5 99.106 Error@1 12.574
  **Test** Prec@1 66.820 Prec@5 90.490 Error@1 33.180
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:29:12] [Epoch=109/200] [Need: 00:09:24] [learning_rate=0.0430] [Best : Accuracy=66.85, Error=33.15]
  Epoch: [109][000/128]   Time 0.132 (0.132)   Data 0.000 (0.000)   Loss 0.2827 (0.2827)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2025-02-03 18:29:12]
  Epoch: [109][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.4296 (0.3688)   Prec@1 89.062 (88.720)   Prec@5 96.875 (99.227)   [2025-02-03 18:29:15]
  **Train** Prec@1 87.564 Prec@5 99.078 Error@1 12.436
  **Test** Prec@1 65.580 Prec@5 88.770 Error@1 34.420
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:29:18] [Epoch=110/200] [Need: 00:09:18] [learning_rate=0.0422] [Best : Accuracy=66.85, Error=33.15]
  Epoch: [110][000/128]   Time 0.125 (0.125)   Data 0.000 (0.000)   Loss 0.3499 (0.3499)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2025-02-03 18:29:18]
  Epoch: [110][200/128]   Time 0.015 (0.015)   Data 0.000 (0.000)   Loss 0.3775 (0.3651)   Prec@1 88.281 (88.619)   Prec@5 98.438 (99.262)   [2025-02-03 18:29:21]
  **Train** Prec@1 87.748 Prec@5 99.138 Error@1 12.252
  **Test** Prec@1 65.800 Prec@5 89.380 Error@1 34.200
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:29:25] [Epoch=111/200] [Need: 00:09:12] [learning_rate=0.0414] [Best : Accuracy=66.85, Error=33.15]
  Epoch: [111][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.4351 (0.4351)   Prec@1 88.281 (88.281)   Prec@5 99.219 (99.219)   [2025-02-03 18:29:25]
  Epoch: [111][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.3796 (0.3407)   Prec@1 86.719 (89.416)   Prec@5 99.219 (99.390)   [2025-02-03 18:29:28]
  **Train** Prec@1 88.376 Prec@5 99.238 Error@1 11.624
  **Test** Prec@1 66.340 Prec@5 89.320 Error@1 33.660
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:29:31] [Epoch=112/200] [Need: 00:09:06] [learning_rate=0.0406] [Best : Accuracy=66.85, Error=33.15]
  Epoch: [112][000/128]   Time 0.119 (0.119)   Data 0.000 (0.000)   Loss 0.4138 (0.4138)   Prec@1 89.844 (89.844)   Prec@5 98.438 (98.438)   [2025-02-03 18:29:31]
  Epoch: [112][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.3475 (0.3436)   Prec@1 88.281 (89.315)   Prec@5 99.219 (99.386)   [2025-02-03 18:29:34]
  **Train** Prec@1 88.518 Prec@5 99.252 Error@1 11.482
  **Test** Prec@1 66.880 Prec@5 89.800 Error@1 33.120
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:29:37] [Epoch=113/200] [Need: 00:08:59] [learning_rate=0.0399] [Best : Accuracy=66.88, Error=33.12]
  Epoch: [113][000/128]   Time 0.117 (0.117)   Data 0.000 (0.000)   Loss 0.3660 (0.3660)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2025-02-03 18:29:37]
  Epoch: [113][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.3605 (0.3292)   Prec@1 89.062 (89.984)   Prec@5 97.656 (99.413)   [2025-02-03 18:29:40]
  **Train** Prec@1 88.818 Prec@5 99.292 Error@1 11.182
  **Test** Prec@1 65.790 Prec@5 89.240 Error@1 34.210
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:29:43] [Epoch=114/200] [Need: 00:08:53] [learning_rate=0.0391] [Best : Accuracy=66.88, Error=33.12]
  Epoch: [114][000/128]   Time 0.116 (0.116)   Data 0.000 (0.000)   Loss 0.3240 (0.3240)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2025-02-03 18:29:43]
  Epoch: [114][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.2858 (0.3170)   Prec@1 90.625 (90.197)   Prec@5 100.000 (99.502)   [2025-02-03 18:29:46]
  **Train** Prec@1 89.322 Prec@5 99.370 Error@1 10.678
  **Test** Prec@1 65.230 Prec@5 88.470 Error@1 34.770
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:29:49] [Epoch=115/200] [Need: 00:08:47] [learning_rate=0.0383] [Best : Accuracy=66.88, Error=33.12]
  Epoch: [115][000/128]   Time 0.116 (0.116)   Data 0.000 (0.000)   Loss 0.3613 (0.3613)   Prec@1 88.281 (88.281)   Prec@5 99.219 (99.219)   [2025-02-03 18:29:49]
  Epoch: [115][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.3680 (0.3261)   Prec@1 86.719 (90.065)   Prec@5 100.000 (99.506)   [2025-02-03 18:29:52]
  **Train** Prec@1 89.102 Prec@5 99.410 Error@1 10.898
  **Test** Prec@1 66.060 Prec@5 89.330 Error@1 33.940
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:29:55] [Epoch=116/200] [Need: 00:08:41] [learning_rate=0.0376] [Best : Accuracy=66.88, Error=33.12]
  Epoch: [116][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 0.3343 (0.3343)   Prec@1 91.406 (91.406)   Prec@5 98.438 (98.438)   [2025-02-03 18:29:55]
  Epoch: [116][200/128]   Time 0.011 (0.014)   Data 0.000 (0.000)   Loss 0.3949 (0.3092)   Prec@1 87.500 (90.578)   Prec@5 98.438 (99.553)   [2025-02-03 18:29:58]
  **Train** Prec@1 89.348 Prec@5 99.404 Error@1 10.652
  **Test** Prec@1 67.990 Prec@5 89.560 Error@1 32.010
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:30:01] [Epoch=117/200] [Need: 00:08:34] [learning_rate=0.0368] [Best : Accuracy=67.99, Error=32.01]
  Epoch: [117][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.2853 (0.2853)   Prec@1 93.750 (93.750)   Prec@5 99.219 (99.219)   [2025-02-03 18:30:01]
  Epoch: [117][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.2986 (0.2926)   Prec@1 91.406 (91.192)   Prec@5 99.219 (99.600)   [2025-02-03 18:30:04]
  **Train** Prec@1 90.258 Prec@5 99.486 Error@1 9.742
  **Test** Prec@1 66.040 Prec@5 89.230 Error@1 33.960
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:30:08] [Epoch=118/200] [Need: 00:08:28] [learning_rate=0.0361] [Best : Accuracy=67.99, Error=32.01]
  Epoch: [118][000/128]   Time 0.119 (0.119)   Data 0.000 (0.000)   Loss 0.3006 (0.3006)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2025-02-03 18:30:08]
  Epoch: [118][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 0.2705 (0.2996)   Prec@1 94.531 (90.843)   Prec@5 99.219 (99.506)   [2025-02-03 18:30:11]
  **Train** Prec@1 90.016 Prec@5 99.456 Error@1 9.984
  **Test** Prec@1 66.990 Prec@5 89.690 Error@1 33.010
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:30:14] [Epoch=119/200] [Need: 00:08:22] [learning_rate=0.0353] [Best : Accuracy=67.99, Error=32.01]
  Epoch: [119][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.3468 (0.3468)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2025-02-03 18:30:14]
  Epoch: [119][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.3062 (0.2765)   Prec@1 91.406 (91.725)   Prec@5 100.000 (99.623)   [2025-02-03 18:30:17]
  **Train** Prec@1 90.972 Prec@5 99.518 Error@1 9.028
  **Test** Prec@1 67.460 Prec@5 89.170 Error@1 32.540
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:30:20] [Epoch=120/200] [Need: 00:08:16] [learning_rate=0.0345] [Best : Accuracy=67.99, Error=32.01]
  Epoch: [120][000/128]   Time 0.126 (0.126)   Data 0.000 (0.000)   Loss 0.3346 (0.3346)   Prec@1 89.844 (89.844)   Prec@5 99.219 (99.219)   [2025-02-03 18:30:20]
  Epoch: [120][200/128]   Time 0.015 (0.016)   Data 0.000 (0.000)   Loss 0.2822 (0.2636)   Prec@1 91.406 (92.036)   Prec@5 100.000 (99.627)   [2025-02-03 18:30:23]
  **Train** Prec@1 91.072 Prec@5 99.538 Error@1 8.928
  **Test** Prec@1 68.520 Prec@5 90.290 Error@1 31.480
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:30:27] [Epoch=121/200] [Need: 00:08:10] [learning_rate=0.0338] [Best : Accuracy=68.52, Error=31.48]
  Epoch: [121][000/128]   Time 0.117 (0.117)   Data 0.000 (0.000)   Loss 0.2001 (0.2001)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2025-02-03 18:30:27]
  Epoch: [121][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.2304 (0.2560)   Prec@1 92.969 (92.141)   Prec@5 100.000 (99.712)   [2025-02-03 18:30:30]
  **Train** Prec@1 91.676 Prec@5 99.652 Error@1 8.324
  **Test** Prec@1 68.270 Prec@5 90.520 Error@1 31.730
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:30:33] [Epoch=122/200] [Need: 00:08:04] [learning_rate=0.0331] [Best : Accuracy=68.52, Error=31.48]
  Epoch: [122][000/128]   Time 0.124 (0.124)   Data 0.000 (0.000)   Loss 0.2951 (0.2951)   Prec@1 88.281 (88.281)   Prec@5 99.219 (99.219)   [2025-02-03 18:30:34]
  Epoch: [122][200/128]   Time 0.012 (0.014)   Data 0.000 (0.000)   Loss 0.3335 (0.2619)   Prec@1 89.062 (91.939)   Prec@5 100.000 (99.674)   [2025-02-03 18:30:36]
  **Train** Prec@1 91.396 Prec@5 99.594 Error@1 8.604
  **Test** Prec@1 67.990 Prec@5 89.820 Error@1 32.010
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:30:39] [Epoch=123/200] [Need: 00:07:58] [learning_rate=0.0323] [Best : Accuracy=68.52, Error=31.48]
  Epoch: [123][000/128]   Time 0.128 (0.128)   Data 0.000 (0.000)   Loss 0.2989 (0.2989)   Prec@1 89.844 (89.844)   Prec@5 99.219 (99.219)   [2025-02-03 18:30:40]
  Epoch: [123][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.3579 (0.2668)   Prec@1 89.062 (91.853)   Prec@5 100.000 (99.740)   [2025-02-03 18:30:42]
  **Train** Prec@1 91.344 Prec@5 99.636 Error@1 8.656
  **Test** Prec@1 67.360 Prec@5 89.560 Error@1 32.640
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:30:46] [Epoch=124/200] [Need: 00:07:51] [learning_rate=0.0316] [Best : Accuracy=68.52, Error=31.48]
  Epoch: [124][000/128]   Time 0.156 (0.156)   Data 0.000 (0.000)   Loss 0.2576 (0.2576)   Prec@1 92.188 (92.188)   Prec@5 99.219 (99.219)   [2025-02-03 18:30:46]
  Epoch: [124][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.2665 (0.2281)   Prec@1 89.844 (93.109)   Prec@5 100.000 (99.763)   [2025-02-03 18:30:49]
  **Train** Prec@1 92.148 Prec@5 99.712 Error@1 7.852
  **Test** Prec@1 68.190 Prec@5 90.280 Error@1 31.810
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:30:52] [Epoch=125/200] [Need: 00:07:45] [learning_rate=0.0309] [Best : Accuracy=68.52, Error=31.48]
  Epoch: [125][000/128]   Time 0.116 (0.116)   Data 0.000 (0.000)   Loss 0.2468 (0.2468)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2025-02-03 18:30:52]
  Epoch: [125][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 0.1880 (0.2323)   Prec@1 93.750 (93.081)   Prec@5 100.000 (99.872)   [2025-02-03 18:30:55]
  **Train** Prec@1 92.572 Prec@5 99.778 Error@1 7.428
  **Test** Prec@1 68.530 Prec@5 90.110 Error@1 31.470
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:30:58] [Epoch=126/200] [Need: 00:07:39] [learning_rate=0.0301] [Best : Accuracy=68.53, Error=31.47]
  Epoch: [126][000/128]   Time 0.124 (0.124)   Data 0.000 (0.000)   Loss 0.2284 (0.2284)   Prec@1 92.969 (92.969)   Prec@5 99.219 (99.219)   [2025-02-03 18:30:58]
  Epoch: [126][200/128]   Time 0.015 (0.014)   Data 0.000 (0.000)   Loss 0.3083 (0.2067)   Prec@1 92.969 (94.022)   Prec@5 100.000 (99.794)   [2025-02-03 18:31:01]
  **Train** Prec@1 93.012 Prec@5 99.760 Error@1 6.988
  **Test** Prec@1 69.100 Prec@5 90.830 Error@1 30.900
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:31:04] [Epoch=127/200] [Need: 00:07:33] [learning_rate=0.0294] [Best : Accuracy=69.10, Error=30.90]
  Epoch: [127][000/128]   Time 0.119 (0.119)   Data 0.000 (0.000)   Loss 0.2246 (0.2246)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2025-02-03 18:31:04]
  Epoch: [127][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.3216 (0.2095)   Prec@1 89.844 (93.766)   Prec@5 98.438 (99.817)   [2025-02-03 18:31:07]
  **Train** Prec@1 93.022 Prec@5 99.774 Error@1 6.978
  **Test** Prec@1 68.820 Prec@5 89.620 Error@1 31.180
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:31:11] [Epoch=128/200] [Need: 00:07:27] [learning_rate=0.0287] [Best : Accuracy=69.10, Error=30.90]
  Epoch: [128][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.1898 (0.1898)   Prec@1 93.750 (93.750)   Prec@5 99.219 (99.219)   [2025-02-03 18:31:11]
  Epoch: [128][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.3146 (0.1946)   Prec@1 90.625 (94.302)   Prec@5 100.000 (99.868)   [2025-02-03 18:31:13]
  **Train** Prec@1 93.432 Prec@5 99.820 Error@1 6.568
  **Test** Prec@1 68.450 Prec@5 90.830 Error@1 31.550
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:31:17] [Epoch=129/200] [Need: 00:07:20] [learning_rate=0.0280] [Best : Accuracy=69.10, Error=30.90]
  Epoch: [129][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.2072 (0.2072)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2025-02-03 18:31:17]
  Epoch: [129][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 0.1948 (0.1988)   Prec@1 94.531 (94.185)   Prec@5 100.000 (99.806)   [2025-02-03 18:31:19]
  **Train** Prec@1 93.750 Prec@5 99.782 Error@1 6.250
  **Test** Prec@1 69.270 Prec@5 90.740 Error@1 30.730
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:31:23] [Epoch=130/200] [Need: 00:07:14] [learning_rate=0.0273] [Best : Accuracy=69.27, Error=30.73]
  Epoch: [130][000/128]   Time 0.117 (0.117)   Data 0.000 (0.000)   Loss 0.1800 (0.1800)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2025-02-03 18:31:23]
  Epoch: [130][200/128]   Time 0.016 (0.014)   Data 0.000 (0.000)   Loss 0.2211 (0.1778)   Prec@1 92.188 (94.788)   Prec@5 100.000 (99.891)   [2025-02-03 18:31:26]
  **Train** Prec@1 94.148 Prec@5 99.860 Error@1 5.852
  **Test** Prec@1 70.030 Prec@5 91.070 Error@1 29.970
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:31:29] [Epoch=131/200] [Need: 00:07:08] [learning_rate=0.0266] [Best : Accuracy=70.03, Error=29.97]
  Epoch: [131][000/128]   Time 0.126 (0.126)   Data 0.000 (0.000)   Loss 0.1277 (0.1277)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2025-02-03 18:31:29]
  Epoch: [131][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 0.1175 (0.1811)   Prec@1 97.656 (94.788)   Prec@5 100.000 (99.860)   [2025-02-03 18:31:32]
  **Train** Prec@1 94.198 Prec@5 99.866 Error@1 5.802
  **Test** Prec@1 68.830 Prec@5 90.720 Error@1 31.170
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:31:36] [Epoch=132/200] [Need: 00:07:02] [learning_rate=0.0259] [Best : Accuracy=70.03, Error=29.97]
  Epoch: [132][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.2348 (0.2348)   Prec@1 91.406 (91.406)   Prec@5 99.219 (99.219)   [2025-02-03 18:31:36]
  Epoch: [132][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.1482 (0.1689)   Prec@1 96.094 (95.149)   Prec@5 100.000 (99.868)   [2025-02-03 18:31:38]
  **Train** Prec@1 94.562 Prec@5 99.854 Error@1 5.438
  **Test** Prec@1 69.450 Prec@5 90.470 Error@1 30.550
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:31:42] [Epoch=133/200] [Need: 00:06:56] [learning_rate=0.0252] [Best : Accuracy=70.03, Error=29.97]
  Epoch: [133][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.1809 (0.1809)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2025-02-03 18:31:42]
  Epoch: [133][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.1638 (0.1680)   Prec@1 96.094 (95.169)   Prec@5 100.000 (99.899)   [2025-02-03 18:31:45]
  **Train** Prec@1 94.686 Prec@5 99.866 Error@1 5.314
  **Test** Prec@1 69.530 Prec@5 91.110 Error@1 30.470
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:31:48] [Epoch=134/200] [Need: 00:06:49] [learning_rate=0.0245] [Best : Accuracy=70.03, Error=29.97]
  Epoch: [134][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 0.1337 (0.1337)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2025-02-03 18:31:48]
  Epoch: [134][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.1456 (0.1588)   Prec@1 95.312 (95.561)   Prec@5 100.000 (99.887)   [2025-02-03 18:31:51]
  **Train** Prec@1 95.332 Prec@5 99.890 Error@1 4.668
  **Test** Prec@1 69.980 Prec@5 90.770 Error@1 30.020
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:31:54] [Epoch=135/200] [Need: 00:06:43] [learning_rate=0.0239] [Best : Accuracy=70.03, Error=29.97]
  Epoch: [135][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.1851 (0.1851)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2025-02-03 18:31:54]
  Epoch: [135][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.1548 (0.1498)   Prec@1 96.875 (95.736)   Prec@5 99.219 (99.922)   [2025-02-03 18:31:57]
  **Train** Prec@1 95.392 Prec@5 99.902 Error@1 4.608
  **Test** Prec@1 70.190 Prec@5 91.020 Error@1 29.810
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:32:00] [Epoch=136/200] [Need: 00:06:37] [learning_rate=0.0232] [Best : Accuracy=70.19, Error=29.81]
  Epoch: [136][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 0.1676 (0.1676)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2025-02-03 18:32:00]
  Epoch: [136][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.1747 (0.1375)   Prec@1 96.094 (96.090)   Prec@5 100.000 (99.965)   [2025-02-03 18:32:03]
  **Train** Prec@1 95.708 Prec@5 99.928 Error@1 4.292
  **Test** Prec@1 70.410 Prec@5 91.070 Error@1 29.590
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:32:06] [Epoch=137/200] [Need: 00:06:31] [learning_rate=0.0225] [Best : Accuracy=70.41, Error=29.59]
  Epoch: [137][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 0.1290 (0.1290)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2025-02-03 18:32:06]
  Epoch: [137][200/128]   Time 0.015 (0.014)   Data 0.000 (0.000)   Loss 0.1600 (0.1354)   Prec@1 96.875 (96.175)   Prec@5 99.219 (99.946)   [2025-02-03 18:32:09]
  **Train** Prec@1 95.790 Prec@5 99.938 Error@1 4.210
  **Test** Prec@1 71.090 Prec@5 91.170 Error@1 28.910
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:32:12] [Epoch=138/200] [Need: 00:06:24] [learning_rate=0.0219] [Best : Accuracy=71.09, Error=28.91]
  Epoch: [138][000/128]   Time 0.116 (0.116)   Data 0.000 (0.000)   Loss 0.1540 (0.1540)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2025-02-03 18:32:13]
  Epoch: [138][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.1884 (0.1217)   Prec@1 92.188 (96.770)   Prec@5 100.000 (99.953)   [2025-02-03 18:32:15]
  **Train** Prec@1 96.410 Prec@5 99.934 Error@1 3.590
  **Test** Prec@1 70.510 Prec@5 91.120 Error@1 29.490
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:32:19] [Epoch=139/200] [Need: 00:06:18] [learning_rate=0.0212] [Best : Accuracy=71.09, Error=28.91]
  Epoch: [139][000/128]   Time 0.129 (0.129)   Data 0.000 (0.000)   Loss 0.1330 (0.1330)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2025-02-03 18:32:19]
  Epoch: [139][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.1432 (0.1037)   Prec@1 96.094 (97.275)   Prec@5 100.000 (99.977)   [2025-02-03 18:32:22]
  **Train** Prec@1 96.998 Prec@5 99.960 Error@1 3.002
  **Test** Prec@1 71.560 Prec@5 91.560 Error@1 28.440
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:32:25] [Epoch=140/200] [Need: 00:06:12] [learning_rate=0.0206] [Best : Accuracy=71.56, Error=28.44]
  Epoch: [140][000/128]   Time 0.114 (0.114)   Data 0.000 (0.000)   Loss 0.1594 (0.1594)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2025-02-03 18:32:25]
  Epoch: [140][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.1680 (0.1068)   Prec@1 95.312 (97.279)   Prec@5 100.000 (99.981)   [2025-02-03 18:32:28]
  **Train** Prec@1 96.870 Prec@5 99.964 Error@1 3.130
  **Test** Prec@1 71.130 Prec@5 91.520 Error@1 28.870
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:32:31] [Epoch=141/200] [Need: 00:06:06] [learning_rate=0.0200] [Best : Accuracy=71.56, Error=28.44]
  Epoch: [141][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.0948 (0.0948)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2025-02-03 18:32:31]
  Epoch: [141][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.1194 (0.1101)   Prec@1 97.656 (97.112)   Prec@5 100.000 (99.988)   [2025-02-03 18:32:34]
  **Train** Prec@1 97.086 Prec@5 99.964 Error@1 2.914
  **Test** Prec@1 71.920 Prec@5 92.010 Error@1 28.080
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:32:37] [Epoch=142/200] [Need: 00:06:00] [learning_rate=0.0194] [Best : Accuracy=71.92, Error=28.08]
  Epoch: [142][000/128]   Time 0.126 (0.126)   Data 0.000 (0.000)   Loss 0.0724 (0.0724)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2025-02-03 18:32:37]
  Epoch: [142][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0498 (0.0833)   Prec@1 99.219 (97.994)   Prec@5 100.000 (99.977)   [2025-02-03 18:32:40]
  **Train** Prec@1 97.722 Prec@5 99.976 Error@1 2.278
  **Test** Prec@1 71.620 Prec@5 91.070 Error@1 28.380
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:32:44] [Epoch=143/200] [Need: 00:05:53] [learning_rate=0.0187] [Best : Accuracy=71.92, Error=28.08]
  Epoch: [143][000/128]   Time 0.128 (0.128)   Data 0.000 (0.000)   Loss 0.0778 (0.0778)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2025-02-03 18:32:44]
  Epoch: [143][200/128]   Time 0.015 (0.015)   Data 0.000 (0.000)   Loss 0.0597 (0.0934)   Prec@1 98.438 (97.730)   Prec@5 100.000 (99.981)   [2025-02-03 18:32:47]
  **Train** Prec@1 97.594 Prec@5 99.976 Error@1 2.406
  **Test** Prec@1 72.960 Prec@5 91.710 Error@1 27.040
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:32:50] [Epoch=144/200] [Need: 00:05:47] [learning_rate=0.0181] [Best : Accuracy=72.96, Error=27.04]
  Epoch: [144][000/128]   Time 0.149 (0.149)   Data 0.000 (0.000)   Loss 0.0551 (0.0551)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2025-02-03 18:32:50]
  Epoch: [144][200/128]   Time 0.014 (0.015)   Data 0.000 (0.000)   Loss 0.1199 (0.0791)   Prec@1 97.656 (98.088)   Prec@5 100.000 (99.977)   [2025-02-03 18:32:53]
  **Train** Prec@1 97.810 Prec@5 99.980 Error@1 2.190
  **Test** Prec@1 72.060 Prec@5 91.470 Error@1 27.940
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:32:57] [Epoch=145/200] [Need: 00:05:41] [learning_rate=0.0175] [Best : Accuracy=72.96, Error=27.04]
  Epoch: [145][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.0481 (0.0481)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:32:57]
  Epoch: [145][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.0522 (0.0667)   Prec@1 99.219 (98.492)   Prec@5 100.000 (99.992)   [2025-02-03 18:33:00]
  **Train** Prec@1 98.224 Prec@5 99.990 Error@1 1.776
  **Test** Prec@1 72.990 Prec@5 92.750 Error@1 27.010
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:33:03] [Epoch=146/200] [Need: 00:05:35] [learning_rate=0.0169] [Best : Accuracy=72.99, Error=27.01]
  Epoch: [146][000/128]   Time 0.129 (0.129)   Data 0.000 (0.000)   Loss 0.0841 (0.0841)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:03]
  Epoch: [146][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0839 (0.0643)   Prec@1 96.875 (98.589)   Prec@5 100.000 (99.996)   [2025-02-03 18:33:06]
  **Train** Prec@1 98.522 Prec@5 99.998 Error@1 1.478
  **Test** Prec@1 73.260 Prec@5 92.130 Error@1 26.740
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:33:09] [Epoch=147/200] [Need: 00:05:29] [learning_rate=0.0163] [Best : Accuracy=73.26, Error=26.74]
  Epoch: [147][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.0719 (0.0719)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:09]
  Epoch: [147][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0783 (0.0592)   Prec@1 98.438 (98.818)   Prec@5 100.000 (99.992)   [2025-02-03 18:33:12]
  **Train** Prec@1 98.742 Prec@5 99.996 Error@1 1.258
  **Test** Prec@1 73.480 Prec@5 92.470 Error@1 26.520
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:33:15] [Epoch=148/200] [Need: 00:05:23] [learning_rate=0.0158] [Best : Accuracy=73.48, Error=26.52]
  Epoch: [148][000/128]   Time 0.116 (0.116)   Data 0.000 (0.000)   Loss 0.0367 (0.0367)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:15]
  Epoch: [148][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0452 (0.0492)   Prec@1 99.219 (98.993)   Prec@5 100.000 (99.992)   [2025-02-03 18:33:18]
  **Train** Prec@1 98.864 Prec@5 99.990 Error@1 1.136
  **Test** Prec@1 74.090 Prec@5 92.340 Error@1 25.910
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:33:22] [Epoch=149/200] [Need: 00:05:16] [learning_rate=0.0152] [Best : Accuracy=74.09, Error=25.91]
  Epoch: [149][000/128]   Time 0.118 (0.118)   Data 0.000 (0.000)   Loss 0.0321 (0.0321)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:22]
  Epoch: [149][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 0.0415 (0.0415)   Prec@1 99.219 (99.203)   Prec@5 100.000 (99.996)   [2025-02-03 18:33:24]
  **Train** Prec@1 99.160 Prec@5 99.996 Error@1 0.840
  **Test** Prec@1 74.280 Prec@5 92.570 Error@1 25.720
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:33:28] [Epoch=150/200] [Need: 00:05:10] [learning_rate=0.0146] [Best : Accuracy=74.28, Error=25.72]
  Epoch: [150][000/128]   Time 0.111 (0.111)   Data 0.000 (0.000)   Loss 0.0324 (0.0324)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:28]
  Epoch: [150][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0326 (0.0394)   Prec@1 100.000 (99.312)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:30]
  **Train** Prec@1 99.334 Prec@5 99.996 Error@1 0.666
  **Test** Prec@1 75.010 Prec@5 92.830 Error@1 24.990
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:33:34] [Epoch=151/200] [Need: 00:05:04] [learning_rate=0.0141] [Best : Accuracy=75.01, Error=24.99]
  Epoch: [151][000/128]   Time 0.126 (0.126)   Data 0.000 (0.000)   Loss 0.0279 (0.0279)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:34]
  Epoch: [151][200/128]   Time 0.015 (0.014)   Data 0.000 (0.000)   Loss 0.0552 (0.0336)   Prec@1 98.438 (99.429)   Prec@5 100.000 (99.996)   [2025-02-03 18:33:37]
  **Train** Prec@1 99.426 Prec@5 99.998 Error@1 0.574
  **Test** Prec@1 75.030 Prec@5 92.310 Error@1 24.970
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:33:40] [Epoch=152/200] [Need: 00:04:58] [learning_rate=0.0136] [Best : Accuracy=75.03, Error=24.97]
  Epoch: [152][000/128]   Time 0.117 (0.117)   Data 0.000 (0.000)   Loss 0.0445 (0.0445)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:40]
  Epoch: [152][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0399 (0.0326)   Prec@1 99.219 (99.510)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:43]
  **Train** Prec@1 99.468 Prec@5 100.000 Error@1 0.532
  **Test** Prec@1 75.170 Prec@5 92.940 Error@1 24.830
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:33:46] [Epoch=153/200] [Need: 00:04:51] [learning_rate=0.0130] [Best : Accuracy=75.17, Error=24.83]
  Epoch: [153][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 0.0215 (0.0215)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:46]
  Epoch: [153][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0180 (0.0263)   Prec@1 100.000 (99.650)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:49]
  **Train** Prec@1 99.576 Prec@5 100.000 Error@1 0.424
  **Test** Prec@1 75.030 Prec@5 92.750 Error@1 24.970
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:33:52] [Epoch=154/200] [Need: 00:04:45] [learning_rate=0.0125] [Best : Accuracy=75.17, Error=24.83]
  Epoch: [154][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.0251 (0.0251)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:52]
  Epoch: [154][200/128]   Time 0.015 (0.013)   Data 0.000 (0.000)   Loss 0.0190 (0.0233)   Prec@1 99.219 (99.728)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:55]
  **Train** Prec@1 99.636 Prec@5 100.000 Error@1 0.364
  **Test** Prec@1 75.050 Prec@5 93.140 Error@1 24.950
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:33:58] [Epoch=155/200] [Need: 00:04:39] [learning_rate=0.0120] [Best : Accuracy=75.17, Error=24.83]
  Epoch: [155][000/128]   Time 0.116 (0.116)   Data 0.000 (0.000)   Loss 0.0194 (0.0194)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:58]
  Epoch: [155][200/128]   Time 0.015 (0.014)   Data 0.000 (0.000)   Loss 0.0148 (0.0208)   Prec@1 100.000 (99.771)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:01]
  **Train** Prec@1 99.800 Prec@5 100.000 Error@1 0.200
  **Test** Prec@1 76.140 Prec@5 93.410 Error@1 23.860
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:34:04] [Epoch=156/200] [Need: 00:04:33] [learning_rate=0.0115] [Best : Accuracy=76.14, Error=23.86]
  Epoch: [156][000/128]   Time 0.125 (0.125)   Data 0.000 (0.000)   Loss 0.0091 (0.0091)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:04]
  Epoch: [156][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0150 (0.0157)   Prec@1 100.000 (99.860)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:07]
  **Train** Prec@1 99.866 Prec@5 100.000 Error@1 0.134
  **Test** Prec@1 76.930 Prec@5 93.500 Error@1 23.070
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:34:10] [Epoch=157/200] [Need: 00:04:26] [learning_rate=0.0110] [Best : Accuracy=76.93, Error=23.07]
  Epoch: [157][000/128]   Time 0.557 (0.557)   Data 0.000 (0.000)   Loss 0.0138 (0.0138)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:11]
  Epoch: [157][200/128]   Time 0.013 (0.016)   Data 0.000 (0.000)   Loss 0.0072 (0.0139)   Prec@1 100.000 (99.903)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:14]
  **Train** Prec@1 99.890 Prec@5 100.000 Error@1 0.110
  **Test** Prec@1 76.820 Prec@5 93.680 Error@1 23.180
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:34:17] [Epoch=158/200] [Need: 00:04:20] [learning_rate=0.0105] [Best : Accuracy=76.93, Error=23.07]
  Epoch: [158][000/128]   Time 0.118 (0.118)   Data 0.000 (0.000)   Loss 0.0077 (0.0077)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:17]
  Epoch: [158][200/128]   Time 0.015 (0.014)   Data 0.000 (0.000)   Loss 0.0120 (0.0118)   Prec@1 100.000 (99.922)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:20]
  **Train** Prec@1 99.894 Prec@5 100.000 Error@1 0.106
  **Test** Prec@1 76.840 Prec@5 93.750 Error@1 23.160
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:34:23] [Epoch=159/200] [Need: 00:04:14] [learning_rate=0.0100] [Best : Accuracy=76.93, Error=23.07]
  Epoch: [159][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.0071 (0.0071)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:23]
  Epoch: [159][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0145 (0.0124)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:26]
  **Train** Prec@1 99.916 Prec@5 100.000 Error@1 0.084
  **Test** Prec@1 76.880 Prec@5 93.680 Error@1 23.120
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:34:29] [Epoch=160/200] [Need: 00:04:08] [learning_rate=0.0095] [Best : Accuracy=76.93, Error=23.07]
  Epoch: [160][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 0.0111 (0.0111)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:30]
  Epoch: [160][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0209 (0.0125)   Prec@1 99.219 (99.914)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:32]
  **Train** Prec@1 99.914 Prec@5 100.000 Error@1 0.086
  **Test** Prec@1 77.330 Prec@5 93.580 Error@1 22.670
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:34:36] [Epoch=161/200] [Need: 00:04:02] [learning_rate=0.0091] [Best : Accuracy=77.33, Error=22.67]
  Epoch: [161][000/128]   Time 0.119 (0.119)   Data 0.000 (0.000)   Loss 0.0131 (0.0131)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:36]
  Epoch: [161][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0377 (0.0121)   Prec@1 99.219 (99.914)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:38]
  **Train** Prec@1 99.928 Prec@5 100.000 Error@1 0.072
  **Test** Prec@1 77.260 Prec@5 93.950 Error@1 22.740
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:34:42] [Epoch=162/200] [Need: 00:03:56] [learning_rate=0.0086] [Best : Accuracy=77.33, Error=22.67]
  Epoch: [162][000/128]   Time 0.118 (0.118)   Data 0.000 (0.000)   Loss 0.0120 (0.0120)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:42]
  Epoch: [162][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0130 (0.0117)   Prec@1 100.000 (99.938)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:45]
  **Train** Prec@1 99.930 Prec@5 100.000 Error@1 0.070
  **Test** Prec@1 77.650 Prec@5 93.970 Error@1 22.350
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:34:48] [Epoch=163/200] [Need: 00:03:49] [learning_rate=0.0082] [Best : Accuracy=77.65, Error=22.35]
  Epoch: [163][000/128]   Time 0.113 (0.113)   Data 0.000 (0.000)   Loss 0.0086 (0.0086)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:48]
  Epoch: [163][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0088 (0.0109)   Prec@1 100.000 (99.942)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:51]
  **Train** Prec@1 99.928 Prec@5 100.000 Error@1 0.072
  **Test** Prec@1 77.770 Prec@5 93.910 Error@1 22.230
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:34:54] [Epoch=164/200] [Need: 00:03:43] [learning_rate=0.0078] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [164][000/128]   Time 0.119 (0.119)   Data 0.000 (0.000)   Loss 0.0142 (0.0142)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:54]
  Epoch: [164][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.0150 (0.0107)   Prec@1 100.000 (99.961)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:57]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 77.690 Prec@5 93.900 Error@1 22.310
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:35:00] [Epoch=165/200] [Need: 00:03:37] [learning_rate=0.0074] [Best : Accuracy=77.77, Error=22.23]
  Epoch: [165][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.0133 (0.0133)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:00]
  Epoch: [165][200/128]   Time 0.015 (0.015)   Data 0.000 (0.000)   Loss 0.0090 (0.0098)   Prec@1 100.000 (99.957)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:03]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 77.830 Prec@5 93.830 Error@1 22.170
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:35:07] [Epoch=166/200] [Need: 00:03:31] [learning_rate=0.0070] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [166][000/128]   Time 0.117 (0.117)   Data 0.000 (0.000)   Loss 0.0070 (0.0070)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:07]
  Epoch: [166][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0083 (0.0102)   Prec@1 100.000 (99.957)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:10]
  **Train** Prec@1 99.942 Prec@5 100.000 Error@1 0.058
  **Test** Prec@1 77.530 Prec@5 93.790 Error@1 22.470
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:35:13] [Epoch=167/200] [Need: 00:03:24] [learning_rate=0.0066] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [167][000/128]   Time 0.115 (0.115)   Data 0.000 (0.000)   Loss 0.0085 (0.0085)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:13]
  Epoch: [167][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0155 (0.0105)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:16]
  **Train** Prec@1 99.954 Prec@5 100.000 Error@1 0.046
  **Test** Prec@1 77.830 Prec@5 94.080 Error@1 22.170
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:35:19] [Epoch=168/200] [Need: 00:03:18] [learning_rate=0.0062] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [168][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 0.0055 (0.0055)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:19]
  Epoch: [168][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.0124 (0.0098)   Prec@1 100.000 (99.957)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:22]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 77.930 Prec@5 94.170 Error@1 22.070
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:35:25] [Epoch=169/200] [Need: 00:03:12] [learning_rate=0.0058] [Best : Accuracy=77.93, Error=22.07]
  Epoch: [169][000/128]   Time 0.114 (0.114)   Data 0.000 (0.000)   Loss 0.0068 (0.0068)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:25]
  Epoch: [169][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0254 (0.0095)   Prec@1 99.219 (99.965)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:28]
  **Train** Prec@1 99.960 Prec@5 100.000 Error@1 0.040
  **Test** Prec@1 77.940 Prec@5 93.960 Error@1 22.060
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:35:31] [Epoch=170/200] [Need: 00:03:06] [learning_rate=0.0054] [Best : Accuracy=77.94, Error=22.06]
  Epoch: [170][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 0.0103 (0.0103)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:31]
  Epoch: [170][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0095 (0.0097)   Prec@1 100.000 (99.961)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:34]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 78.040 Prec@5 94.000 Error@1 21.960
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:35:38] [Epoch=171/200] [Need: 00:03:00] [learning_rate=0.0051] [Best : Accuracy=78.04, Error=21.96]
  Epoch: [171][000/128]   Time 0.124 (0.124)   Data 0.000 (0.000)   Loss 0.0077 (0.0077)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:38]
  Epoch: [171][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0095 (0.0096)   Prec@1 100.000 (99.973)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:40]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 78.120 Prec@5 93.900 Error@1 21.880
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:35:44] [Epoch=172/200] [Need: 00:02:53] [learning_rate=0.0048] [Best : Accuracy=78.12, Error=21.88]
  Epoch: [172][000/128]   Time 0.132 (0.132)   Data 0.000 (0.000)   Loss 0.0062 (0.0062)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:44]
  Epoch: [172][200/128]   Time 0.013 (0.016)   Data 0.000 (0.000)   Loss 0.0056 (0.0093)   Prec@1 100.000 (99.969)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:47]
  **Train** Prec@1 99.966 Prec@5 100.000 Error@1 0.034
  **Test** Prec@1 78.120 Prec@5 94.040 Error@1 21.880
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:35:50] [Epoch=173/200] [Need: 00:02:47] [learning_rate=0.0044] [Best : Accuracy=78.12, Error=21.88]
  Epoch: [173][000/128]   Time 0.131 (0.131)   Data 0.000 (0.000)   Loss 0.0065 (0.0065)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:50]
  Epoch: [173][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0102 (0.0093)   Prec@1 100.000 (99.977)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:53]
  **Train** Prec@1 99.962 Prec@5 100.000 Error@1 0.038
  **Test** Prec@1 78.280 Prec@5 94.040 Error@1 21.720
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:35:56] [Epoch=174/200] [Need: 00:02:41] [learning_rate=0.0041] [Best : Accuracy=78.28, Error=21.72]
  Epoch: [174][000/128]   Time 0.124 (0.124)   Data 0.000 (0.000)   Loss 0.0075 (0.0075)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:56]
  Epoch: [174][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0089 (0.0099)   Prec@1 100.000 (99.961)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:59]
  **Train** Prec@1 99.960 Prec@5 100.000 Error@1 0.040
  **Test** Prec@1 78.190 Prec@5 93.960 Error@1 21.810
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:36:03] [Epoch=175/200] [Need: 00:02:35] [learning_rate=0.0038] [Best : Accuracy=78.28, Error=21.72]
  Epoch: [175][000/128]   Time 0.138 (0.138)   Data 0.000 (0.000)   Loss 0.0155 (0.0155)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:03]
  Epoch: [175][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0110 (0.0094)   Prec@1 100.000 (99.969)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:06]
  **Train** Prec@1 99.968 Prec@5 100.000 Error@1 0.032
  **Test** Prec@1 78.270 Prec@5 94.020 Error@1 21.730
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:36:09] [Epoch=176/200] [Need: 00:02:29] [learning_rate=0.0035] [Best : Accuracy=78.28, Error=21.72]
  Epoch: [176][000/128]   Time 0.124 (0.124)   Data 0.000 (0.000)   Loss 0.0085 (0.0085)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:09]
  Epoch: [176][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 0.0060 (0.0092)   Prec@1 100.000 (99.973)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:12]
  **Train** Prec@1 99.952 Prec@5 100.000 Error@1 0.048
  **Test** Prec@1 78.080 Prec@5 94.220 Error@1 21.920
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:36:15] [Epoch=177/200] [Need: 00:02:22] [learning_rate=0.0032] [Best : Accuracy=78.28, Error=21.72]
  Epoch: [177][000/128]   Time 0.127 (0.127)   Data 0.000 (0.000)   Loss 0.0093 (0.0093)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:15]
  Epoch: [177][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0081 (0.0093)   Prec@1 100.000 (99.969)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:18]
  **Train** Prec@1 99.974 Prec@5 100.000 Error@1 0.026
  **Test** Prec@1 78.020 Prec@5 94.270 Error@1 21.980
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:36:21] [Epoch=178/200] [Need: 00:02:16] [learning_rate=0.0030] [Best : Accuracy=78.28, Error=21.72]
  Epoch: [178][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.0067 (0.0067)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:22]
  Epoch: [178][200/128]   Time 0.015 (0.015)   Data 0.000 (0.000)   Loss 0.0118 (0.0090)   Prec@1 100.000 (99.984)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:24]
  **Train** Prec@1 99.972 Prec@5 100.000 Error@1 0.028
  **Test** Prec@1 78.180 Prec@5 94.070 Error@1 21.820
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:36:28] [Epoch=179/200] [Need: 00:02:10] [learning_rate=0.0027] [Best : Accuracy=78.28, Error=21.72]
  Epoch: [179][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.0134 (0.0134)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:28]
  Epoch: [179][200/128]   Time 0.014 (0.015)   Data 0.000 (0.000)   Loss 0.0210 (0.0097)   Prec@1 99.219 (99.949)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:31]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 78.220 Prec@5 94.280 Error@1 21.780
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:36:34] [Epoch=180/200] [Need: 00:02:04] [learning_rate=0.0024] [Best : Accuracy=78.28, Error=21.72]
  Epoch: [180][000/128]   Time 0.125 (0.125)   Data 0.000 (0.000)   Loss 0.0067 (0.0067)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:34]
  Epoch: [180][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0108 (0.0093)   Prec@1 100.000 (99.977)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:37]
  **Train** Prec@1 99.986 Prec@5 100.000 Error@1 0.014
  **Test** Prec@1 78.320 Prec@5 94.150 Error@1 21.680
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:36:40] [Epoch=181/200] [Need: 00:01:58] [learning_rate=0.0022] [Best : Accuracy=78.32, Error=21.68]
  Epoch: [181][000/128]   Time 0.114 (0.114)   Data 0.000 (0.000)   Loss 0.0068 (0.0068)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:40]
  Epoch: [181][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.0092 (0.0089)   Prec@1 100.000 (99.973)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:43]
  **Train** Prec@1 99.962 Prec@5 100.000 Error@1 0.038
  **Test** Prec@1 78.230 Prec@5 94.130 Error@1 21.770
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:36:46] [Epoch=182/200] [Need: 00:01:51] [learning_rate=0.0020] [Best : Accuracy=78.32, Error=21.68]
  Epoch: [182][000/128]   Time 0.119 (0.119)   Data 0.000 (0.000)   Loss 0.0183 (0.0183)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:47]
  Epoch: [182][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0066 (0.0092)   Prec@1 100.000 (99.984)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:49]
  **Train** Prec@1 99.974 Prec@5 100.000 Error@1 0.026
  **Test** Prec@1 78.230 Prec@5 94.300 Error@1 21.770
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:36:53] [Epoch=183/200] [Need: 00:01:45] [learning_rate=0.0018] [Best : Accuracy=78.32, Error=21.68]
  Epoch: [183][000/128]   Time 0.118 (0.118)   Data 0.000 (0.000)   Loss 0.0108 (0.0108)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:53]
  Epoch: [183][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0088 (0.0093)   Prec@1 100.000 (99.969)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:55]
  **Train** Prec@1 99.970 Prec@5 100.000 Error@1 0.030
  **Test** Prec@1 78.070 Prec@5 94.260 Error@1 21.930
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:36:59] [Epoch=184/200] [Need: 00:01:39] [learning_rate=0.0016] [Best : Accuracy=78.32, Error=21.68]
  Epoch: [184][000/128]   Time 0.125 (0.125)   Data 0.000 (0.000)   Loss 0.0111 (0.0111)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:59]
  Epoch: [184][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0081 (0.0088)   Prec@1 100.000 (99.981)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:02]
  **Train** Prec@1 99.978 Prec@5 100.000 Error@1 0.022
  **Test** Prec@1 78.230 Prec@5 94.290 Error@1 21.770
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:37:05] [Epoch=185/200] [Need: 00:01:33] [learning_rate=0.0014] [Best : Accuracy=78.32, Error=21.68]
  Epoch: [185][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.0099 (0.0099)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:05]
  Epoch: [185][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 0.0103 (0.0087)   Prec@1 100.000 (99.992)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:08]
  **Train** Prec@1 99.984 Prec@5 100.000 Error@1 0.016
  **Test** Prec@1 78.120 Prec@5 94.180 Error@1 21.880
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:37:11] [Epoch=186/200] [Need: 00:01:26] [learning_rate=0.0012] [Best : Accuracy=78.32, Error=21.68]
  Epoch: [186][000/128]   Time 0.118 (0.118)   Data 0.000 (0.000)   Loss 0.0070 (0.0070)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:11]
  Epoch: [186][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0090 (0.0091)   Prec@1 100.000 (99.961)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:14]
  **Train** Prec@1 99.966 Prec@5 100.000 Error@1 0.034
  **Test** Prec@1 78.330 Prec@5 94.250 Error@1 21.670
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:37:17] [Epoch=187/200] [Need: 00:01:20] [learning_rate=0.0010] [Best : Accuracy=78.33, Error=21.67]
  Epoch: [187][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.0081 (0.0081)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:17]
  Epoch: [187][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0074 (0.0087)   Prec@1 100.000 (99.988)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:20]
  **Train** Prec@1 99.976 Prec@5 100.000 Error@1 0.024
  **Test** Prec@1 78.230 Prec@5 94.220 Error@1 21.770
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:37:23] [Epoch=188/200] [Need: 00:01:14] [learning_rate=0.0009] [Best : Accuracy=78.33, Error=21.67]
  Epoch: [188][000/128]   Time 0.119 (0.119)   Data 0.000 (0.000)   Loss 0.0073 (0.0073)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:23]
  Epoch: [188][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 0.0079 (0.0087)   Prec@1 100.000 (99.981)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:26]
  **Train** Prec@1 99.974 Prec@5 100.000 Error@1 0.026
  **Test** Prec@1 78.230 Prec@5 94.260 Error@1 21.770
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:37:29] [Epoch=189/200] [Need: 00:01:08] [learning_rate=0.0007] [Best : Accuracy=78.33, Error=21.67]
  Epoch: [189][000/128]   Time 0.136 (0.136)   Data 0.000 (0.000)   Loss 0.0087 (0.0087)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:29]
  Epoch: [189][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.0105 (0.0088)   Prec@1 100.000 (99.981)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:32]
  **Train** Prec@1 99.980 Prec@5 100.000 Error@1 0.020
  **Test** Prec@1 78.170 Prec@5 94.220 Error@1 21.830
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:37:36] [Epoch=190/200] [Need: 00:01:02] [learning_rate=0.0006] [Best : Accuracy=78.33, Error=21.67]
  Epoch: [190][000/128]   Time 0.126 (0.126)   Data 0.000 (0.000)   Loss 0.0081 (0.0081)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:36]
  Epoch: [190][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0084 (0.0089)   Prec@1 100.000 (99.977)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:38]
  **Train** Prec@1 99.984 Prec@5 100.000 Error@1 0.016
  **Test** Prec@1 78.360 Prec@5 94.270 Error@1 21.640
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:37:42] [Epoch=191/200] [Need: 00:00:55] [learning_rate=0.0005] [Best : Accuracy=78.36, Error=21.64]
  Epoch: [191][000/128]   Time 0.114 (0.114)   Data 0.000 (0.000)   Loss 0.0059 (0.0059)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:42]
  Epoch: [191][200/128]   Time 0.011 (0.013)   Data 0.000 (0.000)   Loss 0.0081 (0.0088)   Prec@1 100.000 (99.973)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:44]
  **Train** Prec@1 99.978 Prec@5 100.000 Error@1 0.022
  **Test** Prec@1 78.320 Prec@5 94.240 Error@1 21.680
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:37:48] [Epoch=192/200] [Need: 00:00:49] [learning_rate=0.0004] [Best : Accuracy=78.36, Error=21.64]
  Epoch: [192][000/128]   Time 0.133 (0.133)   Data 0.000 (0.000)   Loss 0.0088 (0.0088)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:48]
  Epoch: [192][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0074 (0.0087)   Prec@1 100.000 (99.973)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:51]
  **Train** Prec@1 99.978 Prec@5 100.000 Error@1 0.022
  **Test** Prec@1 78.230 Prec@5 94.250 Error@1 21.770
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:37:54] [Epoch=193/200] [Need: 00:00:43] [learning_rate=0.0003] [Best : Accuracy=78.36, Error=21.64]
  Epoch: [193][000/128]   Time 0.126 (0.126)   Data 0.000 (0.000)   Loss 0.0067 (0.0067)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:54]
  Epoch: [193][200/128]   Time 0.014 (0.013)   Data 0.000 (0.000)   Loss 0.0093 (0.0090)   Prec@1 100.000 (99.969)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:57]
  **Train** Prec@1 99.972 Prec@5 100.000 Error@1 0.028
  **Test** Prec@1 78.340 Prec@5 94.320 Error@1 21.660
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:38:00] [Epoch=194/200] [Need: 00:00:37] [learning_rate=0.0002] [Best : Accuracy=78.36, Error=21.64]
  Epoch: [194][000/128]   Time 0.136 (0.136)   Data 0.000 (0.000)   Loss 0.0063 (0.0063)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:38:00]
  Epoch: [194][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0064 (0.0089)   Prec@1 100.000 (99.981)   Prec@5 100.000 (100.000)   [2025-02-03 18:38:03]
  **Train** Prec@1 99.986 Prec@5 100.000 Error@1 0.014
  **Test** Prec@1 78.110 Prec@5 94.100 Error@1 21.890
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:38:06] [Epoch=195/200] [Need: 00:00:31] [learning_rate=0.0002] [Best : Accuracy=78.36, Error=21.64]
  Epoch: [195][000/128]   Time 0.139 (0.139)   Data 0.000 (0.000)   Loss 0.0083 (0.0083)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:38:07]
  Epoch: [195][200/128]   Time 0.011 (0.014)   Data 0.000 (0.000)   Loss 0.0084 (0.0088)   Prec@1 100.000 (99.981)   Prec@5 100.000 (100.000)   [2025-02-03 18:38:09]
  **Train** Prec@1 99.980 Prec@5 100.000 Error@1 0.020
  **Test** Prec@1 78.230 Prec@5 94.150 Error@1 21.770
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:38:13] [Epoch=196/200] [Need: 00:00:24] [learning_rate=0.0001] [Best : Accuracy=78.36, Error=21.64]
  Epoch: [196][000/128]   Time 0.124 (0.124)   Data 0.000 (0.000)   Loss 0.0081 (0.0081)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:38:13]
  Epoch: [196][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.0061 (0.0088)   Prec@1 100.000 (99.977)   Prec@5 100.000 (100.000)   [2025-02-03 18:38:15]
  **Train** Prec@1 99.980 Prec@5 100.000 Error@1 0.020
  **Test** Prec@1 78.040 Prec@5 94.230 Error@1 21.960
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:38:19] [Epoch=197/200] [Need: 00:00:18] [learning_rate=0.0001] [Best : Accuracy=78.36, Error=21.64]
  Epoch: [197][000/128]   Time 0.117 (0.117)   Data 0.000 (0.000)   Loss 0.0153 (0.0153)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2025-02-03 18:38:19]
  Epoch: [197][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0087 (0.0084)   Prec@1 100.000 (99.981)   Prec@5 100.000 (100.000)   [2025-02-03 18:38:22]
  **Train** Prec@1 99.970 Prec@5 100.000 Error@1 0.030
  **Test** Prec@1 78.290 Prec@5 94.150 Error@1 21.710
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:38:25] [Epoch=198/200] [Need: 00:00:12] [learning_rate=0.0000] [Best : Accuracy=78.36, Error=21.64]
  Epoch: [198][000/128]   Time 0.128 (0.128)   Data 0.000 (0.000)   Loss 0.0092 (0.0092)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:38:25]
  Epoch: [198][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.0066 (0.0088)   Prec@1 100.000 (99.969)   Prec@5 100.000 (100.000)   [2025-02-03 18:38:28]
  **Train** Prec@1 99.972 Prec@5 100.000 Error@1 0.028
  **Test** Prec@1 78.120 Prec@5 94.160 Error@1 21.880
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:38:32] [Epoch=199/200] [Need: 00:00:06] [learning_rate=0.0000] [Best : Accuracy=78.36, Error=21.64]
  Epoch: [199][000/128]   Time 0.110 (0.110)   Data 0.000 (0.000)   Loss 0.0066 (0.0066)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:38:32]
  Epoch: [199][200/128]   Time 0.015 (0.014)   Data 0.000 (0.000)   Loss 0.0089 (0.0085)   Prec@1 100.000 (99.981)   Prec@5 100.000 (100.000)   [2025-02-03 18:38:34]
  **Train** Prec@1 99.978 Prec@5 100.000 Error@1 0.022
  **Test** Prec@1 78.190 Prec@5 94.210 Error@1 21.810
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mranodom_pr0.0_resnet18_cifar100_seed55[0m at: [34mhttps://wandb.ai/hpi-deep-learning/c-class-iterations-full/runs/vgwkmbit[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250203_101753-vgwkmbit/logs[0m
