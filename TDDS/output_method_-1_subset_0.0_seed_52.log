wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/TDDS/wandb/run-20250203_101753-vb1l6u4j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ranodom_pr0.0_resnet18_cifar100_seed52
wandb: ⭐️ View project at https://wandb.ai/hpi-deep-learning/c-class-iterations-full
wandb: 🚀 View run at https://wandb.ai/hpi-deep-learning/c-class-iterations-full/runs/vb1l6u4j
./checkpoint/pruned-dataset
save path : ./checkpoint/pruned-dataset
{'data_path': './data', 'dataset': 'cifar100', 'arch': 'resnet18', 'epochs': 200, 'batch_size': 128, 'learning_rate': 0.1, 'momentum': 0.9, 'decay': 0.0005, 'print_freq': 200, 'save_path': './checkpoint/pruned-dataset', 'evaluate': False, 'subset_rate': 0.0, 'mask_path': './checkpoint/generated_mask/data_mask_win10_ep30.npy', 'score_path': './checkpoint/generated_mask/score_win10_ep30.npy', 'ngpu': 1, 'workers': 2, 'manualSeed': 52, 'pruning_methods': -1, 'use_cuda': True}
Random Seed: 52
python version : 3.12.8 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:31:09) [GCC 11.2.0]
torch  version : 2.5.1
cudnn  version : 90100
Dataset: cifar100
Data Path: ./data
Network: resnet18
Batchsize: 128
Learning Rate: 0.1
Momentum: 0.9
Weight Decay: 0.0005
Loading CIFAR100... Files already downloaded and verified
Files already downloaded and verified
=> creating model 'resnet18'
=> network :
 ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=100, bias=True)
)

==>>[2025-02-03 18:17:56] [Epoch=000/200] [Need: 00:00:00] [learning_rate=0.1000] [Best : Accuracy=0.00, Error=100.00]
  Epoch: [000][000/128]   Time 0.806 (0.806)   Data 0.000 (0.000)   Loss 4.7109 (4.7109)   Prec@1 0.000 (0.000)   Prec@5 4.688 (4.688)   [2025-02-03 18:17:56]
  Epoch: [000][200/128]   Time 0.013 (0.018)   Data 0.000 (0.000)   Loss 3.7288 (4.1122)   Prec@1 7.812 (7.109)   Prec@5 32.812 (24.343)   [2025-02-03 18:17:59]
  **Train** Prec@1 10.336 Prec@5 31.626 Error@1 89.664
  **Test** Prec@1 16.400 Prec@5 42.600 Error@1 83.600
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:18:03] [Epoch=001/200] [Need: 00:22:55] [learning_rate=0.1000] [Best : Accuracy=16.40, Error=83.60]
  Epoch: [001][000/128]   Time 0.111 (0.111)   Data 0.000 (0.000)   Loss 3.1900 (3.1900)   Prec@1 17.188 (17.188)   Prec@5 50.781 (50.781)   [2025-02-03 18:18:03]
  Epoch: [001][200/128]   Time 0.012 (0.013)   Data 0.000 (0.000)   Loss 2.8963 (3.2441)   Prec@1 25.781 (20.258)   Prec@5 62.500 (49.265)   [2025-02-03 18:18:05]
  **Train** Prec@1 22.946 Prec@5 52.888 Error@1 77.054
  **Test** Prec@1 27.870 Prec@5 58.340 Error@1 72.130
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:18:08] [Epoch=002/200] [Need: 00:20:56] [learning_rate=0.1000] [Best : Accuracy=27.87, Error=72.13]
  Epoch: [002][000/128]   Time 0.113 (0.113)   Data 0.000 (0.000)   Loss 2.8246 (2.8246)   Prec@1 28.906 (28.906)   Prec@5 52.344 (52.344)   [2025-02-03 18:18:08]
  Epoch: [002][200/128]   Time 0.012 (0.015)   Data 0.000 (0.000)   Loss 2.5533 (2.6408)   Prec@1 32.812 (31.596)   Prec@5 64.062 (64.230)   [2025-02-03 18:18:11]
  **Train** Prec@1 33.770 Prec@5 66.554 Error@1 66.230
  **Test** Prec@1 34.950 Prec@5 66.700 Error@1 65.050
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:18:15] [Epoch=003/200] [Need: 00:20:45] [learning_rate=0.0999] [Best : Accuracy=34.95, Error=65.05]
  Epoch: [003][000/128]   Time 0.124 (0.124)   Data 0.000 (0.000)   Loss 2.4525 (2.4525)   Prec@1 38.281 (38.281)   Prec@5 72.656 (72.656)   [2025-02-03 18:18:15]
  Epoch: [003][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 2.0912 (2.1755)   Prec@1 46.875 (41.200)   Prec@5 72.656 (74.510)   [2025-02-03 18:18:17]
  **Train** Prec@1 42.346 Prec@5 75.516 Error@1 57.654
  **Test** Prec@1 40.830 Prec@5 73.550 Error@1 59.170
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:18:21] [Epoch=004/200] [Need: 00:20:21] [learning_rate=0.0999] [Best : Accuracy=40.83, Error=59.17]
  Epoch: [004][000/128]   Time 0.128 (0.128)   Data 0.000 (0.000)   Loss 2.2244 (2.2244)   Prec@1 38.281 (38.281)   Prec@5 74.219 (74.219)   [2025-02-03 18:18:21]
  Epoch: [004][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.7701 (1.8770)   Prec@1 50.781 (47.862)   Prec@5 85.156 (80.337)   [2025-02-03 18:18:23]
  **Train** Prec@1 48.656 Prec@5 80.578 Error@1 51.344
  **Test** Prec@1 45.460 Prec@5 77.860 Error@1 54.540
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:18:27] [Epoch=005/200] [Need: 00:20:13] [learning_rate=0.0998] [Best : Accuracy=45.46, Error=54.54]
  Epoch: [005][000/128]   Time 0.125 (0.125)   Data 0.000 (0.000)   Loss 1.5921 (1.5921)   Prec@1 53.906 (53.906)   Prec@5 85.156 (85.156)   [2025-02-03 18:18:27]
  Epoch: [005][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 1.4397 (1.7193)   Prec@1 60.938 (51.873)   Prec@5 85.156 (83.065)   [2025-02-03 18:18:30]
  **Train** Prec@1 52.352 Prec@5 83.380 Error@1 47.648
  **Test** Prec@1 48.120 Prec@5 80.220 Error@1 51.880
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:18:33] [Epoch=006/200] [Need: 00:20:03] [learning_rate=0.0998] [Best : Accuracy=48.12, Error=51.88]
  Epoch: [006][000/128]   Time 0.136 (0.136)   Data 0.000 (0.000)   Loss 1.4417 (1.4417)   Prec@1 60.156 (60.156)   Prec@5 89.844 (89.844)   [2025-02-03 18:18:33]
  Epoch: [006][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.4996 (1.5793)   Prec@1 57.812 (55.325)   Prec@5 81.250 (85.176)   [2025-02-03 18:18:36]
  **Train** Prec@1 55.268 Prec@5 85.290 Error@1 44.732
  **Test** Prec@1 47.680 Prec@5 79.520 Error@1 52.320
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:18:39] [Epoch=007/200] [Need: 00:19:55] [learning_rate=0.0997] [Best : Accuracy=48.12, Error=51.88]
  Epoch: [007][000/128]   Time 0.140 (0.140)   Data 0.000 (0.000)   Loss 1.6070 (1.6070)   Prec@1 57.031 (57.031)   Prec@5 85.938 (85.938)   [2025-02-03 18:18:39]
  Epoch: [007][200/128]   Time 0.012 (0.013)   Data 0.000 (0.000)   Loss 1.6438 (1.4804)   Prec@1 50.000 (57.731)   Prec@5 84.375 (86.629)   [2025-02-03 18:18:42]
  **Train** Prec@1 57.408 Prec@5 86.582 Error@1 42.592
  **Test** Prec@1 47.880 Prec@5 78.600 Error@1 52.120
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:18:45] [Epoch=008/200] [Need: 00:19:45] [learning_rate=0.0996] [Best : Accuracy=48.12, Error=51.88]
  Epoch: [008][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 1.3966 (1.3966)   Prec@1 58.594 (58.594)   Prec@5 86.719 (86.719)   [2025-02-03 18:18:45]
  Epoch: [008][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.4992 (1.4311)   Prec@1 57.031 (59.146)   Prec@5 86.719 (87.776)   [2025-02-03 18:18:48]
  **Train** Prec@1 59.266 Prec@5 87.736 Error@1 40.734
  **Test** Prec@1 49.920 Prec@5 79.480 Error@1 50.080
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:18:51] [Epoch=009/200] [Need: 00:19:37] [learning_rate=0.0995] [Best : Accuracy=49.92, Error=50.08]
  Epoch: [009][000/128]   Time 0.148 (0.148)   Data 0.000 (0.000)   Loss 1.3756 (1.3756)   Prec@1 60.938 (60.938)   Prec@5 90.625 (90.625)   [2025-02-03 18:18:51]
  Epoch: [009][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.5227 (1.3574)   Prec@1 54.688 (60.879)   Prec@5 87.500 (88.888)   [2025-02-03 18:18:54]
  **Train** Prec@1 60.436 Prec@5 88.510 Error@1 39.564
  **Test** Prec@1 49.200 Prec@5 78.360 Error@1 50.800
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:18:57] [Epoch=010/200] [Need: 00:19:28] [learning_rate=0.0994] [Best : Accuracy=49.92, Error=50.08]
  Epoch: [010][000/128]   Time 0.118 (0.118)   Data 0.000 (0.000)   Loss 1.0635 (1.0635)   Prec@1 69.531 (69.531)   Prec@5 92.188 (92.188)   [2025-02-03 18:18:57]
  Epoch: [010][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.3740 (1.3043)   Prec@1 64.062 (62.411)   Prec@5 87.500 (89.482)   [2025-02-03 18:19:00]
  **Train** Prec@1 61.618 Prec@5 89.064 Error@1 38.382
  **Test** Prec@1 54.850 Prec@5 84.080 Error@1 45.150
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:19:03] [Epoch=011/200] [Need: 00:19:21] [learning_rate=0.0993] [Best : Accuracy=54.85, Error=45.15]
  Epoch: [011][000/128]   Time 0.134 (0.134)   Data 0.000 (0.000)   Loss 1.2917 (1.2917)   Prec@1 60.938 (60.938)   Prec@5 88.281 (88.281)   [2025-02-03 18:19:04]
  Epoch: [011][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 1.2691 (1.2697)   Prec@1 64.844 (63.441)   Prec@5 90.625 (90.093)   [2025-02-03 18:19:06]
  **Train** Prec@1 62.754 Prec@5 89.764 Error@1 37.246
  **Test** Prec@1 51.880 Prec@5 81.360 Error@1 48.120
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:19:09] [Epoch=012/200] [Need: 00:19:14] [learning_rate=0.0991] [Best : Accuracy=54.85, Error=45.15]
  Epoch: [012][000/128]   Time 0.128 (0.128)   Data 0.000 (0.000)   Loss 1.1431 (1.1431)   Prec@1 67.969 (67.969)   Prec@5 90.625 (90.625)   [2025-02-03 18:19:10]
  Epoch: [012][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.1717 (1.2384)   Prec@1 63.281 (63.996)   Prec@5 94.531 (90.310)   [2025-02-03 18:19:12]
  **Train** Prec@1 63.288 Prec@5 90.030 Error@1 36.712
  **Test** Prec@1 54.910 Prec@5 83.130 Error@1 45.090
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:19:16] [Epoch=013/200] [Need: 00:19:09] [learning_rate=0.0990] [Best : Accuracy=54.91, Error=45.09]
  Epoch: [013][000/128]   Time 0.137 (0.137)   Data 0.000 (0.000)   Loss 1.2283 (1.2283)   Prec@1 64.844 (64.844)   Prec@5 87.500 (87.500)   [2025-02-03 18:19:16]
  Epoch: [013][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 1.5747 (1.1988)   Prec@1 51.562 (65.159)   Prec@5 85.156 (90.951)   [2025-02-03 18:19:18]
  **Train** Prec@1 64.470 Prec@5 90.402 Error@1 35.530
  **Test** Prec@1 53.970 Prec@5 82.910 Error@1 46.030
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:19:22] [Epoch=014/200] [Need: 00:19:03] [learning_rate=0.0988] [Best : Accuracy=54.91, Error=45.09]
  Epoch: [014][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 1.1247 (1.1247)   Prec@1 66.406 (66.406)   Prec@5 90.625 (90.625)   [2025-02-03 18:19:22]
  Epoch: [014][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.2405 (1.1657)   Prec@1 64.844 (66.080)   Prec@5 89.844 (91.527)   [2025-02-03 18:19:24]
  **Train** Prec@1 64.900 Prec@5 90.862 Error@1 35.100
  **Test** Prec@1 53.430 Prec@5 82.490 Error@1 46.570
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:19:28] [Epoch=015/200] [Need: 00:18:57] [learning_rate=0.0986] [Best : Accuracy=54.91, Error=45.09]
  Epoch: [015][000/128]   Time 0.127 (0.127)   Data 0.000 (0.000)   Loss 1.0777 (1.0777)   Prec@1 67.188 (67.188)   Prec@5 92.969 (92.969)   [2025-02-03 18:19:28]
  Epoch: [015][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.0715 (1.1620)   Prec@1 71.094 (66.185)   Prec@5 93.750 (91.585)   [2025-02-03 18:19:31]
  **Train** Prec@1 65.490 Prec@5 91.196 Error@1 34.510
  **Test** Prec@1 55.480 Prec@5 84.140 Error@1 44.520
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:19:34] [Epoch=016/200] [Need: 00:18:51] [learning_rate=0.0984] [Best : Accuracy=55.48, Error=44.52]
  Epoch: [016][000/128]   Time 0.126 (0.126)   Data 0.000 (0.000)   Loss 1.0461 (1.0461)   Prec@1 71.875 (71.875)   Prec@5 90.625 (90.625)   [2025-02-03 18:19:34]
  Epoch: [016][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.0737 (1.1438)   Prec@1 71.094 (66.698)   Prec@5 92.969 (91.608)   [2025-02-03 18:19:37]
  **Train** Prec@1 66.176 Prec@5 91.338 Error@1 33.824
  **Test** Prec@1 57.240 Prec@5 85.360 Error@1 42.760
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:19:40] [Epoch=017/200] [Need: 00:18:43] [learning_rate=0.0982] [Best : Accuracy=57.24, Error=42.76]
  Epoch: [017][000/128]   Time 0.141 (0.141)   Data 0.000 (0.000)   Loss 1.1888 (1.1888)   Prec@1 67.188 (67.188)   Prec@5 88.281 (88.281)   [2025-02-03 18:19:40]
  Epoch: [017][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.5059 (1.1083)   Prec@1 57.031 (67.945)   Prec@5 84.375 (91.888)   [2025-02-03 18:19:43]
  **Train** Prec@1 66.688 Prec@5 91.526 Error@1 33.312
  **Test** Prec@1 56.030 Prec@5 84.180 Error@1 43.970
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:19:46] [Epoch=018/200] [Need: 00:18:37] [learning_rate=0.0980] [Best : Accuracy=57.24, Error=42.76]
  Epoch: [018][000/128]   Time 0.149 (0.149)   Data 0.000 (0.000)   Loss 1.2563 (1.2563)   Prec@1 61.719 (61.719)   Prec@5 92.969 (92.969)   [2025-02-03 18:19:46]
  Epoch: [018][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.0556 (1.1039)   Prec@1 63.281 (67.537)   Prec@5 93.750 (92.129)   [2025-02-03 18:19:49]
  **Train** Prec@1 66.942 Prec@5 91.798 Error@1 33.058
  **Test** Prec@1 58.810 Prec@5 85.810 Error@1 41.190
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:19:52] [Epoch=019/200] [Need: 00:18:29] [learning_rate=0.0978] [Best : Accuracy=58.81, Error=41.19]
  Epoch: [019][000/128]   Time 0.127 (0.127)   Data 0.000 (0.000)   Loss 1.0117 (1.0117)   Prec@1 70.312 (70.312)   Prec@5 92.969 (92.969)   [2025-02-03 18:19:52]
  Epoch: [019][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.1862 (1.0808)   Prec@1 64.844 (68.237)   Prec@5 89.844 (92.685)   [2025-02-03 18:19:55]
  **Train** Prec@1 67.580 Prec@5 92.106 Error@1 32.420
  **Test** Prec@1 58.090 Prec@5 85.200 Error@1 41.910
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:19:58] [Epoch=020/200] [Need: 00:18:23] [learning_rate=0.0976] [Best : Accuracy=58.81, Error=41.19]
  Epoch: [020][000/128]   Time 0.136 (0.136)   Data 0.000 (0.000)   Loss 0.9964 (0.9964)   Prec@1 67.188 (67.188)   Prec@5 92.188 (92.188)   [2025-02-03 18:19:58]
  Epoch: [020][200/128]   Time 0.015 (0.015)   Data 0.000 (0.000)   Loss 1.0997 (1.0653)   Prec@1 67.969 (69.003)   Prec@5 92.969 (92.518)   [2025-02-03 18:20:01]
  **Train** Prec@1 67.974 Prec@5 92.108 Error@1 32.026
  **Test** Prec@1 57.960 Prec@5 85.900 Error@1 42.040
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:20:04] [Epoch=021/200] [Need: 00:18:17] [learning_rate=0.0973] [Best : Accuracy=58.81, Error=41.19]
  Epoch: [021][000/128]   Time 0.129 (0.129)   Data 0.000 (0.000)   Loss 1.3115 (1.3115)   Prec@1 65.625 (65.625)   Prec@5 88.281 (88.281)   [2025-02-03 18:20:05]
  Epoch: [021][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.1494 (1.0507)   Prec@1 67.188 (69.104)   Prec@5 92.969 (93.031)   [2025-02-03 18:20:07]
  **Train** Prec@1 67.998 Prec@5 92.528 Error@1 32.002
  **Test** Prec@1 56.160 Prec@5 83.230 Error@1 43.840
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:20:11] [Epoch=022/200] [Need: 00:18:12] [learning_rate=0.0970] [Best : Accuracy=58.81, Error=41.19]
  Epoch: [022][000/128]   Time 0.144 (0.144)   Data 0.000 (0.000)   Loss 0.6839 (0.6839)   Prec@1 79.688 (79.688)   Prec@5 97.656 (97.656)   [2025-02-03 18:20:11]
  Epoch: [022][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.1086 (1.0375)   Prec@1 67.969 (69.570)   Prec@5 89.844 (93.089)   [2025-02-03 18:20:13]
  **Train** Prec@1 68.520 Prec@5 92.468 Error@1 31.480
  **Test** Prec@1 58.890 Prec@5 85.960 Error@1 41.110
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:20:17] [Epoch=023/200] [Need: 00:18:05] [learning_rate=0.0968] [Best : Accuracy=58.89, Error=41.11]
  Epoch: [023][000/128]   Time 0.155 (0.155)   Data 0.000 (0.000)   Loss 1.0139 (1.0139)   Prec@1 70.312 (70.312)   Prec@5 96.094 (96.094)   [2025-02-03 18:20:17]
  Epoch: [023][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.1748 (1.0090)   Prec@1 67.188 (70.281)   Prec@5 91.406 (93.478)   [2025-02-03 18:20:20]
  **Train** Prec@1 69.002 Prec@5 92.810 Error@1 30.998
  **Test** Prec@1 57.540 Prec@5 85.650 Error@1 42.460
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:20:23] [Epoch=024/200] [Need: 00:17:59] [learning_rate=0.0965] [Best : Accuracy=58.89, Error=41.11]
  Epoch: [024][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.8952 (0.8952)   Prec@1 75.000 (75.000)   Prec@5 96.094 (96.094)   [2025-02-03 18:20:23]
  Epoch: [024][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.0450 (1.0176)   Prec@1 71.094 (70.149)   Prec@5 90.625 (93.276)   [2025-02-03 18:20:26]
  **Train** Prec@1 69.210 Prec@5 92.842 Error@1 30.790
  **Test** Prec@1 57.750 Prec@5 85.900 Error@1 42.250
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:20:29] [Epoch=025/200] [Need: 00:17:52] [learning_rate=0.0962] [Best : Accuracy=58.89, Error=41.11]
  Epoch: [025][000/128]   Time 0.134 (0.134)   Data 0.000 (0.000)   Loss 0.9529 (0.9529)   Prec@1 73.438 (73.438)   Prec@5 92.188 (92.188)   [2025-02-03 18:20:29]
  Epoch: [025][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 1.0290 (1.0055)   Prec@1 74.219 (70.476)   Prec@5 89.062 (93.528)   [2025-02-03 18:20:32]
  **Train** Prec@1 69.606 Prec@5 92.928 Error@1 30.394
  **Test** Prec@1 59.760 Prec@5 86.340 Error@1 40.240
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:20:35] [Epoch=026/200] [Need: 00:17:47] [learning_rate=0.0959] [Best : Accuracy=59.76, Error=40.24]
  Epoch: [026][000/128]   Time 0.127 (0.127)   Data 0.000 (0.000)   Loss 1.0110 (1.0110)   Prec@1 67.188 (67.188)   Prec@5 96.094 (96.094)   [2025-02-03 18:20:35]
  Epoch: [026][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 1.0139 (1.0082)   Prec@1 73.438 (70.375)   Prec@5 94.531 (93.330)   [2025-02-03 18:20:38]
  **Train** Prec@1 69.492 Prec@5 92.928 Error@1 30.508
  **Test** Prec@1 53.720 Prec@5 82.800 Error@1 46.280
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:20:41] [Epoch=027/200] [Need: 00:17:40] [learning_rate=0.0956] [Best : Accuracy=59.76, Error=40.24]
  Epoch: [027][000/128]   Time 0.117 (0.117)   Data 0.000 (0.000)   Loss 0.7473 (0.7473)   Prec@1 75.781 (75.781)   Prec@5 99.219 (99.219)   [2025-02-03 18:20:41]
  Epoch: [027][200/128]   Time 0.012 (0.013)   Data 0.000 (0.000)   Loss 1.0134 (0.9872)   Prec@1 71.875 (70.752)   Prec@5 93.750 (93.785)   [2025-02-03 18:20:44]
  **Train** Prec@1 69.908 Prec@5 93.228 Error@1 30.092
  **Test** Prec@1 55.810 Prec@5 84.180 Error@1 44.190
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:20:47] [Epoch=028/200] [Need: 00:17:33] [learning_rate=0.0952] [Best : Accuracy=59.76, Error=40.24]
  Epoch: [028][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.8857 (0.8857)   Prec@1 75.000 (75.000)   Prec@5 92.969 (92.969)   [2025-02-03 18:20:47]
  Epoch: [028][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.9618 (0.9679)   Prec@1 72.656 (71.591)   Prec@5 92.188 (93.801)   [2025-02-03 18:20:50]
  **Train** Prec@1 70.566 Prec@5 93.314 Error@1 29.434
  **Test** Prec@1 59.460 Prec@5 86.480 Error@1 40.540
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:20:53] [Epoch=029/200] [Need: 00:17:26] [learning_rate=0.0949] [Best : Accuracy=59.76, Error=40.24]
  Epoch: [029][000/128]   Time 0.134 (0.134)   Data 0.000 (0.000)   Loss 0.9769 (0.9769)   Prec@1 75.781 (75.781)   Prec@5 93.750 (93.750)   [2025-02-03 18:20:53]
  Epoch: [029][200/128]   Time 0.012 (0.014)   Data 0.000 (0.000)   Loss 1.3657 (0.9659)   Prec@1 60.156 (71.700)   Prec@5 92.188 (93.870)   [2025-02-03 18:20:56]
  **Train** Prec@1 70.500 Prec@5 93.310 Error@1 29.500
  **Test** Prec@1 59.110 Prec@5 86.320 Error@1 40.890
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:20:59] [Epoch=030/200] [Need: 00:17:20] [learning_rate=0.0946] [Best : Accuracy=59.76, Error=40.24]
  Epoch: [030][000/128]   Time 0.126 (0.126)   Data 0.000 (0.000)   Loss 1.0642 (1.0642)   Prec@1 70.312 (70.312)   Prec@5 92.188 (92.188)   [2025-02-03 18:20:59]
  Epoch: [030][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.9232 (0.9616)   Prec@1 75.000 (71.533)   Prec@5 92.969 (94.139)   [2025-02-03 18:21:02]
  **Train** Prec@1 70.596 Prec@5 93.510 Error@1 29.404
  **Test** Prec@1 58.590 Prec@5 86.470 Error@1 41.410
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:21:05] [Epoch=031/200] [Need: 00:17:14] [learning_rate=0.0942] [Best : Accuracy=59.76, Error=40.24]
  Epoch: [031][000/128]   Time 0.133 (0.133)   Data 0.000 (0.000)   Loss 0.9841 (0.9841)   Prec@1 71.094 (71.094)   Prec@5 93.750 (93.750)   [2025-02-03 18:21:06]
  Epoch: [031][200/128]   Time 0.011 (0.014)   Data 0.000 (0.000)   Loss 0.9044 (0.9436)   Prec@1 69.531 (71.999)   Prec@5 96.094 (94.189)   [2025-02-03 18:21:08]
  **Train** Prec@1 70.758 Prec@5 93.718 Error@1 29.242
  **Test** Prec@1 59.180 Prec@5 86.340 Error@1 40.820
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:21:12] [Epoch=032/200] [Need: 00:17:08] [learning_rate=0.0938] [Best : Accuracy=59.76, Error=40.24]
  Epoch: [032][000/128]   Time 0.127 (0.127)   Data 0.000 (0.000)   Loss 0.8310 (0.8310)   Prec@1 75.000 (75.000)   Prec@5 96.875 (96.875)   [2025-02-03 18:21:12]
  Epoch: [032][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 1.1499 (0.9507)   Prec@1 60.156 (71.875)   Prec@5 95.312 (93.972)   [2025-02-03 18:21:14]
  **Train** Prec@1 71.184 Prec@5 93.616 Error@1 28.816
  **Test** Prec@1 56.940 Prec@5 84.310 Error@1 43.060
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:21:17] [Epoch=033/200] [Need: 00:17:00] [learning_rate=0.0934] [Best : Accuracy=59.76, Error=40.24]
  Epoch: [033][000/128]   Time 0.124 (0.124)   Data 0.000 (0.000)   Loss 0.8585 (0.8585)   Prec@1 74.219 (74.219)   Prec@5 96.875 (96.875)   [2025-02-03 18:21:18]
  Epoch: [033][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.0902 (0.9371)   Prec@1 68.750 (71.992)   Prec@5 89.844 (94.248)   [2025-02-03 18:21:20]
  **Train** Prec@1 70.948 Prec@5 93.670 Error@1 29.052
  **Test** Prec@1 57.080 Prec@5 84.600 Error@1 42.920
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:21:23] [Epoch=034/200] [Need: 00:16:54] [learning_rate=0.0930] [Best : Accuracy=59.76, Error=40.24]
  Epoch: [034][000/128]   Time 0.138 (0.138)   Data 0.000 (0.000)   Loss 0.7356 (0.7356)   Prec@1 76.562 (76.562)   Prec@5 99.219 (99.219)   [2025-02-03 18:21:24]
  Epoch: [034][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.9716 (0.9301)   Prec@1 68.750 (72.310)   Prec@5 96.875 (94.329)   [2025-02-03 18:21:26]
  **Train** Prec@1 71.398 Prec@5 93.768 Error@1 28.602
  **Test** Prec@1 60.520 Prec@5 86.930 Error@1 39.480
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:21:30] [Epoch=035/200] [Need: 00:16:48] [learning_rate=0.0926] [Best : Accuracy=60.52, Error=39.48]
  Epoch: [035][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.7301 (0.7301)   Prec@1 77.344 (77.344)   Prec@5 96.875 (96.875)   [2025-02-03 18:21:30]
  Epoch: [035][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.9030 (0.9146)   Prec@1 72.656 (73.119)   Prec@5 95.312 (94.520)   [2025-02-03 18:21:32]
  **Train** Prec@1 71.828 Prec@5 93.886 Error@1 28.172
  **Test** Prec@1 60.000 Prec@5 87.010 Error@1 40.000
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:21:36] [Epoch=036/200] [Need: 00:16:41] [learning_rate=0.0922] [Best : Accuracy=60.52, Error=39.48]
  Epoch: [036][000/128]   Time 0.128 (0.128)   Data 0.000 (0.000)   Loss 0.9211 (0.9211)   Prec@1 74.219 (74.219)   Prec@5 94.531 (94.531)   [2025-02-03 18:21:36]
  Epoch: [036][200/128]   Time 0.012 (0.014)   Data 0.000 (0.000)   Loss 1.0008 (0.9047)   Prec@1 71.094 (73.154)   Prec@5 93.750 (94.761)   [2025-02-03 18:21:38]
  **Train** Prec@1 71.960 Prec@5 94.112 Error@1 28.040
  **Test** Prec@1 60.940 Prec@5 87.350 Error@1 39.060
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:21:42] [Epoch=037/200] [Need: 00:16:35] [learning_rate=0.0918] [Best : Accuracy=60.94, Error=39.06]
  Epoch: [037][000/128]   Time 0.125 (0.125)   Data 0.000 (0.000)   Loss 0.6583 (0.6583)   Prec@1 82.812 (82.812)   Prec@5 96.094 (96.094)   [2025-02-03 18:21:42]
  Epoch: [037][200/128]   Time 0.012 (0.013)   Data 0.000 (0.000)   Loss 0.7840 (0.9032)   Prec@1 75.000 (73.263)   Prec@5 98.438 (94.733)   [2025-02-03 18:21:44]
  **Train** Prec@1 72.052 Prec@5 94.144 Error@1 27.948
  **Test** Prec@1 59.090 Prec@5 86.060 Error@1 40.910
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:21:47] [Epoch=038/200] [Need: 00:16:28] [learning_rate=0.0914] [Best : Accuracy=60.94, Error=39.06]
  Epoch: [038][000/128]   Time 0.116 (0.116)   Data 0.000 (0.000)   Loss 0.7615 (0.7615)   Prec@1 76.562 (76.562)   Prec@5 97.656 (97.656)   [2025-02-03 18:21:48]
  Epoch: [038][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.9522 (0.9091)   Prec@1 73.438 (72.761)   Prec@5 94.531 (94.652)   [2025-02-03 18:21:50]
  **Train** Prec@1 71.888 Prec@5 94.176 Error@1 28.112
  **Test** Prec@1 60.450 Prec@5 86.790 Error@1 39.550
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:21:54] [Epoch=039/200] [Need: 00:16:22] [learning_rate=0.0909] [Best : Accuracy=60.94, Error=39.06]
  Epoch: [039][000/128]   Time 0.129 (0.129)   Data 0.000 (0.000)   Loss 0.7908 (0.7908)   Prec@1 72.656 (72.656)   Prec@5 96.094 (96.094)   [2025-02-03 18:21:54]
  Epoch: [039][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.0972 (0.9027)   Prec@1 64.062 (73.336)   Prec@5 92.188 (94.543)   [2025-02-03 18:21:56]
  **Train** Prec@1 72.224 Prec@5 94.196 Error@1 27.776
  **Test** Prec@1 59.730 Prec@5 86.890 Error@1 40.270
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:22:00] [Epoch=040/200] [Need: 00:16:16] [learning_rate=0.0905] [Best : Accuracy=60.94, Error=39.06]
  Epoch: [040][000/128]   Time 0.140 (0.140)   Data 0.000 (0.000)   Loss 0.8034 (0.8034)   Prec@1 79.688 (79.688)   Prec@5 96.094 (96.094)   [2025-02-03 18:22:00]
  Epoch: [040][200/128]   Time 0.012 (0.014)   Data 0.000 (0.000)   Loss 0.9627 (0.8955)   Prec@1 72.656 (73.329)   Prec@5 91.406 (94.807)   [2025-02-03 18:22:03]
  **Train** Prec@1 72.504 Prec@5 94.398 Error@1 27.496
  **Test** Prec@1 59.270 Prec@5 85.790 Error@1 40.730
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:22:06] [Epoch=041/200] [Need: 00:16:10] [learning_rate=0.0900] [Best : Accuracy=60.94, Error=39.06]
  Epoch: [041][000/128]   Time 0.126 (0.126)   Data 0.000 (0.000)   Loss 0.8402 (0.8402)   Prec@1 73.438 (73.438)   Prec@5 96.875 (96.875)   [2025-02-03 18:22:06]
  Epoch: [041][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 0.9196 (0.8747)   Prec@1 70.312 (74.048)   Prec@5 94.531 (94.823)   [2025-02-03 18:22:09]
  **Train** Prec@1 72.608 Prec@5 94.274 Error@1 27.392
  **Test** Prec@1 59.720 Prec@5 86.490 Error@1 40.280
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:22:12] [Epoch=042/200] [Need: 00:16:03] [learning_rate=0.0895] [Best : Accuracy=60.94, Error=39.06]
  Epoch: [042][000/128]   Time 0.125 (0.125)   Data 0.000 (0.000)   Loss 0.7536 (0.7536)   Prec@1 75.000 (75.000)   Prec@5 97.656 (97.656)   [2025-02-03 18:22:12]
  Epoch: [042][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 0.8760 (0.8653)   Prec@1 73.438 (74.440)   Prec@5 95.312 (95.110)   [2025-02-03 18:22:15]
  **Train** Prec@1 73.238 Prec@5 94.566 Error@1 26.762
  **Test** Prec@1 61.240 Prec@5 87.240 Error@1 38.760
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:22:18] [Epoch=043/200] [Need: 00:15:58] [learning_rate=0.0890] [Best : Accuracy=61.24, Error=38.76]
  Epoch: [043][000/128]   Time 0.116 (0.116)   Data 0.000 (0.000)   Loss 0.9695 (0.9695)   Prec@1 68.750 (68.750)   Prec@5 96.875 (96.875)   [2025-02-03 18:22:18]
  Epoch: [043][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.0082 (0.8668)   Prec@1 71.094 (74.285)   Prec@5 92.969 (95.064)   [2025-02-03 18:22:21]
  **Train** Prec@1 72.992 Prec@5 94.514 Error@1 27.008
  **Test** Prec@1 59.920 Prec@5 86.060 Error@1 40.080
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:22:24] [Epoch=044/200] [Need: 00:15:51] [learning_rate=0.0885] [Best : Accuracy=61.24, Error=38.76]
  Epoch: [044][000/128]   Time 0.125 (0.125)   Data 0.000 (0.000)   Loss 0.9840 (0.9840)   Prec@1 67.969 (67.969)   Prec@5 96.094 (96.094)   [2025-02-03 18:22:24]
  Epoch: [044][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.7116 (0.8712)   Prec@1 75.781 (73.997)   Prec@5 96.875 (95.169)   [2025-02-03 18:22:27]
  **Train** Prec@1 73.038 Prec@5 94.706 Error@1 26.962
  **Test** Prec@1 59.950 Prec@5 86.620 Error@1 40.050
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:22:30] [Epoch=045/200] [Need: 00:15:46] [learning_rate=0.0880] [Best : Accuracy=61.24, Error=38.76]
  Epoch: [045][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.8864 (0.8864)   Prec@1 75.000 (75.000)   Prec@5 94.531 (94.531)   [2025-02-03 18:22:30]
  Epoch: [045][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.9820 (0.8642)   Prec@1 71.875 (74.192)   Prec@5 96.094 (95.141)   [2025-02-03 18:22:33]
  **Train** Prec@1 73.162 Prec@5 94.726 Error@1 26.838
  **Test** Prec@1 56.290 Prec@5 85.270 Error@1 43.710
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:22:36] [Epoch=046/200] [Need: 00:15:39] [learning_rate=0.0875] [Best : Accuracy=61.24, Error=38.76]
  Epoch: [046][000/128]   Time 0.127 (0.127)   Data 0.000 (0.000)   Loss 0.8012 (0.8012)   Prec@1 72.656 (72.656)   Prec@5 97.656 (97.656)   [2025-02-03 18:22:36]
  Epoch: [046][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.6675 (0.8495)   Prec@1 80.469 (74.401)   Prec@5 97.656 (95.449)   [2025-02-03 18:22:39]
  **Train** Prec@1 73.384 Prec@5 94.902 Error@1 26.616
  **Test** Prec@1 62.210 Prec@5 87.600 Error@1 37.790
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:22:43] [Epoch=047/200] [Need: 00:15:33] [learning_rate=0.0870] [Best : Accuracy=62.21, Error=37.79]
  Epoch: [047][000/128]   Time 0.125 (0.125)   Data 0.000 (0.000)   Loss 0.6815 (0.6815)   Prec@1 81.250 (81.250)   Prec@5 99.219 (99.219)   [2025-02-03 18:22:43]
  Epoch: [047][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.9721 (0.8381)   Prec@1 70.312 (74.942)   Prec@5 95.312 (95.476)   [2025-02-03 18:22:45]
  **Train** Prec@1 73.574 Prec@5 94.806 Error@1 26.426
  **Test** Prec@1 56.090 Prec@5 84.190 Error@1 43.910
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:22:49] [Epoch=048/200] [Need: 00:15:27] [learning_rate=0.0864] [Best : Accuracy=62.21, Error=37.79]
  Epoch: [048][000/128]   Time 0.129 (0.129)   Data 0.000 (0.000)   Loss 0.8377 (0.8377)   Prec@1 75.781 (75.781)   Prec@5 94.531 (94.531)   [2025-02-03 18:22:49]
  Epoch: [048][200/128]   Time 0.011 (0.014)   Data 0.000 (0.000)   Loss 1.0115 (0.8395)   Prec@1 71.875 (74.899)   Prec@5 93.750 (95.460)   [2025-02-03 18:22:52]
  **Train** Prec@1 73.946 Prec@5 94.990 Error@1 26.054
  **Test** Prec@1 55.100 Prec@5 83.350 Error@1 44.900
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:22:55] [Epoch=049/200] [Need: 00:15:22] [learning_rate=0.0859] [Best : Accuracy=62.21, Error=37.79]
  Epoch: [049][000/128]   Time 0.119 (0.119)   Data 0.000 (0.000)   Loss 0.8104 (0.8104)   Prec@1 75.000 (75.000)   Prec@5 96.875 (96.875)   [2025-02-03 18:22:55]
  Epoch: [049][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.6949 (0.8393)   Prec@1 76.562 (75.008)   Prec@5 96.094 (95.359)   [2025-02-03 18:22:58]
  **Train** Prec@1 74.088 Prec@5 94.950 Error@1 25.912
  **Test** Prec@1 61.110 Prec@5 87.950 Error@1 38.890
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:23:01] [Epoch=050/200] [Need: 00:15:15] [learning_rate=0.0854] [Best : Accuracy=62.21, Error=37.79]
  Epoch: [050][000/128]   Time 0.125 (0.125)   Data 0.000 (0.000)   Loss 0.7238 (0.7238)   Prec@1 77.344 (77.344)   Prec@5 96.094 (96.094)   [2025-02-03 18:23:01]
  Epoch: [050][200/128]   Time 0.011 (0.014)   Data 0.000 (0.000)   Loss 0.7311 (0.8311)   Prec@1 77.344 (75.210)   Prec@5 93.750 (95.542)   [2025-02-03 18:23:04]
  **Train** Prec@1 74.056 Prec@5 94.998 Error@1 25.944
  **Test** Prec@1 60.570 Prec@5 87.500 Error@1 39.430
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:23:07] [Epoch=051/200] [Need: 00:15:09] [learning_rate=0.0848] [Best : Accuracy=62.21, Error=37.79]
  Epoch: [051][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.7851 (0.7851)   Prec@1 74.219 (74.219)   Prec@5 95.312 (95.312)   [2025-02-03 18:23:07]
  Epoch: [051][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.6020 (0.8106)   Prec@1 82.812 (75.770)   Prec@5 98.438 (95.779)   [2025-02-03 18:23:10]
  **Train** Prec@1 74.574 Prec@5 95.210 Error@1 25.426
  **Test** Prec@1 62.370 Prec@5 88.190 Error@1 37.630
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:23:13] [Epoch=052/200] [Need: 00:15:02] [learning_rate=0.0842] [Best : Accuracy=62.37, Error=37.63]
  Epoch: [052][000/128]   Time 0.127 (0.127)   Data 0.000 (0.000)   Loss 0.6914 (0.6914)   Prec@1 80.469 (80.469)   Prec@5 96.094 (96.094)   [2025-02-03 18:23:13]
  Epoch: [052][200/128]   Time 0.012 (0.013)   Data 0.000 (0.000)   Loss 0.9488 (0.7998)   Prec@1 68.750 (76.042)   Prec@5 98.438 (95.756)   [2025-02-03 18:23:16]
  **Train** Prec@1 74.630 Prec@5 95.170 Error@1 25.370
  **Test** Prec@1 58.430 Prec@5 84.910 Error@1 41.570
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:23:19] [Epoch=053/200] [Need: 00:14:56] [learning_rate=0.0837] [Best : Accuracy=62.37, Error=37.63]
  Epoch: [053][000/128]   Time 0.126 (0.126)   Data 0.000 (0.000)   Loss 0.8305 (0.8305)   Prec@1 75.000 (75.000)   Prec@5 97.656 (97.656)   [2025-02-03 18:23:19]
  Epoch: [053][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.0517 (0.8166)   Prec@1 65.625 (75.272)   Prec@5 92.969 (95.787)   [2025-02-03 18:23:22]
  **Train** Prec@1 74.458 Prec@5 95.390 Error@1 25.542
  **Test** Prec@1 60.540 Prec@5 87.080 Error@1 39.460
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:23:25] [Epoch=054/200] [Need: 00:14:50] [learning_rate=0.0831] [Best : Accuracy=62.37, Error=37.63]
  Epoch: [054][000/128]   Time 0.109 (0.109)   Data 0.000 (0.000)   Loss 0.6348 (0.6348)   Prec@1 82.031 (82.031)   Prec@5 97.656 (97.656)   [2025-02-03 18:23:25]
  Epoch: [054][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.9159 (0.8139)   Prec@1 72.656 (75.544)   Prec@5 96.875 (95.888)   [2025-02-03 18:23:28]
  **Train** Prec@1 74.620 Prec@5 95.428 Error@1 25.380
  **Test** Prec@1 60.470 Prec@5 86.520 Error@1 39.530
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:23:31] [Epoch=055/200] [Need: 00:14:44] [learning_rate=0.0825] [Best : Accuracy=62.37, Error=37.63]
  Epoch: [055][000/128]   Time 0.106 (0.106)   Data 0.000 (0.000)   Loss 0.6747 (0.6747)   Prec@1 82.031 (82.031)   Prec@5 96.875 (96.875)   [2025-02-03 18:23:31]
  Epoch: [055][200/128]   Time 0.012 (0.014)   Data 0.000 (0.000)   Loss 0.8089 (0.7885)   Prec@1 78.906 (76.454)   Prec@5 95.312 (95.911)   [2025-02-03 18:23:34]
  **Train** Prec@1 75.240 Prec@5 95.582 Error@1 24.760
  **Test** Prec@1 58.560 Prec@5 86.020 Error@1 41.440
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:23:37] [Epoch=056/200] [Need: 00:14:38] [learning_rate=0.0819] [Best : Accuracy=62.37, Error=37.63]
  Epoch: [056][000/128]   Time 0.143 (0.143)   Data 0.000 (0.000)   Loss 0.7246 (0.7246)   Prec@1 78.125 (78.125)   Prec@5 96.875 (96.875)   [2025-02-03 18:23:37]
  Epoch: [056][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.9529 (0.7948)   Prec@1 71.875 (76.069)   Prec@5 96.094 (95.973)   [2025-02-03 18:23:40]
  **Train** Prec@1 74.814 Prec@5 95.464 Error@1 25.186
  **Test** Prec@1 60.030 Prec@5 87.150 Error@1 39.970
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:23:44] [Epoch=057/200] [Need: 00:14:32] [learning_rate=0.0813] [Best : Accuracy=62.37, Error=37.63]
  Epoch: [057][000/128]   Time 0.126 (0.126)   Data 0.000 (0.000)   Loss 0.6395 (0.6395)   Prec@1 76.562 (76.562)   Prec@5 98.438 (98.438)   [2025-02-03 18:23:44]
  Epoch: [057][200/128]   Time 0.012 (0.014)   Data 0.000 (0.000)   Loss 0.8507 (0.7769)   Prec@1 75.000 (76.613)   Prec@5 93.750 (96.094)   [2025-02-03 18:23:46]
  **Train** Prec@1 75.516 Prec@5 95.690 Error@1 24.484
  **Test** Prec@1 60.930 Prec@5 87.210 Error@1 39.070
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:23:50] [Epoch=058/200] [Need: 00:14:26] [learning_rate=0.0806] [Best : Accuracy=62.37, Error=37.63]
  Epoch: [058][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.8106 (0.8106)   Prec@1 75.781 (75.781)   Prec@5 95.312 (95.312)   [2025-02-03 18:23:50]
  Epoch: [058][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 1.0275 (0.7891)   Prec@1 64.844 (76.154)   Prec@5 92.969 (96.070)   [2025-02-03 18:23:52]
  **Train** Prec@1 75.080 Prec@5 95.562 Error@1 24.920
  **Test** Prec@1 61.430 Prec@5 87.600 Error@1 38.570
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:23:56] [Epoch=059/200] [Need: 00:14:20] [learning_rate=0.0800] [Best : Accuracy=62.37, Error=37.63]
  Epoch: [059][000/128]   Time 0.127 (0.127)   Data 0.000 (0.000)   Loss 0.7766 (0.7766)   Prec@1 81.250 (81.250)   Prec@5 94.531 (94.531)   [2025-02-03 18:23:56]
  Epoch: [059][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.8578 (0.7651)   Prec@1 75.781 (76.994)   Prec@5 94.531 (96.203)   [2025-02-03 18:23:59]
  **Train** Prec@1 75.668 Prec@5 95.676 Error@1 24.332
  **Test** Prec@1 61.560 Prec@5 87.480 Error@1 38.440
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:24:02] [Epoch=060/200] [Need: 00:14:14] [learning_rate=0.0794] [Best : Accuracy=62.37, Error=37.63]
  Epoch: [060][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.6280 (0.6280)   Prec@1 78.125 (78.125)   Prec@5 96.094 (96.094)   [2025-02-03 18:24:02]
  Epoch: [060][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.5612 (0.7632)   Prec@1 82.031 (77.041)   Prec@5 97.656 (96.327)   [2025-02-03 18:24:05]
  **Train** Prec@1 76.012 Prec@5 95.956 Error@1 23.988
  **Test** Prec@1 63.030 Prec@5 88.240 Error@1 36.970
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:24:08] [Epoch=061/200] [Need: 00:14:08] [learning_rate=0.0788] [Best : Accuracy=63.03, Error=36.97]
  Epoch: [061][000/128]   Time 0.147 (0.147)   Data 0.000 (0.000)   Loss 0.6032 (0.6032)   Prec@1 84.375 (84.375)   Prec@5 96.875 (96.875)   [2025-02-03 18:24:08]
  Epoch: [061][200/128]   Time 0.012 (0.014)   Data 0.000 (0.000)   Loss 0.8374 (0.7599)   Prec@1 75.781 (77.079)   Prec@5 96.875 (96.354)   [2025-02-03 18:24:11]
  **Train** Prec@1 75.786 Prec@5 95.750 Error@1 24.214
  **Test** Prec@1 62.850 Prec@5 88.420 Error@1 37.150
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:24:14] [Epoch=062/200] [Need: 00:14:02] [learning_rate=0.0781] [Best : Accuracy=63.03, Error=36.97]
  Epoch: [062][000/128]   Time 0.117 (0.117)   Data 0.000 (0.000)   Loss 0.6929 (0.6929)   Prec@1 78.906 (78.906)   Prec@5 95.312 (95.312)   [2025-02-03 18:24:14]
  Epoch: [062][200/128]   Time 0.012 (0.013)   Data 0.000 (0.000)   Loss 1.0228 (0.7391)   Prec@1 67.188 (77.923)   Prec@5 93.750 (96.529)   [2025-02-03 18:24:17]
  **Train** Prec@1 76.504 Prec@5 96.046 Error@1 23.496
  **Test** Prec@1 57.570 Prec@5 85.070 Error@1 42.430
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:24:20] [Epoch=063/200] [Need: 00:13:56] [learning_rate=0.0775] [Best : Accuracy=63.03, Error=36.97]
  Epoch: [063][000/128]   Time 0.115 (0.115)   Data 0.000 (0.000)   Loss 0.6677 (0.6677)   Prec@1 82.812 (82.812)   Prec@5 96.094 (96.094)   [2025-02-03 18:24:20]
  Epoch: [063][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.8983 (0.7492)   Prec@1 78.125 (77.476)   Prec@5 96.094 (96.397)   [2025-02-03 18:24:23]
  **Train** Prec@1 76.296 Prec@5 95.966 Error@1 23.704
  **Test** Prec@1 61.710 Prec@5 86.830 Error@1 38.290
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:24:27] [Epoch=064/200] [Need: 00:13:50] [learning_rate=0.0768] [Best : Accuracy=63.03, Error=36.97]
  Epoch: [064][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.8479 (0.8479)   Prec@1 72.656 (72.656)   Prec@5 93.750 (93.750)   [2025-02-03 18:24:27]
  Epoch: [064][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.8223 (0.7317)   Prec@1 75.000 (78.039)   Prec@5 96.094 (96.599)   [2025-02-03 18:24:29]
  **Train** Prec@1 76.594 Prec@5 96.116 Error@1 23.406
  **Test** Prec@1 62.780 Prec@5 87.790 Error@1 37.220
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:24:33] [Epoch=065/200] [Need: 00:13:44] [learning_rate=0.0761] [Best : Accuracy=63.03, Error=36.97]
  Epoch: [065][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 0.6511 (0.6511)   Prec@1 83.594 (83.594)   Prec@5 96.094 (96.094)   [2025-02-03 18:24:33]
  Epoch: [065][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 0.9451 (0.7302)   Prec@1 74.219 (77.783)   Prec@5 95.312 (96.618)   [2025-02-03 18:24:35]
  **Train** Prec@1 76.862 Prec@5 96.156 Error@1 23.138
  **Test** Prec@1 60.100 Prec@5 86.920 Error@1 39.900
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:24:39] [Epoch=066/200] [Need: 00:13:38] [learning_rate=0.0755] [Best : Accuracy=63.03, Error=36.97]
  Epoch: [066][000/128]   Time 0.115 (0.115)   Data 0.000 (0.000)   Loss 0.7602 (0.7602)   Prec@1 78.125 (78.125)   Prec@5 98.438 (98.438)   [2025-02-03 18:24:39]
  Epoch: [066][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.6614 (0.7072)   Prec@1 78.906 (78.568)   Prec@5 99.219 (96.778)   [2025-02-03 18:24:41]
  **Train** Prec@1 77.056 Prec@5 96.170 Error@1 22.944
  **Test** Prec@1 61.730 Prec@5 86.310 Error@1 38.270
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:24:45] [Epoch=067/200] [Need: 00:13:32] [learning_rate=0.0748] [Best : Accuracy=63.03, Error=36.97]
  Epoch: [067][000/128]   Time 0.110 (0.110)   Data 0.000 (0.000)   Loss 0.7588 (0.7588)   Prec@1 78.906 (78.906)   Prec@5 96.094 (96.094)   [2025-02-03 18:24:45]
  Epoch: [067][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.8028 (0.7131)   Prec@1 75.781 (78.459)   Prec@5 96.875 (96.696)   [2025-02-03 18:24:47]
  **Train** Prec@1 77.240 Prec@5 96.332 Error@1 22.760
  **Test** Prec@1 60.740 Prec@5 86.100 Error@1 39.260
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:24:51] [Epoch=068/200] [Need: 00:13:25] [learning_rate=0.0741] [Best : Accuracy=63.03, Error=36.97]
  Epoch: [068][000/128]   Time 0.133 (0.133)   Data 0.000 (0.000)   Loss 0.6286 (0.6286)   Prec@1 80.469 (80.469)   Prec@5 97.656 (97.656)   [2025-02-03 18:24:51]
  Epoch: [068][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 1.0305 (0.7093)   Prec@1 67.969 (78.630)   Prec@5 94.531 (96.727)   [2025-02-03 18:24:54]
  **Train** Prec@1 77.678 Prec@5 96.462 Error@1 22.322
  **Test** Prec@1 61.130 Prec@5 87.270 Error@1 38.870
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:24:57] [Epoch=069/200] [Need: 00:13:19] [learning_rate=0.0734] [Best : Accuracy=63.03, Error=36.97]
  Epoch: [069][000/128]   Time 0.151 (0.151)   Data 0.000 (0.000)   Loss 0.7054 (0.7054)   Prec@1 74.219 (74.219)   Prec@5 97.656 (97.656)   [2025-02-03 18:24:57]
  Epoch: [069][200/128]   Time 0.012 (0.014)   Data 0.000 (0.000)   Loss 0.8320 (0.7049)   Prec@1 78.906 (78.339)   Prec@5 94.531 (96.898)   [2025-02-03 18:25:00]
  **Train** Prec@1 77.466 Prec@5 96.468 Error@1 22.534
  **Test** Prec@1 61.900 Prec@5 86.670 Error@1 38.100
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:25:03] [Epoch=070/200] [Need: 00:13:13] [learning_rate=0.0727] [Best : Accuracy=63.03, Error=36.97]
  Epoch: [070][000/128]   Time 0.139 (0.139)   Data 0.000 (0.000)   Loss 0.7342 (0.7342)   Prec@1 80.469 (80.469)   Prec@5 98.438 (98.438)   [2025-02-03 18:25:03]
  Epoch: [070][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.6221 (0.6849)   Prec@1 81.250 (78.949)   Prec@5 98.438 (96.941)   [2025-02-03 18:25:06]
  **Train** Prec@1 77.748 Prec@5 96.482 Error@1 22.252
  **Test** Prec@1 60.300 Prec@5 87.030 Error@1 39.700
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:25:09] [Epoch=071/200] [Need: 00:13:07] [learning_rate=0.0720] [Best : Accuracy=63.03, Error=36.97]
  Epoch: [071][000/128]   Time 0.141 (0.141)   Data 0.000 (0.000)   Loss 0.6939 (0.6939)   Prec@1 76.562 (76.562)   Prec@5 96.094 (96.094)   [2025-02-03 18:25:09]
  Epoch: [071][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.6419 (0.6861)   Prec@1 77.344 (78.813)   Prec@5 97.656 (97.015)   [2025-02-03 18:25:12]
  **Train** Prec@1 77.584 Prec@5 96.568 Error@1 22.416
  **Test** Prec@1 61.330 Prec@5 87.480 Error@1 38.670
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:25:15] [Epoch=072/200] [Need: 00:13:01] [learning_rate=0.0713] [Best : Accuracy=63.03, Error=36.97]
  Epoch: [072][000/128]   Time 0.115 (0.115)   Data 0.000 (0.000)   Loss 0.6446 (0.6446)   Prec@1 78.906 (78.906)   Prec@5 98.438 (98.438)   [2025-02-03 18:25:15]
  Epoch: [072][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.7501 (0.6636)   Prec@1 79.688 (80.030)   Prec@5 95.312 (97.135)   [2025-02-03 18:25:18]
  **Train** Prec@1 78.440 Prec@5 96.608 Error@1 21.560
  **Test** Prec@1 61.600 Prec@5 86.500 Error@1 38.400
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:25:21] [Epoch=073/200] [Need: 00:12:54] [learning_rate=0.0706] [Best : Accuracy=63.03, Error=36.97]
  Epoch: [073][000/128]   Time 0.113 (0.113)   Data 0.000 (0.000)   Loss 0.6126 (0.6126)   Prec@1 81.250 (81.250)   Prec@5 99.219 (99.219)   [2025-02-03 18:25:21]
  Epoch: [073][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.6468 (0.6633)   Prec@1 85.938 (79.967)   Prec@5 99.219 (97.198)   [2025-02-03 18:25:24]
  **Train** Prec@1 78.502 Prec@5 96.750 Error@1 21.498
  **Test** Prec@1 59.940 Prec@5 86.620 Error@1 40.060
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:25:27] [Epoch=074/200] [Need: 00:12:48] [learning_rate=0.0699] [Best : Accuracy=63.03, Error=36.97]
  Epoch: [074][000/128]   Time 0.141 (0.141)   Data 0.000 (0.000)   Loss 0.5753 (0.5753)   Prec@1 79.688 (79.688)   Prec@5 100.000 (100.000)   [2025-02-03 18:25:27]
  Epoch: [074][200/128]   Time 0.015 (0.013)   Data 0.000 (0.000)   Loss 0.6182 (0.6583)   Prec@1 82.812 (79.792)   Prec@5 96.875 (97.334)   [2025-02-03 18:25:30]
  **Train** Prec@1 78.712 Prec@5 96.852 Error@1 21.288
  **Test** Prec@1 63.240 Prec@5 88.250 Error@1 36.760
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:25:33] [Epoch=075/200] [Need: 00:12:42] [learning_rate=0.0691] [Best : Accuracy=63.24, Error=36.76]
  Epoch: [075][000/128]   Time 0.360 (0.360)   Data 0.000 (0.000)   Loss 0.6671 (0.6671)   Prec@1 78.125 (78.125)   Prec@5 98.438 (98.438)   [2025-02-03 18:25:34]
  Epoch: [075][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.7350 (0.6485)   Prec@1 75.000 (80.286)   Prec@5 96.875 (97.303)   [2025-02-03 18:25:36]
  **Train** Prec@1 78.720 Prec@5 96.904 Error@1 21.280
  **Test** Prec@1 63.700 Prec@5 88.810 Error@1 36.300
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:25:40] [Epoch=076/200] [Need: 00:12:37] [learning_rate=0.0684] [Best : Accuracy=63.70, Error=36.30]
  Epoch: [076][000/128]   Time 0.127 (0.127)   Data 0.000 (0.000)   Loss 0.4506 (0.4506)   Prec@1 85.156 (85.156)   Prec@5 99.219 (99.219)   [2025-02-03 18:25:40]
  Epoch: [076][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.8404 (0.6474)   Prec@1 74.219 (80.294)   Prec@5 96.094 (97.458)   [2025-02-03 18:25:43]
  **Train** Prec@1 79.110 Prec@5 97.054 Error@1 20.890
  **Test** Prec@1 61.630 Prec@5 87.700 Error@1 38.370
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:25:46] [Epoch=077/200] [Need: 00:12:31] [learning_rate=0.0677] [Best : Accuracy=63.70, Error=36.30]
  Epoch: [077][000/128]   Time 0.128 (0.128)   Data 0.000 (0.000)   Loss 0.6993 (0.6993)   Prec@1 77.344 (77.344)   Prec@5 95.312 (95.312)   [2025-02-03 18:25:46]
  Epoch: [077][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.6852 (0.6449)   Prec@1 78.125 (80.418)   Prec@5 96.094 (97.213)   [2025-02-03 18:25:49]
  **Train** Prec@1 79.106 Prec@5 96.870 Error@1 20.894
  **Test** Prec@1 62.990 Prec@5 87.470 Error@1 37.010
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:25:52] [Epoch=078/200] [Need: 00:12:25] [learning_rate=0.0669] [Best : Accuracy=63.70, Error=36.30]
  Epoch: [078][000/128]   Time 0.137 (0.137)   Data 0.000 (0.000)   Loss 0.6428 (0.6428)   Prec@1 82.812 (82.812)   Prec@5 96.875 (96.875)   [2025-02-03 18:25:52]
  Epoch: [078][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.6156 (0.6238)   Prec@1 81.250 (80.865)   Prec@5 97.656 (97.625)   [2025-02-03 18:25:55]
  **Train** Prec@1 79.544 Prec@5 97.146 Error@1 20.456
  **Test** Prec@1 62.850 Prec@5 87.090 Error@1 37.150
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:25:58] [Epoch=079/200] [Need: 00:12:19] [learning_rate=0.0662] [Best : Accuracy=63.70, Error=36.30]
  Epoch: [079][000/128]   Time 0.130 (0.130)   Data 0.000 (0.000)   Loss 0.7236 (0.7236)   Prec@1 82.031 (82.031)   Prec@5 97.656 (97.656)   [2025-02-03 18:25:59]
  Epoch: [079][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.5729 (0.6214)   Prec@1 84.375 (81.285)   Prec@5 97.656 (97.532)   [2025-02-03 18:26:01]
  **Train** Prec@1 79.816 Prec@5 97.146 Error@1 20.184
  **Test** Prec@1 61.180 Prec@5 86.760 Error@1 38.820
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:26:04] [Epoch=080/200] [Need: 00:12:13] [learning_rate=0.0655] [Best : Accuracy=63.70, Error=36.30]
  Epoch: [080][000/128]   Time 0.116 (0.116)   Data 0.000 (0.000)   Loss 0.7470 (0.7470)   Prec@1 79.688 (79.688)   Prec@5 97.656 (97.656)   [2025-02-03 18:26:05]
  Epoch: [080][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.7855 (0.6101)   Prec@1 75.781 (81.440)   Prec@5 96.094 (97.656)   [2025-02-03 18:26:07]
  **Train** Prec@1 80.110 Prec@5 97.300 Error@1 19.890
  **Test** Prec@1 62.820 Prec@5 88.060 Error@1 37.180
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:26:11] [Epoch=081/200] [Need: 00:12:06] [learning_rate=0.0647] [Best : Accuracy=63.70, Error=36.30]
  Epoch: [081][000/128]   Time 0.126 (0.126)   Data 0.000 (0.000)   Loss 0.5434 (0.5434)   Prec@1 86.719 (86.719)   Prec@5 96.875 (96.875)   [2025-02-03 18:26:11]
  Epoch: [081][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.8531 (0.6185)   Prec@1 74.219 (81.180)   Prec@5 95.312 (97.411)   [2025-02-03 18:26:13]
  **Train** Prec@1 79.802 Prec@5 97.210 Error@1 20.198
  **Test** Prec@1 62.990 Prec@5 87.200 Error@1 37.010
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:26:17] [Epoch=082/200] [Need: 00:12:00] [learning_rate=0.0639] [Best : Accuracy=63.70, Error=36.30]
  Epoch: [082][000/128]   Time 0.125 (0.125)   Data 0.000 (0.000)   Loss 0.6620 (0.6620)   Prec@1 81.250 (81.250)   Prec@5 98.438 (98.438)   [2025-02-03 18:26:17]
  Epoch: [082][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.5518 (0.5750)   Prec@1 85.156 (82.323)   Prec@5 95.312 (97.870)   [2025-02-03 18:26:19]
  **Train** Prec@1 80.710 Prec@5 97.414 Error@1 19.290
  **Test** Prec@1 63.480 Prec@5 88.100 Error@1 36.520
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:26:23] [Epoch=083/200] [Need: 00:11:54] [learning_rate=0.0632] [Best : Accuracy=63.70, Error=36.30]
  Epoch: [083][000/128]   Time 0.106 (0.106)   Data 0.000 (0.000)   Loss 0.5453 (0.5453)   Prec@1 82.812 (82.812)   Prec@5 99.219 (99.219)   [2025-02-03 18:26:23]
  Epoch: [083][200/128]   Time 0.011 (0.013)   Data 0.000 (0.000)   Loss 0.6771 (0.5858)   Prec@1 82.812 (81.891)   Prec@5 95.312 (97.788)   [2025-02-03 18:26:25]
  **Train** Prec@1 80.406 Prec@5 97.420 Error@1 19.594
  **Test** Prec@1 63.730 Prec@5 88.230 Error@1 36.270
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:26:29] [Epoch=084/200] [Need: 00:11:48] [learning_rate=0.0624] [Best : Accuracy=63.73, Error=36.27]
  Epoch: [084][000/128]   Time 0.114 (0.114)   Data 0.000 (0.000)   Loss 0.6019 (0.6019)   Prec@1 78.906 (78.906)   Prec@5 96.875 (96.875)   [2025-02-03 18:26:29]
  Epoch: [084][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.6048 (0.5830)   Prec@1 80.469 (82.148)   Prec@5 97.656 (97.940)   [2025-02-03 18:26:31]
  **Train** Prec@1 80.654 Prec@5 97.538 Error@1 19.346
  **Test** Prec@1 62.860 Prec@5 87.650 Error@1 37.140
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:26:35] [Epoch=085/200] [Need: 00:11:42] [learning_rate=0.0617] [Best : Accuracy=63.73, Error=36.27]
  Epoch: [085][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.4083 (0.4083)   Prec@1 89.062 (89.062)   Prec@5 100.000 (100.000)   [2025-02-03 18:26:35]
  Epoch: [085][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.6019 (0.5763)   Prec@1 84.375 (82.171)   Prec@5 97.656 (98.076)   [2025-02-03 18:26:37]
  **Train** Prec@1 80.758 Prec@5 97.546 Error@1 19.242
  **Test** Prec@1 63.760 Prec@5 88.810 Error@1 36.240
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:26:41] [Epoch=086/200] [Need: 00:11:35] [learning_rate=0.0609] [Best : Accuracy=63.76, Error=36.24]
  Epoch: [086][000/128]   Time 0.127 (0.127)   Data 0.000 (0.000)   Loss 0.4590 (0.4590)   Prec@1 84.375 (84.375)   Prec@5 98.438 (98.438)   [2025-02-03 18:26:41]
  Epoch: [086][200/128]   Time 0.014 (0.015)   Data 0.000 (0.000)   Loss 0.5761 (0.5549)   Prec@1 82.812 (82.976)   Prec@5 97.656 (98.123)   [2025-02-03 18:26:44]
  **Train** Prec@1 81.402 Prec@5 97.688 Error@1 18.598
  **Test** Prec@1 64.580 Prec@5 88.520 Error@1 35.420
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:26:47] [Epoch=087/200] [Need: 00:11:30] [learning_rate=0.0601] [Best : Accuracy=64.58, Error=35.42]
  Epoch: [087][000/128]   Time 0.133 (0.133)   Data 0.000 (0.000)   Loss 0.4900 (0.4900)   Prec@1 86.719 (86.719)   Prec@5 96.875 (96.875)   [2025-02-03 18:26:47]
  Epoch: [087][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.5918 (0.5608)   Prec@1 80.469 (82.739)   Prec@5 98.438 (98.095)   [2025-02-03 18:26:50]
  **Train** Prec@1 81.322 Prec@5 97.716 Error@1 18.678
  **Test** Prec@1 64.070 Prec@5 88.880 Error@1 35.930
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:26:53] [Epoch=088/200] [Need: 00:11:23] [learning_rate=0.0594] [Best : Accuracy=64.58, Error=35.42]
  Epoch: [088][000/128]   Time 0.125 (0.125)   Data 0.000 (0.000)   Loss 0.5561 (0.5561)   Prec@1 83.594 (83.594)   Prec@5 99.219 (99.219)   [2025-02-03 18:26:53]
  Epoch: [088][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.6319 (0.5635)   Prec@1 78.125 (82.925)   Prec@5 96.875 (97.979)   [2025-02-03 18:26:56]
  **Train** Prec@1 81.928 Prec@5 97.806 Error@1 18.072
  **Test** Prec@1 62.110 Prec@5 87.770 Error@1 37.890
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:26:59] [Epoch=089/200] [Need: 00:11:17] [learning_rate=0.0586] [Best : Accuracy=64.58, Error=35.42]
  Epoch: [089][000/128]   Time 0.127 (0.127)   Data 0.000 (0.000)   Loss 0.5291 (0.5291)   Prec@1 86.719 (86.719)   Prec@5 98.438 (98.438)   [2025-02-03 18:26:59]
  Epoch: [089][200/128]   Time 0.064 (0.015)   Data 0.000 (0.000)   Loss 0.5571 (0.5386)   Prec@1 82.031 (83.345)   Prec@5 96.094 (98.099)   [2025-02-03 18:27:02]
  **Train** Prec@1 82.228 Prec@5 97.818 Error@1 17.772
  **Test** Prec@1 65.890 Prec@5 88.770 Error@1 34.110
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:27:05] [Epoch=090/200] [Need: 00:11:11] [learning_rate=0.0578] [Best : Accuracy=65.89, Error=34.11]
  Epoch: [090][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.5167 (0.5167)   Prec@1 82.812 (82.812)   Prec@5 99.219 (99.219)   [2025-02-03 18:27:06]
  Epoch: [090][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.5929 (0.5354)   Prec@1 84.375 (83.469)   Prec@5 97.656 (98.290)   [2025-02-03 18:27:08]
  **Train** Prec@1 82.258 Prec@5 97.968 Error@1 17.742
  **Test** Prec@1 63.380 Prec@5 88.580 Error@1 36.620
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:27:11] [Epoch=091/200] [Need: 00:11:05] [learning_rate=0.0570] [Best : Accuracy=65.89, Error=34.11]
  Epoch: [091][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.4225 (0.4225)   Prec@1 88.281 (88.281)   Prec@5 97.656 (97.656)   [2025-02-03 18:27:12]
  Epoch: [091][200/128]   Time 0.014 (0.015)   Data 0.000 (0.000)   Loss 0.6142 (0.5295)   Prec@1 80.469 (83.893)   Prec@5 99.219 (98.204)   [2025-02-03 18:27:14]
  **Train** Prec@1 82.474 Prec@5 97.982 Error@1 17.526
  **Test** Prec@1 63.260 Prec@5 88.200 Error@1 36.740
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:27:18] [Epoch=092/200] [Need: 00:10:59] [learning_rate=0.0563] [Best : Accuracy=65.89, Error=34.11]
  Epoch: [092][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.4257 (0.4257)   Prec@1 86.719 (86.719)   Prec@5 99.219 (99.219)   [2025-02-03 18:27:18]
  Epoch: [092][200/128]   Time 0.012 (0.013)   Data 0.000 (0.000)   Loss 0.5407 (0.5100)   Prec@1 79.688 (84.356)   Prec@5 100.000 (98.449)   [2025-02-03 18:27:20]
  **Train** Prec@1 82.802 Prec@5 98.106 Error@1 17.198
  **Test** Prec@1 63.980 Prec@5 88.060 Error@1 36.020
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:27:24] [Epoch=093/200] [Need: 00:10:53] [learning_rate=0.0555] [Best : Accuracy=65.89, Error=34.11]
  Epoch: [093][000/128]   Time 0.349 (0.349)   Data 0.000 (0.000)   Loss 0.5117 (0.5117)   Prec@1 85.938 (85.938)   Prec@5 98.438 (98.438)   [2025-02-03 18:27:24]
  Epoch: [093][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.5278 (0.5110)   Prec@1 81.250 (84.142)   Prec@5 99.219 (98.387)   [2025-02-03 18:27:27]
  **Train** Prec@1 83.154 Prec@5 98.050 Error@1 16.846
  **Test** Prec@1 64.960 Prec@5 89.050 Error@1 35.040
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:27:30] [Epoch=094/200] [Need: 00:10:47] [learning_rate=0.0547] [Best : Accuracy=65.89, Error=34.11]
  Epoch: [094][000/128]   Time 0.127 (0.127)   Data 0.000 (0.000)   Loss 0.4401 (0.4401)   Prec@1 88.281 (88.281)   Prec@5 98.438 (98.438)   [2025-02-03 18:27:30]
  Epoch: [094][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 0.4844 (0.4879)   Prec@1 85.938 (85.253)   Prec@5 98.438 (98.511)   [2025-02-03 18:27:33]
  **Train** Prec@1 83.536 Prec@5 98.146 Error@1 16.464
  **Test** Prec@1 66.040 Prec@5 89.720 Error@1 33.960
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:27:36] [Epoch=095/200] [Need: 00:10:41] [learning_rate=0.0539] [Best : Accuracy=66.04, Error=33.96]
  Epoch: [095][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.5626 (0.5626)   Prec@1 83.594 (83.594)   Prec@5 99.219 (99.219)   [2025-02-03 18:27:36]
  Epoch: [095][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.4860 (0.4874)   Prec@1 85.938 (85.044)   Prec@5 98.438 (98.640)   [2025-02-03 18:27:39]
  **Train** Prec@1 83.620 Prec@5 98.272 Error@1 16.380
  **Test** Prec@1 65.290 Prec@5 88.920 Error@1 34.710
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:27:43] [Epoch=096/200] [Need: 00:10:35] [learning_rate=0.0531] [Best : Accuracy=66.04, Error=33.96]
  Epoch: [096][000/128]   Time 0.146 (0.146)   Data 0.000 (0.000)   Loss 0.5956 (0.5956)   Prec@1 81.250 (81.250)   Prec@5 97.656 (97.656)   [2025-02-03 18:27:43]
  Epoch: [096][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.4120 (0.4843)   Prec@1 88.281 (85.102)   Prec@5 99.219 (98.647)   [2025-02-03 18:27:45]
  **Train** Prec@1 83.766 Prec@5 98.292 Error@1 16.234
  **Test** Prec@1 64.460 Prec@5 88.090 Error@1 35.540
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:27:49] [Epoch=097/200] [Need: 00:10:29] [learning_rate=0.0524] [Best : Accuracy=66.04, Error=33.96]
  Epoch: [097][000/128]   Time 0.128 (0.128)   Data 0.000 (0.000)   Loss 0.5908 (0.5908)   Prec@1 77.344 (77.344)   Prec@5 97.656 (97.656)   [2025-02-03 18:27:49]
  Epoch: [097][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.5366 (0.4791)   Prec@1 84.375 (85.079)   Prec@5 98.438 (98.725)   [2025-02-03 18:27:51]
  **Train** Prec@1 83.956 Prec@5 98.410 Error@1 16.044
  **Test** Prec@1 65.690 Prec@5 89.380 Error@1 34.310
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:27:54] [Epoch=098/200] [Need: 00:10:23] [learning_rate=0.0516] [Best : Accuracy=66.04, Error=33.96]
  Epoch: [098][000/128]   Time 0.124 (0.124)   Data 0.000 (0.000)   Loss 0.3308 (0.3308)   Prec@1 89.844 (89.844)   Prec@5 99.219 (99.219)   [2025-02-03 18:27:55]
  Epoch: [098][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.2978 (0.4585)   Prec@1 90.625 (85.716)   Prec@5 100.000 (98.857)   [2025-02-03 18:27:57]
  **Train** Prec@1 84.356 Prec@5 98.592 Error@1 15.644
  **Test** Prec@1 65.640 Prec@5 89.060 Error@1 34.360
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:28:01] [Epoch=099/200] [Need: 00:10:17] [learning_rate=0.0508] [Best : Accuracy=66.04, Error=33.96]
  Epoch: [099][000/128]   Time 0.117 (0.117)   Data 0.000 (0.000)   Loss 0.4389 (0.4389)   Prec@1 88.281 (88.281)   Prec@5 99.219 (99.219)   [2025-02-03 18:28:01]
  Epoch: [099][200/128]   Time 0.014 (0.015)   Data 0.000 (0.000)   Loss 0.4972 (0.4640)   Prec@1 86.719 (85.840)   Prec@5 99.219 (98.826)   [2025-02-03 18:28:04]
  **Train** Prec@1 84.508 Prec@5 98.492 Error@1 15.492
  **Test** Prec@1 65.100 Prec@5 88.430 Error@1 34.900
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:28:07] [Epoch=100/200] [Need: 00:10:11] [learning_rate=0.0500] [Best : Accuracy=66.04, Error=33.96]
  Epoch: [100][000/128]   Time 0.137 (0.137)   Data 0.000 (0.000)   Loss 0.4778 (0.4778)   Prec@1 86.719 (86.719)   Prec@5 98.438 (98.438)   [2025-02-03 18:28:07]
  Epoch: [100][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.4817 (0.4398)   Prec@1 85.156 (86.384)   Prec@5 98.438 (98.997)   [2025-02-03 18:28:10]
  **Train** Prec@1 85.202 Prec@5 98.706 Error@1 14.798
  **Test** Prec@1 65.400 Prec@5 89.180 Error@1 34.600
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:28:13] [Epoch=101/200] [Need: 00:10:05] [learning_rate=0.0492] [Best : Accuracy=66.04, Error=33.96]
  Epoch: [101][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 0.4847 (0.4847)   Prec@1 85.938 (85.938)   Prec@5 99.219 (99.219)   [2025-02-03 18:28:13]
  Epoch: [101][200/128]   Time 0.015 (0.015)   Data 0.000 (0.000)   Loss 0.4510 (0.4357)   Prec@1 85.938 (86.416)   Prec@5 99.219 (98.982)   [2025-02-03 18:28:16]
  **Train** Prec@1 85.374 Prec@5 98.726 Error@1 14.626
  **Test** Prec@1 64.750 Prec@5 89.080 Error@1 35.250
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:28:19] [Epoch=102/200] [Need: 00:09:59] [learning_rate=0.0484] [Best : Accuracy=66.04, Error=33.96]
  Epoch: [102][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.4711 (0.4711)   Prec@1 83.594 (83.594)   Prec@5 99.219 (99.219)   [2025-02-03 18:28:19]
  Epoch: [102][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.5721 (0.4239)   Prec@1 78.906 (86.995)   Prec@5 99.219 (98.958)   [2025-02-03 18:28:22]
  **Train** Prec@1 85.348 Prec@5 98.632 Error@1 14.652
  **Test** Prec@1 65.550 Prec@5 88.710 Error@1 34.450
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:28:26] [Epoch=103/200] [Need: 00:09:53] [learning_rate=0.0476] [Best : Accuracy=66.04, Error=33.96]
  Epoch: [103][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.4770 (0.4770)   Prec@1 86.719 (86.719)   Prec@5 99.219 (99.219)   [2025-02-03 18:28:26]
  Epoch: [103][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.4479 (0.4077)   Prec@1 89.062 (87.481)   Prec@5 98.438 (99.021)   [2025-02-03 18:28:29]
  **Train** Prec@1 86.400 Prec@5 98.836 Error@1 13.600
  **Test** Prec@1 65.640 Prec@5 88.930 Error@1 34.360
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:28:32] [Epoch=104/200] [Need: 00:09:47] [learning_rate=0.0469] [Best : Accuracy=66.04, Error=33.96]
  Epoch: [104][000/128]   Time 0.117 (0.117)   Data 0.000 (0.000)   Loss 0.4136 (0.4136)   Prec@1 85.156 (85.156)   Prec@5 99.219 (99.219)   [2025-02-03 18:28:32]
  Epoch: [104][200/128]   Time 0.012 (0.014)   Data 0.000 (0.000)   Loss 0.5257 (0.4004)   Prec@1 83.594 (87.830)   Prec@5 98.438 (99.087)   [2025-02-03 18:28:35]
  **Train** Prec@1 86.568 Prec@5 98.818 Error@1 13.432
  **Test** Prec@1 64.450 Prec@5 88.250 Error@1 35.550
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:28:38] [Epoch=105/200] [Need: 00:09:41] [learning_rate=0.0461] [Best : Accuracy=66.04, Error=33.96]
  Epoch: [105][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.2733 (0.2733)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2025-02-03 18:28:38]
  Epoch: [105][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.3517 (0.3887)   Prec@1 88.281 (87.928)   Prec@5 99.219 (99.184)   [2025-02-03 18:28:41]
  **Train** Prec@1 86.832 Prec@5 99.004 Error@1 13.168
  **Test** Prec@1 66.080 Prec@5 89.020 Error@1 33.920
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:28:44] [Epoch=106/200] [Need: 00:09:35] [learning_rate=0.0453] [Best : Accuracy=66.08, Error=33.92]
  Epoch: [106][000/128]   Time 0.119 (0.119)   Data 0.000 (0.000)   Loss 0.3713 (0.3713)   Prec@1 89.844 (89.844)   Prec@5 97.656 (97.656)   [2025-02-03 18:28:44]
  Epoch: [106][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.4456 (0.4055)   Prec@1 89.062 (87.356)   Prec@5 96.875 (99.075)   [2025-02-03 18:28:47]
  **Train** Prec@1 86.532 Prec@5 98.866 Error@1 13.468
  **Test** Prec@1 66.020 Prec@5 88.970 Error@1 33.980
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:28:50] [Epoch=107/200] [Need: 00:09:28] [learning_rate=0.0445] [Best : Accuracy=66.08, Error=33.92]
  Epoch: [107][000/128]   Time 0.115 (0.115)   Data 0.000 (0.000)   Loss 0.4084 (0.4084)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2025-02-03 18:28:50]
  Epoch: [107][200/128]   Time 0.014 (0.015)   Data 0.000 (0.000)   Loss 0.5086 (0.3892)   Prec@1 82.812 (87.912)   Prec@5 99.219 (99.168)   [2025-02-03 18:28:53]
  **Train** Prec@1 86.848 Prec@5 98.960 Error@1 13.152
  **Test** Prec@1 67.440 Prec@5 89.960 Error@1 32.560
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:28:57] [Epoch=108/200] [Need: 00:09:22] [learning_rate=0.0437] [Best : Accuracy=67.44, Error=32.56]
  Epoch: [108][000/128]   Time 0.117 (0.117)   Data 0.000 (0.000)   Loss 0.4916 (0.4916)   Prec@1 83.594 (83.594)   Prec@5 98.438 (98.438)   [2025-02-03 18:28:57]
  Epoch: [108][200/128]   Time 0.012 (0.014)   Data 0.000 (0.000)   Loss 0.2550 (0.3780)   Prec@1 92.188 (88.169)   Prec@5 100.000 (99.293)   [2025-02-03 18:28:59]
  **Train** Prec@1 87.114 Prec@5 99.104 Error@1 12.886
  **Test** Prec@1 65.530 Prec@5 88.630 Error@1 34.470
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:29:03] [Epoch=109/200] [Need: 00:09:16] [learning_rate=0.0430] [Best : Accuracy=67.44, Error=32.56]
  Epoch: [109][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.2634 (0.2634)   Prec@1 95.312 (95.312)   Prec@5 99.219 (99.219)   [2025-02-03 18:29:03]
  Epoch: [109][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.4230 (0.3575)   Prec@1 88.281 (89.028)   Prec@5 98.438 (99.335)   [2025-02-03 18:29:06]
  **Train** Prec@1 87.760 Prec@5 99.126 Error@1 12.240
  **Test** Prec@1 66.710 Prec@5 89.460 Error@1 33.290
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:29:09] [Epoch=110/200] [Need: 00:09:10] [learning_rate=0.0422] [Best : Accuracy=67.44, Error=32.56]
  Epoch: [110][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.4046 (0.4046)   Prec@1 86.719 (86.719)   Prec@5 100.000 (100.000)   [2025-02-03 18:29:09]
  Epoch: [110][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.4800 (0.3604)   Prec@1 89.844 (88.717)   Prec@5 97.656 (99.293)   [2025-02-03 18:29:11]
  **Train** Prec@1 87.792 Prec@5 99.152 Error@1 12.208
  **Test** Prec@1 65.900 Prec@5 89.210 Error@1 34.100
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:29:15] [Epoch=111/200] [Need: 00:09:04] [learning_rate=0.0414] [Best : Accuracy=67.44, Error=32.56]
  Epoch: [111][000/128]   Time 0.539 (0.539)   Data 0.000 (0.000)   Loss 0.3985 (0.3985)   Prec@1 87.500 (87.500)   Prec@5 99.219 (99.219)   [2025-02-03 18:29:15]
  Epoch: [111][200/128]   Time 0.015 (0.016)   Data 0.000 (0.000)   Loss 0.4391 (0.3496)   Prec@1 86.719 (89.164)   Prec@5 99.219 (99.417)   [2025-02-03 18:29:18]
  **Train** Prec@1 88.236 Prec@5 99.216 Error@1 11.764
  **Test** Prec@1 66.460 Prec@5 89.470 Error@1 33.540
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:29:21] [Epoch=112/200] [Need: 00:08:58] [learning_rate=0.0406] [Best : Accuracy=67.44, Error=32.56]
  Epoch: [112][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.3649 (0.3649)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2025-02-03 18:29:21]
  Epoch: [112][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.4313 (0.3610)   Prec@1 86.719 (88.845)   Prec@5 100.000 (99.359)   [2025-02-03 18:29:24]
  **Train** Prec@1 87.842 Prec@5 99.246 Error@1 12.158
  **Test** Prec@1 65.280 Prec@5 89.040 Error@1 34.720
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:29:27] [Epoch=113/200] [Need: 00:08:52] [learning_rate=0.0399] [Best : Accuracy=67.44, Error=32.56]
  Epoch: [113][000/128]   Time 0.148 (0.148)   Data 0.000 (0.000)   Loss 0.4339 (0.4339)   Prec@1 87.500 (87.500)   Prec@5 97.656 (97.656)   [2025-02-03 18:29:28]
  Epoch: [113][200/128]   Time 0.015 (0.015)   Data 0.000 (0.000)   Loss 0.4378 (0.3255)   Prec@1 87.500 (89.937)   Prec@5 99.219 (99.495)   [2025-02-03 18:29:30]
  **Train** Prec@1 89.090 Prec@5 99.354 Error@1 10.910
  **Test** Prec@1 67.330 Prec@5 89.840 Error@1 32.670
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:29:34] [Epoch=114/200] [Need: 00:08:46] [learning_rate=0.0391] [Best : Accuracy=67.44, Error=32.56]
  Epoch: [114][000/128]   Time 0.140 (0.140)   Data 0.000 (0.000)   Loss 0.3023 (0.3023)   Prec@1 89.844 (89.844)   Prec@5 100.000 (100.000)   [2025-02-03 18:29:34]
  Epoch: [114][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.3542 (0.3278)   Prec@1 90.625 (90.217)   Prec@5 100.000 (99.386)   [2025-02-03 18:29:37]
  **Train** Prec@1 89.250 Prec@5 99.318 Error@1 10.750
  **Test** Prec@1 65.640 Prec@5 89.030 Error@1 34.360
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:29:40] [Epoch=115/200] [Need: 00:08:40] [learning_rate=0.0383] [Best : Accuracy=67.44, Error=32.56]
  Epoch: [115][000/128]   Time 0.115 (0.115)   Data 0.000 (0.000)   Loss 0.2778 (0.2778)   Prec@1 92.969 (92.969)   Prec@5 99.219 (99.219)   [2025-02-03 18:29:40]
  Epoch: [115][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.4545 (0.3108)   Prec@1 85.938 (90.365)   Prec@5 96.875 (99.436)   [2025-02-03 18:29:43]
  **Train** Prec@1 89.346 Prec@5 99.370 Error@1 10.654
  **Test** Prec@1 66.620 Prec@5 88.890 Error@1 33.380
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:29:46] [Epoch=116/200] [Need: 00:08:34] [learning_rate=0.0376] [Best : Accuracy=67.44, Error=32.56]
  Epoch: [116][000/128]   Time 0.116 (0.116)   Data 0.000 (0.000)   Loss 0.2369 (0.2369)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2025-02-03 18:29:46]
  Epoch: [116][200/128]   Time 0.012 (0.013)   Data 0.000 (0.000)   Loss 0.3280 (0.2946)   Prec@1 91.406 (90.928)   Prec@5 98.438 (99.580)   [2025-02-03 18:29:49]
  **Train** Prec@1 89.938 Prec@5 99.458 Error@1 10.062
  **Test** Prec@1 66.920 Prec@5 89.920 Error@1 33.080
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:29:52] [Epoch=117/200] [Need: 00:08:28] [learning_rate=0.0368] [Best : Accuracy=67.44, Error=32.56]
  Epoch: [117][000/128]   Time 0.110 (0.110)   Data 0.000 (0.000)   Loss 0.3253 (0.3253)   Prec@1 88.281 (88.281)   Prec@5 98.438 (98.438)   [2025-02-03 18:29:52]
  Epoch: [117][200/128]   Time 0.011 (0.014)   Data 0.000 (0.000)   Loss 0.4447 (0.2949)   Prec@1 87.500 (90.854)   Prec@5 98.438 (99.580)   [2025-02-03 18:29:55]
  **Train** Prec@1 89.816 Prec@5 99.452 Error@1 10.184
  **Test** Prec@1 67.600 Prec@5 89.780 Error@1 32.400
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:29:58] [Epoch=118/200] [Need: 00:08:22] [learning_rate=0.0361] [Best : Accuracy=67.60, Error=32.40]
  Epoch: [118][000/128]   Time 0.116 (0.116)   Data 0.000 (0.000)   Loss 0.2828 (0.2828)   Prec@1 92.188 (92.188)   Prec@5 99.219 (99.219)   [2025-02-03 18:29:58]
  Epoch: [118][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.2737 (0.2813)   Prec@1 92.188 (91.461)   Prec@5 100.000 (99.611)   [2025-02-03 18:30:01]
  **Train** Prec@1 90.518 Prec@5 99.506 Error@1 9.482
  **Test** Prec@1 67.240 Prec@5 90.220 Error@1 32.760
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:30:04] [Epoch=119/200] [Need: 00:08:15] [learning_rate=0.0353] [Best : Accuracy=67.60, Error=32.40]
  Epoch: [119][000/128]   Time 0.126 (0.126)   Data 0.000 (0.000)   Loss 0.3566 (0.3566)   Prec@1 86.719 (86.719)   Prec@5 99.219 (99.219)   [2025-02-03 18:30:04]
  Epoch: [119][200/128]   Time 0.012 (0.014)   Data 0.000 (0.000)   Loss 0.2722 (0.2796)   Prec@1 92.969 (91.581)   Prec@5 98.438 (99.685)   [2025-02-03 18:30:07]
  **Train** Prec@1 91.108 Prec@5 99.608 Error@1 8.892
  **Test** Prec@1 67.170 Prec@5 89.710 Error@1 32.830
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:30:10] [Epoch=120/200] [Need: 00:08:09] [learning_rate=0.0345] [Best : Accuracy=67.60, Error=32.40]
  Epoch: [120][000/128]   Time 0.125 (0.125)   Data 0.000 (0.000)   Loss 0.3023 (0.3023)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2025-02-03 18:30:10]
  Epoch: [120][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.3601 (0.2559)   Prec@1 89.844 (92.211)   Prec@5 98.438 (99.740)   [2025-02-03 18:30:13]
  **Train** Prec@1 91.106 Prec@5 99.588 Error@1 8.894
  **Test** Prec@1 67.450 Prec@5 90.160 Error@1 32.550
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:30:16] [Epoch=121/200] [Need: 00:08:03] [learning_rate=0.0338] [Best : Accuracy=67.60, Error=32.40]
  Epoch: [121][000/128]   Time 0.118 (0.118)   Data 0.000 (0.000)   Loss 0.3763 (0.3763)   Prec@1 84.375 (84.375)   Prec@5 98.438 (98.438)   [2025-02-03 18:30:16]
  Epoch: [121][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.2657 (0.2555)   Prec@1 94.531 (92.308)   Prec@5 100.000 (99.674)   [2025-02-03 18:30:19]
  **Train** Prec@1 91.340 Prec@5 99.582 Error@1 8.660
  **Test** Prec@1 67.840 Prec@5 89.580 Error@1 32.160
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:30:23] [Epoch=122/200] [Need: 00:07:57] [learning_rate=0.0331] [Best : Accuracy=67.84, Error=32.16]
  Epoch: [122][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.2381 (0.2381)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2025-02-03 18:30:23]
  Epoch: [122][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.2850 (0.2640)   Prec@1 91.406 (92.055)   Prec@5 99.219 (99.685)   [2025-02-03 18:30:25]
  **Train** Prec@1 91.426 Prec@5 99.610 Error@1 8.574
  **Test** Prec@1 69.100 Prec@5 90.240 Error@1 30.900
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:30:29] [Epoch=123/200] [Need: 00:07:51] [learning_rate=0.0323] [Best : Accuracy=69.10, Error=30.90]
  Epoch: [123][000/128]   Time 0.119 (0.119)   Data 0.000 (0.000)   Loss 0.2425 (0.2425)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2025-02-03 18:30:29]
  Epoch: [123][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.2401 (0.2426)   Prec@1 90.625 (92.631)   Prec@5 100.000 (99.712)   [2025-02-03 18:30:32]
  **Train** Prec@1 91.570 Prec@5 99.624 Error@1 8.430
  **Test** Prec@1 66.690 Prec@5 89.590 Error@1 33.310
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:30:35] [Epoch=124/200] [Need: 00:07:45] [learning_rate=0.0316] [Best : Accuracy=69.10, Error=30.90]
  Epoch: [124][000/128]   Time 0.127 (0.127)   Data 0.000 (0.000)   Loss 0.3862 (0.3862)   Prec@1 87.500 (87.500)   Prec@5 99.219 (99.219)   [2025-02-03 18:30:35]
  Epoch: [124][200/128]   Time 0.014 (0.013)   Data 0.000 (0.000)   Loss 0.1449 (0.2323)   Prec@1 95.312 (93.066)   Prec@5 100.000 (99.771)   [2025-02-03 18:30:38]
  **Train** Prec@1 92.272 Prec@5 99.714 Error@1 7.728
  **Test** Prec@1 68.990 Prec@5 90.640 Error@1 31.010
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:30:41] [Epoch=125/200] [Need: 00:07:39] [learning_rate=0.0309] [Best : Accuracy=69.10, Error=30.90]
  Epoch: [125][000/128]   Time 0.125 (0.125)   Data 0.000 (0.000)   Loss 0.2214 (0.2214)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2025-02-03 18:30:41]
  Epoch: [125][200/128]   Time 0.014 (0.015)   Data 0.000 (0.000)   Loss 0.2155 (0.2190)   Prec@1 91.406 (93.478)   Prec@5 100.000 (99.833)   [2025-02-03 18:30:44]
  **Train** Prec@1 93.004 Prec@5 99.794 Error@1 6.996
  **Test** Prec@1 69.090 Prec@5 90.660 Error@1 30.910
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:30:47] [Epoch=126/200] [Need: 00:07:33] [learning_rate=0.0301] [Best : Accuracy=69.10, Error=30.90]
  Epoch: [126][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 0.3605 (0.3605)   Prec@1 89.844 (89.844)   Prec@5 99.219 (99.219)   [2025-02-03 18:30:48]
  Epoch: [126][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.2565 (0.2188)   Prec@1 92.188 (93.443)   Prec@5 99.219 (99.751)   [2025-02-03 18:30:50]
  **Train** Prec@1 92.926 Prec@5 99.722 Error@1 7.074
  **Test** Prec@1 70.240 Prec@5 90.870 Error@1 29.760
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:30:53] [Epoch=127/200] [Need: 00:07:26] [learning_rate=0.0294] [Best : Accuracy=70.24, Error=29.76]
  Epoch: [127][000/128]   Time 0.108 (0.108)   Data 0.000 (0.000)   Loss 0.2025 (0.2025)   Prec@1 94.531 (94.531)   Prec@5 99.219 (99.219)   [2025-02-03 18:30:53]
  Epoch: [127][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.1261 (0.1991)   Prec@1 97.656 (94.244)   Prec@5 100.000 (99.790)   [2025-02-03 18:30:56]
  **Train** Prec@1 93.304 Prec@5 99.752 Error@1 6.696
  **Test** Prec@1 67.920 Prec@5 89.790 Error@1 32.080
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:31:00] [Epoch=128/200] [Need: 00:07:20] [learning_rate=0.0287] [Best : Accuracy=70.24, Error=29.76]
  Epoch: [128][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.3075 (0.3075)   Prec@1 91.406 (91.406)   Prec@5 100.000 (100.000)   [2025-02-03 18:31:00]
  Epoch: [128][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.2140 (0.2010)   Prec@1 93.750 (93.956)   Prec@5 100.000 (99.895)   [2025-02-03 18:31:02]
  **Train** Prec@1 93.494 Prec@5 99.844 Error@1 6.506
  **Test** Prec@1 68.310 Prec@5 89.940 Error@1 31.690
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:31:06] [Epoch=129/200] [Need: 00:07:14] [learning_rate=0.0280] [Best : Accuracy=70.24, Error=29.76]
  Epoch: [129][000/128]   Time 0.124 (0.124)   Data 0.000 (0.000)   Loss 0.1582 (0.1582)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2025-02-03 18:31:06]
  Epoch: [129][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.2328 (0.1969)   Prec@1 93.750 (94.220)   Prec@5 98.438 (99.860)   [2025-02-03 18:31:08]
  **Train** Prec@1 93.730 Prec@5 99.824 Error@1 6.270
  **Test** Prec@1 69.190 Prec@5 89.990 Error@1 30.810
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:31:12] [Epoch=130/200] [Need: 00:07:08] [learning_rate=0.0273] [Best : Accuracy=70.24, Error=29.76]
  Epoch: [130][000/128]   Time 0.115 (0.115)   Data 0.000 (0.000)   Loss 0.2096 (0.2096)   Prec@1 93.750 (93.750)   Prec@5 99.219 (99.219)   [2025-02-03 18:31:12]
  Epoch: [130][200/128]   Time 0.012 (0.014)   Data 0.000 (0.000)   Loss 0.1816 (0.1761)   Prec@1 95.312 (94.885)   Prec@5 100.000 (99.895)   [2025-02-03 18:31:15]
  **Train** Prec@1 94.192 Prec@5 99.850 Error@1 5.808
  **Test** Prec@1 68.440 Prec@5 90.140 Error@1 31.560
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:31:18] [Epoch=131/200] [Need: 00:07:02] [learning_rate=0.0266] [Best : Accuracy=70.24, Error=29.76]
  Epoch: [131][000/128]   Time 0.118 (0.118)   Data 0.000 (0.000)   Loss 0.1377 (0.1377)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2025-02-03 18:31:18]
  Epoch: [131][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.2964 (0.1880)   Prec@1 86.719 (94.469)   Prec@5 100.000 (99.860)   [2025-02-03 18:31:21]
  **Train** Prec@1 93.888 Prec@5 99.814 Error@1 6.112
  **Test** Prec@1 69.050 Prec@5 90.370 Error@1 30.950
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:31:24] [Epoch=132/200] [Need: 00:06:56] [learning_rate=0.0259] [Best : Accuracy=70.24, Error=29.76]
  Epoch: [132][000/128]   Time 0.124 (0.124)   Data 0.000 (0.000)   Loss 0.2174 (0.2174)   Prec@1 94.531 (94.531)   Prec@5 99.219 (99.219)   [2025-02-03 18:31:24]
  Epoch: [132][200/128]   Time 0.012 (0.014)   Data 0.000 (0.000)   Loss 0.1593 (0.1732)   Prec@1 95.312 (95.165)   Prec@5 100.000 (99.880)   [2025-02-03 18:31:27]
  **Train** Prec@1 94.508 Prec@5 99.858 Error@1 5.492
  **Test** Prec@1 68.470 Prec@5 89.870 Error@1 31.530
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:31:30] [Epoch=133/200] [Need: 00:06:50] [learning_rate=0.0252] [Best : Accuracy=70.24, Error=29.76]
  Epoch: [133][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.1347 (0.1347)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2025-02-03 18:31:30]
  Epoch: [133][200/128]   Time 0.014 (0.015)   Data 0.000 (0.000)   Loss 0.1254 (0.1682)   Prec@1 96.875 (95.095)   Prec@5 100.000 (99.911)   [2025-02-03 18:31:33]
  **Train** Prec@1 94.764 Prec@5 99.870 Error@1 5.236
  **Test** Prec@1 68.910 Prec@5 90.630 Error@1 31.090
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:31:36] [Epoch=134/200] [Need: 00:06:44] [learning_rate=0.0245] [Best : Accuracy=70.24, Error=29.76]
  Epoch: [134][000/128]   Time 0.114 (0.114)   Data 0.000 (0.000)   Loss 0.1913 (0.1913)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2025-02-03 18:31:37]
  Epoch: [134][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.1611 (0.1575)   Prec@1 95.312 (95.522)   Prec@5 100.000 (99.907)   [2025-02-03 18:31:39]
  **Train** Prec@1 94.792 Prec@5 99.878 Error@1 5.208
  **Test** Prec@1 69.000 Prec@5 90.510 Error@1 31.000
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:31:43] [Epoch=135/200] [Need: 00:06:38] [learning_rate=0.0239] [Best : Accuracy=70.24, Error=29.76]
  Epoch: [135][000/128]   Time 0.117 (0.117)   Data 0.000 (0.000)   Loss 0.0618 (0.0618)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2025-02-03 18:31:43]
  Epoch: [135][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.1865 (0.1461)   Prec@1 94.531 (96.004)   Prec@5 100.000 (99.957)   [2025-02-03 18:31:45]
  **Train** Prec@1 95.720 Prec@5 99.936 Error@1 4.280
  **Test** Prec@1 70.640 Prec@5 90.670 Error@1 29.360
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:31:49] [Epoch=136/200] [Need: 00:06:31] [learning_rate=0.0232] [Best : Accuracy=70.64, Error=29.36]
  Epoch: [136][000/128]   Time 0.146 (0.146)   Data 0.000 (0.000)   Loss 0.1053 (0.1053)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2025-02-03 18:31:49]
  Epoch: [136][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.0752 (0.1251)   Prec@1 100.000 (96.436)   Prec@5 100.000 (99.981)   [2025-02-03 18:31:52]
  **Train** Prec@1 95.750 Prec@5 99.930 Error@1 4.250
  **Test** Prec@1 69.190 Prec@5 90.270 Error@1 30.810
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:31:55] [Epoch=137/200] [Need: 00:06:25] [learning_rate=0.0225] [Best : Accuracy=70.64, Error=29.36]
  Epoch: [137][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.0695 (0.0695)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2025-02-03 18:31:55]
  Epoch: [137][200/128]   Time 0.014 (0.013)   Data 0.000 (0.000)   Loss 0.1292 (0.1266)   Prec@1 95.312 (96.630)   Prec@5 100.000 (99.977)   [2025-02-03 18:31:58]
  **Train** Prec@1 96.206 Prec@5 99.954 Error@1 3.794
  **Test** Prec@1 69.960 Prec@5 90.810 Error@1 30.040
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:32:01] [Epoch=138/200] [Need: 00:06:19] [learning_rate=0.0219] [Best : Accuracy=70.64, Error=29.36]
  Epoch: [138][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.1962 (0.1962)   Prec@1 95.312 (95.312)   Prec@5 99.219 (99.219)   [2025-02-03 18:32:01]
  Epoch: [138][200/128]   Time 0.011 (0.014)   Data 0.000 (0.000)   Loss 0.1317 (0.1178)   Prec@1 96.094 (96.778)   Prec@5 100.000 (99.957)   [2025-02-03 18:32:04]
  **Train** Prec@1 96.358 Prec@5 99.954 Error@1 3.642
  **Test** Prec@1 71.070 Prec@5 90.740 Error@1 28.930
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:32:07] [Epoch=139/200] [Need: 00:06:13] [learning_rate=0.0212] [Best : Accuracy=71.07, Error=28.93]
  Epoch: [139][000/128]   Time 0.117 (0.117)   Data 0.000 (0.000)   Loss 0.0820 (0.0820)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2025-02-03 18:32:07]
  Epoch: [139][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.1718 (0.1125)   Prec@1 93.750 (96.894)   Prec@5 100.000 (99.961)   [2025-02-03 18:32:10]
  **Train** Prec@1 96.592 Prec@5 99.942 Error@1 3.408
  **Test** Prec@1 68.840 Prec@5 90.500 Error@1 31.160
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:32:13] [Epoch=140/200] [Need: 00:06:07] [learning_rate=0.0206] [Best : Accuracy=71.07, Error=28.93]
  Epoch: [140][000/128]   Time 0.124 (0.124)   Data 0.000 (0.000)   Loss 0.1436 (0.1436)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2025-02-03 18:32:13]
  Epoch: [140][200/128]   Time 0.013 (0.016)   Data 0.000 (0.000)   Loss 0.1255 (0.1142)   Prec@1 96.094 (97.027)   Prec@5 100.000 (99.953)   [2025-02-03 18:32:16]
  **Train** Prec@1 96.884 Prec@5 99.948 Error@1 3.116
  **Test** Prec@1 71.340 Prec@5 91.160 Error@1 28.660
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:32:19] [Epoch=141/200] [Need: 00:06:01] [learning_rate=0.0200] [Best : Accuracy=71.34, Error=28.66]
  Epoch: [141][000/128]   Time 0.118 (0.118)   Data 0.000 (0.000)   Loss 0.1275 (0.1275)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2025-02-03 18:32:20]
  Epoch: [141][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0706 (0.0946)   Prec@1 96.875 (97.575)   Prec@5 100.000 (99.973)   [2025-02-03 18:32:22]
  **Train** Prec@1 97.296 Prec@5 99.976 Error@1 2.704
  **Test** Prec@1 71.470 Prec@5 91.290 Error@1 28.530
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:32:25] [Epoch=142/200] [Need: 00:05:55] [learning_rate=0.0194] [Best : Accuracy=71.47, Error=28.53]
  Epoch: [142][000/128]   Time 0.134 (0.134)   Data 0.000 (0.000)   Loss 0.1157 (0.1157)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2025-02-03 18:32:26]
  Epoch: [142][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.0785 (0.1023)   Prec@1 100.000 (97.295)   Prec@5 100.000 (99.981)   [2025-02-03 18:32:28]
  **Train** Prec@1 97.234 Prec@5 99.978 Error@1 2.766
  **Test** Prec@1 71.990 Prec@5 91.590 Error@1 28.010
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:32:31] [Epoch=143/200] [Need: 00:05:49] [learning_rate=0.0187] [Best : Accuracy=71.99, Error=28.01]
  Epoch: [143][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 0.0791 (0.0791)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2025-02-03 18:32:32]
  Epoch: [143][200/128]   Time 0.015 (0.015)   Data 0.000 (0.000)   Loss 0.0709 (0.0824)   Prec@1 97.656 (97.983)   Prec@5 100.000 (99.988)   [2025-02-03 18:32:34]
  **Train** Prec@1 97.910 Prec@5 99.986 Error@1 2.090
  **Test** Prec@1 72.910 Prec@5 91.970 Error@1 27.090
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:32:38] [Epoch=144/200] [Need: 00:05:43] [learning_rate=0.0181] [Best : Accuracy=72.91, Error=27.09]
  Epoch: [144][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 0.0569 (0.0569)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2025-02-03 18:32:38]
  Epoch: [144][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0549 (0.0758)   Prec@1 99.219 (98.169)   Prec@5 100.000 (100.000)   [2025-02-03 18:32:41]
  **Train** Prec@1 98.010 Prec@5 99.988 Error@1 1.990
  **Test** Prec@1 71.510 Prec@5 91.520 Error@1 28.490
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:32:44] [Epoch=145/200] [Need: 00:05:36] [learning_rate=0.0175] [Best : Accuracy=72.91, Error=27.09]
  Epoch: [145][000/128]   Time 0.118 (0.118)   Data 0.000 (0.000)   Loss 0.0691 (0.0691)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2025-02-03 18:32:44]
  Epoch: [145][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 0.0420 (0.0702)   Prec@1 100.000 (98.403)   Prec@5 100.000 (99.992)   [2025-02-03 18:32:47]
  **Train** Prec@1 98.236 Prec@5 99.988 Error@1 1.764
  **Test** Prec@1 72.980 Prec@5 92.160 Error@1 27.020
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:32:50] [Epoch=146/200] [Need: 00:05:30] [learning_rate=0.0169] [Best : Accuracy=72.98, Error=27.02]
  Epoch: [146][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.0413 (0.0413)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2025-02-03 18:32:50]
  Epoch: [146][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0727 (0.0588)   Prec@1 98.438 (98.721)   Prec@5 100.000 (99.984)   [2025-02-03 18:32:53]
  **Train** Prec@1 98.584 Prec@5 99.984 Error@1 1.416
  **Test** Prec@1 72.970 Prec@5 92.010 Error@1 27.030
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:32:57] [Epoch=147/200] [Need: 00:05:24] [learning_rate=0.0163] [Best : Accuracy=72.98, Error=27.02]
  Epoch: [147][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.0576 (0.0576)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2025-02-03 18:32:57]
  Epoch: [147][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.0560 (0.0521)   Prec@1 98.438 (98.861)   Prec@5 100.000 (99.992)   [2025-02-03 18:32:59]
  **Train** Prec@1 98.832 Prec@5 99.994 Error@1 1.168
  **Test** Prec@1 73.950 Prec@5 92.440 Error@1 26.050
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:33:03] [Epoch=148/200] [Need: 00:05:18] [learning_rate=0.0158] [Best : Accuracy=73.95, Error=26.05]
  Epoch: [148][000/128]   Time 0.114 (0.114)   Data 0.000 (0.000)   Loss 0.0561 (0.0561)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:03]
  Epoch: [148][200/128]   Time 0.011 (0.014)   Data 0.000 (0.000)   Loss 0.0389 (0.0468)   Prec@1 99.219 (99.106)   Prec@5 100.000 (99.996)   [2025-02-03 18:33:05]
  **Train** Prec@1 99.034 Prec@5 99.994 Error@1 0.966
  **Test** Prec@1 73.980 Prec@5 92.110 Error@1 26.020
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:33:09] [Epoch=149/200] [Need: 00:05:12] [learning_rate=0.0152] [Best : Accuracy=73.98, Error=26.02]
  Epoch: [149][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.0222 (0.0222)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:09]
  Epoch: [149][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.0449 (0.0405)   Prec@1 98.438 (99.273)   Prec@5 100.000 (99.996)   [2025-02-03 18:33:11]
  **Train** Prec@1 99.216 Prec@5 99.992 Error@1 0.784
  **Test** Prec@1 74.590 Prec@5 92.810 Error@1 25.410
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:33:15] [Epoch=150/200] [Need: 00:05:06] [learning_rate=0.0146] [Best : Accuracy=74.59, Error=25.41]
  Epoch: [150][000/128]   Time 0.116 (0.116)   Data 0.000 (0.000)   Loss 0.0215 (0.0215)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:15]
  Epoch: [150][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0190 (0.0349)   Prec@1 100.000 (99.456)   Prec@5 100.000 (99.996)   [2025-02-03 18:33:18]
  **Train** Prec@1 99.428 Prec@5 99.998 Error@1 0.572
  **Test** Prec@1 74.460 Prec@5 92.630 Error@1 25.540
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:33:21] [Epoch=151/200] [Need: 00:05:00] [learning_rate=0.0141] [Best : Accuracy=74.59, Error=25.41]
  Epoch: [151][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.0228 (0.0228)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:21]
  Epoch: [151][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0234 (0.0314)   Prec@1 100.000 (99.514)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:24]
  **Train** Prec@1 99.454 Prec@5 100.000 Error@1 0.546
  **Test** Prec@1 74.790 Prec@5 92.720 Error@1 25.210
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:33:27] [Epoch=152/200] [Need: 00:04:54] [learning_rate=0.0136] [Best : Accuracy=74.79, Error=25.21]
  Epoch: [152][000/128]   Time 0.125 (0.125)   Data 0.000 (0.000)   Loss 0.0555 (0.0555)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:27]
  Epoch: [152][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0463 (0.0361)   Prec@1 99.219 (99.320)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:30]
  **Train** Prec@1 99.408 Prec@5 100.000 Error@1 0.592
  **Test** Prec@1 75.880 Prec@5 92.730 Error@1 24.120
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:33:33] [Epoch=153/200] [Need: 00:04:47] [learning_rate=0.0130] [Best : Accuracy=75.88, Error=24.12]
  Epoch: [153][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.0175 (0.0175)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:33]
  Epoch: [153][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.0217 (0.0252)   Prec@1 99.219 (99.697)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:36]
  **Train** Prec@1 99.726 Prec@5 100.000 Error@1 0.274
  **Test** Prec@1 75.760 Prec@5 93.200 Error@1 24.240
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:33:39] [Epoch=154/200] [Need: 00:04:41] [learning_rate=0.0125] [Best : Accuracy=75.88, Error=24.12]
  Epoch: [154][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.0204 (0.0204)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:39]
  Epoch: [154][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.0145 (0.0193)   Prec@1 100.000 (99.771)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:42]
  **Train** Prec@1 99.688 Prec@5 100.000 Error@1 0.312
  **Test** Prec@1 75.810 Prec@5 92.920 Error@1 24.190
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:33:45] [Epoch=155/200] [Need: 00:04:35] [learning_rate=0.0120] [Best : Accuracy=75.88, Error=24.12]
  Epoch: [155][000/128]   Time 0.138 (0.138)   Data 0.000 (0.000)   Loss 0.0103 (0.0103)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:45]
  Epoch: [155][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.0110 (0.0200)   Prec@1 100.000 (99.817)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:48]
  **Train** Prec@1 99.798 Prec@5 100.000 Error@1 0.202
  **Test** Prec@1 76.350 Prec@5 93.350 Error@1 23.650
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:33:52] [Epoch=156/200] [Need: 00:04:29] [learning_rate=0.0115] [Best : Accuracy=76.35, Error=23.65]
  Epoch: [156][000/128]   Time 0.113 (0.113)   Data 0.000 (0.000)   Loss 0.0157 (0.0157)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:52]
  Epoch: [156][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0314 (0.0147)   Prec@1 99.219 (99.899)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:54]
  **Train** Prec@1 99.876 Prec@5 100.000 Error@1 0.124
  **Test** Prec@1 76.230 Prec@5 93.450 Error@1 23.770
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:33:58] [Epoch=157/200] [Need: 00:04:23] [learning_rate=0.0110] [Best : Accuracy=76.35, Error=23.65]
  Epoch: [157][000/128]   Time 0.114 (0.114)   Data 0.000 (0.000)   Loss 0.0134 (0.0134)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:33:58]
  Epoch: [157][200/128]   Time 0.012 (0.013)   Data 0.000 (0.000)   Loss 0.0132 (0.0141)   Prec@1 100.000 (99.922)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:00]
  **Train** Prec@1 99.918 Prec@5 100.000 Error@1 0.082
  **Test** Prec@1 76.860 Prec@5 93.590 Error@1 23.140
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:34:04] [Epoch=158/200] [Need: 00:04:17] [learning_rate=0.0105] [Best : Accuracy=76.86, Error=23.14]
  Epoch: [158][000/128]   Time 0.124 (0.124)   Data 0.000 (0.000)   Loss 0.0069 (0.0069)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:04]
  Epoch: [158][200/128]   Time 0.014 (0.013)   Data 0.000 (0.000)   Loss 0.0073 (0.0130)   Prec@1 100.000 (99.903)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:06]
  **Train** Prec@1 99.886 Prec@5 100.000 Error@1 0.114
  **Test** Prec@1 77.600 Prec@5 93.640 Error@1 22.400
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:34:10] [Epoch=159/200] [Need: 00:04:11] [learning_rate=0.0100] [Best : Accuracy=77.60, Error=22.40]
  Epoch: [159][000/128]   Time 0.125 (0.125)   Data 0.000 (0.000)   Loss 0.0117 (0.0117)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:10]
  Epoch: [159][200/128]   Time 0.011 (0.013)   Data 0.000 (0.000)   Loss 0.0104 (0.0126)   Prec@1 100.000 (99.930)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:12]
  **Train** Prec@1 99.922 Prec@5 100.000 Error@1 0.078
  **Test** Prec@1 77.380 Prec@5 93.680 Error@1 22.620
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:34:16] [Epoch=160/200] [Need: 00:04:05] [learning_rate=0.0095] [Best : Accuracy=77.60, Error=22.40]
  Epoch: [160][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 0.0175 (0.0175)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:16]
  Epoch: [160][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.0129 (0.0123)   Prec@1 100.000 (99.911)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:18]
  **Train** Prec@1 99.920 Prec@5 100.000 Error@1 0.080
  **Test** Prec@1 77.340 Prec@5 93.890 Error@1 22.660
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:34:22] [Epoch=161/200] [Need: 00:03:58] [learning_rate=0.0091] [Best : Accuracy=77.60, Error=22.40]
  Epoch: [161][000/128]   Time 0.125 (0.125)   Data 0.000 (0.000)   Loss 0.0144 (0.0144)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:22]
  Epoch: [161][200/128]   Time 0.012 (0.013)   Data 0.000 (0.000)   Loss 0.0069 (0.0111)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:24]
  **Train** Prec@1 99.946 Prec@5 100.000 Error@1 0.054
  **Test** Prec@1 77.540 Prec@5 93.910 Error@1 22.460
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:34:28] [Epoch=162/200] [Need: 00:03:52] [learning_rate=0.0086] [Best : Accuracy=77.60, Error=22.40]
  Epoch: [162][000/128]   Time 0.124 (0.124)   Data 0.000 (0.000)   Loss 0.0074 (0.0074)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:28]
  Epoch: [162][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.0082 (0.0105)   Prec@1 100.000 (99.946)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:30]
  **Train** Prec@1 99.936 Prec@5 100.000 Error@1 0.064
  **Test** Prec@1 77.830 Prec@5 93.840 Error@1 22.170
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:34:34] [Epoch=163/200] [Need: 00:03:46] [learning_rate=0.0082] [Best : Accuracy=77.83, Error=22.17]
  Epoch: [163][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.0083 (0.0083)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:34]
  Epoch: [163][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.0140 (0.0104)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:36]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 78.010 Prec@5 94.220 Error@1 21.990
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:34:40] [Epoch=164/200] [Need: 00:03:40] [learning_rate=0.0078] [Best : Accuracy=78.01, Error=21.99]
  Epoch: [164][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.0052 (0.0052)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:40]
  Epoch: [164][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.0109 (0.0106)   Prec@1 100.000 (99.946)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:43]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 77.940 Prec@5 93.890 Error@1 22.060
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:34:46] [Epoch=165/200] [Need: 00:03:34] [learning_rate=0.0074] [Best : Accuracy=78.01, Error=21.99]
  Epoch: [165][000/128]   Time 0.127 (0.127)   Data 0.000 (0.000)   Loss 0.0098 (0.0098)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:46]
  Epoch: [165][200/128]   Time 0.012 (0.013)   Data 0.000 (0.000)   Loss 0.0240 (0.0108)   Prec@1 99.219 (99.942)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:49]
  **Train** Prec@1 99.940 Prec@5 100.000 Error@1 0.060
  **Test** Prec@1 77.690 Prec@5 93.930 Error@1 22.310
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:34:52] [Epoch=166/200] [Need: 00:03:28] [learning_rate=0.0070] [Best : Accuracy=78.01, Error=21.99]
  Epoch: [166][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 0.0084 (0.0084)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:52]
  Epoch: [166][200/128]   Time 0.012 (0.013)   Data 0.000 (0.000)   Loss 0.0118 (0.0099)   Prec@1 100.000 (99.973)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:55]
  **Train** Prec@1 99.956 Prec@5 100.000 Error@1 0.044
  **Test** Prec@1 78.080 Prec@5 93.890 Error@1 21.920
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:34:58] [Epoch=167/200] [Need: 00:03:22] [learning_rate=0.0066] [Best : Accuracy=78.08, Error=21.92]
  Epoch: [167][000/128]   Time 0.111 (0.111)   Data 0.000 (0.000)   Loss 0.0091 (0.0091)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:34:58]
  Epoch: [167][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.0094 (0.0103)   Prec@1 100.000 (99.969)   Prec@5 100.000 (99.996)   [2025-02-03 18:35:01]
  **Train** Prec@1 99.964 Prec@5 99.998 Error@1 0.036
  **Test** Prec@1 78.050 Prec@5 94.070 Error@1 21.950
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:35:04] [Epoch=168/200] [Need: 00:03:15] [learning_rate=0.0062] [Best : Accuracy=78.08, Error=21.92]
  Epoch: [168][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.0082 (0.0082)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:04]
  Epoch: [168][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.0099 (0.0098)   Prec@1 100.000 (99.981)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:07]
  **Train** Prec@1 99.964 Prec@5 100.000 Error@1 0.036
  **Test** Prec@1 78.060 Prec@5 94.030 Error@1 21.940
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:35:10] [Epoch=169/200] [Need: 00:03:09] [learning_rate=0.0058] [Best : Accuracy=78.08, Error=21.92]
  Epoch: [169][000/128]   Time 0.128 (0.128)   Data 0.000 (0.000)   Loss 0.0061 (0.0061)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:10]
  Epoch: [169][200/128]   Time 0.012 (0.013)   Data 0.000 (0.000)   Loss 0.0122 (0.0098)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:13]
  **Train** Prec@1 99.956 Prec@5 100.000 Error@1 0.044
  **Test** Prec@1 77.890 Prec@5 94.060 Error@1 22.110
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:35:16] [Epoch=170/200] [Need: 00:03:03] [learning_rate=0.0054] [Best : Accuracy=78.08, Error=21.92]
  Epoch: [170][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 0.0112 (0.0112)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:16]
  Epoch: [170][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.0115 (0.0097)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:19]
  **Train** Prec@1 99.962 Prec@5 100.000 Error@1 0.038
  **Test** Prec@1 78.230 Prec@5 94.040 Error@1 21.770
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:35:22] [Epoch=171/200] [Need: 00:02:57] [learning_rate=0.0051] [Best : Accuracy=78.23, Error=21.77]
  Epoch: [171][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.0109 (0.0109)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:22]
  Epoch: [171][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0077 (0.0099)   Prec@1 100.000 (99.969)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:25]
  **Train** Prec@1 99.958 Prec@5 100.000 Error@1 0.042
  **Test** Prec@1 78.350 Prec@5 94.140 Error@1 21.650
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:35:28] [Epoch=172/200] [Need: 00:02:51] [learning_rate=0.0048] [Best : Accuracy=78.35, Error=21.65]
  Epoch: [172][000/128]   Time 0.127 (0.127)   Data 0.000 (0.000)   Loss 0.0109 (0.0109)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:28]
  Epoch: [172][200/128]   Time 0.012 (0.014)   Data 0.000 (0.000)   Loss 0.0069 (0.0097)   Prec@1 100.000 (99.953)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:31]
  **Train** Prec@1 99.966 Prec@5 100.000 Error@1 0.034
  **Test** Prec@1 78.130 Prec@5 94.110 Error@1 21.870
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:35:35] [Epoch=173/200] [Need: 00:02:45] [learning_rate=0.0044] [Best : Accuracy=78.35, Error=21.65]
  Epoch: [173][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.0135 (0.0135)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:35]
  Epoch: [173][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 0.0091 (0.0095)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:37]
  **Train** Prec@1 99.956 Prec@5 100.000 Error@1 0.044
  **Test** Prec@1 78.130 Prec@5 94.150 Error@1 21.870
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:35:41] [Epoch=174/200] [Need: 00:02:39] [learning_rate=0.0041] [Best : Accuracy=78.35, Error=21.65]
  Epoch: [174][000/128]   Time 0.124 (0.124)   Data 0.000 (0.000)   Loss 0.0092 (0.0092)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:41]
  Epoch: [174][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0098 (0.0096)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:43]
  **Train** Prec@1 99.960 Prec@5 100.000 Error@1 0.040
  **Test** Prec@1 78.390 Prec@5 94.320 Error@1 21.610
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:35:47] [Epoch=175/200] [Need: 00:02:33] [learning_rate=0.0038] [Best : Accuracy=78.39, Error=21.61]
  Epoch: [175][000/128]   Time 0.133 (0.133)   Data 0.000 (0.000)   Loss 0.0103 (0.0103)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:47]
  Epoch: [175][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0077 (0.0093)   Prec@1 100.000 (99.961)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:49]
  **Train** Prec@1 99.968 Prec@5 100.000 Error@1 0.032
  **Test** Prec@1 78.470 Prec@5 94.090 Error@1 21.530
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:35:53] [Epoch=176/200] [Need: 00:02:26] [learning_rate=0.0035] [Best : Accuracy=78.47, Error=21.53]
  Epoch: [176][000/128]   Time 0.125 (0.125)   Data 0.000 (0.000)   Loss 0.0079 (0.0079)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:53]
  Epoch: [176][200/128]   Time 0.016 (0.015)   Data 0.000 (0.000)   Loss 0.0087 (0.0093)   Prec@1 100.000 (99.984)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:56]
  **Train** Prec@1 99.970 Prec@5 100.000 Error@1 0.030
  **Test** Prec@1 78.470 Prec@5 94.300 Error@1 21.530
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:35:59] [Epoch=177/200] [Need: 00:02:20] [learning_rate=0.0032] [Best : Accuracy=78.47, Error=21.53]
  Epoch: [177][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.0137 (0.0137)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:35:59]
  Epoch: [177][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0144 (0.0097)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:02]
  **Train** Prec@1 99.972 Prec@5 100.000 Error@1 0.028
  **Test** Prec@1 78.400 Prec@5 94.340 Error@1 21.600
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:36:05] [Epoch=178/200] [Need: 00:02:14] [learning_rate=0.0030] [Best : Accuracy=78.47, Error=21.53]
  Epoch: [178][000/128]   Time 0.124 (0.124)   Data 0.000 (0.000)   Loss 0.0100 (0.0100)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:05]
  Epoch: [178][200/128]   Time 0.014 (0.014)   Data 0.000 (0.000)   Loss 0.0099 (0.0091)   Prec@1 100.000 (99.977)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:08]
  **Train** Prec@1 99.978 Prec@5 100.000 Error@1 0.022
  **Test** Prec@1 78.290 Prec@5 94.290 Error@1 21.710
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:36:12] [Epoch=179/200] [Need: 00:02:08] [learning_rate=0.0027] [Best : Accuracy=78.47, Error=21.53]
  Epoch: [179][000/128]   Time 0.135 (0.135)   Data 0.000 (0.000)   Loss 0.0155 (0.0155)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:12]
  Epoch: [179][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.0093 (0.0093)   Prec@1 100.000 (99.969)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:14]
  **Train** Prec@1 99.970 Prec@5 100.000 Error@1 0.030
  **Test** Prec@1 78.330 Prec@5 94.260 Error@1 21.670
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:36:18] [Epoch=180/200] [Need: 00:02:02] [learning_rate=0.0024] [Best : Accuracy=78.47, Error=21.53]
  Epoch: [180][000/128]   Time 0.123 (0.123)   Data 0.000 (0.000)   Loss 0.0095 (0.0095)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:18]
  Epoch: [180][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.0137 (0.0093)   Prec@1 100.000 (99.977)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:20]
  **Train** Prec@1 99.972 Prec@5 100.000 Error@1 0.028
  **Test** Prec@1 78.400 Prec@5 94.390 Error@1 21.600
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:36:24] [Epoch=181/200] [Need: 00:01:56] [learning_rate=0.0022] [Best : Accuracy=78.47, Error=21.53]
  Epoch: [181][000/128]   Time 0.120 (0.120)   Data 0.000 (0.000)   Loss 0.0233 (0.0233)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:24]
  Epoch: [181][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0080 (0.0092)   Prec@1 100.000 (99.973)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:27]
  **Train** Prec@1 99.970 Prec@5 100.000 Error@1 0.030
  **Test** Prec@1 78.620 Prec@5 94.280 Error@1 21.380
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:36:30] [Epoch=182/200] [Need: 00:01:50] [learning_rate=0.0020] [Best : Accuracy=78.62, Error=21.38]
  Epoch: [182][000/128]   Time 0.115 (0.115)   Data 0.000 (0.000)   Loss 0.0086 (0.0086)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:30]
  Epoch: [182][200/128]   Time 0.012 (0.013)   Data 0.000 (0.000)   Loss 0.0096 (0.0092)   Prec@1 100.000 (99.969)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:33]
  **Train** Prec@1 99.970 Prec@5 100.000 Error@1 0.030
  **Test** Prec@1 78.630 Prec@5 94.280 Error@1 21.370
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:36:36] [Epoch=183/200] [Need: 00:01:44] [learning_rate=0.0018] [Best : Accuracy=78.63, Error=21.37]
  Epoch: [183][000/128]   Time 0.134 (0.134)   Data 0.000 (0.000)   Loss 0.0086 (0.0086)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:36]
  Epoch: [183][200/128]   Time 0.011 (0.014)   Data 0.000 (0.000)   Loss 0.0119 (0.0091)   Prec@1 100.000 (99.961)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:39]
  **Train** Prec@1 99.966 Prec@5 100.000 Error@1 0.034
  **Test** Prec@1 78.490 Prec@5 94.190 Error@1 21.510
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:36:42] [Epoch=184/200] [Need: 00:01:37] [learning_rate=0.0016] [Best : Accuracy=78.63, Error=21.37]
  Epoch: [184][000/128]   Time 0.122 (0.122)   Data 0.000 (0.000)   Loss 0.0101 (0.0101)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:42]
  Epoch: [184][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0086 (0.0092)   Prec@1 100.000 (99.969)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:45]
  **Train** Prec@1 99.968 Prec@5 100.000 Error@1 0.032
  **Test** Prec@1 78.550 Prec@5 94.180 Error@1 21.450
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:36:48] [Epoch=185/200] [Need: 00:01:31] [learning_rate=0.0014] [Best : Accuracy=78.63, Error=21.37]
  Epoch: [185][000/128]   Time 0.117 (0.117)   Data 0.000 (0.000)   Loss 0.0071 (0.0071)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:48]
  Epoch: [185][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0077 (0.0090)   Prec@1 100.000 (99.984)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:51]
  **Train** Prec@1 99.968 Prec@5 100.000 Error@1 0.032
  **Test** Prec@1 78.440 Prec@5 94.290 Error@1 21.560
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:36:54] [Epoch=186/200] [Need: 00:01:25] [learning_rate=0.0012] [Best : Accuracy=78.63, Error=21.37]
  Epoch: [186][000/128]   Time 0.143 (0.143)   Data 0.000 (0.000)   Loss 0.0079 (0.0079)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:54]
  Epoch: [186][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0076 (0.0091)   Prec@1 100.000 (99.973)   Prec@5 100.000 (100.000)   [2025-02-03 18:36:57]
  **Train** Prec@1 99.978 Prec@5 100.000 Error@1 0.022
  **Test** Prec@1 78.440 Prec@5 94.240 Error@1 21.560
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:37:00] [Epoch=187/200] [Need: 00:01:19] [learning_rate=0.0010] [Best : Accuracy=78.63, Error=21.37]
  Epoch: [187][000/128]   Time 0.143 (0.143)   Data 0.000 (0.000)   Loss 0.0148 (0.0148)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:00]
  Epoch: [187][200/128]   Time 0.013 (0.015)   Data 0.000 (0.000)   Loss 0.0112 (0.0089)   Prec@1 100.000 (99.973)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:03]
  **Train** Prec@1 99.974 Prec@5 100.000 Error@1 0.026
  **Test** Prec@1 78.530 Prec@5 94.290 Error@1 21.470
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:37:06] [Epoch=188/200] [Need: 00:01:13] [learning_rate=0.0009] [Best : Accuracy=78.63, Error=21.37]
  Epoch: [188][000/128]   Time 0.126 (0.126)   Data 0.000 (0.000)   Loss 0.0071 (0.0071)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:07]
  Epoch: [188][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.0069 (0.0090)   Prec@1 100.000 (99.973)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:09]
  **Train** Prec@1 99.980 Prec@5 100.000 Error@1 0.020
  **Test** Prec@1 78.460 Prec@5 94.250 Error@1 21.540
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:37:12] [Epoch=189/200] [Need: 00:01:07] [learning_rate=0.0007] [Best : Accuracy=78.63, Error=21.37]
  Epoch: [189][000/128]   Time 0.137 (0.137)   Data 0.000 (0.000)   Loss 0.0064 (0.0064)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:13]
  Epoch: [189][200/128]   Time 0.012 (0.015)   Data 0.000 (0.000)   Loss 0.0141 (0.0088)   Prec@1 100.000 (99.992)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:15]
  **Train** Prec@1 99.976 Prec@5 100.000 Error@1 0.024
  **Test** Prec@1 78.480 Prec@5 94.280 Error@1 21.520
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:37:19] [Epoch=190/200] [Need: 00:01:01] [learning_rate=0.0006] [Best : Accuracy=78.63, Error=21.37]
  Epoch: [190][000/128]   Time 0.112 (0.112)   Data 0.000 (0.000)   Loss 0.0100 (0.0100)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:19]
  Epoch: [190][200/128]   Time 0.012 (0.013)   Data 0.000 (0.000)   Loss 0.0080 (0.0089)   Prec@1 100.000 (99.969)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:21]
  **Train** Prec@1 99.970 Prec@5 100.000 Error@1 0.030
  **Test** Prec@1 78.570 Prec@5 94.160 Error@1 21.430
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:37:24] [Epoch=191/200] [Need: 00:00:55] [learning_rate=0.0005] [Best : Accuracy=78.63, Error=21.37]
  Epoch: [191][000/128]   Time 0.125 (0.125)   Data 0.000 (0.000)   Loss 0.0105 (0.0105)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:24]
  Epoch: [191][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0076 (0.0087)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:27]
  **Train** Prec@1 99.976 Prec@5 100.000 Error@1 0.024
  **Test** Prec@1 78.430 Prec@5 94.180 Error@1 21.570
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:37:30] [Epoch=192/200] [Need: 00:00:48] [learning_rate=0.0004] [Best : Accuracy=78.63, Error=21.37]
  Epoch: [192][000/128]   Time 0.129 (0.129)   Data 0.000 (0.000)   Loss 0.0090 (0.0090)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:31]
  Epoch: [192][200/128]   Time 0.015 (0.014)   Data 0.000 (0.000)   Loss 0.0077 (0.0087)   Prec@1 100.000 (99.981)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:33]
  **Train** Prec@1 99.972 Prec@5 100.000 Error@1 0.028
  **Test** Prec@1 78.580 Prec@5 94.250 Error@1 21.420
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:37:36] [Epoch=193/200] [Need: 00:00:42] [learning_rate=0.0003] [Best : Accuracy=78.63, Error=21.37]
  Epoch: [193][000/128]   Time 0.115 (0.115)   Data 0.000 (0.000)   Loss 0.0095 (0.0095)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:37]
  Epoch: [193][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0092 (0.0090)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:39]
  **Train** Prec@1 99.970 Prec@5 100.000 Error@1 0.030
  **Test** Prec@1 78.670 Prec@5 94.170 Error@1 21.330
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:37:43] [Epoch=194/200] [Need: 00:00:36] [learning_rate=0.0002] [Best : Accuracy=78.67, Error=21.33]
  Epoch: [194][000/128]   Time 0.118 (0.118)   Data 0.000 (0.000)   Loss 0.0065 (0.0065)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:43]
  Epoch: [194][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0076 (0.0085)   Prec@1 100.000 (99.992)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:45]
  **Train** Prec@1 99.986 Prec@5 100.000 Error@1 0.014
  **Test** Prec@1 78.550 Prec@5 94.260 Error@1 21.450
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:37:49] [Epoch=195/200] [Need: 00:00:30] [learning_rate=0.0002] [Best : Accuracy=78.67, Error=21.33]
  Epoch: [195][000/128]   Time 0.121 (0.121)   Data 0.000 (0.000)   Loss 0.0077 (0.0077)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:49]
  Epoch: [195][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0094 (0.0088)   Prec@1 100.000 (99.965)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:51]
  **Train** Prec@1 99.976 Prec@5 100.000 Error@1 0.024
  **Test** Prec@1 78.500 Prec@5 94.180 Error@1 21.500
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:37:55] [Epoch=196/200] [Need: 00:00:24] [learning_rate=0.0001] [Best : Accuracy=78.67, Error=21.33]
  Epoch: [196][000/128]   Time 0.116 (0.116)   Data 0.000 (0.000)   Loss 0.0076 (0.0076)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:55]
  Epoch: [196][200/128]   Time 0.012 (0.013)   Data 0.000 (0.000)   Loss 0.0090 (0.0088)   Prec@1 100.000 (99.977)   Prec@5 100.000 (100.000)   [2025-02-03 18:37:58]
  **Train** Prec@1 99.974 Prec@5 100.000 Error@1 0.026
  **Test** Prec@1 78.550 Prec@5 94.200 Error@1 21.450
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:38:01] [Epoch=197/200] [Need: 00:00:18] [learning_rate=0.0001] [Best : Accuracy=78.67, Error=21.33]
  Epoch: [197][000/128]   Time 0.119 (0.119)   Data 0.000 (0.000)   Loss 0.0078 (0.0078)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:38:01]
  Epoch: [197][200/128]   Time 0.013 (0.014)   Data 0.000 (0.000)   Loss 0.0100 (0.0089)   Prec@1 100.000 (99.981)   Prec@5 100.000 (100.000)   [2025-02-03 18:38:04]
  **Train** Prec@1 99.982 Prec@5 100.000 Error@1 0.018
  **Test** Prec@1 78.570 Prec@5 94.240 Error@1 21.430
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:38:07] [Epoch=198/200] [Need: 00:00:12] [learning_rate=0.0000] [Best : Accuracy=78.67, Error=21.33]
  Epoch: [198][000/128]   Time 0.115 (0.115)   Data 0.000 (0.000)   Loss 0.0083 (0.0083)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:38:07]
  Epoch: [198][200/128]   Time 0.015 (0.013)   Data 0.000 (0.000)   Loss 0.0097 (0.0086)   Prec@1 100.000 (99.981)   Prec@5 100.000 (100.000)   [2025-02-03 18:38:10]
  **Train** Prec@1 99.976 Prec@5 100.000 Error@1 0.024
  **Test** Prec@1 78.510 Prec@5 94.120 Error@1 21.490
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png

==>>[2025-02-03 18:38:13] [Epoch=199/200] [Need: 00:00:06] [learning_rate=0.0000] [Best : Accuracy=78.67, Error=21.33]
  Epoch: [199][000/128]   Time 0.133 (0.133)   Data 0.000 (0.000)   Loss 0.0058 (0.0058)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2025-02-03 18:38:13]
  Epoch: [199][200/128]   Time 0.013 (0.013)   Data 0.000 (0.000)   Loss 0.0128 (0.0087)   Prec@1 100.000 (99.977)   Prec@5 100.000 (100.000)   [2025-02-03 18:38:16]
  **Train** Prec@1 99.972 Prec@5 100.000 Error@1 0.028
  **Test** Prec@1 78.400 Prec@5 94.220 Error@1 21.600
---- save figure the accuracy/loss curve of train/val into ./checkpoint/pruned-dataset/curve.png
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mranodom_pr0.0_resnet18_cifar100_seed52[0m at: [34mhttps://wandb.ai/hpi-deep-learning/c-class-iterations-full/runs/vb1l6u4j[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250203_101753-vb1l6u4j/logs[0m
