nohup: ignoring input
Running with pruning_rate=0.0 on GPU=0
Running with pruning_rate=0.1 on GPU=1
Running with pruning_rate=0.2 on GPU=2
Running with pruning_rate=0.3 on GPU=3
Running with pruning_rate=0.4 on GPU=0
Running with pruning_rate=0.5 on GPU=1
Running with pruning_rate=0.6 on GPU=2
Running with pruning_rate=0.7 on GPU=3
Running with pruning_rate=0.8 on GPU=0
Running with pruning_rate=0.9 on GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250122_172146-oy2x5yh8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.001_bs1024_dr0.25
wandb: ⭐️ View project at https://wandb.ai/hpi-deep-learning/air-quality
wandb: 🚀 View run at https://wandb.ai/hpi-deep-learning/air-quality/runs/oy2x5yh8
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250122_172357-9j3di6zb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.8_lr0.005_bs512_dr0.1
wandb: ⭐️ View project at https://wandb.ai/hpi-deep-learning/air-quality
wandb: 🚀 View run at https://wandb.ai/hpi-deep-learning/air-quality/runs/9j3di6zb
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250122_172646-lzod81a3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs2048_dr0.1
wandb: ⭐️ View project at https://wandb.ai/hpi-deep-learning/air-quality
wandb: 🚀 View run at https://wandb.ai/hpi-deep-learning/air-quality/runs/lzod81a3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250122_172649-xuymcoh6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.001_bs512_dr0.1
wandb: ⭐️ View project at https://wandb.ai/hpi-deep-learning/air-quality
wandb: 🚀 View run at https://wandb.ai/hpi-deep-learning/air-quality/runs/xuymcoh6
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250122_172702-1hzbao71
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.6_lr0.01_bs1024_dr0.1
wandb: ⭐️ View project at https://wandb.ai/hpi-deep-learning/air-quality
wandb: 🚀 View run at https://wandb.ai/hpi-deep-learning/air-quality/runs/1hzbao71
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250122_172801-bypflrhn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.2_lr0.01_bs2048_dr0.1
wandb: ⭐️ View project at https://wandb.ai/hpi-deep-learning/air-quality
wandb: 🚀 View run at https://wandb.ai/hpi-deep-learning/air-quality/runs/bypflrhn
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250122_172920-anz1yzs4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.1_lr0.05_bs2048_dr0.1
wandb: ⭐️ View project at https://wandb.ai/hpi-deep-learning/air-quality
wandb: 🚀 View run at https://wandb.ai/hpi-deep-learning/air-quality/runs/anz1yzs4
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250122_172951-n5w1fus6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.005_bs4096_dr0.15
wandb: ⭐️ View project at https://wandb.ai/hpi-deep-learning/air-quality
wandb: 🚀 View run at https://wandb.ai/hpi-deep-learning/air-quality/runs/n5w1fus6
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250122_173030-jza3u853
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.005_bs4096_dr0.2
wandb: ⭐️ View project at https://wandb.ai/hpi-deep-learning/air-quality
wandb: 🚀 View run at https://wandb.ai/hpi-deep-learning/air-quality/runs/jza3u853
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250122_173135-276arpvk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.4_lr0.005_bs4096_dr0.1
wandb: ⭐️ View project at https://wandb.ai/hpi-deep-learning/air-quality
wandb: 🚀 View run at https://wandb.ai/hpi-deep-learning/air-quality/runs/276arpvk
Starting hyperparameter optimization...
[lr=0.05, bs=512, dr=0.1] -> best_test_loss = 0.985372
[lr=0.05, bs=512, dr=0.15] -> best_test_loss = 0.982342
[lr=0.05, bs=512, dr=0.2] -> best_test_loss = 0.984194
[lr=0.05, bs=512, dr=0.25] -> best_test_loss = 0.982093
[lr=0.05, bs=512, dr=0.3] -> best_test_loss = 0.980981
[lr=0.05, bs=1024, dr=0.1] -> best_test_loss = 0.978219
[lr=0.05, bs=1024, dr=0.15] -> best_test_loss = 0.969584
[lr=0.05, bs=1024, dr=0.2] -> best_test_loss = 0.971098
[lr=0.05, bs=1024, dr=0.25] -> best_test_loss = 0.974860
[lr=0.05, bs=1024, dr=0.3] -> best_test_loss = 0.972879
[lr=0.05, bs=2048, dr=0.1] -> best_test_loss = 0.978219
[lr=0.05, bs=2048, dr=0.15] -> best_test_loss = 0.969584
[lr=0.05, bs=2048, dr=0.2] -> best_test_loss = 0.971098
[lr=0.05, bs=2048, dr=0.25] -> best_test_loss = 0.974860
[lr=0.05, bs=2048, dr=0.3] -> best_test_loss = 0.972879
[lr=0.05, bs=4096, dr=0.1] -> best_test_loss = 0.978219
[lr=0.05, bs=4096, dr=0.15] -> best_test_loss = 0.969584
[lr=0.05, bs=4096, dr=0.2] -> best_test_loss = 0.971098
[lr=0.05, bs=4096, dr=0.25] -> best_test_loss = 0.974860
[lr=0.05, bs=4096, dr=0.3] -> best_test_loss = 0.972879
[lr=0.01, bs=512, dr=0.1] -> best_test_loss = 0.982095
[lr=0.01, bs=512, dr=0.15] -> best_test_loss = 0.981018
[lr=0.01, bs=512, dr=0.2] -> best_test_loss = 0.980723
[lr=0.01, bs=512, dr=0.25] -> best_test_loss = 0.984301
[lr=0.01, bs=512, dr=0.3] -> best_test_loss = 0.985402
[lr=0.01, bs=1024, dr=0.1] -> best_test_loss = 0.972485
[lr=0.01, bs=1024, dr=0.15] -> best_test_loss = 0.971484
[lr=0.01, bs=1024, dr=0.2] -> best_test_loss = 0.972239
[lr=0.01, bs=1024, dr=0.25] -> best_test_loss = 0.973566
[lr=0.01, bs=1024, dr=0.3] -> best_test_loss = 0.974536
[lr=0.01, bs=2048, dr=0.1] -> best_test_loss = 0.972485
[lr=0.01, bs=2048, dr=0.15] -> best_test_loss = 0.971484
[lr=0.01, bs=2048, dr=0.2] -> best_test_loss = 0.972239
[lr=0.01, bs=2048, dr=0.25] -> best_test_loss = 0.973566
[lr=0.01, bs=2048, dr=0.3] -> best_test_loss = 0.974536
[lr=0.01, bs=4096, dr=0.1] -> best_test_loss = 0.972485
[lr=0.01, bs=4096, dr=0.15] -> best_test_loss = 0.971484
[lr=0.01, bs=4096, dr=0.2] -> best_test_loss = 0.972239
[lr=0.01, bs=4096, dr=0.25] -> best_test_loss = 0.973566
[lr=0.01, bs=4096, dr=0.3] -> best_test_loss = 0.974536
[lr=0.005, bs=512, dr=0.1] -> best_test_loss = 0.977973
[lr=0.005, bs=512, dr=0.15] -> best_test_loss = 0.977755
[lr=0.005, bs=512, dr=0.2] -> best_test_loss = 0.975649
[lr=0.005, bs=512, dr=0.25] -> best_test_loss = 0.978577
[lr=0.005, bs=512, dr=0.3] -> best_test_loss = 0.980068
[lr=0.005, bs=1024, dr=0.1] -> best_test_loss = 0.972339
[lr=0.005, bs=1024, dr=0.15] -> best_test_loss = 0.972602
[lr=0.005, bs=1024, dr=0.2] -> best_test_loss = 0.974807
[lr=0.005, bs=1024, dr=0.25] -> best_test_loss = 0.976235
[lr=0.005, bs=1024, dr=0.3] -> best_test_loss = 0.976291
[lr=0.005, bs=2048, dr=0.1] -> best_test_loss = 0.972339
[lr=0.005, bs=2048, dr=0.15] -> best_test_loss = 0.972602
[lr=0.005, bs=2048, dr=0.2] -> best_test_loss = 0.974807
[lr=0.005, bs=2048, dr=0.25] -> best_test_loss = 0.976235
[lr=0.005, bs=2048, dr=0.3] -> best_test_loss = 0.976291
[lr=0.005, bs=4096, dr=0.1] -> best_test_loss = 0.972339
[lr=0.005, bs=4096, dr=0.15] -> best_test_loss = 0.972602
[lr=0.005, bs=4096, dr=0.2] -> best_test_loss = 0.974807
[lr=0.005, bs=4096, dr=0.25] -> best_test_loss = 0.976235
[lr=0.005, bs=4096, dr=0.3] -> best_test_loss = 0.976291
[lr=0.001, bs=512, dr=0.1] -> best_test_loss = 0.972911
[lr=0.001, bs=512, dr=0.15] -> best_test_loss = 0.972032
[lr=0.001, bs=512, dr=0.2] -> best_test_loss = 0.973836
[lr=0.001, bs=512, dr=0.25] -> best_test_loss = 0.978902
[lr=0.001, bs=512, dr=0.3] -> best_test_loss = 0.978584
[lr=0.001, bs=1024, dr=0.1] -> best_test_loss = 0.972925
[lr=0.001, bs=1024, dr=0.15] -> best_test_loss = 0.970032
[lr=0.001, bs=1024, dr=0.2] -> best_test_loss = 0.968107
[lr=0.001, bs=1024, dr=0.25] -> best_test_loss = 0.965671
[lr=0.001, bs=1024, dr=0.3] -> best_test_loss = 0.972223
[lr=0.001, bs=2048, dr=0.1] -> best_test_loss = 0.972925
[lr=0.001, bs=2048, dr=0.15] -> best_test_loss = 0.970032
[lr=0.001, bs=2048, dr=0.2] -> best_test_loss = 0.968107
[lr=0.001, bs=2048, dr=0.25] -> best_test_loss = 0.965671
[lr=0.001, bs=2048, dr=0.3] -> best_test_loss = 0.972223
[lr=0.001, bs=4096, dr=0.1] -> best_test_loss = 0.972925
[lr=0.001, bs=4096, dr=0.15] -> best_test_loss = 0.970032
[lr=0.001, bs=4096, dr=0.2] -> best_test_loss = 0.968107
[lr=0.001, bs=4096, dr=0.25] -> best_test_loss = 0.965671
[lr=0.001, bs=4096, dr=0.3] -> best_test_loss = 0.972223
[lr=0.0005, bs=512, dr=0.1] -> best_test_loss = 0.976300
[lr=0.0005, bs=512, dr=0.15] -> best_test_loss = 0.977550
[lr=0.0005, bs=512, dr=0.2] -> best_test_loss = 0.979529
[lr=0.0005, bs=512, dr=0.25] -> best_test_loss = 0.982101
[lr=0.0005, bs=512, dr=0.3] -> best_test_loss = 0.984934
[lr=0.0005, bs=1024, dr=0.1] -> best_test_loss = 0.974731
[lr=0.0005, bs=1024, dr=0.15] -> best_test_loss = 0.969872
[lr=0.0005, bs=1024, dr=0.2] -> best_test_loss = 0.970536
[lr=0.0005, bs=1024, dr=0.25] -> best_test_loss = 0.971707
[lr=0.0005, bs=1024, dr=0.3] -> best_test_loss = 0.976214
[lr=0.0005, bs=2048, dr=0.1] -> best_test_loss = 0.974731
[lr=0.0005, bs=2048, dr=0.15] -> best_test_loss = 0.969872
[lr=0.0005, bs=2048, dr=0.2] -> best_test_loss = 0.970536
[lr=0.0005, bs=2048, dr=0.25] -> best_test_loss = 0.971707
[lr=0.0005, bs=2048, dr=0.3] -> best_test_loss = 0.976214
[lr=0.0005, bs=4096, dr=0.1] -> best_test_loss = 0.974731
[lr=0.0005, bs=4096, dr=0.15] -> best_test_loss = 0.969872
[lr=0.0005, bs=4096, dr=0.2] -> best_test_loss = 0.970536
[lr=0.0005, bs=4096, dr=0.25] -> best_test_loss = 0.971707
[lr=0.0005, bs=4096, dr=0.3] -> best_test_loss = 0.976214
[lr=0.0001, bs=512, dr=0.1] -> best_test_loss = 0.988652
[lr=0.0001, bs=512, dr=0.15] -> best_test_loss = 0.989180
[lr=0.0001, bs=512, dr=0.2] -> best_test_loss = 0.988304
[lr=0.0001, bs=512, dr=0.25] -> best_test_loss = 0.988386
[lr=0.0001, bs=512, dr=0.3] -> best_test_loss = 0.990245
[lr=0.0001, bs=1024, dr=0.1] -> best_test_loss = 0.983884
[lr=0.0001, bs=1024, dr=0.15] -> best_test_loss = 0.983656
[lr=0.0001, bs=1024, dr=0.2] -> best_test_loss = 0.984872
[lr=0.0001, bs=1024, dr=0.25] -> best_test_loss = 0.985351
[lr=0.0001, bs=1024, dr=0.3] -> best_test_loss = 0.987585
[lr=0.0001, bs=2048, dr=0.1] -> best_test_loss = 0.983884
[lr=0.0001, bs=2048, dr=0.15] -> best_test_loss = 0.983656
[lr=0.0001, bs=2048, dr=0.2] -> best_test_loss = 0.984872
[lr=0.0001, bs=2048, dr=0.25] -> best_test_loss = 0.985351
[lr=0.0001, bs=2048, dr=0.3] -> best_test_loss = 0.987585
[lr=0.0001, bs=4096, dr=0.1] -> best_test_loss = 0.983884
[lr=0.0001, bs=4096, dr=0.15] -> best_test_loss = 0.983656
[lr=0.0001, bs=4096, dr=0.2] -> best_test_loss = 0.984872
[lr=0.0001, bs=4096, dr=0.25] -> best_test_loss = 0.985351
[lr=0.0001, bs=4096, dr=0.3] -> best_test_loss = 0.987585
Best parameters: {'learning_rate': 0.001, 'batch_size': 1024, 'dropout_rate': 0.25} with Test Loss: 0.9656711247926508
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mrandom_prune0.9_lr0.001_bs1024_dr0.25[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air-quality/runs/oy2x5yh8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250122_172146-oy2x5yh8/logs[0m
Starting hyperparameter optimization...
[lr=0.05, bs=512, dr=0.1] -> best_test_loss = 0.962056
[lr=0.05, bs=512, dr=0.15] -> best_test_loss = 0.969135
[lr=0.05, bs=512, dr=0.2] -> best_test_loss = 0.968151
[lr=0.05, bs=512, dr=0.25] -> best_test_loss = 0.973564
[lr=0.05, bs=512, dr=0.3] -> best_test_loss = 0.975120
[lr=0.05, bs=1024, dr=0.1] -> best_test_loss = 0.966227
[lr=0.05, bs=1024, dr=0.15] -> best_test_loss = 0.971196
[lr=0.05, bs=1024, dr=0.2] -> best_test_loss = 0.974770
[lr=0.05, bs=1024, dr=0.25] -> best_test_loss = 0.976266
[lr=0.05, bs=1024, dr=0.3] -> best_test_loss = 0.979282
[lr=0.05, bs=2048, dr=0.1] -> best_test_loss = 0.957832
[lr=0.05, bs=2048, dr=0.15] -> best_test_loss = 0.958687
[lr=0.05, bs=2048, dr=0.2] -> best_test_loss = 0.959842
[lr=0.05, bs=2048, dr=0.25] -> best_test_loss = 0.959570
[lr=0.05, bs=2048, dr=0.3] -> best_test_loss = 0.964395
[lr=0.05, bs=4096, dr=0.1] -> best_test_loss = 0.957832
[lr=0.05, bs=4096, dr=0.15] -> best_test_loss = 0.958687
[lr=0.05, bs=4096, dr=0.2] -> best_test_loss = 0.959842
[lr=0.05, bs=4096, dr=0.25] -> best_test_loss = 0.959570
[lr=0.05, bs=4096, dr=0.3] -> best_test_loss = 0.964395
[lr=0.01, bs=512, dr=0.1] -> best_test_loss = 0.962021
[lr=0.01, bs=512, dr=0.15] -> best_test_loss = 0.966512
[lr=0.01, bs=512, dr=0.2] -> best_test_loss = 0.965565
[lr=0.01, bs=512, dr=0.25] -> best_test_loss = 0.972172
[lr=0.01, bs=512, dr=0.3] -> best_test_loss = 0.967258
[lr=0.01, bs=1024, dr=0.1] -> best_test_loss = 0.963657
[lr=0.01, bs=1024, dr=0.15] -> best_test_loss = 0.966275
[lr=0.01, bs=1024, dr=0.2] -> best_test_loss = 0.966946
[lr=0.01, bs=1024, dr=0.25] -> best_test_loss = 0.972991
[lr=0.01, bs=1024, dr=0.3] -> best_test_loss = 0.972729
[lr=0.01, bs=2048, dr=0.1] -> best_test_loss = 0.963845
[lr=0.01, bs=2048, dr=0.15] -> best_test_loss = 0.964589
[lr=0.01, bs=2048, dr=0.2] -> best_test_loss = 0.966542
[lr=0.01, bs=2048, dr=0.25] -> best_test_loss = 0.963285
[lr=0.01, bs=2048, dr=0.3] -> best_test_loss = 0.962018
[lr=0.01, bs=4096, dr=0.1] -> best_test_loss = 0.963845
[lr=0.01, bs=4096, dr=0.15] -> best_test_loss = 0.964589
[lr=0.01, bs=4096, dr=0.2] -> best_test_loss = 0.966542
[lr=0.01, bs=4096, dr=0.25] -> best_test_loss = 0.963285
[lr=0.01, bs=4096, dr=0.3] -> best_test_loss = 0.962018
[lr=0.005, bs=512, dr=0.1] -> best_test_loss = 0.954586
[lr=0.005, bs=512, dr=0.15] -> best_test_loss = 0.961235
[lr=0.005, bs=512, dr=0.2] -> best_test_loss = 0.963413
[lr=0.005, bs=512, dr=0.25] -> best_test_loss = 0.962849
[lr=0.005, bs=512, dr=0.3] -> best_test_loss = 0.962528
[lr=0.005, bs=1024, dr=0.1] -> best_test_loss = 0.964010
[lr=0.005, bs=1024, dr=0.15] -> best_test_loss = 0.966258
[lr=0.005, bs=1024, dr=0.2] -> best_test_loss = 0.963709
[lr=0.005, bs=1024, dr=0.25] -> best_test_loss = 0.965236
[lr=0.005, bs=1024, dr=0.3] -> best_test_loss = 0.967079
[lr=0.005, bs=2048, dr=0.1] -> best_test_loss = 0.963295
[lr=0.005, bs=2048, dr=0.15] -> best_test_loss = 0.966580
[lr=0.005, bs=2048, dr=0.2] -> best_test_loss = 0.964187
[lr=0.005, bs=2048, dr=0.25] -> best_test_loss = 0.963227
[lr=0.005, bs=2048, dr=0.3] -> best_test_loss = 0.966844
[lr=0.005, bs=4096, dr=0.1] -> best_test_loss = 0.963295
[lr=0.005, bs=4096, dr=0.15] -> best_test_loss = 0.966580
[lr=0.005, bs=4096, dr=0.2] -> best_test_loss = 0.964187
[lr=0.005, bs=4096, dr=0.25] -> best_test_loss = 0.963227
[lr=0.005, bs=4096, dr=0.3] -> best_test_loss = 0.966844
[lr=0.001, bs=512, dr=0.1] -> best_test_loss = 0.966808
[lr=0.001, bs=512, dr=0.15] -> best_test_loss = 0.967866
[lr=0.001, bs=512, dr=0.2] -> best_test_loss = 0.970609
[lr=0.001, bs=512, dr=0.25] -> best_test_loss = 0.970753
[lr=0.001, bs=512, dr=0.3] -> best_test_loss = 0.976264
[lr=0.001, bs=1024, dr=0.1] -> best_test_loss = 0.965796
[lr=0.001, bs=1024, dr=0.15] -> best_test_loss = 0.967929
[lr=0.001, bs=1024, dr=0.2] -> best_test_loss = 0.971565
[lr=0.001, bs=1024, dr=0.25] -> best_test_loss = 0.974384
[lr=0.001, bs=1024, dr=0.3] -> best_test_loss = 0.975315
[lr=0.001, bs=2048, dr=0.1] -> best_test_loss = 0.965093
[lr=0.001, bs=2048, dr=0.15] -> best_test_loss = 0.965326
[lr=0.001, bs=2048, dr=0.2] -> best_test_loss = 0.964484
[lr=0.001, bs=2048, dr=0.25] -> best_test_loss = 0.965183
[lr=0.001, bs=2048, dr=0.3] -> best_test_loss = 0.968589
[lr=0.001, bs=4096, dr=0.1] -> best_test_loss = 0.965093
[lr=0.001, bs=4096, dr=0.15] -> best_test_loss = 0.965326
[lr=0.001, bs=4096, dr=0.2] -> best_test_loss = 0.964484
[lr=0.001, bs=4096, dr=0.25] -> best_test_loss = 0.965183
[lr=0.001, bs=4096, dr=0.3] -> best_test_loss = 0.968589
[lr=0.0005, bs=512, dr=0.1] -> best_test_loss = 0.967687
[lr=0.0005, bs=512, dr=0.15] -> best_test_loss = 0.971306
[lr=0.0005, bs=512, dr=0.2] -> best_test_loss = 0.973614
[lr=0.0005, bs=512, dr=0.25] -> best_test_loss = 0.977313
[lr=0.0005, bs=512, dr=0.3] -> best_test_loss = 0.980916
[lr=0.0005, bs=1024, dr=0.1] -> best_test_loss = 0.969446
[lr=0.0005, bs=1024, dr=0.15] -> best_test_loss = 0.973196
[lr=0.0005, bs=1024, dr=0.2] -> best_test_loss = 0.975880
[lr=0.0005, bs=1024, dr=0.25] -> best_test_loss = 0.977768
[lr=0.0005, bs=1024, dr=0.3] -> best_test_loss = 0.981890
[lr=0.0005, bs=2048, dr=0.1] -> best_test_loss = 0.968159
[lr=0.0005, bs=2048, dr=0.15] -> best_test_loss = 0.967516
[lr=0.0005, bs=2048, dr=0.2] -> best_test_loss = 0.966712
[lr=0.0005, bs=2048, dr=0.25] -> best_test_loss = 0.970732
[lr=0.0005, bs=2048, dr=0.3] -> best_test_loss = 0.974992
[lr=0.0005, bs=4096, dr=0.1] -> best_test_loss = 0.968159
[lr=0.0005, bs=4096, dr=0.15] -> best_test_loss = 0.967516
[lr=0.0005, bs=4096, dr=0.2] -> best_test_loss = 0.966712
[lr=0.0005, bs=4096, dr=0.25] -> best_test_loss = 0.970732
[lr=0.0005, bs=4096, dr=0.3] -> best_test_loss = 0.974992
[lr=0.0001, bs=512, dr=0.1] -> best_test_loss = 0.980349
[lr=0.0001, bs=512, dr=0.15] -> best_test_loss = 0.981704
[lr=0.0001, bs=512, dr=0.2] -> best_test_loss = 0.983532
[lr=0.0001, bs=512, dr=0.25] -> best_test_loss = 0.983721
[lr=0.0001, bs=512, dr=0.3] -> best_test_loss = 0.984699
[lr=0.0001, bs=1024, dr=0.1] -> best_test_loss = 0.982172
[lr=0.0001, bs=1024, dr=0.15] -> best_test_loss = 0.984976
[lr=0.0001, bs=1024, dr=0.2] -> best_test_loss = 0.985826
[lr=0.0001, bs=1024, dr=0.25] -> best_test_loss = 0.986143
[lr=0.0001, bs=1024, dr=0.3] -> best_test_loss = 0.986510
[lr=0.0001, bs=2048, dr=0.1] -> best_test_loss = 0.974992
[lr=0.0001, bs=2048, dr=0.15] -> best_test_loss = 0.975848
[lr=0.0001, bs=2048, dr=0.2] -> best_test_loss = 0.978072
[lr=0.0001, bs=2048, dr=0.25] -> best_test_loss = 0.980710
[lr=0.0001, bs=2048, dr=0.3] -> best_test_loss = 0.982114
[lr=0.0001, bs=4096, dr=0.1] -> best_test_loss = 0.974992
[lr=0.0001, bs=4096, dr=0.15] -> best_test_loss = 0.975848
[lr=0.0001, bs=4096, dr=0.2] -> best_test_loss = 0.978072
[lr=0.0001, bs=4096, dr=0.25] -> best_test_loss = 0.980710
[lr=0.0001, bs=4096, dr=0.3] -> best_test_loss = 0.982114
Best parameters: {'learning_rate': 0.005, 'batch_size': 512, 'dropout_rate': 0.1} with Test Loss: 0.9545859375561557
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mrandom_prune0.8_lr0.005_bs512_dr0.1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air-quality/runs/9j3di6zb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250122_172357-9j3di6zb/logs[0m
Starting hyperparameter optimization...
[lr=0.05, bs=512, dr=0.1] -> best_test_loss = 0.979496
[lr=0.05, bs=512, dr=0.15] -> best_test_loss = 0.978063
[lr=0.05, bs=512, dr=0.2] -> best_test_loss = 0.981379
[lr=0.05, bs=512, dr=0.25] -> best_test_loss = 0.982775
[lr=0.05, bs=512, dr=0.3] -> best_test_loss = 0.981427
[lr=0.05, bs=1024, dr=0.1] -> best_test_loss = 0.979729
[lr=0.05, bs=1024, dr=0.15] -> best_test_loss = 0.981469
[lr=0.05, bs=1024, dr=0.2] -> best_test_loss = 0.978838
[lr=0.05, bs=1024, dr=0.25] -> best_test_loss = 0.979279
[lr=0.05, bs=1024, dr=0.3] -> best_test_loss = 0.980344
[lr=0.05, bs=2048, dr=0.1] -> best_test_loss = 0.983038
[lr=0.05, bs=2048, dr=0.15] -> best_test_loss = 0.986488
[lr=0.05, bs=2048, dr=0.2] -> best_test_loss = 0.983571
[lr=0.05, bs=2048, dr=0.25] -> best_test_loss = 0.983720
[lr=0.05, bs=2048, dr=0.3] -> best_test_loss = 0.982895
[lr=0.05, bs=4096, dr=0.1] -> best_test_loss = 0.990503
[lr=0.05, bs=4096, dr=0.15] -> best_test_loss = 0.987663
[lr=0.05, bs=4096, dr=0.2] -> best_test_loss = 0.989942
[lr=0.05, bs=4096, dr=0.25] -> best_test_loss = 0.988147
[lr=0.05, bs=4096, dr=0.3] -> best_test_loss = 0.991100
[lr=0.01, bs=512, dr=0.1] -> best_test_loss = 0.966123
[lr=0.01, bs=512, dr=0.15] -> best_test_loss = 0.967951
[lr=0.01, bs=512, dr=0.2] -> best_test_loss = 0.969086
[lr=0.01, bs=512, dr=0.25] -> best_test_loss = 0.972195
[lr=0.01, bs=512, dr=0.3] -> best_test_loss = 0.973954
[lr=0.01, bs=1024, dr=0.1] -> best_test_loss = 0.967008
[lr=0.01, bs=1024, dr=0.15] -> best_test_loss = 0.980017
[lr=0.01, bs=1024, dr=0.2] -> best_test_loss = 0.977594
[lr=0.01, bs=1024, dr=0.25] -> best_test_loss = 0.973322
[lr=0.01, bs=1024, dr=0.3] -> best_test_loss = 0.980854
[lr=0.01, bs=2048, dr=0.1] -> best_test_loss = 0.978982
[lr=0.01, bs=2048, dr=0.15] -> best_test_loss = 0.976700
[lr=0.01, bs=2048, dr=0.2] -> best_test_loss = 0.984908
[lr=0.01, bs=2048, dr=0.25] -> best_test_loss = 0.976700
[lr=0.01, bs=2048, dr=0.3] -> best_test_loss = 0.983336
[lr=0.01, bs=4096, dr=0.1] -> best_test_loss = 0.986980
[lr=0.01, bs=4096, dr=0.15] -> best_test_loss = 0.983230
[lr=0.01, bs=4096, dr=0.2] -> best_test_loss = 0.992187
[lr=0.01, bs=4096, dr=0.25] -> best_test_loss = 0.985318
[lr=0.01, bs=4096, dr=0.3] -> best_test_loss = 0.986786
[lr=0.005, bs=512, dr=0.1] -> best_test_loss = 0.960042
[lr=0.005, bs=512, dr=0.15] -> best_test_loss = 0.961208
[lr=0.005, bs=512, dr=0.2] -> best_test_loss = 0.965585
[lr=0.005, bs=512, dr=0.25] -> best_test_loss = 0.963120
[lr=0.005, bs=512, dr=0.3] -> best_test_loss = 0.965216
[lr=0.005, bs=1024, dr=0.1] -> best_test_loss = 0.965072
[lr=0.005, bs=1024, dr=0.15] -> best_test_loss = 0.971394
[lr=0.005, bs=1024, dr=0.2] -> best_test_loss = 0.970285
[lr=0.005, bs=1024, dr=0.25] -> best_test_loss = 0.969807
[lr=0.005, bs=1024, dr=0.3] -> best_test_loss = 0.974093
[lr=0.005, bs=2048, dr=0.1] -> best_test_loss = 0.977627
[lr=0.005, bs=2048, dr=0.15] -> best_test_loss = 0.978955
[lr=0.005, bs=2048, dr=0.2] -> best_test_loss = 0.976406
[lr=0.005, bs=2048, dr=0.25] -> best_test_loss = 0.977163
[lr=0.005, bs=2048, dr=0.3] -> best_test_loss = 0.983427
[lr=0.005, bs=4096, dr=0.1] -> best_test_loss = 0.982069
[lr=0.005, bs=4096, dr=0.15] -> best_test_loss = 0.979054
[lr=0.005, bs=4096, dr=0.2] -> best_test_loss = 0.981866
[lr=0.005, bs=4096, dr=0.25] -> best_test_loss = 0.983299
[lr=0.005, bs=4096, dr=0.3] -> best_test_loss = 0.984622
[lr=0.001, bs=512, dr=0.1] -> best_test_loss = 0.954983
[lr=0.001, bs=512, dr=0.15] -> best_test_loss = 0.957877
[lr=0.001, bs=512, dr=0.2] -> best_test_loss = 0.965290
[lr=0.001, bs=512, dr=0.25] -> best_test_loss = 0.966829
[lr=0.001, bs=512, dr=0.3] -> best_test_loss = 0.973059
[lr=0.001, bs=1024, dr=0.1] -> best_test_loss = 0.963018
[lr=0.001, bs=1024, dr=0.15] -> best_test_loss = 0.968758
[lr=0.001, bs=1024, dr=0.2] -> best_test_loss = 0.974407
[lr=0.001, bs=1024, dr=0.25] -> best_test_loss = 0.976874
[lr=0.001, bs=1024, dr=0.3] -> best_test_loss = 0.979250
[lr=0.001, bs=2048, dr=0.1] -> best_test_loss = 0.970240
[lr=0.001, bs=2048, dr=0.15] -> best_test_loss = 0.973235
[lr=0.001, bs=2048, dr=0.2] -> best_test_loss = 0.974956
[lr=0.001, bs=2048, dr=0.25] -> best_test_loss = 0.983348
[lr=0.001, bs=2048, dr=0.3] -> best_test_loss = 0.979908
[lr=0.001, bs=4096, dr=0.1] -> best_test_loss = 0.970405
[lr=0.001, bs=4096, dr=0.15] -> best_test_loss = 0.978702
[lr=0.001, bs=4096, dr=0.2] -> best_test_loss = 0.980474
[lr=0.001, bs=4096, dr=0.25] -> best_test_loss = 0.980704
[lr=0.001, bs=4096, dr=0.3] -> best_test_loss = 0.981543
[lr=0.0005, bs=512, dr=0.1] -> best_test_loss = 0.958917
[lr=0.0005, bs=512, dr=0.15] -> best_test_loss = 0.963973
[lr=0.0005, bs=512, dr=0.2] -> best_test_loss = 0.968104
[lr=0.0005, bs=512, dr=0.25] -> best_test_loss = 0.968951
[lr=0.0005, bs=512, dr=0.3] -> best_test_loss = 0.973480
[lr=0.0005, bs=1024, dr=0.1] -> best_test_loss = 0.967125
[lr=0.0005, bs=1024, dr=0.15] -> best_test_loss = 0.969489
[lr=0.0005, bs=1024, dr=0.2] -> best_test_loss = 0.976500
[lr=0.0005, bs=1024, dr=0.25] -> best_test_loss = 0.979308
[lr=0.0005, bs=1024, dr=0.3] -> best_test_loss = 0.981556
[lr=0.0005, bs=2048, dr=0.1] -> best_test_loss = 0.973646
[lr=0.0005, bs=2048, dr=0.15] -> best_test_loss = 0.976986
[lr=0.0005, bs=2048, dr=0.2] -> best_test_loss = 0.979632
[lr=0.0005, bs=2048, dr=0.25] -> best_test_loss = 0.982663
[lr=0.0005, bs=2048, dr=0.3] -> best_test_loss = 0.982360
[lr=0.0005, bs=4096, dr=0.1] -> best_test_loss = 0.978576
[lr=0.0005, bs=4096, dr=0.15] -> best_test_loss = 0.977751
[lr=0.0005, bs=4096, dr=0.2] -> best_test_loss = 0.981621
[lr=0.0005, bs=4096, dr=0.25] -> best_test_loss = 0.981726
[lr=0.0005, bs=4096, dr=0.3] -> best_test_loss = 0.985051
[lr=0.0001, bs=512, dr=0.1] -> best_test_loss = 0.977086
[lr=0.0001, bs=512, dr=0.15] -> best_test_loss = 0.978155
[lr=0.0001, bs=512, dr=0.2] -> best_test_loss = 0.979660
[lr=0.0001, bs=512, dr=0.25] -> best_test_loss = 0.980548
[lr=0.0001, bs=512, dr=0.3] -> best_test_loss = 0.982016
[lr=0.0001, bs=1024, dr=0.1] -> best_test_loss = 0.978893
[lr=0.0001, bs=1024, dr=0.15] -> best_test_loss = 0.980539
[lr=0.0001, bs=1024, dr=0.2] -> best_test_loss = 0.984481
[lr=0.0001, bs=1024, dr=0.25] -> best_test_loss = 0.985092
[lr=0.0001, bs=1024, dr=0.3] -> best_test_loss = 0.986139
[lr=0.0001, bs=2048, dr=0.1] -> best_test_loss = 0.986016
[lr=0.0001, bs=2048, dr=0.15] -> best_test_loss = 0.986385
[lr=0.0001, bs=2048, dr=0.2] -> best_test_loss = 0.988360
[lr=0.0001, bs=2048, dr=0.25] -> best_test_loss = 0.989097
[lr=0.0001, bs=2048, dr=0.3] -> best_test_loss = 0.988454
[lr=0.0001, bs=4096, dr=0.1] -> best_test_loss = 0.988311
[lr=0.0001, bs=4096, dr=0.15] -> best_test_loss = 0.989091
[lr=0.0001, bs=4096, dr=0.2] -> best_test_loss = 0.987098
[lr=0.0001, bs=4096, dr=0.25] -> best_test_loss = 0.986317
[lr=0.0001, bs=4096, dr=0.3] -> best_test_loss = 0.988773
Best parameters: {'learning_rate': 0.001, 'batch_size': 512, 'dropout_rate': 0.1} with Test Loss: 0.9549832869906909
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mrandom_prune0.3_lr0.001_bs512_dr0.1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air-quality/runs/xuymcoh6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250122_172649-xuymcoh6/logs[0m
Starting hyperparameter optimization...
[lr=0.05, bs=512, dr=0.1] -> best_test_loss = 0.960533
[lr=0.05, bs=512, dr=0.15] -> best_test_loss = 0.959816
[lr=0.05, bs=512, dr=0.2] -> best_test_loss = 0.967806
[lr=0.05, bs=512, dr=0.25] -> best_test_loss = 0.964417
[lr=0.05, bs=512, dr=0.3] -> best_test_loss = 0.972121
[lr=0.05, bs=1024, dr=0.1] -> best_test_loss = 0.956889
[lr=0.05, bs=1024, dr=0.15] -> best_test_loss = 0.957349
[lr=0.05, bs=1024, dr=0.2] -> best_test_loss = 0.961226
[lr=0.05, bs=1024, dr=0.25] -> best_test_loss = 0.967415
[lr=0.05, bs=1024, dr=0.3] -> best_test_loss = 0.968169
[lr=0.05, bs=2048, dr=0.1] -> best_test_loss = 0.963221
[lr=0.05, bs=2048, dr=0.15] -> best_test_loss = 0.961086
[lr=0.05, bs=2048, dr=0.2] -> best_test_loss = 0.967582
[lr=0.05, bs=2048, dr=0.25] -> best_test_loss = 0.972696
[lr=0.05, bs=2048, dr=0.3] -> best_test_loss = 0.970076
[lr=0.05, bs=4096, dr=0.1] -> best_test_loss = 0.957078
[lr=0.05, bs=4096, dr=0.15] -> best_test_loss = 0.958401
[lr=0.05, bs=4096, dr=0.2] -> best_test_loss = 0.958401
[lr=0.05, bs=4096, dr=0.25] -> best_test_loss = 0.960542
[lr=0.05, bs=4096, dr=0.3] -> best_test_loss = 0.957640
[lr=0.01, bs=512, dr=0.1] -> best_test_loss = 0.949516
[lr=0.01, bs=512, dr=0.15] -> best_test_loss = 0.955365
[lr=0.01, bs=512, dr=0.2] -> best_test_loss = 0.958100
[lr=0.01, bs=512, dr=0.25] -> best_test_loss = 0.954603
[lr=0.01, bs=512, dr=0.3] -> best_test_loss = 0.960139
[lr=0.01, bs=1024, dr=0.1] -> best_test_loss = 0.944679
[lr=0.01, bs=1024, dr=0.15] -> best_test_loss = 0.949448
[lr=0.01, bs=1024, dr=0.2] -> best_test_loss = 0.955780
[lr=0.01, bs=1024, dr=0.25] -> best_test_loss = 0.957240
[lr=0.01, bs=1024, dr=0.3] -> best_test_loss = 0.959463
[lr=0.01, bs=2048, dr=0.1] -> best_test_loss = 0.952532
[lr=0.01, bs=2048, dr=0.15] -> best_test_loss = 0.954837
[lr=0.01, bs=2048, dr=0.2] -> best_test_loss = 0.956984
[lr=0.01, bs=2048, dr=0.25] -> best_test_loss = 0.958431
[lr=0.01, bs=2048, dr=0.3] -> best_test_loss = 0.967941
[lr=0.01, bs=4096, dr=0.1] -> best_test_loss = 0.951590
[lr=0.01, bs=4096, dr=0.15] -> best_test_loss = 0.949802
[lr=0.01, bs=4096, dr=0.2] -> best_test_loss = 0.951683
[lr=0.01, bs=4096, dr=0.25] -> best_test_loss = 0.954017
[lr=0.01, bs=4096, dr=0.3] -> best_test_loss = 0.956772
[lr=0.005, bs=512, dr=0.1] -> best_test_loss = 0.950260
[lr=0.005, bs=512, dr=0.15] -> best_test_loss = 0.953657
[lr=0.005, bs=512, dr=0.2] -> best_test_loss = 0.951665
[lr=0.005, bs=512, dr=0.25] -> best_test_loss = 0.959361
[lr=0.005, bs=512, dr=0.3] -> best_test_loss = 0.958862
[lr=0.005, bs=1024, dr=0.1] -> best_test_loss = 0.948945
[lr=0.005, bs=1024, dr=0.15] -> best_test_loss = 0.948162
[lr=0.005, bs=1024, dr=0.2] -> best_test_loss = 0.952411
[lr=0.005, bs=1024, dr=0.25] -> best_test_loss = 0.957013
[lr=0.005, bs=1024, dr=0.3] -> best_test_loss = 0.955850
[lr=0.005, bs=2048, dr=0.1] -> best_test_loss = 0.954270
[lr=0.005, bs=2048, dr=0.15] -> best_test_loss = 0.956307
[lr=0.005, bs=2048, dr=0.2] -> best_test_loss = 0.955189
[lr=0.005, bs=2048, dr=0.25] -> best_test_loss = 0.955559
[lr=0.005, bs=2048, dr=0.3] -> best_test_loss = 0.960304
[lr=0.005, bs=4096, dr=0.1] -> best_test_loss = 0.949927
[lr=0.005, bs=4096, dr=0.15] -> best_test_loss = 0.949692
[lr=0.005, bs=4096, dr=0.2] -> best_test_loss = 0.952388
[lr=0.005, bs=4096, dr=0.25] -> best_test_loss = 0.955592
[lr=0.005, bs=4096, dr=0.3] -> best_test_loss = 0.956936
[lr=0.001, bs=512, dr=0.1] -> best_test_loss = 0.957260
[lr=0.001, bs=512, dr=0.15] -> best_test_loss = 0.958309
[lr=0.001, bs=512, dr=0.2] -> best_test_loss = 0.961372
[lr=0.001, bs=512, dr=0.25] -> best_test_loss = 0.963678
[lr=0.001, bs=512, dr=0.3] -> best_test_loss = 0.966047
[lr=0.001, bs=1024, dr=0.1] -> best_test_loss = 0.955810
[lr=0.001, bs=1024, dr=0.15] -> best_test_loss = 0.956120
[lr=0.001, bs=1024, dr=0.2] -> best_test_loss = 0.957997
[lr=0.001, bs=1024, dr=0.25] -> best_test_loss = 0.961919
[lr=0.001, bs=1024, dr=0.3] -> best_test_loss = 0.964953
[lr=0.001, bs=2048, dr=0.1] -> best_test_loss = 0.954866
[lr=0.001, bs=2048, dr=0.15] -> best_test_loss = 0.957657
[lr=0.001, bs=2048, dr=0.2] -> best_test_loss = 0.959085
[lr=0.001, bs=2048, dr=0.25] -> best_test_loss = 0.963452
[lr=0.001, bs=2048, dr=0.3] -> best_test_loss = 0.966639
[lr=0.001, bs=4096, dr=0.1] -> best_test_loss = 0.951171
[lr=0.001, bs=4096, dr=0.15] -> best_test_loss = 0.951865
[lr=0.001, bs=4096, dr=0.2] -> best_test_loss = 0.955320
[lr=0.001, bs=4096, dr=0.25] -> best_test_loss = 0.955791
[lr=0.001, bs=4096, dr=0.3] -> best_test_loss = 0.957627
[lr=0.0005, bs=512, dr=0.1] -> best_test_loss = 0.959614
[lr=0.0005, bs=512, dr=0.15] -> best_test_loss = 0.963075
[lr=0.0005, bs=512, dr=0.2] -> best_test_loss = 0.966651
[lr=0.0005, bs=512, dr=0.25] -> best_test_loss = 0.970637
[lr=0.0005, bs=512, dr=0.3] -> best_test_loss = 0.974070
[lr=0.0005, bs=1024, dr=0.1] -> best_test_loss = 0.957632
[lr=0.0005, bs=1024, dr=0.15] -> best_test_loss = 0.960644
[lr=0.0005, bs=1024, dr=0.2] -> best_test_loss = 0.964825
[lr=0.0005, bs=1024, dr=0.25] -> best_test_loss = 0.967174
[lr=0.0005, bs=1024, dr=0.3] -> best_test_loss = 0.972010
[lr=0.0005, bs=2048, dr=0.1] -> best_test_loss = 0.959240
[lr=0.0005, bs=2048, dr=0.15] -> best_test_loss = 0.960885
[lr=0.0005, bs=2048, dr=0.2] -> best_test_loss = 0.965055
[lr=0.0005, bs=2048, dr=0.25] -> best_test_loss = 0.969806
[lr=0.0005, bs=2048, dr=0.3] -> best_test_loss = 0.973426
[lr=0.0005, bs=4096, dr=0.1] -> best_test_loss = 0.956416
[lr=0.0005, bs=4096, dr=0.15] -> best_test_loss = 0.956226
[lr=0.0005, bs=4096, dr=0.2] -> best_test_loss = 0.958942
[lr=0.0005, bs=4096, dr=0.25] -> best_test_loss = 0.962034
[lr=0.0005, bs=4096, dr=0.3] -> best_test_loss = 0.964618
[lr=0.0001, bs=512, dr=0.1] -> best_test_loss = 0.973219
[lr=0.0001, bs=512, dr=0.15] -> best_test_loss = 0.975747
[lr=0.0001, bs=512, dr=0.2] -> best_test_loss = 0.977979
[lr=0.0001, bs=512, dr=0.25] -> best_test_loss = 0.980738
[lr=0.0001, bs=512, dr=0.3] -> best_test_loss = 0.982165
[lr=0.0001, bs=1024, dr=0.1] -> best_test_loss = 0.972284
[lr=0.0001, bs=1024, dr=0.15] -> best_test_loss = 0.974360
[lr=0.0001, bs=1024, dr=0.2] -> best_test_loss = 0.976082
[lr=0.0001, bs=1024, dr=0.25] -> best_test_loss = 0.978101
[lr=0.0001, bs=1024, dr=0.3] -> best_test_loss = 0.979258
[lr=0.0001, bs=2048, dr=0.1] -> best_test_loss = 0.972507
[lr=0.0001, bs=2048, dr=0.15] -> best_test_loss = 0.975455
[lr=0.0001, bs=2048, dr=0.2] -> best_test_loss = 0.978230
[lr=0.0001, bs=2048, dr=0.25] -> best_test_loss = 0.979892
[lr=0.0001, bs=2048, dr=0.3] -> best_test_loss = 0.981763
[lr=0.0001, bs=4096, dr=0.1] -> best_test_loss = 0.965315
[lr=0.0001, bs=4096, dr=0.15] -> best_test_loss = 0.969049
[lr=0.0001, bs=4096, dr=0.2] -> best_test_loss = 0.971969
[lr=0.0001, bs=4096, dr=0.25] -> best_test_loss = 0.975504
[lr=0.0001, bs=4096, dr=0.3] -> best_test_loss = 0.977903
Best parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1} with Test Loss: 0.9446789332195721
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mrandom_prune0.6_lr0.01_bs1024_dr0.1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air-quality/runs/1hzbao71[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250122_172702-1hzbao71/logs[0m
Starting hyperparameter optimization...
[lr=0.05, bs=512, dr=0.1] -> best_test_loss = 0.964302
[lr=0.05, bs=512, dr=0.15] -> best_test_loss = 0.963700
[lr=0.05, bs=512, dr=0.2] -> best_test_loss = 0.972161
[lr=0.05, bs=512, dr=0.25] -> best_test_loss = 0.973100
[lr=0.05, bs=512, dr=0.3] -> best_test_loss = 0.973748
[lr=0.05, bs=1024, dr=0.1] -> best_test_loss = 0.956192
[lr=0.05, bs=1024, dr=0.15] -> best_test_loss = 0.955402
[lr=0.05, bs=1024, dr=0.2] -> best_test_loss = 0.958502
[lr=0.05, bs=1024, dr=0.25] -> best_test_loss = 0.968253
[lr=0.05, bs=1024, dr=0.3] -> best_test_loss = 0.963809
[lr=0.05, bs=2048, dr=0.1] -> best_test_loss = 0.957764
[lr=0.05, bs=2048, dr=0.15] -> best_test_loss = 0.955605
[lr=0.05, bs=2048, dr=0.2] -> best_test_loss = 0.958240
[lr=0.05, bs=2048, dr=0.25] -> best_test_loss = 0.958081
[lr=0.05, bs=2048, dr=0.3] -> best_test_loss = 0.964287
[lr=0.05, bs=4096, dr=0.1] -> best_test_loss = 0.957933
[lr=0.05, bs=4096, dr=0.15] -> best_test_loss = 0.955927
[lr=0.05, bs=4096, dr=0.2] -> best_test_loss = 0.963744
[lr=0.05, bs=4096, dr=0.25] -> best_test_loss = 0.962573
[lr=0.05, bs=4096, dr=0.3] -> best_test_loss = 0.967580
[lr=0.01, bs=512, dr=0.1] -> best_test_loss = 0.959597
[lr=0.01, bs=512, dr=0.15] -> best_test_loss = 0.960715
[lr=0.01, bs=512, dr=0.2] -> best_test_loss = 0.962182
[lr=0.01, bs=512, dr=0.25] -> best_test_loss = 0.965257
[lr=0.01, bs=512, dr=0.3] -> best_test_loss = 0.968695
[lr=0.01, bs=1024, dr=0.1] -> best_test_loss = 0.954195
[lr=0.01, bs=1024, dr=0.15] -> best_test_loss = 0.953683
[lr=0.01, bs=1024, dr=0.2] -> best_test_loss = 0.954974
[lr=0.01, bs=1024, dr=0.25] -> best_test_loss = 0.959929
[lr=0.01, bs=1024, dr=0.3] -> best_test_loss = 0.961956
[lr=0.01, bs=2048, dr=0.1] -> best_test_loss = 0.948865
[lr=0.01, bs=2048, dr=0.15] -> best_test_loss = 0.951047
[lr=0.01, bs=2048, dr=0.2] -> best_test_loss = 0.952396
[lr=0.01, bs=2048, dr=0.25] -> best_test_loss = 0.956323
[lr=0.01, bs=2048, dr=0.3] -> best_test_loss = 0.956867
[lr=0.01, bs=4096, dr=0.1] -> best_test_loss = 0.955323
[lr=0.01, bs=4096, dr=0.15] -> best_test_loss = 0.952662
[lr=0.01, bs=4096, dr=0.2] -> best_test_loss = 0.952785
[lr=0.01, bs=4096, dr=0.25] -> best_test_loss = 0.955184
[lr=0.01, bs=4096, dr=0.3] -> best_test_loss = 0.958159
[lr=0.005, bs=512, dr=0.1] -> best_test_loss = 0.957229
[lr=0.005, bs=512, dr=0.15] -> best_test_loss = 0.958147
[lr=0.005, bs=512, dr=0.2] -> best_test_loss = 0.956742
[lr=0.005, bs=512, dr=0.25] -> best_test_loss = 0.965082
[lr=0.005, bs=512, dr=0.3] -> best_test_loss = 0.967037
[lr=0.005, bs=1024, dr=0.1] -> best_test_loss = 0.953941
[lr=0.005, bs=1024, dr=0.15] -> best_test_loss = 0.953345
[lr=0.005, bs=1024, dr=0.2] -> best_test_loss = 0.954860
[lr=0.005, bs=1024, dr=0.25] -> best_test_loss = 0.955502
[lr=0.005, bs=1024, dr=0.3] -> best_test_loss = 0.958971
[lr=0.005, bs=2048, dr=0.1] -> best_test_loss = 0.951171
[lr=0.005, bs=2048, dr=0.15] -> best_test_loss = 0.949752
[lr=0.005, bs=2048, dr=0.2] -> best_test_loss = 0.955025
[lr=0.005, bs=2048, dr=0.25] -> best_test_loss = 0.953150
[lr=0.005, bs=2048, dr=0.3] -> best_test_loss = 0.958406
[lr=0.005, bs=4096, dr=0.1] -> best_test_loss = 0.953197
[lr=0.005, bs=4096, dr=0.15] -> best_test_loss = 0.950892
[lr=0.005, bs=4096, dr=0.2] -> best_test_loss = 0.952347
[lr=0.005, bs=4096, dr=0.25] -> best_test_loss = 0.957417
[lr=0.005, bs=4096, dr=0.3] -> best_test_loss = 0.958060
[lr=0.001, bs=512, dr=0.1] -> best_test_loss = 0.959103
[lr=0.001, bs=512, dr=0.15] -> best_test_loss = 0.962527
[lr=0.001, bs=512, dr=0.2] -> best_test_loss = 0.966950
[lr=0.001, bs=512, dr=0.25] -> best_test_loss = 0.971057
[lr=0.001, bs=512, dr=0.3] -> best_test_loss = 0.974340
[lr=0.001, bs=1024, dr=0.1] -> best_test_loss = 0.956748
[lr=0.001, bs=1024, dr=0.15] -> best_test_loss = 0.959114
[lr=0.001, bs=1024, dr=0.2] -> best_test_loss = 0.962403
[lr=0.001, bs=1024, dr=0.25] -> best_test_loss = 0.966695
[lr=0.001, bs=1024, dr=0.3] -> best_test_loss = 0.968777
[lr=0.001, bs=2048, dr=0.1] -> best_test_loss = 0.955094
[lr=0.001, bs=2048, dr=0.15] -> best_test_loss = 0.957193
[lr=0.001, bs=2048, dr=0.2] -> best_test_loss = 0.959046
[lr=0.001, bs=2048, dr=0.25] -> best_test_loss = 0.962972
[lr=0.001, bs=2048, dr=0.3] -> best_test_loss = 0.966201
[lr=0.001, bs=4096, dr=0.1] -> best_test_loss = 0.955505
[lr=0.001, bs=4096, dr=0.15] -> best_test_loss = 0.958124
[lr=0.001, bs=4096, dr=0.2] -> best_test_loss = 0.961634
[lr=0.001, bs=4096, dr=0.25] -> best_test_loss = 0.965215
[lr=0.001, bs=4096, dr=0.3] -> best_test_loss = 0.967895
[lr=0.0005, bs=512, dr=0.1] -> best_test_loss = 0.962246
[lr=0.0005, bs=512, dr=0.15] -> best_test_loss = 0.967654
[lr=0.0005, bs=512, dr=0.2] -> best_test_loss = 0.972807
[lr=0.0005, bs=512, dr=0.25] -> best_test_loss = 0.977329
[lr=0.0005, bs=512, dr=0.3] -> best_test_loss = 0.981298
[lr=0.0005, bs=1024, dr=0.1] -> best_test_loss = 0.960864
[lr=0.0005, bs=1024, dr=0.15] -> best_test_loss = 0.965141
[lr=0.0005, bs=1024, dr=0.2] -> best_test_loss = 0.968681
[lr=0.0005, bs=1024, dr=0.25] -> best_test_loss = 0.972739
[lr=0.0005, bs=1024, dr=0.3] -> best_test_loss = 0.976230
[lr=0.0005, bs=2048, dr=0.1] -> best_test_loss = 0.959234
[lr=0.0005, bs=2048, dr=0.15] -> best_test_loss = 0.961771
[lr=0.0005, bs=2048, dr=0.2] -> best_test_loss = 0.965504
[lr=0.0005, bs=2048, dr=0.25] -> best_test_loss = 0.968955
[lr=0.0005, bs=2048, dr=0.3] -> best_test_loss = 0.972871
[lr=0.0005, bs=4096, dr=0.1] -> best_test_loss = 0.958416
[lr=0.0005, bs=4096, dr=0.15] -> best_test_loss = 0.962854
[lr=0.0005, bs=4096, dr=0.2] -> best_test_loss = 0.967327
[lr=0.0005, bs=4096, dr=0.25] -> best_test_loss = 0.971983
[lr=0.0005, bs=4096, dr=0.3] -> best_test_loss = 0.975135
[lr=0.0001, bs=512, dr=0.1] -> best_test_loss = 0.977370
[lr=0.0001, bs=512, dr=0.15] -> best_test_loss = 0.979681
[lr=0.0001, bs=512, dr=0.2] -> best_test_loss = 0.982587
[lr=0.0001, bs=512, dr=0.25] -> best_test_loss = 0.984690
[lr=0.0001, bs=512, dr=0.3] -> best_test_loss = 0.985921
[lr=0.0001, bs=1024, dr=0.1] -> best_test_loss = 0.974918
[lr=0.0001, bs=1024, dr=0.15] -> best_test_loss = 0.977914
[lr=0.0001, bs=1024, dr=0.2] -> best_test_loss = 0.980426
[lr=0.0001, bs=1024, dr=0.25] -> best_test_loss = 0.982866
[lr=0.0001, bs=1024, dr=0.3] -> best_test_loss = 0.984180
[lr=0.0001, bs=2048, dr=0.1] -> best_test_loss = 0.972662
[lr=0.0001, bs=2048, dr=0.15] -> best_test_loss = 0.974939
[lr=0.0001, bs=2048, dr=0.2] -> best_test_loss = 0.977549
[lr=0.0001, bs=2048, dr=0.25] -> best_test_loss = 0.979144
[lr=0.0001, bs=2048, dr=0.3] -> best_test_loss = 0.981481
[lr=0.0001, bs=4096, dr=0.1] -> best_test_loss = 0.973492
[lr=0.0001, bs=4096, dr=0.15] -> best_test_loss = 0.975419
[lr=0.0001, bs=4096, dr=0.2] -> best_test_loss = 0.978565
[lr=0.0001, bs=4096, dr=0.25] -> best_test_loss = 0.981439
[lr=0.0001, bs=4096, dr=0.3] -> best_test_loss = 0.983879
Best parameters: {'learning_rate': 0.01, 'batch_size': 2048, 'dropout_rate': 0.1} with Test Loss: 0.9488649075334782
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mrandom_prune0.2_lr0.01_bs2048_dr0.1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air-quality/runs/bypflrhn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250122_172801-bypflrhn/logs[0m
Starting hyperparameter optimization...
[lr=0.05, bs=512, dr=0.1] -> best_test_loss = 0.960602
[lr=0.05, bs=512, dr=0.15] -> best_test_loss = 0.962493
[lr=0.05, bs=512, dr=0.2] -> best_test_loss = 0.963121
[lr=0.05, bs=512, dr=0.25] -> best_test_loss = 0.965265
[lr=0.05, bs=512, dr=0.3] -> best_test_loss = 0.964372
[lr=0.05, bs=1024, dr=0.1] -> best_test_loss = 0.957127
[lr=0.05, bs=1024, dr=0.15] -> best_test_loss = 0.959612
[lr=0.05, bs=1024, dr=0.2] -> best_test_loss = 0.962156
[lr=0.05, bs=1024, dr=0.25] -> best_test_loss = 0.962887
[lr=0.05, bs=1024, dr=0.3] -> best_test_loss = 0.964314
[lr=0.05, bs=2048, dr=0.1] -> best_test_loss = 0.962931
[lr=0.05, bs=2048, dr=0.15] -> best_test_loss = 0.959795
[lr=0.05, bs=2048, dr=0.2] -> best_test_loss = 0.962677
[lr=0.05, bs=2048, dr=0.25] -> best_test_loss = 0.962936
[lr=0.05, bs=2048, dr=0.3] -> best_test_loss = 0.961813
[lr=0.05, bs=4096, dr=0.1] -> best_test_loss = 0.962931
[lr=0.05, bs=4096, dr=0.15] -> best_test_loss = 0.959795
[lr=0.05, bs=4096, dr=0.2] -> best_test_loss = 0.962677
[lr=0.05, bs=4096, dr=0.25] -> best_test_loss = 0.962936
[lr=0.05, bs=4096, dr=0.3] -> best_test_loss = 0.961813
[lr=0.01, bs=512, dr=0.1] -> best_test_loss = 0.957886
[lr=0.01, bs=512, dr=0.15] -> best_test_loss = 0.958648
[lr=0.01, bs=512, dr=0.2] -> best_test_loss = 0.956652
[lr=0.01, bs=512, dr=0.25] -> best_test_loss = 0.961651
[lr=0.01, bs=512, dr=0.3] -> best_test_loss = 0.964280
[lr=0.01, bs=1024, dr=0.1] -> best_test_loss = 0.958046
[lr=0.01, bs=1024, dr=0.15] -> best_test_loss = 0.957900
[lr=0.01, bs=1024, dr=0.2] -> best_test_loss = 0.961004
[lr=0.01, bs=1024, dr=0.25] -> best_test_loss = 0.962476
[lr=0.01, bs=1024, dr=0.3] -> best_test_loss = 0.961423
[lr=0.01, bs=2048, dr=0.1] -> best_test_loss = 0.955562
[lr=0.01, bs=2048, dr=0.15] -> best_test_loss = 0.956901
[lr=0.01, bs=2048, dr=0.2] -> best_test_loss = 0.959553
[lr=0.01, bs=2048, dr=0.25] -> best_test_loss = 0.959141
[lr=0.01, bs=2048, dr=0.3] -> best_test_loss = 0.963892
[lr=0.01, bs=4096, dr=0.1] -> best_test_loss = 0.955562
[lr=0.01, bs=4096, dr=0.15] -> best_test_loss = 0.956901
[lr=0.01, bs=4096, dr=0.2] -> best_test_loss = 0.959553
[lr=0.01, bs=4096, dr=0.25] -> best_test_loss = 0.959141
[lr=0.01, bs=4096, dr=0.3] -> best_test_loss = 0.963892
[lr=0.005, bs=512, dr=0.1] -> best_test_loss = 0.956223
[lr=0.005, bs=512, dr=0.15] -> best_test_loss = 0.957979
[lr=0.005, bs=512, dr=0.2] -> best_test_loss = 0.956004
[lr=0.005, bs=512, dr=0.25] -> best_test_loss = 0.957510
[lr=0.005, bs=512, dr=0.3] -> best_test_loss = 0.959359
[lr=0.005, bs=1024, dr=0.1] -> best_test_loss = 0.961005
[lr=0.005, bs=1024, dr=0.15] -> best_test_loss = 0.961836
[lr=0.005, bs=1024, dr=0.2] -> best_test_loss = 0.960080
[lr=0.005, bs=1024, dr=0.25] -> best_test_loss = 0.958269
[lr=0.005, bs=1024, dr=0.3] -> best_test_loss = 0.959898
[lr=0.005, bs=2048, dr=0.1] -> best_test_loss = 0.957286
[lr=0.005, bs=2048, dr=0.15] -> best_test_loss = 0.959260
[lr=0.005, bs=2048, dr=0.2] -> best_test_loss = 0.957270
[lr=0.005, bs=2048, dr=0.25] -> best_test_loss = 0.959786
[lr=0.005, bs=2048, dr=0.3] -> best_test_loss = 0.960115
[lr=0.005, bs=4096, dr=0.1] -> best_test_loss = 0.957286
[lr=0.005, bs=4096, dr=0.15] -> best_test_loss = 0.959260
[lr=0.005, bs=4096, dr=0.2] -> best_test_loss = 0.957270
[lr=0.005, bs=4096, dr=0.25] -> best_test_loss = 0.959786
[lr=0.005, bs=4096, dr=0.3] -> best_test_loss = 0.960115
[lr=0.001, bs=512, dr=0.1] -> best_test_loss = 0.963975
[lr=0.001, bs=512, dr=0.15] -> best_test_loss = 0.962266
[lr=0.001, bs=512, dr=0.2] -> best_test_loss = 0.964407
[lr=0.001, bs=512, dr=0.25] -> best_test_loss = 0.968284
[lr=0.001, bs=512, dr=0.3] -> best_test_loss = 0.968624
[lr=0.001, bs=1024, dr=0.1] -> best_test_loss = 0.957480
[lr=0.001, bs=1024, dr=0.15] -> best_test_loss = 0.962215
[lr=0.001, bs=1024, dr=0.2] -> best_test_loss = 0.961701
[lr=0.001, bs=1024, dr=0.25] -> best_test_loss = 0.963156
[lr=0.001, bs=1024, dr=0.3] -> best_test_loss = 0.965622
[lr=0.001, bs=2048, dr=0.1] -> best_test_loss = 0.960262
[lr=0.001, bs=2048, dr=0.15] -> best_test_loss = 0.960960
[lr=0.001, bs=2048, dr=0.2] -> best_test_loss = 0.960578
[lr=0.001, bs=2048, dr=0.25] -> best_test_loss = 0.957400
[lr=0.001, bs=2048, dr=0.3] -> best_test_loss = 0.960426
[lr=0.001, bs=4096, dr=0.1] -> best_test_loss = 0.960262
[lr=0.001, bs=4096, dr=0.15] -> best_test_loss = 0.960960
[lr=0.001, bs=4096, dr=0.2] -> best_test_loss = 0.960578
[lr=0.001, bs=4096, dr=0.25] -> best_test_loss = 0.957400
[lr=0.001, bs=4096, dr=0.3] -> best_test_loss = 0.960426
[lr=0.0005, bs=512, dr=0.1] -> best_test_loss = 0.961996
[lr=0.0005, bs=512, dr=0.15] -> best_test_loss = 0.963937
[lr=0.0005, bs=512, dr=0.2] -> best_test_loss = 0.967763
[lr=0.0005, bs=512, dr=0.25] -> best_test_loss = 0.971290
[lr=0.0005, bs=512, dr=0.3] -> best_test_loss = 0.975061
[lr=0.0005, bs=1024, dr=0.1] -> best_test_loss = 0.959064
[lr=0.0005, bs=1024, dr=0.15] -> best_test_loss = 0.964272
[lr=0.0005, bs=1024, dr=0.2] -> best_test_loss = 0.967015
[lr=0.0005, bs=1024, dr=0.25] -> best_test_loss = 0.968084
[lr=0.0005, bs=1024, dr=0.3] -> best_test_loss = 0.969787
[lr=0.0005, bs=2048, dr=0.1] -> best_test_loss = 0.960113
[lr=0.0005, bs=2048, dr=0.15] -> best_test_loss = 0.964110
[lr=0.0005, bs=2048, dr=0.2] -> best_test_loss = 0.963550
[lr=0.0005, bs=2048, dr=0.25] -> best_test_loss = 0.964549
[lr=0.0005, bs=2048, dr=0.3] -> best_test_loss = 0.966758
[lr=0.0005, bs=4096, dr=0.1] -> best_test_loss = 0.960113
[lr=0.0005, bs=4096, dr=0.15] -> best_test_loss = 0.964110
[lr=0.0005, bs=4096, dr=0.2] -> best_test_loss = 0.963550
[lr=0.0005, bs=4096, dr=0.25] -> best_test_loss = 0.964549
[lr=0.0005, bs=4096, dr=0.3] -> best_test_loss = 0.966758
[lr=0.0001, bs=512, dr=0.1] -> best_test_loss = 0.974042
[lr=0.0001, bs=512, dr=0.15] -> best_test_loss = 0.975672
[lr=0.0001, bs=512, dr=0.2] -> best_test_loss = 0.978379
[lr=0.0001, bs=512, dr=0.25] -> best_test_loss = 0.979493
[lr=0.0001, bs=512, dr=0.3] -> best_test_loss = 0.980907
[lr=0.0001, bs=1024, dr=0.1] -> best_test_loss = 0.971133
[lr=0.0001, bs=1024, dr=0.15] -> best_test_loss = 0.972528
[lr=0.0001, bs=1024, dr=0.2] -> best_test_loss = 0.975337
[lr=0.0001, bs=1024, dr=0.25] -> best_test_loss = 0.977479
[lr=0.0001, bs=1024, dr=0.3] -> best_test_loss = 0.979623
[lr=0.0001, bs=2048, dr=0.1] -> best_test_loss = 0.967671
[lr=0.0001, bs=2048, dr=0.15] -> best_test_loss = 0.969317
[lr=0.0001, bs=2048, dr=0.2] -> best_test_loss = 0.972496
[lr=0.0001, bs=2048, dr=0.25] -> best_test_loss = 0.975478
[lr=0.0001, bs=2048, dr=0.3] -> best_test_loss = 0.977629
[lr=0.0001, bs=4096, dr=0.1] -> best_test_loss = 0.967671
[lr=0.0001, bs=4096, dr=0.15] -> best_test_loss = 0.969317
[lr=0.0001, bs=4096, dr=0.2] -> best_test_loss = 0.972496
[lr=0.0001, bs=4096, dr=0.25] -> best_test_loss = 0.975478
[lr=0.0001, bs=4096, dr=0.3] -> best_test_loss = 0.977629
Best parameters: {'learning_rate': 0.01, 'batch_size': 2048, 'dropout_rate': 0.1} with Test Loss: 0.9555615231729512
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mrandom_prune0.7_lr0.01_bs2048_dr0.1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air-quality/runs/lzod81a3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250122_172646-lzod81a3/logs[0m
Starting hyperparameter optimization...
[lr=0.05, bs=512, dr=0.1] -> best_test_loss = 0.959553
[lr=0.05, bs=512, dr=0.15] -> best_test_loss = 0.968611
[lr=0.05, bs=512, dr=0.2] -> best_test_loss = 0.969009
[lr=0.05, bs=512, dr=0.25] -> best_test_loss = 0.963028
[lr=0.05, bs=512, dr=0.3] -> best_test_loss = 0.970563
[lr=0.05, bs=1024, dr=0.1] -> best_test_loss = 0.960632
[lr=0.05, bs=1024, dr=0.15] -> best_test_loss = 0.967295
[lr=0.05, bs=1024, dr=0.2] -> best_test_loss = 0.970009
[lr=0.05, bs=1024, dr=0.25] -> best_test_loss = 0.970260
[lr=0.05, bs=1024, dr=0.3] -> best_test_loss = 0.974316
[lr=0.05, bs=2048, dr=0.1] -> best_test_loss = 0.949419
[lr=0.05, bs=2048, dr=0.15] -> best_test_loss = 0.953079
[lr=0.05, bs=2048, dr=0.2] -> best_test_loss = 0.954790
[lr=0.05, bs=2048, dr=0.25] -> best_test_loss = 0.960031
[lr=0.05, bs=2048, dr=0.3] -> best_test_loss = 0.956981
[lr=0.05, bs=4096, dr=0.1] -> best_test_loss = 0.954308
[lr=0.05, bs=4096, dr=0.15] -> best_test_loss = 0.951638
[lr=0.05, bs=4096, dr=0.2] -> best_test_loss = 0.956629
[lr=0.05, bs=4096, dr=0.25] -> best_test_loss = 0.958913
[lr=0.05, bs=4096, dr=0.3] -> best_test_loss = 0.963343
[lr=0.01, bs=512, dr=0.1] -> best_test_loss = 0.958498
[lr=0.01, bs=512, dr=0.15] -> best_test_loss = 0.959695
[lr=0.01, bs=512, dr=0.2] -> best_test_loss = 0.959185
[lr=0.01, bs=512, dr=0.25] -> best_test_loss = 0.958311
[lr=0.01, bs=512, dr=0.3] -> best_test_loss = 0.960037
[lr=0.01, bs=1024, dr=0.1] -> best_test_loss = 0.959681
[lr=0.01, bs=1024, dr=0.15] -> best_test_loss = 0.962423
[lr=0.01, bs=1024, dr=0.2] -> best_test_loss = 0.961032
[lr=0.01, bs=1024, dr=0.25] -> best_test_loss = 0.959264
[lr=0.01, bs=1024, dr=0.3] -> best_test_loss = 0.965101
[lr=0.01, bs=2048, dr=0.1] -> best_test_loss = 0.951159
[lr=0.01, bs=2048, dr=0.15] -> best_test_loss = 0.951752
[lr=0.01, bs=2048, dr=0.2] -> best_test_loss = 0.950846
[lr=0.01, bs=2048, dr=0.25] -> best_test_loss = 0.954703
[lr=0.01, bs=2048, dr=0.3] -> best_test_loss = 0.954837
[lr=0.01, bs=4096, dr=0.1] -> best_test_loss = 0.950995
[lr=0.01, bs=4096, dr=0.15] -> best_test_loss = 0.950060
[lr=0.01, bs=4096, dr=0.2] -> best_test_loss = 0.954042
[lr=0.01, bs=4096, dr=0.25] -> best_test_loss = 0.954152
[lr=0.01, bs=4096, dr=0.3] -> best_test_loss = 0.960267
[lr=0.005, bs=512, dr=0.1] -> best_test_loss = 0.954422
[lr=0.005, bs=512, dr=0.15] -> best_test_loss = 0.955048
[lr=0.005, bs=512, dr=0.2] -> best_test_loss = 0.957977
[lr=0.005, bs=512, dr=0.25] -> best_test_loss = 0.956546
[lr=0.005, bs=512, dr=0.3] -> best_test_loss = 0.959192
[lr=0.005, bs=1024, dr=0.1] -> best_test_loss = 0.957389
[lr=0.005, bs=1024, dr=0.15] -> best_test_loss = 0.957987
[lr=0.005, bs=1024, dr=0.2] -> best_test_loss = 0.958245
[lr=0.005, bs=1024, dr=0.25] -> best_test_loss = 0.958920
[lr=0.005, bs=1024, dr=0.3] -> best_test_loss = 0.962126
[lr=0.005, bs=2048, dr=0.1] -> best_test_loss = 0.952320
[lr=0.005, bs=2048, dr=0.15] -> best_test_loss = 0.951209
[lr=0.005, bs=2048, dr=0.2] -> best_test_loss = 0.953191
[lr=0.005, bs=2048, dr=0.25] -> best_test_loss = 0.954587
[lr=0.005, bs=2048, dr=0.3] -> best_test_loss = 0.954797
[lr=0.005, bs=4096, dr=0.1] -> best_test_loss = 0.950603
[lr=0.005, bs=4096, dr=0.15] -> best_test_loss = 0.950357
[lr=0.005, bs=4096, dr=0.2] -> best_test_loss = 0.953533
[lr=0.005, bs=4096, dr=0.25] -> best_test_loss = 0.954612
[lr=0.005, bs=4096, dr=0.3] -> best_test_loss = 0.955169
[lr=0.001, bs=512, dr=0.1] -> best_test_loss = 0.956351
[lr=0.001, bs=512, dr=0.15] -> best_test_loss = 0.958170
[lr=0.001, bs=512, dr=0.2] -> best_test_loss = 0.960455
[lr=0.001, bs=512, dr=0.25] -> best_test_loss = 0.963106
[lr=0.001, bs=512, dr=0.3] -> best_test_loss = 0.967101
[lr=0.001, bs=1024, dr=0.1] -> best_test_loss = 0.961150
[lr=0.001, bs=1024, dr=0.15] -> best_test_loss = 0.962148
[lr=0.001, bs=1024, dr=0.2] -> best_test_loss = 0.966932
[lr=0.001, bs=1024, dr=0.25] -> best_test_loss = 0.969248
[lr=0.001, bs=1024, dr=0.3] -> best_test_loss = 0.972123
[lr=0.001, bs=2048, dr=0.1] -> best_test_loss = 0.955933
[lr=0.001, bs=2048, dr=0.15] -> best_test_loss = 0.957630
[lr=0.001, bs=2048, dr=0.2] -> best_test_loss = 0.961618
[lr=0.001, bs=2048, dr=0.25] -> best_test_loss = 0.962534
[lr=0.001, bs=2048, dr=0.3] -> best_test_loss = 0.964975
[lr=0.001, bs=4096, dr=0.1] -> best_test_loss = 0.955280
[lr=0.001, bs=4096, dr=0.15] -> best_test_loss = 0.958680
[lr=0.001, bs=4096, dr=0.2] -> best_test_loss = 0.961516
[lr=0.001, bs=4096, dr=0.25] -> best_test_loss = 0.966437
[lr=0.001, bs=4096, dr=0.3] -> best_test_loss = 0.969523
[lr=0.0005, bs=512, dr=0.1] -> best_test_loss = 0.960142
[lr=0.0005, bs=512, dr=0.15] -> best_test_loss = 0.961711
[lr=0.0005, bs=512, dr=0.2] -> best_test_loss = 0.966189
[lr=0.0005, bs=512, dr=0.25] -> best_test_loss = 0.968906
[lr=0.0005, bs=512, dr=0.3] -> best_test_loss = 0.972071
[lr=0.0005, bs=1024, dr=0.1] -> best_test_loss = 0.964097
[lr=0.0005, bs=1024, dr=0.15] -> best_test_loss = 0.967294
[lr=0.0005, bs=1024, dr=0.2] -> best_test_loss = 0.971616
[lr=0.0005, bs=1024, dr=0.25] -> best_test_loss = 0.975514
[lr=0.0005, bs=1024, dr=0.3] -> best_test_loss = 0.978854
[lr=0.0005, bs=2048, dr=0.1] -> best_test_loss = 0.959728
[lr=0.0005, bs=2048, dr=0.15] -> best_test_loss = 0.964858
[lr=0.0005, bs=2048, dr=0.2] -> best_test_loss = 0.968144
[lr=0.0005, bs=2048, dr=0.25] -> best_test_loss = 0.970583
[lr=0.0005, bs=2048, dr=0.3] -> best_test_loss = 0.974436
[lr=0.0005, bs=4096, dr=0.1] -> best_test_loss = 0.959331
[lr=0.0005, bs=4096, dr=0.15] -> best_test_loss = 0.963568
[lr=0.0005, bs=4096, dr=0.2] -> best_test_loss = 0.968745
[lr=0.0005, bs=4096, dr=0.25] -> best_test_loss = 0.971718
[lr=0.0005, bs=4096, dr=0.3] -> best_test_loss = 0.975236
[lr=0.0001, bs=512, dr=0.1] -> best_test_loss = 0.973793
[lr=0.0001, bs=512, dr=0.15] -> best_test_loss = 0.975956
[lr=0.0001, bs=512, dr=0.2] -> best_test_loss = 0.977292
[lr=0.0001, bs=512, dr=0.25] -> best_test_loss = 0.979040
[lr=0.0001, bs=512, dr=0.3] -> best_test_loss = 0.980687
[lr=0.0001, bs=1024, dr=0.1] -> best_test_loss = 0.977014
[lr=0.0001, bs=1024, dr=0.15] -> best_test_loss = 0.978945
[lr=0.0001, bs=1024, dr=0.2] -> best_test_loss = 0.980618
[lr=0.0001, bs=1024, dr=0.25] -> best_test_loss = 0.982531
[lr=0.0001, bs=1024, dr=0.3] -> best_test_loss = 0.984145
[lr=0.0001, bs=2048, dr=0.1] -> best_test_loss = 0.973181
[lr=0.0001, bs=2048, dr=0.15] -> best_test_loss = 0.976267
[lr=0.0001, bs=2048, dr=0.2] -> best_test_loss = 0.978970
[lr=0.0001, bs=2048, dr=0.25] -> best_test_loss = 0.980866
[lr=0.0001, bs=2048, dr=0.3] -> best_test_loss = 0.982984
[lr=0.0001, bs=4096, dr=0.1] -> best_test_loss = 0.972891
[lr=0.0001, bs=4096, dr=0.15] -> best_test_loss = 0.976543
[lr=0.0001, bs=4096, dr=0.2] -> best_test_loss = 0.979651
[lr=0.0001, bs=4096, dr=0.25] -> best_test_loss = 0.982530
[lr=0.0001, bs=4096, dr=0.3] -> best_test_loss = 0.984818
Best parameters: {'learning_rate': 0.05, 'batch_size': 2048, 'dropout_rate': 0.1} with Test Loss: 0.9494194319412123
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mrandom_prune0.1_lr0.05_bs2048_dr0.1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air-quality/runs/anz1yzs4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250122_172920-anz1yzs4/logs[0m
Starting hyperparameter optimization...
[lr=0.05, bs=512, dr=0.1] -> best_test_loss = 0.958962
[lr=0.05, bs=512, dr=0.15] -> best_test_loss = 0.958897
[lr=0.05, bs=512, dr=0.2] -> best_test_loss = 0.961237
[lr=0.05, bs=512, dr=0.25] -> best_test_loss = 0.964555
[lr=0.05, bs=512, dr=0.3] -> best_test_loss = 0.966981
[lr=0.05, bs=1024, dr=0.1] -> best_test_loss = 0.949289
[lr=0.05, bs=1024, dr=0.15] -> best_test_loss = 0.955729
[lr=0.05, bs=1024, dr=0.2] -> best_test_loss = 0.956999
[lr=0.05, bs=1024, dr=0.25] -> best_test_loss = 0.955210
[lr=0.05, bs=1024, dr=0.3] -> best_test_loss = 0.956610
[lr=0.05, bs=2048, dr=0.1] -> best_test_loss = 0.952007
[lr=0.05, bs=2048, dr=0.15] -> best_test_loss = 0.955755
[lr=0.05, bs=2048, dr=0.2] -> best_test_loss = 0.957256
[lr=0.05, bs=2048, dr=0.25] -> best_test_loss = 0.958903
[lr=0.05, bs=2048, dr=0.3] -> best_test_loss = 0.959993
[lr=0.05, bs=4096, dr=0.1] -> best_test_loss = 0.951458
[lr=0.05, bs=4096, dr=0.15] -> best_test_loss = 0.950310
[lr=0.05, bs=4096, dr=0.2] -> best_test_loss = 0.955425
[lr=0.05, bs=4096, dr=0.25] -> best_test_loss = 0.956484
[lr=0.05, bs=4096, dr=0.3] -> best_test_loss = 0.952681
[lr=0.01, bs=512, dr=0.1] -> best_test_loss = 0.952287
[lr=0.01, bs=512, dr=0.15] -> best_test_loss = 0.952245
[lr=0.01, bs=512, dr=0.2] -> best_test_loss = 0.955587
[lr=0.01, bs=512, dr=0.25] -> best_test_loss = 0.956961
[lr=0.01, bs=512, dr=0.3] -> best_test_loss = 0.954913
[lr=0.01, bs=1024, dr=0.1] -> best_test_loss = 0.952537
[lr=0.01, bs=1024, dr=0.15] -> best_test_loss = 0.948791
[lr=0.01, bs=1024, dr=0.2] -> best_test_loss = 0.951307
[lr=0.01, bs=1024, dr=0.25] -> best_test_loss = 0.951255
[lr=0.01, bs=1024, dr=0.3] -> best_test_loss = 0.956216
[lr=0.01, bs=2048, dr=0.1] -> best_test_loss = 0.949366
[lr=0.01, bs=2048, dr=0.15] -> best_test_loss = 0.949380
[lr=0.01, bs=2048, dr=0.2] -> best_test_loss = 0.952041
[lr=0.01, bs=2048, dr=0.25] -> best_test_loss = 0.956639
[lr=0.01, bs=2048, dr=0.3] -> best_test_loss = 0.957337
[lr=0.01, bs=4096, dr=0.1] -> best_test_loss = 0.951219
[lr=0.01, bs=4096, dr=0.15] -> best_test_loss = 0.949368
[lr=0.01, bs=4096, dr=0.2] -> best_test_loss = 0.949710
[lr=0.01, bs=4096, dr=0.25] -> best_test_loss = 0.951003
[lr=0.01, bs=4096, dr=0.3] -> best_test_loss = 0.953227
[lr=0.005, bs=512, dr=0.1] -> best_test_loss = 0.950882
[lr=0.005, bs=512, dr=0.15] -> best_test_loss = 0.954884
[lr=0.005, bs=512, dr=0.2] -> best_test_loss = 0.955012
[lr=0.005, bs=512, dr=0.25] -> best_test_loss = 0.957326
[lr=0.005, bs=512, dr=0.3] -> best_test_loss = 0.955581
[lr=0.005, bs=1024, dr=0.1] -> best_test_loss = 0.951476
[lr=0.005, bs=1024, dr=0.15] -> best_test_loss = 0.951784
[lr=0.005, bs=1024, dr=0.2] -> best_test_loss = 0.950635
[lr=0.005, bs=1024, dr=0.25] -> best_test_loss = 0.953800
[lr=0.005, bs=1024, dr=0.3] -> best_test_loss = 0.953433
[lr=0.005, bs=2048, dr=0.1] -> best_test_loss = 0.951824
[lr=0.005, bs=2048, dr=0.15] -> best_test_loss = 0.951347
[lr=0.005, bs=2048, dr=0.2] -> best_test_loss = 0.950100
[lr=0.005, bs=2048, dr=0.25] -> best_test_loss = 0.954074
[lr=0.005, bs=2048, dr=0.3] -> best_test_loss = 0.955861
[lr=0.005, bs=4096, dr=0.1] -> best_test_loss = 0.949097
[lr=0.005, bs=4096, dr=0.15] -> best_test_loss = 0.945948
[lr=0.005, bs=4096, dr=0.2] -> best_test_loss = 0.949787
[lr=0.005, bs=4096, dr=0.25] -> best_test_loss = 0.952837
[lr=0.005, bs=4096, dr=0.3] -> best_test_loss = 0.951831
[lr=0.001, bs=512, dr=0.1] -> best_test_loss = 0.957311
[lr=0.001, bs=512, dr=0.15] -> best_test_loss = 0.958695
[lr=0.001, bs=512, dr=0.2] -> best_test_loss = 0.960906
[lr=0.001, bs=512, dr=0.25] -> best_test_loss = 0.962605
[lr=0.001, bs=512, dr=0.3] -> best_test_loss = 0.967015
[lr=0.001, bs=1024, dr=0.1] -> best_test_loss = 0.953948
[lr=0.001, bs=1024, dr=0.15] -> best_test_loss = 0.954964
[lr=0.001, bs=1024, dr=0.2] -> best_test_loss = 0.958159
[lr=0.001, bs=1024, dr=0.25] -> best_test_loss = 0.961078
[lr=0.001, bs=1024, dr=0.3] -> best_test_loss = 0.963637
[lr=0.001, bs=2048, dr=0.1] -> best_test_loss = 0.953313
[lr=0.001, bs=2048, dr=0.15] -> best_test_loss = 0.954215
[lr=0.001, bs=2048, dr=0.2] -> best_test_loss = 0.956952
[lr=0.001, bs=2048, dr=0.25] -> best_test_loss = 0.958340
[lr=0.001, bs=2048, dr=0.3] -> best_test_loss = 0.960210
[lr=0.001, bs=4096, dr=0.1] -> best_test_loss = 0.951784
[lr=0.001, bs=4096, dr=0.15] -> best_test_loss = 0.952785
[lr=0.001, bs=4096, dr=0.2] -> best_test_loss = 0.953874
[lr=0.001, bs=4096, dr=0.25] -> best_test_loss = 0.956719
[lr=0.001, bs=4096, dr=0.3] -> best_test_loss = 0.958029
[lr=0.0005, bs=512, dr=0.1] -> best_test_loss = 0.959656
[lr=0.0005, bs=512, dr=0.15] -> best_test_loss = 0.962804
[lr=0.0005, bs=512, dr=0.2] -> best_test_loss = 0.966442
[lr=0.0005, bs=512, dr=0.25] -> best_test_loss = 0.969122
[lr=0.0005, bs=512, dr=0.3] -> best_test_loss = 0.972726
[lr=0.0005, bs=1024, dr=0.1] -> best_test_loss = 0.957248
[lr=0.0005, bs=1024, dr=0.15] -> best_test_loss = 0.959090
[lr=0.0005, bs=1024, dr=0.2] -> best_test_loss = 0.961945
[lr=0.0005, bs=1024, dr=0.25] -> best_test_loss = 0.965638
[lr=0.0005, bs=1024, dr=0.3] -> best_test_loss = 0.969847
[lr=0.0005, bs=2048, dr=0.1] -> best_test_loss = 0.955759
[lr=0.0005, bs=2048, dr=0.15] -> best_test_loss = 0.959257
[lr=0.0005, bs=2048, dr=0.2] -> best_test_loss = 0.962736
[lr=0.0005, bs=2048, dr=0.25] -> best_test_loss = 0.965557
[lr=0.0005, bs=2048, dr=0.3] -> best_test_loss = 0.969092
[lr=0.0005, bs=4096, dr=0.1] -> best_test_loss = 0.954910
[lr=0.0005, bs=4096, dr=0.15] -> best_test_loss = 0.956691
[lr=0.0005, bs=4096, dr=0.2] -> best_test_loss = 0.959469
[lr=0.0005, bs=4096, dr=0.25] -> best_test_loss = 0.962119
[lr=0.0005, bs=4096, dr=0.3] -> best_test_loss = 0.964474
[lr=0.0001, bs=512, dr=0.1] -> best_test_loss = 0.972564
[lr=0.0001, bs=512, dr=0.15] -> best_test_loss = 0.974517
[lr=0.0001, bs=512, dr=0.2] -> best_test_loss = 0.976868
[lr=0.0001, bs=512, dr=0.25] -> best_test_loss = 0.978611
[lr=0.0001, bs=512, dr=0.3] -> best_test_loss = 0.980177
[lr=0.0001, bs=1024, dr=0.1] -> best_test_loss = 0.970350
[lr=0.0001, bs=1024, dr=0.15] -> best_test_loss = 0.972531
[lr=0.0001, bs=1024, dr=0.2] -> best_test_loss = 0.975030
[lr=0.0001, bs=1024, dr=0.25] -> best_test_loss = 0.977118
[lr=0.0001, bs=1024, dr=0.3] -> best_test_loss = 0.979806
[lr=0.0001, bs=2048, dr=0.1] -> best_test_loss = 0.970972
[lr=0.0001, bs=2048, dr=0.15] -> best_test_loss = 0.973382
[lr=0.0001, bs=2048, dr=0.2] -> best_test_loss = 0.975517
[lr=0.0001, bs=2048, dr=0.25] -> best_test_loss = 0.978286
[lr=0.0001, bs=2048, dr=0.3] -> best_test_loss = 0.980700
[lr=0.0001, bs=4096, dr=0.1] -> best_test_loss = 0.966332
[lr=0.0001, bs=4096, dr=0.15] -> best_test_loss = 0.969536
[lr=0.0001, bs=4096, dr=0.2] -> best_test_loss = 0.973015
[lr=0.0001, bs=4096, dr=0.25] -> best_test_loss = 0.976525
[lr=0.0001, bs=4096, dr=0.3] -> best_test_loss = 0.979025
Best parameters: {'learning_rate': 0.005, 'batch_size': 4096, 'dropout_rate': 0.15} with Test Loss: 0.9459476976917259
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mrandom_prune0.5_lr0.005_bs4096_dr0.15[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air-quality/runs/n5w1fus6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250122_172951-n5w1fus6/logs[0m
Starting hyperparameter optimization...
[lr=0.05, bs=512, dr=0.1] -> best_test_loss = 0.967501
[lr=0.05, bs=512, dr=0.15] -> best_test_loss = 0.971358
[lr=0.05, bs=512, dr=0.2] -> best_test_loss = 0.969791
[lr=0.05, bs=512, dr=0.25] -> best_test_loss = 0.970739
[lr=0.05, bs=512, dr=0.3] -> best_test_loss = 0.973989
[lr=0.05, bs=1024, dr=0.1] -> best_test_loss = 0.960448
[lr=0.05, bs=1024, dr=0.15] -> best_test_loss = 0.954771
[lr=0.05, bs=1024, dr=0.2] -> best_test_loss = 0.957703
[lr=0.05, bs=1024, dr=0.25] -> best_test_loss = 0.961869
[lr=0.05, bs=1024, dr=0.3] -> best_test_loss = 0.964130
[lr=0.05, bs=2048, dr=0.1] -> best_test_loss = 0.955088
[lr=0.05, bs=2048, dr=0.15] -> best_test_loss = 0.954519
[lr=0.05, bs=2048, dr=0.2] -> best_test_loss = 0.955584
[lr=0.05, bs=2048, dr=0.25] -> best_test_loss = 0.958737
[lr=0.05, bs=2048, dr=0.3] -> best_test_loss = 0.962515
[lr=0.05, bs=4096, dr=0.1] -> best_test_loss = 0.953623
[lr=0.05, bs=4096, dr=0.15] -> best_test_loss = 0.952683
[lr=0.05, bs=4096, dr=0.2] -> best_test_loss = 0.955790
[lr=0.05, bs=4096, dr=0.25] -> best_test_loss = 0.958983
[lr=0.05, bs=4096, dr=0.3] -> best_test_loss = 0.957833
[lr=0.01, bs=512, dr=0.1] -> best_test_loss = 0.956439
[lr=0.01, bs=512, dr=0.15] -> best_test_loss = 0.959444
[lr=0.01, bs=512, dr=0.2] -> best_test_loss = 0.957767
[lr=0.01, bs=512, dr=0.25] -> best_test_loss = 0.964963
[lr=0.01, bs=512, dr=0.3] -> best_test_loss = 0.963903
[lr=0.01, bs=1024, dr=0.1] -> best_test_loss = 0.951289
[lr=0.01, bs=1024, dr=0.15] -> best_test_loss = 0.954116
[lr=0.01, bs=1024, dr=0.2] -> best_test_loss = 0.957428
[lr=0.01, bs=1024, dr=0.25] -> best_test_loss = 0.955024
[lr=0.01, bs=1024, dr=0.3] -> best_test_loss = 0.959789
[lr=0.01, bs=2048, dr=0.1] -> best_test_loss = 0.954329
[lr=0.01, bs=2048, dr=0.15] -> best_test_loss = 0.956042
[lr=0.01, bs=2048, dr=0.2] -> best_test_loss = 0.955098
[lr=0.01, bs=2048, dr=0.25] -> best_test_loss = 0.955191
[lr=0.01, bs=2048, dr=0.3] -> best_test_loss = 0.959438
[lr=0.01, bs=4096, dr=0.1] -> best_test_loss = 0.951017
[lr=0.01, bs=4096, dr=0.15] -> best_test_loss = 0.952989
[lr=0.01, bs=4096, dr=0.2] -> best_test_loss = 0.952172
[lr=0.01, bs=4096, dr=0.25] -> best_test_loss = 0.955811
[lr=0.01, bs=4096, dr=0.3] -> best_test_loss = 0.956928
[lr=0.005, bs=512, dr=0.1] -> best_test_loss = 0.958531
[lr=0.005, bs=512, dr=0.15] -> best_test_loss = 0.957469
[lr=0.005, bs=512, dr=0.2] -> best_test_loss = 0.957478
[lr=0.005, bs=512, dr=0.25] -> best_test_loss = 0.957060
[lr=0.005, bs=512, dr=0.3] -> best_test_loss = 0.960044
[lr=0.005, bs=1024, dr=0.1] -> best_test_loss = 0.954821
[lr=0.005, bs=1024, dr=0.15] -> best_test_loss = 0.954275
[lr=0.005, bs=1024, dr=0.2] -> best_test_loss = 0.957186
[lr=0.005, bs=1024, dr=0.25] -> best_test_loss = 0.958148
[lr=0.005, bs=1024, dr=0.3] -> best_test_loss = 0.962843
[lr=0.005, bs=2048, dr=0.1] -> best_test_loss = 0.952018
[lr=0.005, bs=2048, dr=0.15] -> best_test_loss = 0.955141
[lr=0.005, bs=2048, dr=0.2] -> best_test_loss = 0.956153
[lr=0.005, bs=2048, dr=0.25] -> best_test_loss = 0.954906
[lr=0.005, bs=2048, dr=0.3] -> best_test_loss = 0.957588
[lr=0.005, bs=4096, dr=0.1] -> best_test_loss = 0.952634
[lr=0.005, bs=4096, dr=0.15] -> best_test_loss = 0.951967
[lr=0.005, bs=4096, dr=0.2] -> best_test_loss = 0.949742
[lr=0.005, bs=4096, dr=0.25] -> best_test_loss = 0.952466
[lr=0.005, bs=4096, dr=0.3] -> best_test_loss = 0.954029
[lr=0.001, bs=512, dr=0.1] -> best_test_loss = 0.955963
[lr=0.001, bs=512, dr=0.15] -> best_test_loss = 0.959117
[lr=0.001, bs=512, dr=0.2] -> best_test_loss = 0.963068
[lr=0.001, bs=512, dr=0.25] -> best_test_loss = 0.967066
[lr=0.001, bs=512, dr=0.3] -> best_test_loss = 0.968710
[lr=0.001, bs=1024, dr=0.1] -> best_test_loss = 0.957082
[lr=0.001, bs=1024, dr=0.15] -> best_test_loss = 0.960282
[lr=0.001, bs=1024, dr=0.2] -> best_test_loss = 0.963664
[lr=0.001, bs=1024, dr=0.25] -> best_test_loss = 0.966133
[lr=0.001, bs=1024, dr=0.3] -> best_test_loss = 0.968802
[lr=0.001, bs=2048, dr=0.1] -> best_test_loss = 0.954037
[lr=0.001, bs=2048, dr=0.15] -> best_test_loss = 0.957537
[lr=0.001, bs=2048, dr=0.2] -> best_test_loss = 0.959721
[lr=0.001, bs=2048, dr=0.25] -> best_test_loss = 0.964247
[lr=0.001, bs=2048, dr=0.3] -> best_test_loss = 0.967245
[lr=0.001, bs=4096, dr=0.1] -> best_test_loss = 0.954586
[lr=0.001, bs=4096, dr=0.15] -> best_test_loss = 0.957085
[lr=0.001, bs=4096, dr=0.2] -> best_test_loss = 0.959389
[lr=0.001, bs=4096, dr=0.25] -> best_test_loss = 0.962845
[lr=0.001, bs=4096, dr=0.3] -> best_test_loss = 0.966727
[lr=0.0005, bs=512, dr=0.1] -> best_test_loss = 0.959694
[lr=0.0005, bs=512, dr=0.15] -> best_test_loss = 0.962731
[lr=0.0005, bs=512, dr=0.2] -> best_test_loss = 0.966087
[lr=0.0005, bs=512, dr=0.25] -> best_test_loss = 0.968788
[lr=0.0005, bs=512, dr=0.3] -> best_test_loss = 0.971868
[lr=0.0005, bs=1024, dr=0.1] -> best_test_loss = 0.960078
[lr=0.0005, bs=1024, dr=0.15] -> best_test_loss = 0.966072
[lr=0.0005, bs=1024, dr=0.2] -> best_test_loss = 0.971288
[lr=0.0005, bs=1024, dr=0.25] -> best_test_loss = 0.973642
[lr=0.0005, bs=1024, dr=0.3] -> best_test_loss = 0.977683
[lr=0.0005, bs=2048, dr=0.1] -> best_test_loss = 0.957887
[lr=0.0005, bs=2048, dr=0.15] -> best_test_loss = 0.962594
[lr=0.0005, bs=2048, dr=0.2] -> best_test_loss = 0.965836
[lr=0.0005, bs=2048, dr=0.25] -> best_test_loss = 0.970285
[lr=0.0005, bs=2048, dr=0.3] -> best_test_loss = 0.973912
[lr=0.0005, bs=4096, dr=0.1] -> best_test_loss = 0.958162
[lr=0.0005, bs=4096, dr=0.15] -> best_test_loss = 0.962317
[lr=0.0005, bs=4096, dr=0.2] -> best_test_loss = 0.966011
[lr=0.0005, bs=4096, dr=0.25] -> best_test_loss = 0.969528
[lr=0.0005, bs=4096, dr=0.3] -> best_test_loss = 0.974188
[lr=0.0001, bs=512, dr=0.1] -> best_test_loss = 0.973712
[lr=0.0001, bs=512, dr=0.15] -> best_test_loss = 0.975745
[lr=0.0001, bs=512, dr=0.2] -> best_test_loss = 0.976378
[lr=0.0001, bs=512, dr=0.25] -> best_test_loss = 0.978168
[lr=0.0001, bs=512, dr=0.3] -> best_test_loss = 0.979482
[lr=0.0001, bs=1024, dr=0.1] -> best_test_loss = 0.974853
[lr=0.0001, bs=1024, dr=0.15] -> best_test_loss = 0.976728
[lr=0.0001, bs=1024, dr=0.2] -> best_test_loss = 0.979147
[lr=0.0001, bs=1024, dr=0.25] -> best_test_loss = 0.980911
[lr=0.0001, bs=1024, dr=0.3] -> best_test_loss = 0.982547
[lr=0.0001, bs=2048, dr=0.1] -> best_test_loss = 0.973725
[lr=0.0001, bs=2048, dr=0.15] -> best_test_loss = 0.975722
[lr=0.0001, bs=2048, dr=0.2] -> best_test_loss = 0.978566
[lr=0.0001, bs=2048, dr=0.25] -> best_test_loss = 0.980908
[lr=0.0001, bs=2048, dr=0.3] -> best_test_loss = 0.982971
[lr=0.0001, bs=4096, dr=0.1] -> best_test_loss = 0.972454
[lr=0.0001, bs=4096, dr=0.15] -> best_test_loss = 0.976251
[lr=0.0001, bs=4096, dr=0.2] -> best_test_loss = 0.979792
[lr=0.0001, bs=4096, dr=0.25] -> best_test_loss = 0.982148
[lr=0.0001, bs=4096, dr=0.3] -> best_test_loss = 0.984209
Best parameters: {'learning_rate': 0.005, 'batch_size': 4096, 'dropout_rate': 0.2} with Test Loss: 0.9497418196693094
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mrandom_prune0.0_lr0.005_bs4096_dr0.2[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air-quality/runs/jza3u853[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250122_173030-jza3u853/logs[0m
Starting hyperparameter optimization...
[lr=0.05, bs=512, dr=0.1] -> best_test_loss = 0.964346
[lr=0.05, bs=512, dr=0.15] -> best_test_loss = 0.952987
[lr=0.05, bs=512, dr=0.2] -> best_test_loss = 0.959183
[lr=0.05, bs=512, dr=0.25] -> best_test_loss = 0.965707
[lr=0.05, bs=512, dr=0.3] -> best_test_loss = 0.967902
[lr=0.05, bs=1024, dr=0.1] -> best_test_loss = 0.957244
[lr=0.05, bs=1024, dr=0.15] -> best_test_loss = 0.955821
[lr=0.05, bs=1024, dr=0.2] -> best_test_loss = 0.960772
[lr=0.05, bs=1024, dr=0.25] -> best_test_loss = 0.961251
[lr=0.05, bs=1024, dr=0.3] -> best_test_loss = 0.961026
[lr=0.05, bs=2048, dr=0.1] -> best_test_loss = 0.948244
[lr=0.05, bs=2048, dr=0.15] -> best_test_loss = 0.949401
[lr=0.05, bs=2048, dr=0.2] -> best_test_loss = 0.955209
[lr=0.05, bs=2048, dr=0.25] -> best_test_loss = 0.953812
[lr=0.05, bs=2048, dr=0.3] -> best_test_loss = 0.958708
[lr=0.05, bs=4096, dr=0.1] -> best_test_loss = 0.951324
[lr=0.05, bs=4096, dr=0.15] -> best_test_loss = 0.949810
[lr=0.05, bs=4096, dr=0.2] -> best_test_loss = 0.949770
[lr=0.05, bs=4096, dr=0.25] -> best_test_loss = 0.952027
[lr=0.05, bs=4096, dr=0.3] -> best_test_loss = 0.956430
[lr=0.01, bs=512, dr=0.1] -> best_test_loss = 0.955827
[lr=0.01, bs=512, dr=0.15] -> best_test_loss = 0.953841
[lr=0.01, bs=512, dr=0.2] -> best_test_loss = 0.956850
[lr=0.01, bs=512, dr=0.25] -> best_test_loss = 0.958260
[lr=0.01, bs=512, dr=0.3] -> best_test_loss = 0.958627
[lr=0.01, bs=1024, dr=0.1] -> best_test_loss = 0.950819
[lr=0.01, bs=1024, dr=0.15] -> best_test_loss = 0.949458
[lr=0.01, bs=1024, dr=0.2] -> best_test_loss = 0.951837
[lr=0.01, bs=1024, dr=0.25] -> best_test_loss = 0.953857
[lr=0.01, bs=1024, dr=0.3] -> best_test_loss = 0.956079
[lr=0.01, bs=2048, dr=0.1] -> best_test_loss = 0.949514
[lr=0.01, bs=2048, dr=0.15] -> best_test_loss = 0.948000
[lr=0.01, bs=2048, dr=0.2] -> best_test_loss = 0.949640
[lr=0.01, bs=2048, dr=0.25] -> best_test_loss = 0.952199
[lr=0.01, bs=2048, dr=0.3] -> best_test_loss = 0.948093
[lr=0.01, bs=4096, dr=0.1] -> best_test_loss = 0.950931
[lr=0.01, bs=4096, dr=0.15] -> best_test_loss = 0.950604
[lr=0.01, bs=4096, dr=0.2] -> best_test_loss = 0.952141
[lr=0.01, bs=4096, dr=0.25] -> best_test_loss = 0.949628
[lr=0.01, bs=4096, dr=0.3] -> best_test_loss = 0.953282
[lr=0.005, bs=512, dr=0.1] -> best_test_loss = 0.952764
[lr=0.005, bs=512, dr=0.15] -> best_test_loss = 0.953390
[lr=0.005, bs=512, dr=0.2] -> best_test_loss = 0.953527
[lr=0.005, bs=512, dr=0.25] -> best_test_loss = 0.953931
[lr=0.005, bs=512, dr=0.3] -> best_test_loss = 0.955161
[lr=0.005, bs=1024, dr=0.1] -> best_test_loss = 0.951120
[lr=0.005, bs=1024, dr=0.15] -> best_test_loss = 0.952875
[lr=0.005, bs=1024, dr=0.2] -> best_test_loss = 0.951145
[lr=0.005, bs=1024, dr=0.25] -> best_test_loss = 0.955691
[lr=0.005, bs=1024, dr=0.3] -> best_test_loss = 0.957477
[lr=0.005, bs=2048, dr=0.1] -> best_test_loss = 0.946433
[lr=0.005, bs=2048, dr=0.15] -> best_test_loss = 0.949539
[lr=0.005, bs=2048, dr=0.2] -> best_test_loss = 0.950298
[lr=0.005, bs=2048, dr=0.25] -> best_test_loss = 0.951538
[lr=0.005, bs=2048, dr=0.3] -> best_test_loss = 0.954772
[lr=0.005, bs=4096, dr=0.1] -> best_test_loss = 0.944634
[lr=0.005, bs=4096, dr=0.15] -> best_test_loss = 0.949949
[lr=0.005, bs=4096, dr=0.2] -> best_test_loss = 0.950102
[lr=0.005, bs=4096, dr=0.25] -> best_test_loss = 0.950082
[lr=0.005, bs=4096, dr=0.3] -> best_test_loss = 0.949988
[lr=0.001, bs=512, dr=0.1] -> best_test_loss = 0.954769
[lr=0.001, bs=512, dr=0.15] -> best_test_loss = 0.957660
[lr=0.001, bs=512, dr=0.2] -> best_test_loss = 0.958084
[lr=0.001, bs=512, dr=0.25] -> best_test_loss = 0.961258
[lr=0.001, bs=512, dr=0.3] -> best_test_loss = 0.963857
[lr=0.001, bs=1024, dr=0.1] -> best_test_loss = 0.956486
[lr=0.001, bs=1024, dr=0.15] -> best_test_loss = 0.955937
[lr=0.001, bs=1024, dr=0.2] -> best_test_loss = 0.958769
[lr=0.001, bs=1024, dr=0.25] -> best_test_loss = 0.961763
[lr=0.001, bs=1024, dr=0.3] -> best_test_loss = 0.963848
[lr=0.001, bs=2048, dr=0.1] -> best_test_loss = 0.952649
[lr=0.001, bs=2048, dr=0.15] -> best_test_loss = 0.951692
[lr=0.001, bs=2048, dr=0.2] -> best_test_loss = 0.956530
[lr=0.001, bs=2048, dr=0.25] -> best_test_loss = 0.959308
[lr=0.001, bs=2048, dr=0.3] -> best_test_loss = 0.961649
[lr=0.001, bs=4096, dr=0.1] -> best_test_loss = 0.947310
[lr=0.001, bs=4096, dr=0.15] -> best_test_loss = 0.950370
[lr=0.001, bs=4096, dr=0.2] -> best_test_loss = 0.952331
[lr=0.001, bs=4096, dr=0.25] -> best_test_loss = 0.955755
[lr=0.001, bs=4096, dr=0.3] -> best_test_loss = 0.959066
[lr=0.0005, bs=512, dr=0.1] -> best_test_loss = 0.957882
[lr=0.0005, bs=512, dr=0.15] -> best_test_loss = 0.960899
[lr=0.0005, bs=512, dr=0.2] -> best_test_loss = 0.963285
[lr=0.0005, bs=512, dr=0.25] -> best_test_loss = 0.967108
[lr=0.0005, bs=512, dr=0.3] -> best_test_loss = 0.971415
[lr=0.0005, bs=1024, dr=0.1] -> best_test_loss = 0.957593
[lr=0.0005, bs=1024, dr=0.15] -> best_test_loss = 0.960391
[lr=0.0005, bs=1024, dr=0.2] -> best_test_loss = 0.964353
[lr=0.0005, bs=1024, dr=0.25] -> best_test_loss = 0.968788
[lr=0.0005, bs=1024, dr=0.3] -> best_test_loss = 0.972016
[lr=0.0005, bs=2048, dr=0.1] -> best_test_loss = 0.956468
[lr=0.0005, bs=2048, dr=0.15] -> best_test_loss = 0.957893
[lr=0.0005, bs=2048, dr=0.2] -> best_test_loss = 0.962070
[lr=0.0005, bs=2048, dr=0.25] -> best_test_loss = 0.965236
[lr=0.0005, bs=2048, dr=0.3] -> best_test_loss = 0.968753
[lr=0.0005, bs=4096, dr=0.1] -> best_test_loss = 0.955043
[lr=0.0005, bs=4096, dr=0.15] -> best_test_loss = 0.957195
[lr=0.0005, bs=4096, dr=0.2] -> best_test_loss = 0.960485
[lr=0.0005, bs=4096, dr=0.25] -> best_test_loss = 0.962583
[lr=0.0005, bs=4096, dr=0.3] -> best_test_loss = 0.965140
[lr=0.0001, bs=512, dr=0.1] -> best_test_loss = 0.970669
[lr=0.0001, bs=512, dr=0.15] -> best_test_loss = 0.973702
[lr=0.0001, bs=512, dr=0.2] -> best_test_loss = 0.975131
[lr=0.0001, bs=512, dr=0.25] -> best_test_loss = 0.976753
[lr=0.0001, bs=512, dr=0.3] -> best_test_loss = 0.978890
[lr=0.0001, bs=1024, dr=0.1] -> best_test_loss = 0.971139
[lr=0.0001, bs=1024, dr=0.15] -> best_test_loss = 0.973510
[lr=0.0001, bs=1024, dr=0.2] -> best_test_loss = 0.975845
[lr=0.0001, bs=1024, dr=0.25] -> best_test_loss = 0.978578
[lr=0.0001, bs=1024, dr=0.3] -> best_test_loss = 0.981180
[lr=0.0001, bs=2048, dr=0.1] -> best_test_loss = 0.968010
[lr=0.0001, bs=2048, dr=0.15] -> best_test_loss = 0.971118
[lr=0.0001, bs=2048, dr=0.2] -> best_test_loss = 0.974245
[lr=0.0001, bs=2048, dr=0.25] -> best_test_loss = 0.977447
[lr=0.0001, bs=2048, dr=0.3] -> best_test_loss = 0.979906
[lr=0.0001, bs=4096, dr=0.1] -> best_test_loss = 0.966677
[lr=0.0001, bs=4096, dr=0.15] -> best_test_loss = 0.969851
[lr=0.0001, bs=4096, dr=0.2] -> best_test_loss = 0.972386
[lr=0.0001, bs=4096, dr=0.25] -> best_test_loss = 0.975476
[lr=0.0001, bs=4096, dr=0.3] -> best_test_loss = 0.978206
Best parameters: {'learning_rate': 0.005, 'batch_size': 4096, 'dropout_rate': 0.1} with Test Loss: 0.9446337332605423
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mrandom_prune0.4_lr0.005_bs4096_dr0.1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air-quality/runs/276arpvk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250122_173135-276arpvk/logs[0m
All tasks completed.
