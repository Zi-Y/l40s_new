nohup: ignoring input
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=0, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=1, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=2, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=3, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=4, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=5, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=6, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=7, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=8, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=9, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=10, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=11, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=12, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=13, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=14, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=15, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=16, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=17, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=18, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=19, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=20, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=21, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=22, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=23, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=24, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=25, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=26, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=27, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=28, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=29, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=30, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=31, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=32, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=33, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=34, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=35, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=36, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=37, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=38, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=39, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=40, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=41, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=42, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=43, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=44, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=45, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=46, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=47, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=48, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=49, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=50, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=51, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=52, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=53, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=54, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=55, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=56, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=57, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=58, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=59, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=60, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=61, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=62, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=63, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161720-flcs5st3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/flcs5st3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161721-eacpbm8d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/eacpbm8d
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161722-fo6xhv1a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fo6xhv1a
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161722-hvs2xl0h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hvs2xl0h
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161722-nlcbpdre
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nlcbpdre
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161722-56fxx09e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/56fxx09e
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161722-gzrs8nu3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gzrs8nu3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161722-vt81s4k7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vt81s4k7
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161722-ckmhzn58
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ckmhzn58
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161722-qwsk4rku
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qwsk4rku
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161722-ysdujemo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ysdujemo
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161722-v76zzt8j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v76zzt8j
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161722-yiixpurw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yiixpurw
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161722-hx9i4ml0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hx9i4ml0
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-moi9g484
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/moi9g484
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161722-gvjb90u1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gvjb90u1
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-knl9ezpg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/knl9ezpg
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-72odyenr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/72odyenr
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-dxn2se4b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dxn2se4b
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161722-ha1w58h3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ha1w58h3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161722-7wd6324f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7wd6324f
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161722-9mspucd3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9mspucd3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-wrcbxiqz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wrcbxiqz
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-l10gcief
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l10gcief
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-t6zftiu3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/t6zftiu3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-dvr7jhkk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dvr7jhkk
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-98p7v150
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/98p7v150
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-ahzzsf15
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ahzzsf15
wandb: Tracking run with wandb version 0.19.4
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-ezjasveg
wandb: Run `wandb offline` to turn off syncing.
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-lq3uiza5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ezjasveg
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lq3uiza5
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-oksff0fm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oksff0fm
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-jszbfmci
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jszbfmci
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-6nme7dz3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6nme7dz3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-u5mtf62v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u5mtf62v
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-ajtz9xbg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ajtz9xbg
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-edgt67lh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/edgt67lh
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-wlwouho2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wlwouho2
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-qegf54zd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qegf54zd
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-kqdevopp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kqdevopp
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-z9yqxv8e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z9yqxv8e
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-r5aywwsh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r5aywwsh
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-rup3ar5a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rup3ar5a
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-wodlapbu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wodlapbu
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-278ol3w2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/278ol3w2
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-zxqdohtz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zxqdohtz
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-9e1vnzes
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9e1vnzes
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-brd2b9w6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/brd2b9w6
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-6hsu7er2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6hsu7er2
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-8o70hydo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8o70hydo
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-319gz1iu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/319gz1iu
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-awqlxhex
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/awqlxhex
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-igzpy6th
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/igzpy6th
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-aou7lvb6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/aou7lvb6
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-jze9a62v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jze9a62v
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-rp5rm3pd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rp5rm3pd
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-rorg2hmc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rorg2hmc
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-p3nslmxr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p3nslmxr
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-6h2i85t1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6h2i85t1
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-gu6wsh9u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gu6wsh9u
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-pb2oy0qz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pb2oy0qz
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-55fbjmz3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/55fbjmz3
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161727-br2czpsc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/br2czpsc
wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/flcs5st3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161720-flcs5st3/logs[0m
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161723-aaoe87cg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/aaoe87cg
wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=64, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161722-wb0zi06y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wb0zi06y
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fo6xhv1a[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161722-fo6xhv1a/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/eacpbm8d[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161721-eacpbm8d/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=65, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=66, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161749-1uexfynz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1uexfynz
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hvs2xl0h[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161722-hvs2xl0h/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=67, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161752-mq3bpz98
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mq3bpz98
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161752-xl7yq8ps
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xl7yq8ps
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v76zzt8j[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161722-v76zzt8j/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=68, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161756-g1g06set
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g1g06set
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gzrs8nu3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161722-gzrs8nu3/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ezjasveg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-ezjasveg/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/56fxx09e[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161722-56fxx09e/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ckmhzn58[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161722-ckmhzn58/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qegf54zd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-qegf54zd/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jszbfmci[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-jszbfmci/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=69, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=70, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=71, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=72, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=73, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=74, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161759-ncvxn9yo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ncvxn9yo
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/brd2b9w6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-brd2b9w6/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/278ol3w2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-278ol3w2/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kqdevopp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-kqdevopp/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qwsk4rku[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161722-qwsk4rku/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/igzpy6th[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-igzpy6th/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8o70hydo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-8o70hydo/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/319gz1iu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-319gz1iu/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7wd6324f[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161722-7wd6324f/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wodlapbu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-wodlapbu/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/aou7lvb6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-aou7lvb6/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9mspucd3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161722-9mspucd3/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/moi9g484[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-moi9g484/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wrcbxiqz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-wrcbxiqz/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p3nslmxr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-p3nslmxr/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/knl9ezpg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-knl9ezpg/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vt81s4k7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161722-vt81s4k7/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6nme7dz3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-6nme7dz3/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=75, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=76, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=77, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ahzzsf15[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-ahzzsf15/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/72odyenr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-72odyenr/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/98p7v150[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-98p7v150/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gvjb90u1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161722-gvjb90u1/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6hsu7er2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-6hsu7er2/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ysdujemo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161722-ysdujemo/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dvr7jhkk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-dvr7jhkk/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/t6zftiu3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-t6zftiu3/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yiixpurw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161722-yiixpurw/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dxn2se4b[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-dxn2se4b/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ha1w58h3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161722-ha1w58h3/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u5mtf62v[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-u5mtf62v/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l10gcief[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-l10gcief/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nlcbpdre[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161722-nlcbpdre/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rup3ar5a[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-rup3ar5a/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/awqlxhex[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-awqlxhex/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rorg2hmc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-rorg2hmc/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6h2i85t1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-6h2i85t1/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wlwouho2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-wlwouho2/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rp5rm3pd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-rp5rm3pd/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zxqdohtz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-zxqdohtz/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z9yqxv8e[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-z9yqxv8e/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/br2czpsc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161727-br2czpsc/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lq3uiza5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-lq3uiza5/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9e1vnzes[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-9e1vnzes/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=78, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=79, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=80, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=81, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=82, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=83, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=84, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=85, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=86, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ajtz9xbg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-ajtz9xbg/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=87, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=88, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=89, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=90, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=91, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=92, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=93, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=94, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=95, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=96, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=97, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=98, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=99, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oksff0fm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-oksff0fm/logs[0m
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=100, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=101, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=102, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=103, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=104, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=105, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=106, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=107, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=108, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=109, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=110, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=111, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=112, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=113, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=114, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=115, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=116, wandb_name=random, GPU=0
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161802-wcqo8w3o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wcqo8w3o
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161803-7tqilx2g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7tqilx2g
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161802-oem3i41u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oem3i41u
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161803-e07g5bzf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e07g5bzf
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=117, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=118, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161805-7dbna307
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7dbna307
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161805-mjaub6wc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mjaub6wc
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161805-2sfj9op1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2sfj9op1
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161805-hemnjbg1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hemnjbg1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: \ Waiting for wandb.init()...wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161805-jo8c0w1y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jo8c0w1y
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161805-bkr36pts
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bkr36pts
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161806-58g4odzw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/58g4odzw
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161806-ek2wchl7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ek2wchl7
wandb: - Waiting for wandb.init()...wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161805-20h4p97i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/20h4p97i
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hx9i4ml0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161722-hx9i4ml0/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161805-pkb7dolp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pkb7dolp
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161806-pzkf7k4j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pzkf7k4j
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161806-vwjkdb5c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vwjkdb5c
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161806-2zbdmj7q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2zbdmj7q
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/aaoe87cg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-aaoe87cg/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161806-othxmn08
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/othxmn08
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161807-6psn8ijv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6psn8ijv
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161807-sy2wyvna
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sy2wyvna
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161806-58noymxg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/58noymxg
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161807-gfki2ual
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gfki2ual
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161807-soc13uqp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/soc13uqp
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wb0zi06y[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161722-wb0zi06y/logs[0m
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=119, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=120, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161808-mfmqaaro
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mfmqaaro
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161808-5qqk3h9z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5qqk3h9z
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161808-s1v3s5tm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s1v3s5tm
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161808-xz1tfs1u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xz1tfs1u
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161809-x428ffnh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x428ffnh
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161810-e1vytj08
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e1vytj08
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161810-bxckkxsx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bxckkxsx
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161811-5nnz34hz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5nnz34hz
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161810-8c9ubuek
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8c9ubuek
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161811-t7rmuwno
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/t7rmuwno
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161811-dqjdo5y3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dqjdo5y3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161811-yd9fte47
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yd9fte47
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jze9a62v[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-jze9a62v/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=121, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161811-qq5do6jc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qq5do6jc
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161811-9marqw55
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9marqw55
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161812-6ykbxxvt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6ykbxxvt
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161811-d87gt0w3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/d87gt0w3
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161812-p5g6ve3p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p5g6ve3p
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161811-icppamtp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/icppamtp
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161812-x3bmryt8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x3bmryt8
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161812-snimdzp8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/snimdzp8
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161812-ef1z1rwr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ef1z1rwr
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161812-nnsn4qcv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nnsn4qcv
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/edgt67lh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-edgt67lh/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=122, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161812-t8r82jul
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/t8r82jul
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161814-v9ltztj9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v9ltztj9
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=123, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g1g06set[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161756-g1g06set/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161814-nvxp2nih
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nvxp2nih
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xl7yq8ps[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161752-xl7yq8ps/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gu6wsh9u[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-gu6wsh9u/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161815-z55c8s6m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z55c8s6m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mq3bpz98[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161752-mq3bpz98/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161816-z1wp23i3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z1wp23i3
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161816-ecd9mpx4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ecd9mpx4
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pb2oy0qz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-pb2oy0qz/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=124, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161817-ppjtc8ij
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ppjtc8ij
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1uexfynz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161749-1uexfynz/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/55fbjmz3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-55fbjmz3/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=125, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=126, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=127, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161817-zjqbl6ju
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zjqbl6ju
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=128, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=129, wandb_name=random, GPU=1
wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161819-6lhz2ke8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6lhz2ke8
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=130, wandb_name=random, GPU=2
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ncvxn9yo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161759-ncvxn9yo/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161821-6vnts5js
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6vnts5js
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=131, wandb_name=random, GPU=3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161822-gzf1eyeb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gzf1eyeb
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161822-tfrbx2gp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tfrbx2gp
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161822-k9oiz7mh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k9oiz7mh
wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161823-q7icbvyi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q7icbvyi
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161824-ajyu2les
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ajyu2les
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r5aywwsh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161723-r5aywwsh/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161826-lfsboild
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lfsboild
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=132, wandb_name=random, GPU=0
wandb: / Waiting for wandb.init()...wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161828-m17afo5z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m17afo5z
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7tqilx2g[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161803-7tqilx2g/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e07g5bzf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161803-e07g5bzf/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161831-rk2vlrzr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rk2vlrzr
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oem3i41u[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161802-oem3i41u/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=133, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=134, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2sfj9op1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161805-2sfj9op1/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7dbna307[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161805-7dbna307/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hemnjbg1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161805-hemnjbg1/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mjaub6wc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161805-mjaub6wc/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=135, wandb_name=random, GPU=3
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=136, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=137, wandb_name=random, GPU=1
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2zbdmj7q[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161806-2zbdmj7q/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/20h4p97i[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161805-20h4p97i/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/58g4odzw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161806-58g4odzw/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=138, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=139, wandb_name=random, GPU=3
wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vwjkdb5c[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161806-vwjkdb5c/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/othxmn08[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161806-othxmn08/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jo8c0w1y[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161805-jo8c0w1y/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bkr36pts[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161805-bkr36pts/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161836-kjqrhc79
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kjqrhc79
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ek2wchl7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161806-ek2wchl7/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=140, wandb_name=random, GPU=0
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161836-ztlhmc2f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ztlhmc2f
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=141, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=142, wandb_name=random, GPU=2
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pkb7dolp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161805-pkb7dolp/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pzkf7k4j[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161806-pzkf7k4j/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=143, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=144, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=145, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=146, wandb_name=random, GPU=2
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=147, wandb_name=random, GPU=3
wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=148, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=149, wandb_name=random, GPU=1
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161838-45i52i7f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/45i52i7f
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161838-510wqaa0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/510wqaa0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sy2wyvna[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161807-sy2wyvna/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5qqk3h9z[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161808-5qqk3h9z/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x428ffnh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161809-x428ffnh/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s1v3s5tm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161808-s1v3s5tm/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xz1tfs1u[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161808-xz1tfs1u/logs[0m
wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/soc13uqp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161807-soc13uqp/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mfmqaaro[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161808-mfmqaaro/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6psn8ijv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161807-6psn8ijv/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gfki2ual[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161807-gfki2ual/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161840-v2spqdzy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v2spqdzy
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=150, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=151, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8c9ubuek[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161810-8c9ubuek/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bxckkxsx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161810-bxckkxsx/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161840-evq88r6o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/evq88r6o
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161841-0996amu4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0996amu4
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161840-vryo3409
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vryo3409
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=152, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=153, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=154, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=155, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=156, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=157, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=158, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161841-c6trike8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c6trike8
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=159, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=160, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161843-i2jfzpps
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/i2jfzpps
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161843-7vclmrup
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7vclmrup
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161843-5hqwsosw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5hqwsosw
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161843-3ugb9rdy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3ugb9rdy
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161843-073jk9cn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/073jk9cn
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161843-6uuk206r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6uuk206r
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161844-ivjcq01h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ivjcq01h
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/t7rmuwno[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161811-t7rmuwno/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ef1z1rwr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161812-ef1z1rwr/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161844-qp581uw6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qp581uw6
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zjqbl6ju[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161817-zjqbl6ju/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z55c8s6m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161815-z55c8s6m/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9marqw55[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161811-9marqw55/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161812-o1g18hw6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o1g18hw6
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6ykbxxvt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161812-6ykbxxvt/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ppjtc8ij[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161817-ppjtc8ij/logs[0m
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161845-79wdsoav
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/79wdsoav
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p5g6ve3p[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161812-p5g6ve3p/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161846-o1hqyd1c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o1hqyd1c
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161846-k8alx0d5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k8alx0d5
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v9ltztj9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161814-v9ltztj9/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161846-u0r3xigw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u0r3xigw
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161846-rizxthho
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rizxthho
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nvxp2nih[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161814-nvxp2nih/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z1wp23i3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161816-z1wp23i3/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=161, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=162, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=163, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=164, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=165, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=166, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=167, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6lhz2ke8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161819-6lhz2ke8/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161846-vv3kxbeo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vv3kxbeo
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161846-zjzugev8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zjzugev8
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161846-fpyuov6x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fpyuov6x
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161847-p1a8u97d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p1a8u97d
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6vnts5js[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161821-6vnts5js/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=168, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k9oiz7mh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161822-k9oiz7mh/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5nnz34hz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161811-5nnz34hz/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161847-rab894gf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rab894gf
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=169, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=170, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=171, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=172, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yd9fte47[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161811-yd9fte47/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qq5do6jc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161811-qq5do6jc/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q7icbvyi[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161823-q7icbvyi/logs[0m
wandb: / Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=173, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=174, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=175, wandb_name=random, GPU=3
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161850-9ik9gjse
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9ik9gjse
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161850-nwhcp5io
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nwhcp5io
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161850-340ldpdn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/340ldpdn
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161850-2mkrssnu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2mkrssnu
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161850-8msjztw6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8msjztw6
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161850-ijka6kra
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ijka6kra
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161850-ox67isyn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ox67isyn
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dqjdo5y3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161811-dqjdo5y3/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=176, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=177, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=178, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161851-ua5ziyxp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ua5ziyxp
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lfsboild[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161826-lfsboild/logs[0m
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m17afo5z[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161828-m17afo5z/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=179, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161853-8ofbsouw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8ofbsouw
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161853-hqfi7hxf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hqfi7hxf
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161853-c6005swq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c6005swq
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161853-m6gyiwi7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m6gyiwi7
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=180, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161854-25d79e4h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/25d79e4h
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=181, wandb_name=random, GPU=1
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161854-i0zmsym8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/i0zmsym8
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161855-y2s99v8x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y2s99v8x
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161855-glfor308
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/glfor308
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161856-7mulh9ip
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7mulh9ip
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161857-anijinl6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/anijinl6
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161857-orbw4rda
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/orbw4rda
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161858-o04oh2ec
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o04oh2ec
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kjqrhc79[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161836-kjqrhc79/logs[0m
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tfrbx2gp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161822-tfrbx2gp/logs[0m
wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=182, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e1vytj08[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161810-e1vytj08/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nnsn4qcv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161812-nnsn4qcv/logs[0m
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ztlhmc2f[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161836-ztlhmc2f/logs[0m
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161859-rtxjjus5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rtxjjus5
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/t8r82jul[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161812-t8r82jul/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=183, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/45i52i7f[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161838-45i52i7f/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/58noymxg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161806-58noymxg/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gzf1eyeb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161822-gzf1eyeb/logs[0m
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ajyu2les[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161824-ajyu2les/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/icppamtp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161811-icppamtp/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=184, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=185, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=186, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=187, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ecd9mpx4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161816-ecd9mpx4/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/d87gt0w3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161811-d87gt0w3/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/snimdzp8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161812-snimdzp8/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=188, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=189, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=190, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=191, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=192, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vryo3409[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161840-vryo3409/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wcqo8w3o[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161802-wcqo8w3o/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161904-n61wnvzv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n61wnvzv
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rk2vlrzr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161831-rk2vlrzr/logs[0m
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161837-4q3wxeas
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4q3wxeas
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0996amu4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161841-0996amu4/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x3bmryt8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161812-x3bmryt8/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/evq88r6o[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161840-evq88r6o/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=193, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=194, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=195, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c6trike8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161841-c6trike8/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161906-3t5xkefg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3t5xkefg
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=196, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=197, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=198, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=199, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=200, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v2spqdzy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161840-v2spqdzy/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7vclmrup[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161843-7vclmrup/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/i2jfzpps[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161843-i2jfzpps/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161907-lz0r88zf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lz0r88zf
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=201, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=202, wandb_name=random, GPU=2
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161907-qtznqqj9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qtznqqj9
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161907-vas8acb3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vas8acb3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161907-cnch8urx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cnch8urx
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/510wqaa0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161838-510wqaa0/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=203, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161908-h5ql5jsg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h5ql5jsg
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=204, wandb_name=random, GPU=0
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161908-v14m6d8g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v14m6d8g
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=205, wandb_name=random, GPU=1
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161908-b6hn8grc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b6hn8grc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161908-sxct1mxn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sxct1mxn
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161908-3b1iqs9v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3b1iqs9v
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=206, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161910-urkik5b0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/urkik5b0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161910-yo3isg6c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yo3isg6c
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161910-r4273400
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r4273400
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161911-9n4wzeei
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9n4wzeei
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161911-11sm6mj8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/11sm6mj8
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161911-9ek772yp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9ek772yp
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161912-5olug072
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5olug072
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161912-9fbultps
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9fbultps
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161912-ncfnigk4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ncfnigk4
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161912-o4gtxbk7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o4gtxbk7
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161912-89z5wco5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/89z5wco5
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rizxthho[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161846-rizxthho/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5hqwsosw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161843-5hqwsosw/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o1g18hw6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161812-o1g18hw6/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/073jk9cn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161843-073jk9cn/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161915-4lu3kdja
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4lu3kdja
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161915-5wlu4j17
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5wlu4j17
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3ugb9rdy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161843-3ugb9rdy/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o1hqyd1c[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161846-o1hqyd1c/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161915-3tjwa2qt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3tjwa2qt
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p1a8u97d[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161847-p1a8u97d/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9ik9gjse[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161850-9ik9gjse/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zjzugev8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161846-zjzugev8/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u0r3xigw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161846-u0r3xigw/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vv3kxbeo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161846-vv3kxbeo/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ijka6kra[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161850-ijka6kra/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ivjcq01h[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161844-ivjcq01h/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/340ldpdn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161850-340ldpdn/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=207, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=208, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=209, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=210, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ua5ziyxp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161851-ua5ziyxp/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nwhcp5io[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161850-nwhcp5io/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6uuk206r[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161843-6uuk206r/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8msjztw6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161850-8msjztw6/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=211, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=212, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=213, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=214, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=215, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=216, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2mkrssnu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161850-2mkrssnu/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=217, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=218, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qp581uw6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161844-qp581uw6/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m6gyiwi7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161853-m6gyiwi7/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/79wdsoav[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161845-79wdsoav/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/25d79e4h[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161854-25d79e4h/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hqfi7hxf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161853-hqfi7hxf/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=219, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=220, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=221, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=222, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=223, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=224, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=225, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c6005swq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161853-c6005swq/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k8alx0d5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161846-k8alx0d5/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/i0zmsym8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161854-i0zmsym8/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8ofbsouw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161853-8ofbsouw/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=226, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=227, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=228, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=229, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rab894gf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161847-rab894gf/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7mulh9ip[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161856-7mulh9ip/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161920-py9drds4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/py9drds4
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=230, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=231, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=232, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=233, wandb_name=random, GPU=1
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161920-6oy20mkq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6oy20mkq
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161920-p5iwerie
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p5iwerie
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/glfor308[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161855-glfor308/logs[0m
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/anijinl6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161857-anijinl6/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=234, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=235, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161921-77loiyd9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/77loiyd9
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161922-hokg2u8a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hokg2u8a
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161921-lewzk1ih
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lewzk1ih
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161922-itr7i2hl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/itr7i2hl
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161922-o624bps3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o624bps3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161922-u0fwpr5h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u0fwpr5h
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161922-mi7cynev
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mi7cynev
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=236, wandb_name=random, GPU=0
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161922-49dare8u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/49dare8u
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: | Waiting for wandb.init()...wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=237, wandb_name=random, GPU=1
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161923-thnk4ya9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/thnk4ya9
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=238, wandb_name=random, GPU=2
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161923-xgv1r4e7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xgv1r4e7
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161923-7zw7vpo2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7zw7vpo2
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161923-omugq44c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/omugq44c
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161923-opycc1tm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/opycc1tm
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161924-g1btf4x5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g1btf4x5
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161923-fuon966o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fuon966o
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161926-gdy791rl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gdy791rl
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161926-bv3cr2qq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bv3cr2qq
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161926-nbipye3f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nbipye3f
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161926-kdbcpttv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kdbcpttv
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161926-7k0lpban
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7k0lpban
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161927-tjcl0nw7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tjcl0nw7
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161927-d2npk1d0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/d2npk1d0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161927-6l22msk4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6l22msk4
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161927-7bzo0hyc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7bzo0hyc
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161928-x1cuw2gv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x1cuw2gv
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161927-0sy0jl3l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0sy0jl3l
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161927-rvcwwk7i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rvcwwk7i
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o04oh2ec[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161858-o04oh2ec/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/orbw4rda[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161857-orbw4rda/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4q3wxeas[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161837-4q3wxeas/logs[0m
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lz0r88zf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161907-lz0r88zf/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161931-yju44jg8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yju44jg8
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n61wnvzv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161904-n61wnvzv/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=239, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=240, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=241, wandb_name=random, GPU=1
wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=242, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vas8acb3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161907-vas8acb3/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fpyuov6x[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161846-fpyuov6x/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b6hn8grc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161908-b6hn8grc/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=243, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h5ql5jsg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161908-h5ql5jsg/logs[0m
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cnch8urx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161907-cnch8urx/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qtznqqj9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161907-qtznqqj9/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=244, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=245, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v14m6d8g[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161908-v14m6d8g/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=246, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=247, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=248, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=249, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sxct1mxn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161908-sxct1mxn/logs[0m
wandb: / Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161935-iml602u5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iml602u5
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161936-cspoe1bd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cspoe1bd
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r4273400[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161910-r4273400/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/urkik5b0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161910-urkik5b0/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/11sm6mj8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161911-11sm6mj8/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=250, wandb_name=random, GPU=2
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161936-9cu5t5d4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9cu5t5d4
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9n4wzeei[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161911-9n4wzeei/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161937-iqyo0mtq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iqyo0mtq
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=251, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=252, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=253, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161938-hskiwmhr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hskiwmhr
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=254, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=255, wandb_name=random, GPU=3
wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161939-tf8h86tp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tf8h86tp
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161939-w7ghwj5l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/w7ghwj5l
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161939-165gmdcq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/165gmdcq
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161939-lb9tobxu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lb9tobxu
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161939-h1oqt9dg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h1oqt9dg
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161939-5yeb1l3n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5yeb1l3n
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161941-bubdon5r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bubdon5r
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161942-0by01lkl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0by01lkl
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161942-xj6f49s4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xj6f49s4
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161942-lko3dlrt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lko3dlrt
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161942-jbny4rqk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jbny4rqk
wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3t5xkefg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161906-3t5xkefg/logs[0m
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3tjwa2qt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161915-3tjwa2qt/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rtxjjus5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161859-rtxjjus5/logs[0m
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ncfnigk4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161912-ncfnigk4/logs[0m
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=256, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p5iwerie[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161920-p5iwerie/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o4gtxbk7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161912-o4gtxbk7/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/89z5wco5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161912-89z5wco5/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9fbultps[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161912-9fbultps/logs[0m
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=257, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=258, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=259, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6oy20mkq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161920-6oy20mkq/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4lu3kdja[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161915-4lu3kdja/logs[0m
wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=260, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=261, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=262, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=263, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hokg2u8a[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161922-hokg2u8a/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u0fwpr5h[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161922-u0fwpr5h/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5wlu4j17[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161915-5wlu4j17/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o624bps3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161922-o624bps3/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=264, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=265, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ox67isyn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161850-ox67isyn/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lewzk1ih[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161921-lewzk1ih/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161949-k96qq9uv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k96qq9uv
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/49dare8u[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161922-49dare8u/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mi7cynev[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161922-mi7cynev/logs[0m
wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=266, wandb_name=random, GPU=2
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=267, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=268, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=269, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/thnk4ya9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161923-thnk4ya9/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y2s99v8x[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161855-y2s99v8x/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161950-cu03pe0a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cu03pe0a
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161950-m71t527q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m71t527q
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fuon966o[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161923-fuon966o/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: | Waiting for wandb.init()...wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161950-pyss2qj2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pyss2qj2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/opycc1tm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161923-opycc1tm/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/omugq44c[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161923-omugq44c/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=270, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bv3cr2qq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161926-bv3cr2qq/logs[0m
wandb: / Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=271, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=272, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=273, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=274, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=275, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=276, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161952-6t78rexp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6t78rexp
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nbipye3f[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161926-nbipye3f/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161952-ggskluih
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ggskluih
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161920-0ryfyxcd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0ryfyxcd
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=277, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=278, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=279, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161953-isrc537e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/isrc537e
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161953-z6s2kwwi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z6s2kwwi
wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161953-5n50uf4d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5n50uf4d
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161953-fhm4t6jk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fhm4t6jk
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161953-vnp8dkoh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vnp8dkoh
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161953-4jh95gg5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4jh95gg5
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161954-s98aim54
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s98aim54
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161954-gm2sna7b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gm2sna7b
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=280, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161955-6kfpqokx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6kfpqokx
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161956-kin789vs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kin789vs
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161956-oabt4ci8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oabt4ci8
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161956-yyqze8c0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yyqze8c0
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161956-rw93yi13
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rw93yi13
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161956-j6f1d27k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/j6f1d27k
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161957-2rysxqt9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2rysxqt9
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161957-dy0am04q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dy0am04q
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161957-5dbjyqfd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5dbjyqfd
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161957-dv46hc4m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dv46hc4m
wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gdy791rl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161926-gdy791rl/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cspoe1bd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161936-cspoe1bd/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161959-oyudsyfk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oyudsyfk
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7k0lpban[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161926-7k0lpban/logs[0m
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/d2npk1d0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161927-d2npk1d0/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7zw7vpo2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161923-7zw7vpo2/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kdbcpttv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161926-kdbcpttv/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=281, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=282, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5olug072[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161912-5olug072/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6l22msk4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161927-6l22msk4/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tjcl0nw7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161927-tjcl0nw7/logs[0m
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iml602u5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161935-iml602u5/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iqyo0mtq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161937-iqyo0mtq/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tf8h86tp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161939-tf8h86tp/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=283, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=284, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=285, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=286, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=287, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/py9drds4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161920-py9drds4/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/165gmdcq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161939-165gmdcq/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5yeb1l3n[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161939-5yeb1l3n/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/w7ghwj5l[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161939-w7ghwj5l/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yju44jg8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161931-yju44jg8/logs[0m
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lb9tobxu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161939-lb9tobxu/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=288, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=289, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=290, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=291, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=292, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9ek772yp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161911-9ek772yp/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h1oqt9dg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161939-h1oqt9dg/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g1btf4x5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161924-g1btf4x5/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rvcwwk7i[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161927-rvcwwk7i/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xj6f49s4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161942-xj6f49s4/logs[0m
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_161942-pog6ce0y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pog6ce0y
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=293, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=294, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=295, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=296, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=297, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=298, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bubdon5r[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161941-bubdon5r/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0sy0jl3l[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161927-0sy0jl3l/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x1cuw2gv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161928-x1cuw2gv/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0by01lkl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161942-0by01lkl/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yo3isg6c[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161910-yo3isg6c/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3b1iqs9v[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161908-3b1iqs9v/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xgv1r4e7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161923-xgv1r4e7/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hskiwmhr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161938-hskiwmhr/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7bzo0hyc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161927-7bzo0hyc/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162004-flbppwpy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/flbppwpy
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162005-xjfwzjgc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xjfwzjgc
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=299, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=300, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=301, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=302, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lko3dlrt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161942-lko3dlrt/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=303, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=304, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=305, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=306, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=307, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=308, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=309, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162005-o0gjegg7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o0gjegg7
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162006-vytkh8y4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vytkh8y4
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162006-lwvysf3q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lwvysf3q
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162006-kysj8suv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kysj8suv
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162006-l7z590h2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l7z590h2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=310, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=311, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=312, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=313, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162008-h5e4p2qr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h5e4p2qr
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162008-b1o9gh8v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b1o9gh8v
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162008-woes223i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/woes223i
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162008-khygc5vd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/khygc5vd
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162008-87nj4f22
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/87nj4f22
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162009-9mvaa6mp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9mvaa6mp
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162009-3mr7ygmo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3mr7ygmo
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162009-64xvsifk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/64xvsifk
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162009-hrs1p4qu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hrs1p4qu
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162009-d65ymg7n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/d65ymg7n
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162009-gg4itlvl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gg4itlvl
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162009-rykv1szp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rykv1szp
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162010-u9jkcdms
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u9jkcdms
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162010-lypso8va
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lypso8va
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162011-3t94e7hd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3t94e7hd
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162012-ydrdgcbz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ydrdgcbz
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162011-k3abjdch
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k3abjdch
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162012-5uwo6r4a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5uwo6r4a
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162012-uqu4b2fg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uqu4b2fg
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162012-etkvfoec
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/etkvfoec
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162012-23ic9m1m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/23ic9m1m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162012-zuvav1qs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zuvav1qs
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162013-0rxlkb5q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0rxlkb5q
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162013-vydio96e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vydio96e
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162013-l9rl3brr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l9rl3brr
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162014-a92hv66z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a92hv66z
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k96qq9uv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161949-k96qq9uv/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pyss2qj2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161950-pyss2qj2/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=314, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6t78rexp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161952-6t78rexp/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ggskluih[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161952-ggskluih/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0ryfyxcd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161920-0ryfyxcd/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=315, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vnp8dkoh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161953-vnp8dkoh/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/isrc537e[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161953-isrc537e/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fhm4t6jk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161953-fhm4t6jk/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5n50uf4d[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161953-5n50uf4d/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s98aim54[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161954-s98aim54/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4jh95gg5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161953-4jh95gg5/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=316, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=317, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=318, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=319, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gm2sna7b[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161954-gm2sna7b/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6kfpqokx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161955-6kfpqokx/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=320, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=321, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=322, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=323, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=324, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/j6f1d27k[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161956-j6f1d27k/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=325, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=326, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kin789vs[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161956-kin789vs/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z6s2kwwi[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161953-z6s2kwwi/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162020-6qsq45um
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6qsq45um
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162021-mm7q16p1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mm7q16p1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yyqze8c0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161956-yyqze8c0/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=327, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=328, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=329, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=330, wandb_name=random, GPU=2
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162022-8uoyw5k4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8uoyw5k4
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162022-2rzx30qt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2rzx30qt
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162022-866t00xz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/866t00xz
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162023-na13jueu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/na13jueu
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162023-31w6uojy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/31w6uojy
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162024-bs72xep4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bs72xep4
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162024-6nwvbcer
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6nwvbcer
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162024-l1npe1ho
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l1npe1ho
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162025-o30ar1zb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o30ar1zb
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162025-afin3oqt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/afin3oqt
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162027-ukvh45u9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ukvh45u9
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162027-n10rkaqt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n10rkaqt
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162027-q84qqpwy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q84qqpwy
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162027-vs9sdbt6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vs9sdbt6
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162027-fnfl4lna
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fnfl4lna
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oabt4ci8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161956-oabt4ci8/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dy0am04q[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161957-dy0am04q/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/flbppwpy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162004-flbppwpy/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/itr7i2hl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161922-itr7i2hl/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pog6ce0y[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161942-pog6ce0y/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oyudsyfk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161959-oyudsyfk/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=331, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=332, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=333, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vytkh8y4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162006-vytkh8y4/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=334, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=335, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=336, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l7z590h2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162006-l7z590h2/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/77loiyd9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161921-77loiyd9/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kysj8suv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162006-kysj8suv/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lwvysf3q[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162006-lwvysf3q/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=337, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/87nj4f22[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162008-87nj4f22/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=338, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=339, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=340, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=341, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162035-x181blld
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x181blld
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/woes223i[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162008-woes223i/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162035-dw7wlpas
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dw7wlpas
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162036-yq8s59cg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yq8s59cg
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/khygc5vd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162008-khygc5vd/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162036-c6074rbd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c6074rbd
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162036-bppgk2z1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bppgk2z1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=342, wandb_name=random, GPU=2
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162036-7qt4s55x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7qt4s55x
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dv46hc4m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161957-dv46hc4m/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u9jkcdms[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162010-u9jkcdms/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9mvaa6mp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162009-9mvaa6mp/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/64xvsifk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162009-64xvsifk/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/d65ymg7n[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162009-d65ymg7n/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=343, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=344, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=345, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=346, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=347, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=348, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=349, wandb_name=random, GPU=1
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162038-iq1me5sp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iq1me5sp
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162038-3qcz9m4z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3qcz9m4z
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162038-9iihw0tn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9iihw0tn
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162038-g29w97r9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g29w97r9
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162040-adjma4kg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/adjma4kg
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162041-kxvg27rp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kxvg27rp
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162042-bj1uq49r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bj1uq49r
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162042-7x182yw1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7x182yw1
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162042-o5a7n1yr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o5a7n1yr
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162042-v1zebsje
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v1zebsje
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162042-kjwj3q5h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kjwj3q5h
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162042-mdhvki7z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mdhvki7z
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3mr7ygmo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162009-3mr7ygmo/logs[0m
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3t94e7hd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162011-3t94e7hd/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gg4itlvl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162009-gg4itlvl/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mm7q16p1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162021-mm7q16p1/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hrs1p4qu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162009-hrs1p4qu/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5uwo6r4a[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162012-5uwo6r4a/logs[0m
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k3abjdch[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162011-k3abjdch/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/866t00xz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162022-866t00xz/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lypso8va[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162010-lypso8va/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/etkvfoec[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162012-etkvfoec/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=350, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=351, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=352, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a92hv66z[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162014-a92hv66z/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8uoyw5k4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162022-8uoyw5k4/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2rzx30qt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162022-2rzx30qt/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ydrdgcbz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162012-ydrdgcbz/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/23ic9m1m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162012-23ic9m1m/logs[0m
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l9rl3brr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162013-l9rl3brr/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/31w6uojy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162023-31w6uojy/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=353, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=354, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=355, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=356, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=357, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=358, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=359, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=360, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=361, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h5e4p2qr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162008-h5e4p2qr/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0rxlkb5q[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162013-0rxlkb5q/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bs72xep4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162024-bs72xep4/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vydio96e[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162013-vydio96e/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9cu5t5d4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161936-9cu5t5d4/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=362, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=363, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=364, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=365, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=366, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6nwvbcer[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162024-6nwvbcer/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o30ar1zb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162025-o30ar1zb/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l1npe1ho[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162024-l1npe1ho/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/afin3oqt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162025-afin3oqt/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vs9sdbt6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162027-vs9sdbt6/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o0gjegg7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162005-o0gjegg7/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rykv1szp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162009-rykv1szp/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ukvh45u9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162027-ukvh45u9/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=367, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=368, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q84qqpwy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162027-q84qqpwy/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=369, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=370, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=371, wandb_name=random, GPU=3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162049-90m4ymdj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/90m4ymdj
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162049-xppa5z3t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xppa5z3t
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162049-dwzsmxc2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dwzsmxc2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fnfl4lna[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162027-fnfl4lna/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=372, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=373, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=374, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=375, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=376, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=377, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=378, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=379, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=380, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162051-9nvzhie8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9nvzhie8
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162051-oat8tk3w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oat8tk3w
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162051-2y60oius
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2y60oius
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162051-cy1h59v5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cy1h59v5
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162051-f6wftqw6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f6wftqw6
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162051-5d5vgsr3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5d5vgsr3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162051-tbdts75e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tbdts75e
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162051-oy142tn7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oy142tn7
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162052-l6zlcjjm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l6zlcjjm
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=381, wandb_name=random, GPU=1
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162052-cv60p1cx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cv60p1cx
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zuvav1qs[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162012-zuvav1qs/logs[0m
wandb: | Waiting for wandb.init()...wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162052-nxtvnjqy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nxtvnjqy
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162052-2u0ucdat
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2u0ucdat
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162052-1el5uagd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1el5uagd
wandb: / Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=382, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162054-pd1bjty2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pd1bjty2
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162054-exty3gbs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/exty3gbs
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162055-5izax248
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5izax248
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162055-6jopw8dl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6jopw8dl
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162055-ba6d8jub
wandb: Run `wandb offline` to turn off syncing.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ba6d8jub
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162055-6dn01lb3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6dn01lb3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162056-9chv4cjz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9chv4cjz
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162056-j0pb5ewy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/j0pb5ewy
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162056-prgoyjrz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/prgoyjrz
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162056-6ri0h0qf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6ri0h0qf
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162056-rnjz07l3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rnjz07l3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162056-smqqo3lw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/smqqo3lw
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162056-u9y0cznp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u9y0cznp
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162056-5r3vi3br
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5r3vi3br
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dw7wlpas[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162035-dw7wlpas/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c6074rbd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162036-c6074rbd/logs[0m
wandb: / Waiting for wandb.init()...wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162059-vy1v2x45
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vy1v2x45
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162100-fo9x30md
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fo9x30md
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=383, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=384, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iq1me5sp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162038-iq1me5sp/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uqu4b2fg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162012-uqu4b2fg/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g29w97r9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162038-g29w97r9/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v1zebsje[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162042-v1zebsje/logs[0m
wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kxvg27rp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162041-kxvg27rp/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2rysxqt9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161957-2rysxqt9/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9iihw0tn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162038-9iihw0tn/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bj1uq49r[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162042-bj1uq49r/logs[0m
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=385, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=386, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=387, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=388, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=389, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=390, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=391, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x181blld[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162035-x181blld/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yq8s59cg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162036-yq8s59cg/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o5a7n1yr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162042-o5a7n1yr/logs[0m
wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mdhvki7z[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162042-mdhvki7z/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/adjma4kg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162040-adjma4kg/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=392, wandb_name=random, GPU=0
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162104-qnefizob
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qnefizob
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162104-oh9p277j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oh9p277j
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/na13jueu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162023-na13jueu/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=393, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=394, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=395, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=396, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=397, wandb_name=random, GPU=1
wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=398, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b1o9gh8v[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162008-b1o9gh8v/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162107-yzbkekh7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yzbkekh7
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162106-fgmx9vuf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fgmx9vuf
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162107-vmr1d8hl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vmr1d8hl
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162107-eo73rxi2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/eo73rxi2
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162107-1gfv68vt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1gfv68vt
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162107-88wp61g7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/88wp61g7
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162107-antst6q1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/antst6q1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n10rkaqt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162027-n10rkaqt/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=399, wandb_name=random, GPU=3
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162108-la2rxtoa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/la2rxtoa
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=400, wandb_name=random, GPU=0
wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162110-k6z0ww6b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k6z0ww6b
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162110-plegq076
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/plegq076
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162110-9jw0coqf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9jw0coqf
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162110-cr1qbefe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cr1qbefe
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162110-lod7d8pv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lod7d8pv
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162110-puj1crdy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/puj1crdy
wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162113-2inh78yv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2inh78yv
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162113-lw0hitdf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lw0hitdf
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162042-tkmr2o7i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tkmr2o7i
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xppa5z3t[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162049-xppa5z3t/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oat8tk3w[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162051-oat8tk3w/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7x182yw1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162042-7x182yw1/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5d5vgsr3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162051-5d5vgsr3/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6qsq45um[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162020-6qsq45um/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tbdts75e[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162051-tbdts75e/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xjfwzjgc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162005-xjfwzjgc/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oy142tn7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162051-oy142tn7/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2u0ucdat[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162052-2u0ucdat/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dwzsmxc2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162049-dwzsmxc2/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9nvzhie8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162051-9nvzhie8/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=401, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=402, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2y60oius[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162051-2y60oius/logs[0m
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kjwj3q5h[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162042-kjwj3q5h/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nxtvnjqy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162052-nxtvnjqy/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=403, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=404, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=405, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=406, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=407, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=408, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=409, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=410, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=411, wandb_name=random, GPU=3
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l6zlcjjm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162052-l6zlcjjm/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1el5uagd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162052-1el5uagd/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3qcz9m4z[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162038-3qcz9m4z/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6jopw8dl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162055-6jopw8dl/logs[0m
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162056-yf63nis4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yf63nis4
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/90m4ymdj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162049-90m4ymdj/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=412, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=413, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=414, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5izax248[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162055-5izax248/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: 500 encountered ({"errors":[{"message":"context canceled","path":["upsertBucket"]}],"data":{"upsertBucket":null}}), retrying request
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9chv4cjz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162056-9chv4cjz/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cv60p1cx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162052-cv60p1cx/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=415, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=416, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=417, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=418, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/j0pb5ewy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162056-j0pb5ewy/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/exty3gbs[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162054-exty3gbs/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ba6d8jub[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162055-ba6d8jub/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pd1bjty2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162054-pd1bjty2/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/prgoyjrz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162056-prgoyjrz/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rnjz07l3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162056-rnjz07l3/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162120-yc0m5c1u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yc0m5c1u
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5r3vi3br[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162056-5r3vi3br/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162120-vvfa6qvq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vvfa6qvq
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=419, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=420, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6dn01lb3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162055-6dn01lb3/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6ri0h0qf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162056-6ri0h0qf/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/smqqo3lw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162056-smqqo3lw/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u9y0cznp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162056-u9y0cznp/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=421, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=422, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=423, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=424, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=425, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=426, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=427, wandb_name=random, GPU=3
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=428, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=429, wandb_name=random, GPU=1
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162121-3pksbb20
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3pksbb20
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=430, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=431, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=432, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=433, wandb_name=random, GPU=1
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162121-o82u4ffs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o82u4ffs
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162121-yggtc1ae
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yggtc1ae
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162121-7es8w3lv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7es8w3lv
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162122-v9psnkf1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v9psnkf1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162122-bcf89qm8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bcf89qm8
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162123-1ftnae4p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1ftnae4p
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162123-nzrg1m6d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nzrg1m6d
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162123-88scvln4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/88scvln4
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162123-301z2xnt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/301z2xnt
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162123-whppkybf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/whppkybf
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162124-tdoqqovy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tdoqqovy
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162123-u1gdv2b3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u1gdv2b3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162123-f7fk9hs2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f7fk9hs2
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162124-mku9a10u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mku9a10u
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162124-nu888lch
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nu888lch
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162125-r9cq6ta4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r9cq6ta4
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162125-07l98lag
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/07l98lag
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162127-jc07qsty
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jc07qsty
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162127-dt2245ry
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dt2245ry
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162128-z6liyahd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z6liyahd
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162128-mhk89wfd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mhk89wfd
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162128-ybddxmon
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ybddxmon
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162128-01k4reox
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/01k4reox
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162128-1i1zp3no
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1i1zp3no
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162128-r4zryxkm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r4zryxkm
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162128-tgjvw8e3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tgjvw8e3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162128-jjuxlhrk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jjuxlhrk
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162128-usscb1zx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/usscb1zx
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162128-vrt4yrcx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vrt4yrcx
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162128-z8zk2usy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z8zk2usy
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fo9x30md[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162100-fo9x30md/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oh9p277j[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162104-oh9p277j/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qnefizob[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162104-qnefizob/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yzbkekh7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162107-yzbkekh7/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vmr1d8hl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162107-vmr1d8hl/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1gfv68vt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162107-1gfv68vt/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fgmx9vuf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162106-fgmx9vuf/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/antst6q1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162107-antst6q1/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/88wp61g7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162107-88wp61g7/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rw93yi13[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161956-rw93yi13/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/la2rxtoa[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162108-la2rxtoa/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=434, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=435, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=436, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=437, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=438, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5dbjyqfd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161957-5dbjyqfd/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/eo73rxi2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162107-eo73rxi2/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=439, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=440, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=441, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=442, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=443, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/plegq076[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162110-plegq076/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/puj1crdy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162110-puj1crdy/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=444, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=445, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=446, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lod7d8pv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162110-lod7d8pv/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k6z0ww6b[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162110-k6z0ww6b/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cr1qbefe[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162110-cr1qbefe/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=447, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9jw0coqf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162110-9jw0coqf/logs[0m
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lw0hitdf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162113-lw0hitdf/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162135-5blev8da
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5blev8da
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162135-fakcewzc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fakcewzc
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162135-fj4141ek
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fj4141ek
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=448, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=449, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162136-4ofw98pa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4ofw98pa
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2inh78yv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162113-2inh78yv/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162136-0m5qumz7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0m5qumz7
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=450, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=451, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=452, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=453, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162137-xhl0z2lg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xhl0z2lg
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=454, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162137-brwgzvmc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/brwgzvmc
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162138-hrvd4j1r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hrvd4j1r
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162138-eoaf85ht
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/eoaf85ht
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162138-9wqerp5a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9wqerp5a
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162138-dqw9lso3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dqw9lso3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162138-y24a4qdy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y24a4qdy
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162138-vk39k0xr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vk39k0xr
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162139-8x46oaj9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8x46oaj9
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162141-ve1cu3w9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ve1cu3w9
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162141-qp5cr7tl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qp5cr7tl
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162141-ya23sijx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ya23sijx
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162142-kf1f7z4c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kf1f7z4c
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162142-k80nigw4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k80nigw4
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162142-f4rmkxmt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f4rmkxmt
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162142-4943degt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4943degt
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tkmr2o7i[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162042-tkmr2o7i/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yf63nis4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162056-yf63nis4/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=455, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7qt4s55x[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162036-7qt4s55x/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yc0m5c1u[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162120-yc0m5c1u/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=456, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yggtc1ae[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162121-yggtc1ae/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vvfa6qvq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162120-vvfa6qvq/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=457, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3pksbb20[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162121-3pksbb20/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1ftnae4p[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162123-1ftnae4p/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=458, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=459, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=460, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7es8w3lv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162121-7es8w3lv/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o82u4ffs[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162121-o82u4ffs/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/whppkybf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162123-whppkybf/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162149-kv02w6pc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kv02w6pc
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u1gdv2b3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162123-u1gdv2b3/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=461, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=462, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v9psnkf1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162122-v9psnkf1/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bcf89qm8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162122-bcf89qm8/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mku9a10u[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162124-mku9a10u/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nzrg1m6d[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162123-nzrg1m6d/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162150-tbaj4w4b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tbaj4w4b
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=463, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=464, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=465, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/88scvln4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162123-88scvln4/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f7fk9hs2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162123-f7fk9hs2/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tdoqqovy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162124-tdoqqovy/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nu888lch[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162124-nu888lch/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/07l98lag[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162125-07l98lag/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162151-97zyljbf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/97zyljbf
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=466, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=467, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=468, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=469, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=470, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=471, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=472, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=473, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=474, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=475, wandb_name=random, GPU=3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162153-gwrwmh6d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gwrwmh6d
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162152-3cplw8xj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3cplw8xj
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162153-e87vhmm6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e87vhmm6
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162154-xg9o48gz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xg9o48gz
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162154-obi04shf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/obi04shf
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162155-5f9bdhtu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5f9bdhtu
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162155-tpcbve22
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tpcbve22
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162155-piu6c8hq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/piu6c8hq
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162156-uhjtoexz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uhjtoexz
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162156-bvgqa9ko
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bvgqa9ko
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162156-iptes935
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iptes935
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162156-sar39ase
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sar39ase
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162157-fsap7lxi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fsap7lxi
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162157-2gm45wyv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2gm45wyv
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162157-xkt9h1yk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xkt9h1yk
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162157-8tjmk47i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8tjmk47i
wandb: Tracking run with wandb version 0.19.4
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162158-cjov7iti
wandb: Run `wandb offline` to turn off syncing.
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162157-kftm0cxs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cjov7iti
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kftm0cxs
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ybddxmon[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162128-ybddxmon/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5blev8da[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162135-5blev8da/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=476, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mhk89wfd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162128-mhk89wfd/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fakcewzc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162135-fakcewzc/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jc07qsty[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162127-jc07qsty/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z6liyahd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162128-z6liyahd/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vrt4yrcx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162128-vrt4yrcx/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fj4141ek[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162135-fj4141ek/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dt2245ry[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162127-dt2245ry/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=477, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=478, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cy1h59v5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162051-cy1h59v5/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/01k4reox[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162128-01k4reox/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r4zryxkm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162128-r4zryxkm/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/usscb1zx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162128-usscb1zx/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xhl0z2lg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162137-xhl0z2lg/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=479, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jjuxlhrk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162128-jjuxlhrk/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=480, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=481, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=482, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=483, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=484, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dqw9lso3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162138-dqw9lso3/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=485, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z8zk2usy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162128-z8zk2usy/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/eoaf85ht[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162138-eoaf85ht/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y24a4qdy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162138-y24a4qdy/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/brwgzvmc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162137-brwgzvmc/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tgjvw8e3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162128-tgjvw8e3/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1i1zp3no[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162128-1i1zp3no/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hrvd4j1r[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162138-hrvd4j1r/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8x46oaj9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162139-8x46oaj9/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=486, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=487, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=488, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=489, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9wqerp5a[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162138-9wqerp5a/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162204-ly4nb872
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ly4nb872
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qp5cr7tl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162141-qp5cr7tl/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vk39k0xr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162138-vk39k0xr/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f6wftqw6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162051-f6wftqw6/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=490, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=491, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=492, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=493, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=494, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=495, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=496, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=497, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=498, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=499, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ve1cu3w9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162141-ve1cu3w9/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=500, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ya23sijx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162141-ya23sijx/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kf1f7z4c[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162142-kf1f7z4c/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f4rmkxmt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162142-f4rmkxmt/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k80nigw4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162142-k80nigw4/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162206-b95kzjg2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b95kzjg2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162206-fgn7f2fj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fgn7f2fj
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=0, wandb_name=random, GPU=1
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4943degt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162142-4943degt/logs[0m
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162207-tekaduwy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tekaduwy
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162207-wjn053fk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wjn053fk
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=1, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=2, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=3, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=4, wandb_name=random, GPU=1
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162207-s5yu1llq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s5yu1llq
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162207-uffpvjf1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uffpvjf1
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162207-b6hdi0e0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b6hdi0e0
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162207-hmeaw2jw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hmeaw2jw
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162207-jzov4vnm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jzov4vnm
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=5, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=6, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=7, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=8, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162209-qfhfa3ai
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qfhfa3ai
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162209-7f1rj0a7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7f1rj0a7
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162209-g8mcgf9o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g8mcgf9o
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162209-sn13yfnl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sn13yfnl
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162210-cn0p8ogq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cn0p8ogq
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162210-axo38ylb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/axo38ylb
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162210-2ved36nr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2ved36nr
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162210-besaou2v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/besaou2v
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162210-ukrie7ed
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ukrie7ed
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162211-p9f1t33t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p9f1t33t
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162211-ar6r7w0i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ar6r7w0i
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162211-6ubeza0z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6ubeza0z
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162211-rdx8xyuu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rdx8xyuu
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162211-1lfxmye5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1lfxmye5
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162211-ua2nps4x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ua2nps4x
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162211-n064ikj9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n064ikj9
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162212-32r8yowm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/32r8yowm
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162212-39nzmx2g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/39nzmx2g
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162212-76w1o0k4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/76w1o0k4
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162213-ct4ojs73
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ct4ojs73
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162215-gxwrqwan
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gxwrqwan
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162215-k4xdkcm8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k4xdkcm8
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162215-dw5alm0t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dw5alm0t
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162215-iqkf7xts
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iqkf7xts
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/97zyljbf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162151-97zyljbf/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kv02w6pc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162149-kv02w6pc/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tbaj4w4b[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162150-tbaj4w4b/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3cplw8xj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162152-3cplw8xj/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gwrwmh6d[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162153-gwrwmh6d/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/obi04shf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162154-obi04shf/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e87vhmm6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162153-e87vhmm6/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=9, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=10, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=11, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xg9o48gz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162154-xg9o48gz/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=12, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/piu6c8hq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162155-piu6c8hq/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=13, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=14, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=15, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tpcbve22[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162155-tpcbve22/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5f9bdhtu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162155-5f9bdhtu/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sar39ase[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162156-sar39ase/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=16, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=17, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iptes935[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162156-iptes935/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bvgqa9ko[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162156-bvgqa9ko/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fsap7lxi[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162157-fsap7lxi/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uhjtoexz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162156-uhjtoexz/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=18, wandb_name=random, GPU=3
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=19, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162221-lwjfwfc3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lwjfwfc3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162221-tdp0wq0m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tdp0wq0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2gm45wyv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162157-2gm45wyv/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162221-qb8bcbl7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qb8bcbl7
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=20, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=21, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=22, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8tjmk47i[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162157-8tjmk47i/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162221-ssxhucld
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ssxhucld
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cjov7iti[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162158-cjov7iti/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kftm0cxs[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162157-kftm0cxs/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=23, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=24, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162223-rgd7uq9h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rgd7uq9h
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162223-x78gs54w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x78gs54w
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=25, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=26, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=27, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=28, wandb_name=random, GPU=1
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162223-p23v4u1v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p23v4u1v
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162223-7ghea3hm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7ghea3hm
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162224-lucyt1vn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lucyt1vn
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162224-0h4ov4kr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0h4ov4kr
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162225-py2etbhg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/py2etbhg
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162226-qhy0vbbo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qhy0vbbo
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162226-gsx5xn3j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gsx5xn3j
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162226-laeejqe1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/laeejqe1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162226-6txl8prl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6txl8prl
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162227-68p54tp8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/68p54tp8
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162228-v0wnxpnn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v0wnxpnn
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162228-xb4ktm2h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xb4ktm2h
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162228-v0da05vv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v0da05vv
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162228-whysiw33
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/whysiw33
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ly4nb872[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162204-ly4nb872/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b95kzjg2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162206-b95kzjg2/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=29, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b6hdi0e0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162207-b6hdi0e0/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=30, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tekaduwy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162207-tekaduwy/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jzov4vnm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162207-jzov4vnm/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uffpvjf1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162207-uffpvjf1/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wjn053fk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162207-wjn053fk/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s5yu1llq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162207-s5yu1llq/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hmeaw2jw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162207-hmeaw2jw/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qfhfa3ai[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162209-qfhfa3ai/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=31, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=32, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=33, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=34, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sn13yfnl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162209-sn13yfnl/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162235-jjdyjzio
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jjdyjzio
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g8mcgf9o[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162209-g8mcgf9o/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vy1v2x45[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162059-vy1v2x45/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=35, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=36, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=37, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=38, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7f1rj0a7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162209-7f1rj0a7/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162236-pej7s6wp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pej7s6wp
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cn0p8ogq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162210-cn0p8ogq/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=39, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=40, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n064ikj9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162211-n064ikj9/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2ved36nr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162210-2ved36nr/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6ubeza0z[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162211-6ubeza0z/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ar6r7w0i[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162211-ar6r7w0i/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1lfxmye5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162211-1lfxmye5/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=41, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=42, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=43, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/besaou2v[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162210-besaou2v/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162238-arb2r62v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/arb2r62v
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162238-mrczwjcr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mrczwjcr
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162238-u83516aw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u83516aw
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=44, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=45, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=46, wandb_name=random, GPU=3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162239-ravl8mcv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ravl8mcv
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=47, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=48, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=49, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162240-7naziijh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7naziijh
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162240-qxlmyst2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qxlmyst2
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162241-ei96c1sk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ei96c1sk
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162241-8lllhh9q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8lllhh9q
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162241-gbqycyuk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gbqycyuk
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162241-hevxgrvx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hevxgrvx
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162241-eoqxqprn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/eoqxqprn
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162241-6a5adaqd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6a5adaqd
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162242-dcvecdh5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dcvecdh5
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162243-0cbfmkf1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0cbfmkf1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162243-77k1k69g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/77k1k69g
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162243-n85fxrya
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n85fxrya
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162244-ohcvio4j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ohcvio4j
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162244-52npxp6q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/52npxp6q
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162244-rsye7ebf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rsye7ebf
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p9f1t33t[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162211-p9f1t33t/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rdx8xyuu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162211-rdx8xyuu/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/axo38ylb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162210-axo38ylb/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ua2nps4x[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162211-ua2nps4x/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ssxhucld[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162221-ssxhucld/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tdp0wq0m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162221-tdp0wq0m/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ukrie7ed[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162210-ukrie7ed/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=50, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lwjfwfc3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162221-lwjfwfc3/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qb8bcbl7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162221-qb8bcbl7/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gxwrqwan[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162215-gxwrqwan/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/39nzmx2g[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162212-39nzmx2g/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rgd7uq9h[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162223-rgd7uq9h/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p23v4u1v[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162223-p23v4u1v/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=51, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=52, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=53, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=54, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=55, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=56, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=57, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iqkf7xts[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162215-iqkf7xts/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/76w1o0k4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162212-76w1o0k4/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/32r8yowm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162212-32r8yowm/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ct4ojs73[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162213-ct4ojs73/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k4xdkcm8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162215-k4xdkcm8/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lucyt1vn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162224-lucyt1vn/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0h4ov4kr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162224-0h4ov4kr/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=58, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=59, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=60, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=61, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dw5alm0t[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162215-dw5alm0t/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x78gs54w[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162223-x78gs54w/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7ghea3hm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162223-7ghea3hm/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/py2etbhg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162225-py2etbhg/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qhy0vbbo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162226-qhy0vbbo/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=62, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=63, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=64, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=65, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=66, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=67, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=68, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=69, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gsx5xn3j[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162226-gsx5xn3j/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/laeejqe1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162226-laeejqe1/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162249-p3v63tno
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p3v63tno
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/68p54tp8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162227-68p54tp8/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=70, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=71, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=72, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=73, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6txl8prl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162226-6txl8prl/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162250-73u0ad04
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/73u0ad04
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162251-pk4abltr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pk4abltr
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=74, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=75, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=76, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=77, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/whysiw33[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162228-whysiw33/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162251-trod7q9y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/trod7q9y
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v0da05vv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162228-v0da05vv/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162251-iml7yq6n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iml7yq6n
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162251-tgt6rgie
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tgt6rgie
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162251-zo7iirzt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zo7iirzt
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xb4ktm2h[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162228-xb4ktm2h/logs[0m
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v0wnxpnn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162228-v0wnxpnn/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162252-ld6r0c0x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ld6r0c0x
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162252-bqv85psb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bqv85psb
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162252-4t0ifdba
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4t0ifdba
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162252-92b8fjgj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/92b8fjgj
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162252-tesk6dg2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tesk6dg2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=78, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=79, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=80, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=81, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=82, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162255-qm3ki6yr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qm3ki6yr
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162255-jlcu5tw2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jlcu5tw2
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162255-j9i2k91g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/j9i2k91g
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162255-vps7ol4i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vps7ol4i
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162255-1kp3yqri
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1kp3yqri
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162255-azpehfcf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/azpehfcf
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162255-wl6hgtve
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wl6hgtve
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162255-y38cnj52
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y38cnj52
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162255-6fm7yipt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6fm7yipt
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162256-3vu4724j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3vu4724j
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162256-8j99hcwh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8j99hcwh
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162255-4zusedu2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4zusedu2
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162258-vz9rs3co
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vz9rs3co
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162258-r8g24d79
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r8g24d79
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162258-km2x0iud
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/km2x0iud
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162256-0qu6rqi7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0qu6rqi7
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162259-m5tn4z4y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m5tn4z4y
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162259-b85eib5k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b85eib5k
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162259-zuyqb42p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zuyqb42p
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162259-8gqjhcbo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8gqjhcbo
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bppgk2z1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162036-bppgk2z1/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=83, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/arb2r62v[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162238-arb2r62v/logs[0m
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jjdyjzio[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162235-jjdyjzio/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mrczwjcr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162238-mrczwjcr/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ravl8mcv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162239-ravl8mcv/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=84, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=85, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=86, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7naziijh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162240-7naziijh/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qxlmyst2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162240-qxlmyst2/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6a5adaqd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162241-6a5adaqd/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=87, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4ofw98pa[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162136-4ofw98pa/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8lllhh9q[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162241-8lllhh9q/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hevxgrvx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162241-hevxgrvx/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gbqycyuk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162241-gbqycyuk/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/eoqxqprn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162241-eoqxqprn/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162304-kou1mw02
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kou1mw02
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dcvecdh5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162242-dcvecdh5/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=88, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=89, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u83516aw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162238-u83516aw/logs[0m
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ei96c1sk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162241-ei96c1sk/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0cbfmkf1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162243-0cbfmkf1/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n85fxrya[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162243-n85fxrya/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/77k1k69g[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162243-77k1k69g/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=90, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=91, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=92, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=93, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=94, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=95, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=96, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162307-kxmvogra
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kxmvogra
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162307-485zpplo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/485zpplo
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=97, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ohcvio4j[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162244-ohcvio4j/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=98, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=99, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=100, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162259-3e4lnpzq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3e4lnpzq
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162307-z22dalej
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z22dalej
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162308-jff0t0ik
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jff0t0ik
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=101, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162309-rc3880va
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rc3880va
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=102, wandb_name=random, GPU=3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162309-yj5r6a7m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yj5r6a7m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162310-snir5v11
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/snir5v11
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162310-gxdkgn7l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gxdkgn7l
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162310-r8fkh7zs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r8fkh7zs
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162311-nop4ufz5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nop4ufz5
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162311-rbwfbzjj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rbwfbzjj
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162312-nsteflxv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nsteflxv
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162312-rphqytga
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rphqytga
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162312-esn0yhfx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/esn0yhfx
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162313-g4c68mcx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g4c68mcx
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162313-g0jbqi4u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g0jbqi4u
wandb: / Waiting for wandb.init()...wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162315-np0wg04o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/np0wg04o
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/52npxp6q[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162244-52npxp6q/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rsye7ebf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162244-rsye7ebf/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162315-0xhc297i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0xhc297i
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pk4abltr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162251-pk4abltr/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=103, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p3v63tno[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162249-p3v63tno/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/trod7q9y[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162251-trod7q9y/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/73u0ad04[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162250-73u0ad04/logs[0m
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162310-hxjnfm02
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hxjnfm02
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iml7yq6n[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162251-iml7yq6n/logs[0m
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=104, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=105, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zo7iirzt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162251-zo7iirzt/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tgt6rgie[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162251-tgt6rgie/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fgn7f2fj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162206-fgn7f2fj/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ld6r0c0x[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162252-ld6r0c0x/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=106, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=107, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=108, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=109, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4t0ifdba[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162252-4t0ifdba/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/92b8fjgj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162252-92b8fjgj/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tesk6dg2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162252-tesk6dg2/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bqv85psb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162252-bqv85psb/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=110, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=111, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=112, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=113, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qm3ki6yr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162255-qm3ki6yr/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1kp3yqri[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162255-1kp3yqri/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/j9i2k91g[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162255-j9i2k91g/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162320-276vfwib
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/276vfwib
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=114, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=115, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wl6hgtve[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162255-wl6hgtve/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162321-6oj7rpru
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6oj7rpru
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jlcu5tw2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162255-jlcu5tw2/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/azpehfcf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162255-azpehfcf/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=116, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=117, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=118, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=119, wandb_name=random, GPU=0
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162321-2tyl4fdz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2tyl4fdz
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vps7ol4i[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162255-vps7ol4i/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3vu4724j[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162256-3vu4724j/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162322-txwdslpl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/txwdslpl
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y38cnj52[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162255-y38cnj52/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=120, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=121, wandb_name=random, GPU=2
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162322-id5pnabl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/id5pnabl
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162322-gv2skapm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gv2skapm
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162323-e0hx19u2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e0hx19u2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=122, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=123, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=124, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=125, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=126, wandb_name=random, GPU=3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162323-zombu8uk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zombu8uk
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162323-sqrgiz00
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sqrgiz00
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162324-wy7aq1qo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wy7aq1qo
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162324-76pjtqj4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/76pjtqj4
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162325-dlqt4tps
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dlqt4tps
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162325-g2mx56es
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g2mx56es
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162325-noqlp2u1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/noqlp2u1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162326-hp7j700o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hp7j700o
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162326-jlf16ktc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jlf16ktc
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162326-5qjpr2is
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5qjpr2is
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162327-q0vezy0j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q0vezy0j
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162327-zbf8a5sv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zbf8a5sv
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162327-3utnul00
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3utnul00
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162327-4uhrcui2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4uhrcui2
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162328-ynpi1unl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ynpi1unl
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162328-yw5qmfk7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yw5qmfk7
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162328-chbw7em6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/chbw7em6
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8j99hcwh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162256-8j99hcwh/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vz9rs3co[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162258-vz9rs3co/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6fm7yipt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162255-6fm7yipt/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4zusedu2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162255-4zusedu2/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r8g24d79[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162258-r8g24d79/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kou1mw02[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162304-kou1mw02/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kxmvogra[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162307-kxmvogra/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m5tn4z4y[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162259-m5tn4z4y/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xkt9h1yk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162157-xkt9h1yk/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0qu6rqi7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162256-0qu6rqi7/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/km2x0iud[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162258-km2x0iud/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3e4lnpzq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162259-3e4lnpzq/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=127, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=128, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=129, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=130, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=131, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b85eib5k[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162259-b85eib5k/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zuyqb42p[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162259-zuyqb42p/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/485zpplo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162307-485zpplo/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z22dalej[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162307-z22dalej/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8gqjhcbo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162259-8gqjhcbo/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jff0t0ik[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162308-jff0t0ik/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=132, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=133, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=134, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=135, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=136, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=137, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=138, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=139, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yj5r6a7m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162309-yj5r6a7m/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rc3880va[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162309-rc3880va/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=140, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=141, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=142, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=143, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=144, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/snir5v11[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162310-snir5v11/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r8fkh7zs[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162310-r8fkh7zs/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rbwfbzjj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162311-rbwfbzjj/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=145, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=146, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gxdkgn7l[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162310-gxdkgn7l/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rphqytga[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162312-rphqytga/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162335-e25ea82n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e25ea82n
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162335-0921uzxe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0921uzxe
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162335-3u4koyf9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3u4koyf9
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162335-rgyh2feg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rgyh2feg
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=147, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=148, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nop4ufz5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162311-nop4ufz5/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/esn0yhfx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162312-esn0yhfx/logs[0m
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g4c68mcx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162313-g4c68mcx/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=149, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=150, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=151, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nsteflxv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162312-nsteflxv/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=152, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=153, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=154, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162337-3r90ctti
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3r90ctti
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162337-68jeu7lb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/68jeu7lb
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162338-umbr10c4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/umbr10c4
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162338-ul28q1nm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ul28q1nm
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162338-tmn5d25r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tmn5d25r
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162338-ghtbpmxq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ghtbpmxq
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162338-lu0gjqme
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lu0gjqme
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=155, wandb_name=random, GPU=0
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162338-ohvqisi2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ohvqisi2
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162339-95tjcfmx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/95tjcfmx
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162338-q4o4rsm6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q4o4rsm6
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162339-ynwyglwm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ynwyglwm
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162335-i3frxuxo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/i3frxuxo
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162339-tbtygmwp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tbtygmwp
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162339-7hlnpkgp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7hlnpkgp
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162339-1l1ozg7i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1l1ozg7i
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162340-z75x71q9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z75x71q9
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162341-l1k5le4j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l1k5le4j
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162341-j35dl215
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/j35dl215
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162342-jp8qpltq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jp8qpltq
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162342-34eb51cm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/34eb51cm
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162343-af13kfe1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/af13kfe1
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162343-3hdk8lg8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3hdk8lg8
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162343-vzdjuwu9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vzdjuwu9
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162343-e7tkv4ag
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e7tkv4ag
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162344-4bs1xwn7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4bs1xwn7
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/np0wg04o[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162315-np0wg04o/logs[0m
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g0jbqi4u[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162313-g0jbqi4u/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6oj7rpru[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162321-6oj7rpru/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/276vfwib[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162320-276vfwib/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=156, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=157, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sqrgiz00[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162323-sqrgiz00/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0xhc297i[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162315-0xhc297i/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=158, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=159, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e0hx19u2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162323-e0hx19u2/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gv2skapm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162322-gv2skapm/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/id5pnabl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162322-id5pnabl/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zombu8uk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162323-zombu8uk/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=160, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wy7aq1qo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162324-wy7aq1qo/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hxjnfm02[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162310-hxjnfm02/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=161, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=162, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=163, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=164, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=165, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/txwdslpl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162322-txwdslpl/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5qjpr2is[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162326-5qjpr2is/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/76pjtqj4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162324-76pjtqj4/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g2mx56es[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162325-g2mx56es/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/noqlp2u1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162325-noqlp2u1/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162349-gls5n4ni
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gls5n4ni
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162350-vaz97bxd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vaz97bxd
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dlqt4tps[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162325-dlqt4tps/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=166, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=167, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hp7j700o[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162326-hp7j700o/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jlf16ktc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162326-jlf16ktc/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3utnul00[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162327-3utnul00/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=168, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=169, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=170, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=171, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=172, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=173, wandb_name=random, GPU=2
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162351-xe2hs1d5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xe2hs1d5
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162350-o0ejmopj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o0ejmopj
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4uhrcui2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162327-4uhrcui2/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q0vezy0j[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162327-q0vezy0j/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=174, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=175, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=176, wandb_name=random, GPU=1
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162352-vkx91bta
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vkx91bta
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=177, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=178, wandb_name=random, GPU=3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162353-8dssv92m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8dssv92m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162353-bv1aew3a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bv1aew3a
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162353-8n78tnvr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8n78tnvr
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162354-ukes7axz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ukes7axz
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162354-vgr1afkx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vgr1afkx
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162355-6f2vydul
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6f2vydul
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162356-bciyz0gk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bciyz0gk
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162356-bvqdnbwo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bvqdnbwo
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162356-wm9yjzmd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wm9yjzmd
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162356-iu65be1i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iu65be1i
wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162356-4pu8chmi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4pu8chmi
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162356-crdxz8bi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/crdxz8bi
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162353-3a81nf7z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3a81nf7z
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162356-hsj3wi3r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hsj3wi3r
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162356-7v5zah3n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7v5zah3n
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162356-nskailc0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nskailc0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162358-fbc0zmn7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fbc0zmn7
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162359-0rvct4zl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0rvct4zl
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ynpi1unl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162328-ynpi1unl/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yw5qmfk7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162328-yw5qmfk7/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zbf8a5sv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162327-zbf8a5sv/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3u4koyf9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162335-3u4koyf9/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=179, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=180, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=181, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0921uzxe[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162335-0921uzxe/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rgyh2feg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162335-rgyh2feg/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=182, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e25ea82n[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162335-e25ea82n/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ul28q1nm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162338-ul28q1nm/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3r90ctti[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162337-3r90ctti/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=183, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=184, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/68jeu7lb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162337-68jeu7lb/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/umbr10c4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162338-umbr10c4/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=185, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=186, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=187, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ghtbpmxq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162338-ghtbpmxq/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tmn5d25r[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162338-tmn5d25r/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pej7s6wp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162236-pej7s6wp/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162405-a5x1o0is
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a5x1o0is
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=188, wandb_name=random, GPU=1
wandb: Tracking run with wandb version 0.19.4
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lu0gjqme[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162338-lu0gjqme/logs[0m
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162405-c6ax9mtm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c6ax9mtm
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162405-4354v24m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4354v24m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ynwyglwm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162339-ynwyglwm/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tbtygmwp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162339-tbtygmwp/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7hlnpkgp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162339-7hlnpkgp/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1l1ozg7i[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162339-1l1ozg7i/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=189, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=190, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=191, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=192, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/95tjcfmx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162339-95tjcfmx/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ohvqisi2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162338-ohvqisi2/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/i3frxuxo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162335-i3frxuxo/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l1k5le4j[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162341-l1k5le4j/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162406-r7b36ldd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r7b36ldd
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q4o4rsm6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162338-q4o4rsm6/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=193, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=194, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=195, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=196, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162407-n48gzsn9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n48gzsn9
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162408-4zwhe0jh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4zwhe0jh
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162408-p07203vl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p07203vl
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=197, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=198, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=199, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=200, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=201, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=202, wandb_name=random, GPU=3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162408-x568exef
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x568exef
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162408-sa1u3icm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sa1u3icm
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162409-4gzxkidt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4gzxkidt
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162410-wfs0xrx5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wfs0xrx5
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162410-je4j0u4z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/je4j0u4z
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162410-83vw4xa2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/83vw4xa2
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162411-majpa8vk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/majpa8vk
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162411-tsg209f5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tsg209f5
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162412-00otltrc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/00otltrc
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162413-322lmph9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/322lmph9
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162413-ktgu8qe4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ktgu8qe4
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162413-uspiyfwa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uspiyfwa
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162413-9dqln7q8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9dqln7q8
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162410-mbkf67wo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mbkf67wo
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162413-5r1ob9se
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5r1ob9se
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162413-e82n358a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e82n358a
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162414-d25bt2uw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/d25bt2uw
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jbny4rqk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161942-jbny4rqk/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gls5n4ni[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162349-gls5n4ni/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/af13kfe1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162343-af13kfe1/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2tyl4fdz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162321-2tyl4fdz/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3hdk8lg8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162343-3hdk8lg8/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/34eb51cm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162342-34eb51cm/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vzdjuwu9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162343-vzdjuwu9/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/j35dl215[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162341-j35dl215/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=203, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=204, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=205, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=206, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e7tkv4ag[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162343-e7tkv4ag/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jp8qpltq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162342-jp8qpltq/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vkx91bta[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162352-vkx91bta/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vaz97bxd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162350-vaz97bxd/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4bs1xwn7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162344-4bs1xwn7/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=207, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=208, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=209, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=210, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ukes7axz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162354-ukes7axz/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z75x71q9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162340-z75x71q9/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=211, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=212, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=213, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=214, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=215, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=216, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=217, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bvqdnbwo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162356-bvqdnbwo/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162420-hmfebsaj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hmfebsaj
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162420-gcomfpjm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gcomfpjm
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8n78tnvr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162353-8n78tnvr/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162420-dzhp1wkj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dzhp1wkj
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3a81nf7z[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162353-3a81nf7z/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162420-hqsu3enr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hqsu3enr
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hsj3wi3r[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162356-hsj3wi3r/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vgr1afkx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162354-vgr1afkx/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nskailc0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162356-nskailc0/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bv1aew3a[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162353-bv1aew3a/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wm9yjzmd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162356-wm9yjzmd/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7v5zah3n[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162356-7v5zah3n/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bciyz0gk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162356-bciyz0gk/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8dssv92m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162353-8dssv92m/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iu65be1i[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162356-iu65be1i/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=218, wandb_name=random, GPU=3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162421-7g56ie00
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7g56ie00
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162421-vevg4gff
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vevg4gff
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=219, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=220, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=221, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=222, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=223, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=224, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=225, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=226, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=227, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=228, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=229, wandb_name=random, GPU=2
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162422-7qcrfmfl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7qcrfmfl
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162422-luho3t5o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/luho3t5o
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162424-jz8e0lw2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jz8e0lw2
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162424-68jra0si
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/68jra0si
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162424-rjo2de9h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rjo2de9h
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162424-9sop1kbf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9sop1kbf
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162424-75vxh38z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/75vxh38z
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162424-8sr445b1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8sr445b1
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162424-tqf4pgs5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tqf4pgs5
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162425-hff97qv6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hff97qv6
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162427-gp58w9o4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gp58w9o4
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162427-tvy2at75
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tvy2at75
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162427-56pvsk31
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/56pvsk31
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162427-6p20692i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6p20692i
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162427-uwht10ze
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uwht10ze
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162427-7w8dcnah
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7w8dcnah
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162427-xq9rg52r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xq9rg52r
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162427-89lpmhu5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/89lpmhu5
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162427-auevqtv3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/auevqtv3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162427-gd8x3fu2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gd8x3fu2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0rvct4zl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162359-0rvct4zl/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=230, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c6ax9mtm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162405-c6ax9mtm/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p07203vl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162408-p07203vl/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x568exef[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162408-x568exef/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sa1u3icm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162408-sa1u3icm/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162432-yvpk77we
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yvpk77we
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4gzxkidt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162409-4gzxkidt/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=231, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=232, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=233, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wfs0xrx5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162410-wfs0xrx5/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/je4j0u4z[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162410-je4j0u4z/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=234, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=235, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a5x1o0is[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162405-a5x1o0is/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162434-fkuz0ic1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fkuz0ic1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tsg209f5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162411-tsg209f5/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=236, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/majpa8vk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162411-majpa8vk/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n48gzsn9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162407-n48gzsn9/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4pu8chmi[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162356-4pu8chmi/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/00otltrc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162412-00otltrc/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r7b36ldd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162406-r7b36ldd/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/83vw4xa2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162410-83vw4xa2/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4zwhe0jh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162408-4zwhe0jh/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=237, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=238, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=239, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/322lmph9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162413-322lmph9/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4354v24m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162405-4354v24m/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uspiyfwa[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162413-uspiyfwa/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9dqln7q8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162413-9dqln7q8/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162436-fkvzpghq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fkvzpghq
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162436-d0wxrzzu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/d0wxrzzu
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162436-1u5vykp1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1u5vykp1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ktgu8qe4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162413-ktgu8qe4/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=240, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=241, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=242, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=243, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=244, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=245, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5r1ob9se[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162413-5r1ob9se/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e82n358a[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162413-e82n358a/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162437-z1oyyp4s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z1oyyp4s
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=246, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=247, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=248, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=249, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=250, wandb_name=random, GPU=3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162438-0t09kwih
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0t09kwih
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=251, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=252, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=253, wandb_name=random, GPU=2
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162439-wy73bqcr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wy73bqcr
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162440-y4mg5sic
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y4mg5sic
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162440-enj4gbgk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/enj4gbgk
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162440-czxqgi8m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/czxqgi8m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162441-j9ze8473
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/j9ze8473
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162440-nnh0u4ka
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nnh0u4ka
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162441-nkvvmg9b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nkvvmg9b
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162441-oe3i0udv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oe3i0udv
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162441-gxq40a9f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gxq40a9f
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162441-hay9fob3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hay9fob3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162442-r06c1cr1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r06c1cr1
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162443-3gzajmcw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3gzajmcw
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162442-fvkim87s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fvkim87s
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162443-p9r7bz24
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p9r7bz24
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162443-sv1yzod8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sv1yzod8
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162443-fbpg65dh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fbpg65dh
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162444-aw3k2wsi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/aw3k2wsi
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hmfebsaj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162420-hmfebsaj/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162444-g7wwl7gx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g7wwl7gx
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hqsu3enr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162420-hqsu3enr/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gcomfpjm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162420-gcomfpjm/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dzhp1wkj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162420-dzhp1wkj/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=254, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vevg4gff[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162421-vevg4gff/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7g56ie00[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162421-7g56ie00/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7qcrfmfl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162422-7qcrfmfl/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/luho3t5o[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162422-luho3t5o/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=255, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=256, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=257, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jz8e0lw2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162424-jz8e0lw2/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rjo2de9h[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162424-rjo2de9h/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=258, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=259, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=260, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=261, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tqf4pgs5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162424-tqf4pgs5/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/68jra0si[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162424-68jra0si/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8sr445b1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162424-8sr445b1/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9sop1kbf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162424-9sop1kbf/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=262, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hff97qv6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162425-hff97qv6/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=263, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/75vxh38z[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162424-75vxh38z/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162450-unejl91n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/unejl91n
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=264, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=265, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=266, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=267, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162450-coi957i4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/coi957i4
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162451-jvlc6dtm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jvlc6dtm
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162451-j2tj4igm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/j2tj4igm
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6p20692i[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162427-6p20692i/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=268, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=269, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gp58w9o4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162427-gp58w9o4/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/auevqtv3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162427-auevqtv3/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/89lpmhu5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162427-89lpmhu5/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tvy2at75[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162427-tvy2at75/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/56pvsk31[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162427-56pvsk31/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uwht10ze[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162427-uwht10ze/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gd8x3fu2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162427-gd8x3fu2/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7w8dcnah[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162427-7w8dcnah/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162452-h4obj3tg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h4obj3tg
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162453-rhh4jeqg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rhh4jeqg
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162453-looz5wc7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/looz5wc7
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162453-f1f3w8qm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f1f3w8qm
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=270, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=271, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=272, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=273, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=274, wandb_name=random, GPU=3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162453-rpxbyg93
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rpxbyg93
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=275, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=276, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=277, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=278, wandb_name=random, GPU=3
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162455-amz7zjbu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/amz7zjbu
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162455-7illm4ag
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7illm4ag
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: | Waiting for wandb.init()...wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162455-py1h0oym
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/py1h0oym
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162452-n69p34fn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n69p34fn
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162455-r4yrcmwz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r4yrcmwz
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162456-hay9c6pk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hay9c6pk
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162456-q4bsuixk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q4bsuixk
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162457-z3k0aqbg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z3k0aqbg
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162458-hib1q0uc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hib1q0uc
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162458-vl5ivrl2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vl5ivrl2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162458-17o8j4kr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/17o8j4kr
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162458-ax4pkyph
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ax4pkyph
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162458-rjyrr2di
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rjyrr2di
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162458-gjkkg4dn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gjkkg4dn
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162458-pbhfdlk4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pbhfdlk4
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162459-7tirapaf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7tirapaf
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xq9rg52r[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162427-xq9rg52r/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fkuz0ic1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162434-fkuz0ic1/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/d0wxrzzu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162436-d0wxrzzu/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/chbw7em6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162328-chbw7em6/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fkvzpghq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162436-fkvzpghq/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=279, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=280, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0t09kwih[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162438-0t09kwih/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z1oyyp4s[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162437-z1oyyp4s/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wy73bqcr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162439-wy73bqcr/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yvpk77we[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162432-yvpk77we/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=281, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=282, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=283, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y4mg5sic[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162440-y4mg5sic/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=284, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=285, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=286, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=287, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/czxqgi8m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162440-czxqgi8m/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nnh0u4ka[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162440-nnh0u4ka/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=288, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oe3i0udv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162441-oe3i0udv/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162505-nu7nm9p5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nu7nm9p5
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gxq40a9f[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162441-gxq40a9f/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=289, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hay9fob3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162441-hay9fob3/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162506-h1ss5384
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h1ss5384
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nkvvmg9b[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162441-nkvvmg9b/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fvkim87s[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162442-fvkim87s/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162506-hq1hy2x9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hq1hy2x9
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=290, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=291, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162506-g6r6sg1v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g6r6sg1v
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162507-bh62ppn1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bh62ppn1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g7wwl7gx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162444-g7wwl7gx/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=292, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=293, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=294, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=295, wandb_name=random, GPU=0
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162507-864t99vv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/864t99vv
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r06c1cr1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162442-r06c1cr1/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fbpg65dh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162443-fbpg65dh/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162508-1ksheaam
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1ksheaam
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/301z2xnt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162123-301z2xnt/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=296, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162509-cp8epn59
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cp8epn59
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=297, wandb_name=random, GPU=2
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162509-ypt0ah9h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ypt0ah9h
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=298, wandb_name=random, GPU=3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162509-ec4xcl5u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ec4xcl5u
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=299, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162510-fgumg7xp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fgumg7xp
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162510-aujgx8s2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/aujgx8s2
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162511-n8r4pghf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n8r4pghf
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162512-rvgjnn84
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rvgjnn84
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162512-37fikm5u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/37fikm5u
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162512-iraym3x1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iraym3x1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162512-lox849r4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lox849r4
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: | Waiting for wandb.init()...wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162514-94s8h63h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/94s8h63h
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162514-utb2rg6n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/utb2rg6n
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jvlc6dtm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162451-jvlc6dtm/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/enj4gbgk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162440-enj4gbgk/logs[0m
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/unejl91n[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162450-unejl91n/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/coi957i4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162450-coi957i4/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=300, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=301, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sv1yzod8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162443-sv1yzod8/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162515-o6pctx2i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o6pctx2i
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/aw3k2wsi[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162444-aw3k2wsi/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162510-apq4dbpj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/apq4dbpj
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3gzajmcw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162443-3gzajmcw/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p9r7bz24[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162443-p9r7bz24/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=302, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=303, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/j2tj4igm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162451-j2tj4igm/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f1f3w8qm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162453-f1f3w8qm/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rhh4jeqg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162453-rhh4jeqg/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=304, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=305, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=306, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7illm4ag[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162455-7illm4ag/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=307, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=308, wandb_name=random, GPU=1
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=309, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=310, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/j9ze8473[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162441-j9ze8473/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o0ejmopj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162350-o0ejmopj/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/py1h0oym[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162455-py1h0oym/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n69p34fn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162452-n69p34fn/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z3k0aqbg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162457-z3k0aqbg/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162519-4jts48p0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4jts48p0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q4bsuixk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162456-q4bsuixk/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162519-7jsvxyz2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7jsvxyz2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/looz5wc7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162453-looz5wc7/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=311, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h4obj3tg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162452-h4obj3tg/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rpxbyg93[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162453-rpxbyg93/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162520-n27zsom2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n27zsom2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=312, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=313, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=314, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=315, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=316, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=317, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=318, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/amz7zjbu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162455-amz7zjbu/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7tirapaf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162459-7tirapaf/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162520-uytd1ji9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uytd1ji9
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ax4pkyph[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162458-ax4pkyph/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gjkkg4dn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162458-gjkkg4dn/logs[0m
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/17o8j4kr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162458-17o8j4kr/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hay9c6pk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162456-hay9c6pk/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=319, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=320, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hib1q0uc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162458-hib1q0uc/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162522-lc4k33fb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lc4k33fb
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162522-6a76kcft
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6a76kcft
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=321, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=322, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=323, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=324, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=325, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=326, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162523-5nshixxs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5nshixxs
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162523-0pxjh8us
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0pxjh8us
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162522-f6h0beo8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f6h0beo8
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162524-3dyrv8r4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3dyrv8r4
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=327, wandb_name=random, GPU=0
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162525-1bj3fzj8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1bj3fzj8
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162525-xy9gfyp2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xy9gfyp2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162525-oac0lkvu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oac0lkvu
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162526-vnil3u90
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vnil3u90
wandb: - Waiting for wandb.init()...wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162526-yxg4vwri
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yxg4vwri
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162525-epc3lyav
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/epc3lyav
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162522-k9rocyl2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k9rocyl2
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162527-dhx0zq6i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dhx0zq6i
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162527-y5rs9t0y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y5rs9t0y
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162527-45hfard1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/45hfard1
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162527-tmtd33x5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tmtd33x5
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162527-tzqzfz3o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tzqzfz3o
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162527-0s9193sv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0s9193sv
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pbhfdlk4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162458-pbhfdlk4/logs[0m
wandb: | Waiting for wandb.init()...wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162529-9rhtvfyo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9rhtvfyo
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162529-7hkof2y5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7hkof2y5
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g6r6sg1v[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162506-g6r6sg1v/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=328, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h1ss5384[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162506-h1ss5384/logs[0m
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rjyrr2di[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162458-rjyrr2di/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162527-4tv15rhf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4tv15rhf
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=329, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1ksheaam[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162508-1ksheaam/logs[0m
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=330, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=331, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ypt0ah9h[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162509-ypt0ah9h/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fbc0zmn7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162358-fbc0zmn7/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bh62ppn1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162507-bh62ppn1/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n8r4pghf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162511-n8r4pghf/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=332, wandb_name=random, GPU=1
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162533-1h5fdmyp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1h5fdmyp
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/864t99vv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162507-864t99vv/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nu7nm9p5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162505-nu7nm9p5/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162533-yhdx5dzx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yhdx5dzx
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162526-4jpog85h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4jpog85h
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fgumg7xp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162510-fgumg7xp/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cp8epn59[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162509-cp8epn59/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/crdxz8bi[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162356-crdxz8bi/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vl5ivrl2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162458-vl5ivrl2/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rvgjnn84[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162512-rvgjnn84/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/37fikm5u[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162512-37fikm5u/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/aujgx8s2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162510-aujgx8s2/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lox849r4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162512-lox849r4/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=333, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=334, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=335, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6f2vydul[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162355-6f2vydul/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=336, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=337, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=338, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=339, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=340, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=341, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=342, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=343, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=344, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/utb2rg6n[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162514-utb2rg6n/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/94s8h63h[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162514-94s8h63h/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162535-yutglu00
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yutglu00
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=345, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=346, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=347, wandb_name=random, GPU=0
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162536-7so110vf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: Tracking run with wandb version 0.19.4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7so110vf
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162536-p7cmds9a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p7cmds9a
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162536-nl1h5blz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nl1h5blz
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=348, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=349, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hq1hy2x9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162506-hq1hy2x9/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/apq4dbpj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162510-apq4dbpj/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162538-vaf6jkea
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vaf6jkea
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162538-s0ku7jau
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s0ku7jau
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162538-fbhsr3ic
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fbhsr3ic
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162539-x2gqwqaf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x2gqwqaf
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162539-0zn8q4k8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0zn8q4k8
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162539-0zjqohtp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0zjqohtp
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162539-skgy0do1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/skgy0do1
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162539-wnxmmc3z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wnxmmc3z
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162539-esejhv94
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/esejhv94
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162539-8vsqt22f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8vsqt22f
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=350, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=351, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162539-1ilqv5vn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1ilqv5vn
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162539-v6vhjvp4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v6vhjvp4
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162541-xxhcbbce
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xxhcbbce
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162541-nji9nz81
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nji9nz81
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162541-20m9oi0v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/20m9oi0v
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162543-irqsvu4z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/irqsvu4z
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162544-cq6zzx44
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cq6zzx44
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162544-hlxcnfe6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hlxcnfe6
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162544-l6oie52w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l6oie52w
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uytd1ji9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162520-uytd1ji9/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lc4k33fb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162522-lc4k33fb/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6a76kcft[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162522-6a76kcft/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=352, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n27zsom2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162520-n27zsom2/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mbkf67wo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162410-mbkf67wo/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5nshixxs[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162523-5nshixxs/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0pxjh8us[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162523-0pxjh8us/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=353, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=354, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ec4xcl5u[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162509-ec4xcl5u/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3dyrv8r4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162524-3dyrv8r4/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f6h0beo8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162522-f6h0beo8/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4jts48p0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162519-4jts48p0/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=355, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=356, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=357, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=358, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1bj3fzj8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162525-1bj3fzj8/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vnil3u90[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162526-vnil3u90/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oac0lkvu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162525-oac0lkvu/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iraym3x1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162512-iraym3x1/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=359, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=360, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=361, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=362, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/epc3lyav[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162525-epc3lyav/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k9rocyl2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162522-k9rocyl2/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162550-a33begd4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a33begd4
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=363, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=364, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=365, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=366, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tmtd33x5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162527-tmtd33x5/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tzqzfz3o[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162527-tzqzfz3o/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y5rs9t0y[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162527-y5rs9t0y/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/45hfard1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162527-45hfard1/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1u5vykp1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162436-1u5vykp1/logs[0m
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162551-8iqlbaff
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8iqlbaff
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0s9193sv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162527-0s9193sv/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dhx0zq6i[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162527-dhx0zq6i/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=367, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=368, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162551-4t5pj7ez
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4t5pj7ez
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7hkof2y5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162529-7hkof2y5/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162552-fq2d9dpg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fq2d9dpg
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=369, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=370, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=371, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=372, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=373, wandb_name=random, GPU=2
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162552-hbd7bqgv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hbd7bqgv
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162552-4uxjs3m4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4uxjs3m4
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162552-sd1l2dsc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sd1l2dsc
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=374, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=375, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=376, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162554-70pyke60
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/70pyke60
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162554-rg7kssq2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rg7kssq2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162555-fzro5i0y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fzro5i0y
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162555-985rj6yq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/985rj6yq
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162555-8jsxqkpn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8jsxqkpn
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162555-b09za7mw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b09za7mw
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162557-q6gaxqlu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q6gaxqlu
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162557-3qapu6ek
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3qapu6ek
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162557-6pyvyk84
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6pyvyk84
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162557-9d0jiykz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9d0jiykz
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162557-kj8x07wk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kj8x07wk
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162557-m6q1o0s8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m6q1o0s8
wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162557-pyohdyfb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pyohdyfb
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162558-nez2wc08
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nez2wc08
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162558-korugc4u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/korugc4u
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yutglu00[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162535-yutglu00/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yhdx5dzx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162533-yhdx5dzx/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9rhtvfyo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162529-9rhtvfyo/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162554-sk1qromy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sk1qromy
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162559-b4l9ljp5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b4l9ljp5
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7so110vf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162536-7so110vf/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yxg4vwri[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162526-yxg4vwri/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p7cmds9a[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162536-p7cmds9a/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=377, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=378, wandb_name=random, GPU=3
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4jpog85h[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162526-4jpog85h/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4tv15rhf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162527-4tv15rhf/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=379, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=380, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=381, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=382, wandb_name=random, GPU=3
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=383, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=384, wandb_name=random, GPU=1
wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x2gqwqaf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162539-x2gqwqaf/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1h5fdmyp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162533-1h5fdmyp/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0zn8q4k8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162539-0zn8q4k8/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8vsqt22f[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162539-8vsqt22f/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v6vhjvp4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162539-v6vhjvp4/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162604-7c8f8uhy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7c8f8uhy
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162604-flu7un6s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/flu7un6s
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o6pctx2i[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162515-o6pctx2i/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/skgy0do1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162539-skgy0do1/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/esejhv94[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162539-esejhv94/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fbhsr3ic[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162538-fbhsr3ic/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xxhcbbce[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162541-xxhcbbce/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=385, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=386, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=387, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=388, wandb_name=random, GPU=1
wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=389, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=390, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=391, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/20m9oi0v[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162541-20m9oi0v/logs[0m
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vaf6jkea[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162538-vaf6jkea/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nji9nz81[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162541-nji9nz81/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162605-eqgoav7w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/eqgoav7w
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162605-gbavctk1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gbavctk1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1ilqv5vn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162539-1ilqv5vn/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0zjqohtp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162539-0zjqohtp/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wnxmmc3z[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162539-wnxmmc3z/logs[0m
wandb: / Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=392, wandb_name=random, GPU=1
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162606-gyqalstr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gyqalstr
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=393, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=394, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=395, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=396, wandb_name=random, GPU=1
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162607-7166h9ya
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7166h9ya
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7jsvxyz2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162519-7jsvxyz2/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cq6zzx44[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162544-cq6zzx44/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/irqsvu4z[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162543-irqsvu4z/logs[0m
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=397, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=398, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=399, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=400, wandb_name=random, GPU=1
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=401, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=402, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=403, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162609-9jbivxzd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9jbivxzd
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162609-x09k0gew
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x09k0gew
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162610-7ofk9829
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7ofk9829
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162610-n70p9vlq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n70p9vlq
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162610-9piimjjp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9piimjjp
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162610-w0lscz5q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/w0lscz5q
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162607-dhrsz048
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dhrsz048
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162610-hgcn1j6t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hgcn1j6t
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162555-b16s958q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b16s958q
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162611-2y7kodo9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2y7kodo9
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162610-6jnid4i1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6jnid4i1
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162611-6feu699n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6feu699n
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162611-37mncf6n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/37mncf6n
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162611-dcc3nqik
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dcc3nqik
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162611-mr9o8feb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mr9o8feb
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162613-hwj874si
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hwj874si
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162614-hln1j263
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hln1j263
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162614-q33bp835
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q33bp835
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162614-u5uwf142
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u5uwf142
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162614-duk8piqt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/duk8piqt
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162614-rlf25fil
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rlf25fil
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162614-wqtn091d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wqtn091d
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8iqlbaff[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162551-8iqlbaff/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a33begd4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162550-a33begd4/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fq2d9dpg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162552-fq2d9dpg/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hbd7bqgv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162552-hbd7bqgv/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4uxjs3m4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162552-4uxjs3m4/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nl1h5blz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162536-nl1h5blz/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l6oie52w[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162544-l6oie52w/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s0ku7jau[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162538-s0ku7jau/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xy9gfyp2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162525-xy9gfyp2/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hlxcnfe6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162544-hlxcnfe6/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=404, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=405, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=406, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=407, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=408, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=409, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=410, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=411, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8jsxqkpn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162555-8jsxqkpn/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rg7kssq2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162554-rg7kssq2/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=412, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=413, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fzro5i0y[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162555-fzro5i0y/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sd1l2dsc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162552-sd1l2dsc/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/985rj6yq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162555-985rj6yq/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b09za7mw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162555-b09za7mw/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=414, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=415, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9d0jiykz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162557-9d0jiykz/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162620-vvb2b0th
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vvb2b0th
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162620-prpw2a4v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/prpw2a4v
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=416, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=417, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=418, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pyohdyfb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162557-pyohdyfb/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kj8x07wk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162557-kj8x07wk/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6pyvyk84[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162557-6pyvyk84/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3qapu6ek[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162557-3qapu6ek/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m6q1o0s8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162557-m6q1o0s8/logs[0m
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162622-i61pzduy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/i61pzduy
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162622-mrthjnge
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mrthjnge
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=419, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=420, wandb_name=random, GPU=1
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162622-w66abmbm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/w66abmbm
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/70pyke60[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162554-70pyke60/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162622-17a3l5xz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/17a3l5xz
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162622-n8deapbb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n8deapbb
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=421, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=422, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=423, wandb_name=random, GPU=0
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162623-z0ramg8x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z0ramg8x
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=424, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=425, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=426, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162625-l9db5zzp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l9db5zzp
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162625-kpikcblm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kpikcblm
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162625-mo3x654x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mo3x654x
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162625-575itqam
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/575itqam
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162625-66oq20cq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/66oq20cq
wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162625-u2eljyl0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u2eljyl0
wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162626-hf0pgenj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hf0pgenj
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162626-f9wox28u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f9wox28u
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162628-y8mmnqey
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y8mmnqey
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162628-5ajck7e8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5ajck7e8
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162628-kssa2m85
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kssa2m85
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162628-yhtoiy6c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yhtoiy6c
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162628-knspl3wm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/knspl3wm
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162628-offtietp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/offtietp
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gbavctk1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162605-gbavctk1/logs[0m
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b4l9ljp5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162559-b4l9ljp5/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gyqalstr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162606-gyqalstr/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/korugc4u[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162558-korugc4u/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/flu7un6s[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162604-flu7un6s/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7c8f8uhy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162604-7c8f8uhy/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sk1qromy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162554-sk1qromy/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q6gaxqlu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162557-q6gaxqlu/logs[0m
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/eqgoav7w[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162605-eqgoav7w/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7166h9ya[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162607-7166h9ya/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=427, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=428, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=429, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=430, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=431, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=432, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=433, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=434, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=435, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=436, wandb_name=random, GPU=1
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9jbivxzd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162609-9jbivxzd/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x09k0gew[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162609-x09k0gew/logs[0m
wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=437, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r4yrcmwz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162455-r4yrcmwz/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162635-3kswv1zr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3kswv1zr
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9piimjjp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162610-9piimjjp/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162635-3h44rb0g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3h44rb0g
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162635-glk2xcwb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/glk2xcwb
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hgcn1j6t[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162610-hgcn1j6t/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=438, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7ofk9829[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162610-7ofk9829/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/w0lscz5q[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162610-w0lscz5q/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n70p9vlq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162610-n70p9vlq/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b16s958q[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162555-b16s958q/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=439, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/37mncf6n[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162611-37mncf6n/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162636-mgeabfmu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mgeabfmu
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162636-igd3r4ww
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/igd3r4ww
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162636-5n9tdc0d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5n9tdc0d
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mr9o8feb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162611-mr9o8feb/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162636-x2z6531e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x2z6531e
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2y7kodo9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162611-2y7kodo9/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6feu699n[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162611-6feu699n/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162637-bi3nlyyw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bi3nlyyw
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dcc3nqik[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162611-dcc3nqik/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=440, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=441, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=442, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=443, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=444, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=445, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6jnid4i1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162610-6jnid4i1/logs[0m
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162637-3pt7zzu1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3pt7zzu1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=446, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=447, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=448, wandb_name=random, GPU=1
wandb: / Waiting for wandb.init()...wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=449, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=450, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=451, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162640-75jso43i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/75jso43i
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162640-4bnqpy0x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4bnqpy0x
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162640-q2trwt8s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q2trwt8s
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: \ Waiting for wandb.init()...wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162641-5cmy203y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5cmy203y
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162641-xsfbgei8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xsfbgei8
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162641-ie4dc1o4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ie4dc1o4
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162641-aiunznpd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/aiunznpd
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162641-g8izqbfq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g8izqbfq
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162641-j3ssar8l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/j3ssar8l
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162642-wfumzof7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wfumzof7
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162642-o517o26b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o517o26b
wandb: / Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162644-fmnne0xt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fmnne0xt
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162644-l8lxnlpk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l8lxnlpk
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162644-zy5slszn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zy5slszn
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/d25bt2uw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162414-d25bt2uw/logs[0m
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rlf25fil[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162614-rlf25fil/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/prpw2a4v[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162620-prpw2a4v/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hwj874si[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162613-hwj874si/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/w66abmbm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162622-w66abmbm/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/i61pzduy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162622-i61pzduy/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=452, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=453, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=454, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=455, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wqtn091d[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162614-wqtn091d/logs[0m
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/17a3l5xz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162622-17a3l5xz/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q33bp835[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162614-q33bp835/logs[0m
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162647-h8si48au
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h8si48au
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n8deapbb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162622-n8deapbb/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z0ramg8x[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162623-z0ramg8x/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=456, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=457, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l9db5zzp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162625-l9db5zzp/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kpikcblm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162625-kpikcblm/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=458, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=459, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=460, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=461, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=462, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/66oq20cq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162625-66oq20cq/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/575itqam[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162625-575itqam/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hf0pgenj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162626-hf0pgenj/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mo3x654x[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162625-mo3x654x/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=463, wandb_name=random, GPU=0
wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=464, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u2eljyl0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162625-u2eljyl0/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5ajck7e8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162628-5ajck7e8/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162650-bfnx4iem
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bfnx4iem
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f9wox28u[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162626-f9wox28u/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162650-9hiaqm86
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9hiaqm86
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162650-cjkuh2yi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cjkuh2yi
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162650-rcf4twz6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rcf4twz6
wandb: / Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=465, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=466, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=467, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yhtoiy6c[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162628-yhtoiy6c/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hln1j263[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162614-hln1j263/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/knspl3wm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162628-knspl3wm/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=468, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=469, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=470, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=471, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y8mmnqey[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162628-y8mmnqey/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kssa2m85[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162628-kssa2m85/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/offtietp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162628-offtietp/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162652-noh8dzsr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/noh8dzsr
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162652-fyyeuj5y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fyyeuj5y
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162652-jnol1mbs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jnol1mbs
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=472, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=473, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=474, wandb_name=random, GPU=3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162652-y0q6w7od
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y0q6w7od
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162652-hqj49jgl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hqj49jgl
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162653-e2bo956c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e2bo956c
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162653-s711rcwd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s711rcwd
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=475, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=476, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=477, wandb_name=random, GPU=2
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162653-v8zw8zjf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v8zw8zjf
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162654-qbpz5ssy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qbpz5ssy
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162655-fcgaapt2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fcgaapt2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162655-0tksrrrb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0tksrrrb
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162655-yedn8w3o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yedn8w3o
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162656-0qfvva49
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0qfvva49
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162656-cunjioba
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cunjioba
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162623-blyzp1h3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/blyzp1h3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162656-95q13a9c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/95q13a9c
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162656-wdzraebs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wdzraebs
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162657-v3hbtvq6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v3hbtvq6
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162657-b919e2ad
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b919e2ad
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162657-bx5o7jwq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bx5o7jwq
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162659-twi0w5w8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/twi0w5w8
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162659-vz5yjvch
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vz5yjvch
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162659-6t2et7yo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6t2et7yo
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/glk2xcwb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162635-glk2xcwb/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4t5pj7ez[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162551-4t5pj7ez/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3h44rb0g[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162635-3h44rb0g/logs[0m
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3kswv1zr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162635-3kswv1zr/logs[0m
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dhrsz048[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162607-dhrsz048/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bi3nlyyw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162637-bi3nlyyw/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3pt7zzu1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162637-3pt7zzu1/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=478, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=479, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x2z6531e[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162636-x2z6531e/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=480, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=481, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=482, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=483, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=484, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/75jso43i[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162640-75jso43i/logs[0m
wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q2trwt8s[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162640-q2trwt8s/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u5uwf142[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162614-u5uwf142/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=485, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4bnqpy0x[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162640-4bnqpy0x/logs[0m
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ie4dc1o4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162641-ie4dc1o4/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=486, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=487, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=488, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162705-pje096n1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pje096n1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wfumzof7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162642-wfumzof7/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162705-jiahtyu8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jiahtyu8
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=489, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=490, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/duk8piqt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162614-duk8piqt/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xsfbgei8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162641-xsfbgei8/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l8lxnlpk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162644-l8lxnlpk/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/j3ssar8l[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162641-j3ssar8l/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5cmy203y[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162641-5cmy203y/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/aiunznpd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162641-aiunznpd/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o517o26b[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162642-o517o26b/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g8izqbfq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162641-g8izqbfq/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zy5slszn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162644-zy5slszn/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162706-vk5gg49l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vk5gg49l
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=491, wandb_name=random, GPU=0
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162707-4vfqpfdq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4vfqpfdq
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162707-b2suh4ap
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b2suh4ap
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162707-gli120b3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gli120b3
wandb: / Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=492, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=493, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=494, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=495, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=496, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162707-721h7ppq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/721h7ppq
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=497, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=498, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=499, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=500, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: \ Waiting for wandb.init()...wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162709-e65apgz8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e65apgz8
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162709-2wg5myod
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2wg5myod
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162710-8cblj8v0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8cblj8v0
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162710-2ia87500
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2ia87500
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162710-ahjd97eg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ahjd97eg
wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162710-6zfxg82n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6zfxg82n
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162711-bat1rnpc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bat1rnpc
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162639-rdrtqmee
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rdrtqmee
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162712-dos92gao
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dos92gao
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162712-nz4bmcjw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nz4bmcjw
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162712-w1ud249s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/w1ud249s
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162712-b6isfdbo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b6isfdbo
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162713-vhxdfqad
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vhxdfqad
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162713-4rfnn50u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4rfnn50u
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162713-22md1qll
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/22md1qll
wandb: - Waiting for wandb.init()...wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162713-gzcke90x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gzcke90x
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162713-m5pytvh3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m5pytvh3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rcf4twz6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162650-rcf4twz6/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fmnne0xt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162644-fmnne0xt/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/noh8dzsr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162652-noh8dzsr/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vvb2b0th[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162620-vvb2b0th/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9hiaqm86[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162650-9hiaqm86/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5n9tdc0d[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162636-5n9tdc0d/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bfnx4iem[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162650-bfnx4iem/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cjkuh2yi[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162650-cjkuh2yi/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jnol1mbs[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162652-jnol1mbs/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=0, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=1, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=2, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=3, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=4, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h8si48au[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162647-h8si48au/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e2bo956c[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162653-e2bo956c/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hqj49jgl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162652-hqj49jgl/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y0q6w7od[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162652-y0q6w7od/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fyyeuj5y[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162652-fyyeuj5y/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v8zw8zjf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162653-v8zw8zjf/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=5, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=6, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=7, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=8, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qbpz5ssy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162654-qbpz5ssy/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s711rcwd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162653-s711rcwd/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=9, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=10, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=11, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=12, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=13, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=14, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0tksrrrb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162655-0tksrrrb/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=15, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=16, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fcgaapt2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162655-fcgaapt2/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/blyzp1h3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162623-blyzp1h3/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yedn8w3o[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162655-yedn8w3o/logs[0m
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wdzraebs[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162656-wdzraebs/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cunjioba[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162656-cunjioba/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0qfvva49[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162656-0qfvva49/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162721-gr0jvacv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gr0jvacv
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162721-k2a0bkkx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k2a0bkkx
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162721-fthn9s22
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fthn9s22
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162721-m5ojeb12
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m5ojeb12
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162721-nbylr7rq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nbylr7rq
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v3hbtvq6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162657-v3hbtvq6/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/95q13a9c[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162656-95q13a9c/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=17, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=18, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=19, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162721-p8kj6juw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p8kj6juw
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162722-ymz4z7ws
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ymz4z7ws
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=20, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=21, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=22, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=23, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=24, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=25, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162723-k0otbua8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k0otbua8
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162723-khn9u855
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/khn9u855
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162724-dx6ka2gs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dx6ka2gs
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162725-zah6qmod
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zah6qmod
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162725-7lv9qd0w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7lv9qd0w
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162725-y7x2ax74
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y7x2ax74
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162725-qg941qn6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qg941qn6
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162725-h6ama62i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h6ama62i
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162725-s1vnpfz7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s1vnpfz7
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162725-1485u8hq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1485u8hq
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162726-pzhmi9e2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pzhmi9e2
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162726-zgzlxwe8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zgzlxwe8
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162728-so3adfm4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/so3adfm4
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162728-t0bmwgov
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/t0bmwgov
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162728-mud2f99f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mud2f99f
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162728-0uviw4kb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0uviw4kb
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162728-1ayqe9ej
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1ayqe9ej
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162728-3gk3ilqp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3gk3ilqp
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jiahtyu8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162705-jiahtyu8/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bx5o7jwq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162657-bx5o7jwq/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162729-sp8i56po
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sp8i56po
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=26, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=27, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nez2wc08[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162558-nez2wc08/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b2suh4ap[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162707-b2suh4ap/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e65apgz8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162709-e65apgz8/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8cblj8v0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162710-8cblj8v0/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2ia87500[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162710-2ia87500/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=28, wandb_name=random, GPU=2
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=29, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=30, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6zfxg82n[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162710-6zfxg82n/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162735-tj799r7r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tj799r7r
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162735-2rsf6or7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2rsf6or7
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ahjd97eg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162710-ahjd97eg/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=31, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=32, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bat1rnpc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162711-bat1rnpc/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rdrtqmee[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162639-rdrtqmee/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vhxdfqad[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162713-vhxdfqad/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mrthjnge[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162622-mrthjnge/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gzcke90x[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162713-gzcke90x/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=33, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=34, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nz4bmcjw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162712-nz4bmcjw/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/22md1qll[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162713-22md1qll/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m5pytvh3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162713-m5pytvh3/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4rfnn50u[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162713-4rfnn50u/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b6isfdbo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162712-b6isfdbo/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=35, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=36, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=37, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=38, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=39, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162737-pu3ev2ir
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pu3ev2ir
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162738-gvci4s69
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gvci4s69
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6t2et7yo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162659-6t2et7yo/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162738-8uqqddeo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8uqqddeo
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b919e2ad[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162657-b919e2ad/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=40, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=41, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=42, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162739-z5nclymb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z5nclymb
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162739-7oej0pah
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7oej0pah
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=43, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=44, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=45, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=46, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162740-rmm7l3ph
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rmm7l3ph
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162740-l4datcp9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l4datcp9
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162741-eq3lrnpo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/eq3lrnpo
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162741-7caol39g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7caol39g
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162741-vxiy6z24
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vxiy6z24
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162742-kdzujkmy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kdzujkmy
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162742-1l3a1azr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1l3a1azr
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162742-wpsuc2tz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wpsuc2tz
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162742-gv4aw2ws
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gv4aw2ws
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162744-090rqdre
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/090rqdre
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162744-qzpb85oa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qzpb85oa
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162744-w1mme6v3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/w1mme6v3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162744-w8nkrg6c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/w8nkrg6c
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gr0jvacv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162721-gr0jvacv/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m5ojeb12[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162721-m5ojeb12/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nbylr7rq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162721-nbylr7rq/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k2a0bkkx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162721-k2a0bkkx/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fthn9s22[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162721-fthn9s22/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k0otbua8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162723-k0otbua8/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=47, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p8kj6juw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162721-p8kj6juw/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=48, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=49, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=50, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=51, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=52, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h6ama62i[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162725-h6ama62i/logs[0m
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y7x2ax74[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162725-y7x2ax74/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/igd3r4ww[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162636-igd3r4ww/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=53, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s1vnpfz7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162725-s1vnpfz7/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7lv9qd0w[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162725-7lv9qd0w/logs[0m
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/khn9u855[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162723-khn9u855/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1485u8hq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162725-1485u8hq/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zgzlxwe8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162726-zgzlxwe8/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=54, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=55, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=56, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162750-rj0q5edy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rj0q5edy
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/t0bmwgov[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162728-t0bmwgov/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/721h7ppq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162707-721h7ppq/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=57, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=58, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=59, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=60, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1ayqe9ej[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162728-1ayqe9ej/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mud2f99f[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162728-mud2f99f/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0uviw4kb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162728-0uviw4kb/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/so3adfm4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162728-so3adfm4/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162751-gmsoz7h5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gmsoz7h5
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162751-svt10oah
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/svt10oah
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=61, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=62, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=63, wandb_name=random, GPU=1
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162751-ben8jsv1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ben8jsv1
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162751-14jlkxqx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/14jlkxqx
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sp8i56po[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162729-sp8i56po/logs[0m
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162752-gny25wrn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gny25wrn
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=64, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=65, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=66, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=67, wandb_name=random, GPU=1
wandb: / Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=68, wandb_name=random, GPU=2
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162753-yu3rkjib
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yu3rkjib
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162754-ujujgsl8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ujujgsl8
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162754-4dhidv5r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4dhidv5r
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162754-f3ig4lw3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f3ig4lw3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162754-4tux0ota
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4tux0ota
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162754-r49b6itb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r49b6itb
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162754-hqa9z6e4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hqa9z6e4
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162755-01hqb6me
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/01hqb6me
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162756-m389pjqw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m389pjqw
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162755-5eryfbwj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5eryfbwj
wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162756-5npdpq8i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5npdpq8i
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162756-3h46e2yh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3h46e2yh
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162756-32wamouk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/32wamouk
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162756-25j1brg2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/25j1brg2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: / Waiting for wandb.init()...wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162757-044ozwgu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/044ozwgu
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dx6ka2gs[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162724-dx6ka2gs/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pje096n1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162705-pje096n1/logs[0m
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gvci4s69[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162738-gvci4s69/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pu3ev2ir[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162737-pu3ev2ir/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8uqqddeo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162738-8uqqddeo/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=69, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z5nclymb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162739-z5nclymb/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7oej0pah[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162739-7oej0pah/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/twi0w5w8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162659-twi0w5w8/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wpsuc2tz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162742-wpsuc2tz/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gv4aw2ws[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162742-gv4aw2ws/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=70, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=71, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=72, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=73, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vxiy6z24[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162741-vxiy6z24/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rmm7l3ph[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162740-rmm7l3ph/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kdzujkmy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162742-kdzujkmy/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l4datcp9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162740-l4datcp9/logs[0m
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zah6qmod[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162725-zah6qmod/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tj799r7r[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162735-tj799r7r/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2rsf6or7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162735-2rsf6or7/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2wg5myod[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162709-2wg5myod/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=74, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=75, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=76, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=77, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/eq3lrnpo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162741-eq3lrnpo/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=78, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=79, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=80, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=81, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7caol39g[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162741-7caol39g/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/090rqdre[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162744-090rqdre/logs[0m
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dos92gao[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162712-dos92gao/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qzpb85oa[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162744-qzpb85oa/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=82, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=83, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=84, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=85, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=86, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=87, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=88, wandb_name=random, GPU=2
wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162805-oflhbrvi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oflhbrvi
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/w8nkrg6c[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162744-w8nkrg6c/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=89, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=90, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=91, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162806-giwvktff
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/giwvktff
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162806-f03c828f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f03c828f
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162807-ui3zgdq7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ui3zgdq7
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162807-5dgzhh3h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5dgzhh3h
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162807-y8c7mkuj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y8c7mkuj
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=92, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: | Waiting for wandb.init()...wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162806-msaihaeu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/msaihaeu
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162808-71r1if7m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/71r1if7m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.4
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162808-rw3x6dik
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rw3x6dik
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162808-y656rjsp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y656rjsp
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162808-g0v0vjd4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g0v0vjd4
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162808-d9ltakil
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/d9ltakil
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162809-j7myqpqd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/j7myqpqd
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162809-qft6c4ga
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qft6c4ga
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162809-frgmww7j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/frgmww7j
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162810-vs671yvx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vs671yvx
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162810-hz2r70ti
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hz2r70ti
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162811-84yzsr3c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/84yzsr3c
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162811-zyi8ryne
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zyi8ryne
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162811-2izawqht
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2izawqht
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162811-1wkhqsj2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1wkhqsj2
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162812-qt77jaa5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qt77jaa5
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162812-wmizlowi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wmizlowi
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162741-yh9636bu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yh9636bu
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/svt10oah[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162751-svt10oah/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/14jlkxqx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162751-14jlkxqx/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/w1ud249s[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162712-w1ud249s/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vk5gg49l[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162706-vk5gg49l/logs[0m
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=93, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gny25wrn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162752-gny25wrn/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/25j1brg2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162756-25j1brg2/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ujujgsl8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162754-ujujgsl8/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5npdpq8i[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162756-5npdpq8i/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/044ozwgu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162757-044ozwgu/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=94, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=95, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=96, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4tux0ota[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162754-4tux0ota/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f3ig4lw3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162754-f3ig4lw3/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yu3rkjib[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162753-yu3rkjib/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hqa9z6e4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162754-hqa9z6e4/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r49b6itb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162754-r49b6itb/logs[0m
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/32wamouk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162756-32wamouk/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rj0q5edy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162750-rj0q5edy/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=97, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=98, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=99, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=100, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=101, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=102, wandb_name=random, GPU=0
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ymz4z7ws[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162722-ymz4z7ws/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1l3a1azr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162742-1l3a1azr/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m389pjqw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162756-m389pjqw/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gmsoz7h5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162751-gmsoz7h5/logs[0m
wandb: / Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=103, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=104, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=105, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=106, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=107, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=108, wandb_name=random, GPU=2
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162819-hgo06e23
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hgo06e23
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/01hqb6me[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162755-01hqb6me/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5eryfbwj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162755-5eryfbwj/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/w1mme6v3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162744-w1mme6v3/logs[0m
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4vfqpfdq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162707-4vfqpfdq/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=109, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=110, wandb_name=random, GPU=0
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=111, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qg941qn6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162725-qg941qn6/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162820-a50ejt82
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a50ejt82
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162820-ys26fldc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ys26fldc
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162820-ui5jrf9f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ui5jrf9f
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ben8jsv1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162751-ben8jsv1/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4dhidv5r[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162754-4dhidv5r/logs[0m
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=112, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=113, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=114, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3h46e2yh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162756-3h46e2yh/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162822-w6gwpf3a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/w6gwpf3a
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162822-h4sce96c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h4sce96c
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pzhmi9e2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162726-pzhmi9e2/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162822-0kc8wf2h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0kc8wf2h
wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=115, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=116, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=117, wandb_name=random, GPU=3
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162807-p39z15i6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p39z15i6
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3gk3ilqp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162728-3gk3ilqp/logs[0m
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162822-13xb3yk4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/13xb3yk4
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162822-2rh5vdid
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2rh5vdid
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=118, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=119, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=120, wandb_name=random, GPU=2
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162751-le2t2lvn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/le2t2lvn
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162823-6ldlm9i2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6ldlm9i2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=121, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=122, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162823-xffubich
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xffubich
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162824-demljo33
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/demljo33
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162825-xxbdmcil
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xxbdmcil
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162825-qbi2ufn3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qbi2ufn3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162825-hrao2to3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hrao2to3
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162825-n8kfxsn3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n8kfxsn3
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162825-engkpnmk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/engkpnmk
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162825-4dgfw10r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4dgfw10r
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162825-g06ld3ih
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g06ld3ih
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162826-0hraqwb8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0hraqwb8
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162826-ecnavd43
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ecnavd43
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162827-acpmnh1a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/acpmnh1a
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162827-ps17dd1b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ps17dd1b
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162827-wtncu6vk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wtncu6vk
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162828-b6yhl6e1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b6yhl6e1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162828-cx2qems5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cx2qems5
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162829-n72h0vpo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n72h0vpo
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oflhbrvi[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162805-oflhbrvi/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f03c828f[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162806-f03c828f/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162829-ahwqdf5o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ahwqdf5o
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162829-4tiemkji
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4tiemkji
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162830-fx3d8s9a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fx3d8s9a
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/71r1if7m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162808-71r1if7m/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y8c7mkuj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162807-y8c7mkuj/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=123, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=124, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rw3x6dik[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162808-rw3x6dik/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gli120b3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162707-gli120b3/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y656rjsp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162808-y656rjsp/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g0v0vjd4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162808-g0v0vjd4/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/d9ltakil[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162808-d9ltakil/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=125, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=126, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2izawqht[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162811-2izawqht/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qt77jaa5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162812-qt77jaa5/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wmizlowi[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162812-wmizlowi/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=127, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=128, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=129, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=130, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=131, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1wkhqsj2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162811-1wkhqsj2/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/frgmww7j[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162809-frgmww7j/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vs671yvx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162810-vs671yvx/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hz2r70ti[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162810-hz2r70ti/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zyi8ryne[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162811-zyi8ryne/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=132, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=133, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=134, wandb_name=random, GPU=0
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162834-ar5lzmqn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ar5lzmqn
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162834-tksnr9x5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tksnr9x5
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=135, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=136, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=137, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=138, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yh9636bu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162741-yh9636bu/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ui3zgdq7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162807-ui3zgdq7/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162836-ewtq7agh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ewtq7agh
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162836-3266wbxj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3266wbxj
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=139, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162837-y3a0mlyw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y3a0mlyw
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162837-ecfcrf0w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ecfcrf0w
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162837-19jwel5p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/19jwel5p
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=140, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=141, wandb_name=random, GPU=3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162837-7mdmoeq3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7mdmoeq3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162838-krfgwnl4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/krfgwnl4
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162838-hfds55s5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hfds55s5
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162839-bm60qusc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bm60qusc
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162839-nq7vtqav
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nq7vtqav
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162840-owk3bbd7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/owk3bbd7
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162840-jmu2ahoz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jmu2ahoz
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162840-2poxpp7h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2poxpp7h
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162840-g7syx61u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g7syx61u
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162841-csjjhjpi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/csjjhjpi
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162842-6z5j2i5u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6z5j2i5u
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/w6gwpf3a[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162822-w6gwpf3a/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162847-2v55mws8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2v55mws8
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h4sce96c[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162822-h4sce96c/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p39z15i6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162807-p39z15i6/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=142, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mgeabfmu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162636-mgeabfmu/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/13xb3yk4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162822-13xb3yk4/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=143, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=144, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=145, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=146, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hrao2to3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162825-hrao2to3/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qbi2ufn3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162825-qbi2ufn3/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xffubich[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162823-xffubich/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/giwvktff[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162806-giwvktff/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/demljo33[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162824-demljo33/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162850-ihkive1q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ihkive1q
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n8kfxsn3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162825-n8kfxsn3/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/engkpnmk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162825-engkpnmk/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wtncu6vk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162827-wtncu6vk/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ecnavd43[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162826-ecnavd43/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=147, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=148, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=149, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=150, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ys26fldc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162820-ys26fldc/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ui5jrf9f[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162820-ui5jrf9f/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162852-xf507rzf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xf507rzf
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162852-9x74lqcl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9x74lqcl
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b6yhl6e1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162828-b6yhl6e1/logs[0m
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=151, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=152, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=153, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ps17dd1b[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162827-ps17dd1b/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162853-ig2uuaxa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ig2uuaxa
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162853-5cnbks8e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5cnbks8e
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=154, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=155, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=156, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=157, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=158, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=159, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162855-lugj1qqr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lugj1qqr
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162855-u9gkn8ks
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u9gkn8ks
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162855-9d46k9z3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9d46k9z3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162855-8ngufooa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8ngufooa
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162856-qhj8crdf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qhj8crdf
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162856-b5o7mf3g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b5o7mf3g
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162857-iud0hwdf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iud0hwdf
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162857-jaw79npe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jaw79npe
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162857-4v3aqx2c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4v3aqx2c
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162858-ozx2znyi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ozx2znyi
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162858-qy3yyimb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qy3yyimb
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/84yzsr3c[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162811-84yzsr3c/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/j7myqpqd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162809-j7myqpqd/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cx2qems5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162828-cx2qems5/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6ldlm9i2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162823-6ldlm9i2/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2rh5vdid[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162822-2rh5vdid/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ahwqdf5o[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162829-ahwqdf5o/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hgo06e23[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162819-hgo06e23/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7mdmoeq3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162837-7mdmoeq3/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4tiemkji[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162829-4tiemkji/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=160, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ecfcrf0w[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162837-ecfcrf0w/logs[0m
wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/le2t2lvn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162751-le2t2lvn/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y3a0mlyw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162837-y3a0mlyw/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/csjjhjpi[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162841-csjjhjpi/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3266wbxj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162836-3266wbxj/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bm60qusc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162839-bm60qusc/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/msaihaeu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162806-msaihaeu/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=161, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=162, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=163, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=164, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=165, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=166, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=167, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=168, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=169, wandb_name=random, GPU=3
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xxbdmcil[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162825-xxbdmcil/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n72h0vpo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162829-n72h0vpo/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g06ld3ih[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162825-g06ld3ih/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fx3d8s9a[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162830-fx3d8s9a/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=170, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=171, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=172, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=173, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=174, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=175, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/owk3bbd7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162840-owk3bbd7/logs[0m
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4dgfw10r[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162825-4dgfw10r/logs[0m
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0kc8wf2h[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162822-0kc8wf2h/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jmu2ahoz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162840-jmu2ahoz/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hfds55s5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162838-hfds55s5/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2poxpp7h[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162840-2poxpp7h/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g7syx61u[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162840-g7syx61u/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=176, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=177, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=178, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=179, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=180, wandb_name=random, GPU=2
wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qft6c4ga[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162809-qft6c4ga/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=181, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=182, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=183, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=184, wandb_name=random, GPU=2
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=185, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=186, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162905-wf7290fq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wf7290fq
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162905-zjf8diwt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zjf8diwt
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162905-hc30c9u8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hc30c9u8
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162905-pr8f2dmq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pr8f2dmq
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162905-9o2yd1zg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9o2yd1zg
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162905-scdmv901
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/scdmv901
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162905-3fxdjrla
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3fxdjrla
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162905-p53lb0yy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p53lb0yy
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162905-0cjfrmmt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0cjfrmmt
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2v55mws8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162847-2v55mws8/logs[0m
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=187, wandb_name=random, GPU=1
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=188, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162908-o8rz3fft
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o8rz3fft
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162908-qm1bi0s5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qm1bi0s5
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162908-80cvoszh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/80cvoszh
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162908-unhd3pbu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/unhd3pbu
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162908-ohst8bq8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ohst8bq8
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162908-k4ivk1ln
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k4ivk1ln
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162908-0mxquh4d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0mxquh4d
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162909-8m36lfvp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8m36lfvp
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162909-q4xpy33a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q4xpy33a
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162909-y4m75k4g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y4m75k4g
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162909-e927ot0v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e927ot0v
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162909-3z7j4qaw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3z7j4qaw
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162909-6ipljzjs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6ipljzjs
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162909-in74wtis
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/in74wtis
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162909-kxb1k9ke
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kxb1k9ke
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162909-k47v4cyi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k47v4cyi
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162909-2hc9h2ko
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2hc9h2ko
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162909-ryac9xac
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ryac9xac
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162913-04u5sud1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/04u5sud1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162913-gd2fq5kn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gd2fq5kn
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0hraqwb8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162826-0hraqwb8/logs[0m
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9x74lqcl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162852-9x74lqcl/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qhj8crdf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162856-qhj8crdf/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nq7vtqav[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162839-nq7vtqav/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ar5lzmqn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162834-ar5lzmqn/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5cnbks8e[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162853-5cnbks8e/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: / Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=189, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=190, wandb_name=random, GPU=0
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5dgzhh3h[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162807-5dgzhh3h/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tksnr9x5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162834-tksnr9x5/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4v3aqx2c[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162857-4v3aqx2c/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jaw79npe[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162857-jaw79npe/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ozx2znyi[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162858-ozx2znyi/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lugj1qqr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162855-lugj1qqr/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/acpmnh1a[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162827-acpmnh1a/logs[0m
wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=191, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=192, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=193, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=194, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=195, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=196, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iud0hwdf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162857-iud0hwdf/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162857-wsws19fo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wsws19fo
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8ngufooa[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162855-8ngufooa/logs[0m
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=197, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=198, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=199, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=200, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=201, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=202, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u9gkn8ks[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162855-u9gkn8ks/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qy3yyimb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162858-qy3yyimb/logs[0m
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=203, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9d46k9z3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162855-9d46k9z3/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/19jwel5p[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162837-19jwel5p/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ihkive1q[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162850-ihkive1q/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162919-ehpnvmn3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ehpnvmn3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xf507rzf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162852-xf507rzf/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/krfgwnl4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162838-krfgwnl4/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162919-ru3osvj1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ru3osvj1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ig2uuaxa[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162853-ig2uuaxa/logs[0m
wandb: / Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=204, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=205, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=206, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=207, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=208, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=209, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=210, wandb_name=random, GPU=0
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162921-9lij4oeh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9lij4oeh
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162921-u9nkior1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u9nkior1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162921-5mrniqun
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5mrniqun
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162921-wg0ymwr3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wg0ymwr3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162922-0dn28x7t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0dn28x7t
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=211, wandb_name=random, GPU=1
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162922-0dxluxbs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0dxluxbs
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162922-fzvlfnsa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fzvlfnsa
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162922-yhhezvdr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yhhezvdr
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162922-utuggo6z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/utuggo6z
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162922-17vn5g1n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/17vn5g1n
wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162923-uombj57t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uombj57t
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162924-wwfynjh4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wwfynjh4
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162923-wapahgci
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wapahgci
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162925-r96bx77d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r96bx77d
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162925-mkznr259
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mkznr259
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162925-rxke0ko6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rxke0ko6
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162925-cgeyhr6u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cgeyhr6u
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162925-q5z75s3o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q5z75s3o
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162926-vwmchna2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vwmchna2
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162926-yrvwalgq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yrvwalgq
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162926-9s2aeytf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9s2aeytf
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162856-bn8a1ecn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bn8a1ecn
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zjf8diwt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162905-zjf8diwt/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wf7290fq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162905-wf7290fq/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p53lb0yy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162905-p53lb0yy/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3fxdjrla[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162905-3fxdjrla/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9o2yd1zg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162905-9o2yd1zg/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=212, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0cjfrmmt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162905-0cjfrmmt/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pr8f2dmq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162905-pr8f2dmq/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o8rz3fft[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162908-o8rz3fft/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=213, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=214, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=215, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=216, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qm1bi0s5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162908-qm1bi0s5/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8m36lfvp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162909-8m36lfvp/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q4xpy33a[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162909-q4xpy33a/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k4ivk1ln[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162908-k4ivk1ln/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=217, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ohst8bq8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162908-ohst8bq8/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=218, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=219, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/unhd3pbu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162908-unhd3pbu/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kxb1k9ke[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162909-kxb1k9ke/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y4m75k4g[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162909-y4m75k4g/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/in74wtis[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162909-in74wtis/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=220, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=221, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e927ot0v[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162909-e927ot0v/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6z5j2i5u[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162842-6z5j2i5u/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162935-j7gcjmlf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/j7gcjmlf
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6ipljzjs[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162909-6ipljzjs/logs[0m
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=222, wandb_name=random, GPU=0
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=223, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=224, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=225, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/04u5sud1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162913-04u5sud1/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=226, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=227, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=228, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hc30c9u8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162905-hc30c9u8/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ryac9xac[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162909-ryac9xac/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162935-9wjhw1dj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9wjhw1dj
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162936-0kk66oki
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0kk66oki
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gd2fq5kn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162913-gd2fq5kn/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0mxquh4d[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162908-0mxquh4d/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=229, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=230, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=231, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162936-41qyln0e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/41qyln0e
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162937-z0155qvi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z0155qvi
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162937-9tkl7faq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9tkl7faq
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162937-dfx5slhb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dfx5slhb
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=232, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=233, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=234, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=235, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162938-y77kc5ni
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y77kc5ni
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=236, wandb_name=random, GPU=2
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162938-jjgmbhkr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jjgmbhkr
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162939-yvr7j2xn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yvr7j2xn
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162939-6oipezro
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6oipezro
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162939-spz8yolc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/spz8yolc
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162939-n1eq6qhr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n1eq6qhr
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162939-a0ws3cu3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a0ws3cu3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162940-t0y0svq0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/t0y0svq0
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162940-14sqa3tx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/14sqa3tx
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162940-oq9u36hn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oq9u36hn
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162941-368y94bw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/368y94bw
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162941-3sat9p7q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3sat9p7q
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162942-jut0jb5z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jut0jb5z
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162942-2q7cczo9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2q7cczo9
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162942-o0x1i0ph
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o0x1i0ph
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162943-vkaba0ph
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vkaba0ph
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162943-y58ggrwv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y58ggrwv
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162943-yt5r5nmb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yt5r5nmb
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wsws19fo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162857-wsws19fo/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/scdmv901[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162905-scdmv901/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u9nkior1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162921-u9nkior1/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=237, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/17vn5g1n[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162922-17vn5g1n/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5mrniqun[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162921-5mrniqun/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fzvlfnsa[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162922-fzvlfnsa/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ru3osvj1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162919-ru3osvj1/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=238, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=239, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0dn28x7t[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162922-0dn28x7t/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yhhezvdr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162922-yhhezvdr/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/80cvoszh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162908-80cvoszh/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/utuggo6z[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162922-utuggo6z/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=240, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=241, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wapahgci[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162923-wapahgci/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wwfynjh4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162924-wwfynjh4/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r96bx77d[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162925-r96bx77d/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=242, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=243, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=244, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=245, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=246, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=247, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vwmchna2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162926-vwmchna2/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162949-sp43lku7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sp43lku7
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rxke0ko6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162925-rxke0ko6/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9s2aeytf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162926-9s2aeytf/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mkznr259[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162925-mkznr259/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cgeyhr6u[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162925-cgeyhr6u/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yrvwalgq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162926-yrvwalgq/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q5z75s3o[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162925-q5z75s3o/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=248, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=249, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a50ejt82[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162820-a50ejt82/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162950-tw7mgxj7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tw7mgxj7
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162950-gk9e0knb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gk9e0knb
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=250, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=251, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=252, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=253, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=254, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=255, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=256, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=257, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=258, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162952-f03loa5w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f03loa5w
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162952-qghatvdd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qghatvdd
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162952-52n4soe9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/52n4soe9
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162952-yw8sq6vn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yw8sq6vn
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162952-z6qy500c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z6qy500c
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162952-lghrhztk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lghrhztk
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162952-484rh8zs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/484rh8zs
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162952-io7pknqo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/io7pknqo
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162954-mi64d2n2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mi64d2n2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162955-keq5i3q2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/keq5i3q2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162955-yj1zfrea
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yj1zfrea
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162955-omghpgpv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/omghpgpv
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162955-oyu28ghc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oyu28ghc
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162955-5c1xm99y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5c1xm99y
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162955-bnmra09l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bnmra09l
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162955-mkfq77q1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mkfq77q1
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162955-v9sl0nfj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v9sl0nfj
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162956-qxxwv20f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qxxwv20f
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0kk66oki[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162936-0kk66oki/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b5o7mf3g[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162856-b5o7mf3g/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9tkl7faq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162937-9tkl7faq/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dfx5slhb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162937-dfx5slhb/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3z7j4qaw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162909-3z7j4qaw/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2hc9h2ko[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162909-2hc9h2ko/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=259, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=260, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z0155qvi[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162937-z0155qvi/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ehpnvmn3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162919-ehpnvmn3/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: \ Waiting for wandb.init()...wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/j7gcjmlf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162935-j7gcjmlf/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=261, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=262, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=263, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=264, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=265, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jjgmbhkr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162938-jjgmbhkr/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/14sqa3tx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162940-14sqa3tx/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/spz8yolc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162939-spz8yolc/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6oipezro[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162939-6oipezro/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=266, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=267, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yvr7j2xn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162939-yvr7j2xn/logs[0m
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n1eq6qhr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162939-n1eq6qhr/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/t0y0svq0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162940-t0y0svq0/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oq9u36hn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162940-oq9u36hn/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/368y94bw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162941-368y94bw/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9wjhw1dj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162935-9wjhw1dj/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_163004-9k15378x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9k15378x
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3sat9p7q[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162941-3sat9p7q/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_163004-v0h4scnh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v0h4scnh
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jut0jb5z[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162942-jut0jb5z/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y77kc5ni[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162938-y77kc5ni/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y58ggrwv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162943-y58ggrwv/logs[0m
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2q7cczo9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162942-2q7cczo9/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vkaba0ph[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162943-vkaba0ph/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_163005-9n1p913v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9n1p913v
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_163005-qln1hp3t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qln1hp3t
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_163005-hhsr7j1g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hhsr7j1g
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_163006-b1msenuw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b1msenuw
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yt5r5nmb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162943-yt5r5nmb/logs[0m
wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o0x1i0ph[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162942-o0x1i0ph/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_163006-31iu4soh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/31iu4soh
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_163006-wnv7u4va
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wnv7u4va
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_163006-zzlsfn7e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zzlsfn7e
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k47v4cyi[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162909-k47v4cyi/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0dxluxbs[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162922-0dxluxbs/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qghatvdd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162952-qghatvdd/logs[0m
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z6qy500c[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162952-z6qy500c/logs[0m
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_162955-7q86a5ig
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7q86a5ig
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/io7pknqo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162952-io7pknqo/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lghrhztk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162952-lghrhztk/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/484rh8zs[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162952-484rh8zs/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/52n4soe9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162952-52n4soe9/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uombj57t[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162923-uombj57t/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a0ws3cu3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162939-a0ws3cu3/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sp43lku7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162949-sp43lku7/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tw7mgxj7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162950-tw7mgxj7/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yj1zfrea[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162955-yj1zfrea/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v9sl0nfj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162955-v9sl0nfj/logs[0m
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
wandb: 429 encountered ({"error":"rate limit exceeded"}), retrying request
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mkfq77q1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162955-mkfq77q1/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mi64d2n2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162954-mi64d2n2/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oyu28ghc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162955-oyu28ghc/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yw8sq6vn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162952-yw8sq6vn/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5c1xm99y[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162955-5c1xm99y/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bnmra09l[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162955-bnmra09l/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gk9e0knb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162950-gk9e0knb/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qxxwv20f[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162956-qxxwv20f/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v0h4scnh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_163004-v0h4scnh/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9n1p913v[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_163005-9n1p913v/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hhsr7j1g[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_163005-hhsr7j1g/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wnv7u4va[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_163006-wnv7u4va/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qln1hp3t[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_163005-qln1hp3t/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f03loa5w[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162952-f03loa5w/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/keq5i3q2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162955-keq5i3q2/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b1msenuw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_163006-b1msenuw/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/omghpgpv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162955-omghpgpv/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9k15378x[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_163004-9k15378x/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zzlsfn7e[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_163006-zzlsfn7e/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/31iu4soh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_163006-31iu4soh/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wg0ymwr3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162921-wg0ymwr3/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/41qyln0e[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162936-41qyln0e/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9lij4oeh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162921-9lij4oeh/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bn8a1ecn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162856-bn8a1ecn/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7q86a5ig[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162955-7q86a5ig/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vz5yjvch[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162659-vz5yjvch/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0m5qumz7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162136-0m5qumz7/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ewtq7agh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162836-ewtq7agh/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r9cq6ta4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162125-r9cq6ta4/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xe2hs1d5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_162351-xe2hs1d5/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m71t527q[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161950-m71t527q/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cu03pe0a[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_161950-cu03pe0a/logs[0m
