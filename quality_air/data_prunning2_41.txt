nohup: ignoring input
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=0, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=1, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=2, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=3, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=4, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=5, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=6, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=7, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=8, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=9, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=10, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=11, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_115956-053cis24
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/053cis24
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_115956-mfd2swsp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mfd2swsp
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_115957-rir06j8d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rir06j8d
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_115957-vrmp2p00
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vrmp2p00
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_115957-sgtr1udj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sgtr1udj
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_115958-qlqp6ahn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qlqp6ahn
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_115958-jax4nky2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jax4nky2
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_115958-7h458i9v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7h458i9v
wandb: Tracking run with wandb version 0.19.4
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_115958-uejter8c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uejter8c
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_115958-xuasretn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xuasretn
wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_115959-jnc9fyw7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jnc9fyw7
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120000-0u92oyc5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0u92oyc5
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/053cis24[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_115956-053cis24/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rir06j8d[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_115957-rir06j8d/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sgtr1udj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_115957-sgtr1udj/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=12, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qlqp6ahn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_115958-qlqp6ahn/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=13, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vrmp2p00[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_115957-vrmp2p00/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=14, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=15, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mfd2swsp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_115956-mfd2swsp/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=16, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=17, wandb_name=random, GPU=1
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120053-u3mlejo3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u3mlejo3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120055-l8vj9qxm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l8vj9qxm
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120055-pmh1mkax
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pmh1mkax
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120055-ttlwnord
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ttlwnord
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uejter8c[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_115958-uejter8c/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jnc9fyw7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_115959-jnc9fyw7/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7h458i9v[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_115958-7h458i9v/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120058-a5k958yt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a5k958yt
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xuasretn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_115958-xuasretn/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=18, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=19, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.0, training_seed=20, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120103-w1ec2zmz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/w1ec2zmz
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=21, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jax4nky2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_115958-jax4nky2/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0u92oyc5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120000-0u92oyc5/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=22, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=23, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120115-h47ph25s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h47ph25s
wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120113-a61vfnzw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a61vfnzw
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120114-s22qwmmy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s22qwmmy
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120114-bs6w3j9k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bs6w3j9k
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120121-e09f8zo2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e09f8zo2
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120122-yilc8ht9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yilc8ht9
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u3mlejo3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120053-u3mlejo3/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ttlwnord[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120055-ttlwnord/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l8vj9qxm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120055-l8vj9qxm/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pmh1mkax[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120055-pmh1mkax/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=24, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=25, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=26, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=27, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/w1ec2zmz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120103-w1ec2zmz/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a5k958yt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120058-a5k958yt/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=28, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=29, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120148-nyni08qv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nyni08qv
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120149-28jjxrj1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/28jjxrj1
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120148-34kjdxqx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/34kjdxqx
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120151-jp4nph2w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jp4nph2w
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120155-ni77qyru
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ni77qyru
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a61vfnzw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120113-a61vfnzw/logs[0m
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120156-7hgjb9oc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7hgjb9oc
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h47ph25s[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120115-h47ph25s/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s22qwmmy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120114-s22qwmmy/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=30, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=31, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=32, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bs6w3j9k[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120114-bs6w3j9k/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e09f8zo2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120121-e09f8zo2/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yilc8ht9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120122-yilc8ht9/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=33, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=34, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=35, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120216-mho0a8c2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mho0a8c2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120217-f38uqzub
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f38uqzub
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120217-njzdef2k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/njzdef2k
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120229-1hegiird
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1hegiird
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120231-ivl7b4n9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ivl7b4n9
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120232-giqbd13r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/giqbd13r
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/28jjxrj1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120149-28jjxrj1/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=36, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/34kjdxqx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120148-34kjdxqx/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nyni08qv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120148-nyni08qv/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jp4nph2w[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120151-jp4nph2w/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=37, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=38, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=39, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ni77qyru[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120155-ni77qyru/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7hgjb9oc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120156-7hgjb9oc/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=40, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=41, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120252-djeewil1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/djeewil1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120253-3adkixkb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3adkixkb
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120254-g2ah6u94
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g2ah6u94
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mho0a8c2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120216-mho0a8c2/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/njzdef2k[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120217-njzdef2k/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f38uqzub[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120217-f38uqzub/logs[0m
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120300-vnnpyddy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vnnpyddy
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120256-9b31wbr9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9b31wbr9
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=42, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=43, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=44, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120305-igae9jgd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/igae9jgd
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1hegiird[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120229-1hegiird/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=45, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120315-sj2pfj9n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sj2pfj9n
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ivl7b4n9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120231-ivl7b4n9/logs[0m
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120317-o55mt4h7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o55mt4h7
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120317-ncvtx5xk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ncvtx5xk
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=46, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120324-a148pyap
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a148pyap
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/giqbd13r[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120232-giqbd13r/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=47, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120329-lcxr88x0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lcxr88x0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120334-zcpqw5y6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zcpqw5y6
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3adkixkb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120253-3adkixkb/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g2ah6u94[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120254-g2ah6u94/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/djeewil1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120252-djeewil1/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9b31wbr9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120256-9b31wbr9/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=48, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vnnpyddy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120300-vnnpyddy/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=49, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=50, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=51, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/igae9jgd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120305-igae9jgd/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=52, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sj2pfj9n[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120315-sj2pfj9n/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o55mt4h7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120317-o55mt4h7/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=53, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ncvtx5xk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120317-ncvtx5xk/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=54, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120406-ntpbo8l0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ntpbo8l0
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120406-t16lpoiy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/t16lpoiy
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a148pyap[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120324-a148pyap/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120406-cnb5fmnp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cnb5fmnp
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lcxr88x0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120329-lcxr88x0/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=55, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.0, training_seed=56, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.0, training_seed=57, wandb_name=random, GPU=1
wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120409-4y340jlv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4y340jlv
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120409-3fkq7moz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3fkq7moz
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=58, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zcpqw5y6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120334-zcpqw5y6/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=59, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120417-7fl8iip2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7fl8iip2
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120419-hloewkif
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hloewkif
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120420-e0uyf7wm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e0uyf7wm
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120422-rhj3adty
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rhj3adty
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120423-9f1vcn83
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9f1vcn83
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120422-u2jkgnio
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u2jkgnio
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120425-xi3qpse1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xi3qpse1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/t16lpoiy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120406-t16lpoiy/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ntpbo8l0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120406-ntpbo8l0/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=60, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=61, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cnb5fmnp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120406-cnb5fmnp/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=62, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3fkq7moz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120409-3fkq7moz/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4y340jlv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120409-4y340jlv/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7fl8iip2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120417-7fl8iip2/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=63, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hloewkif[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120419-hloewkif/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=64, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e0uyf7wm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120420-e0uyf7wm/logs[0m
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.0, training_seed=65, wandb_name=random, GPU=1
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120510-t1rjiwtk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/t1rjiwtk
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120511-iuuocx91
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iuuocx91
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=66, wandb_name=random, GPU=2
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120512-mmrjw52v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mmrjw52v
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=67, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rhj3adty[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120422-rhj3adty/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9f1vcn83[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120423-9f1vcn83/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u2jkgnio[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120422-u2jkgnio/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=68, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xi3qpse1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120425-xi3qpse1/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=69, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.0, training_seed=70, wandb_name=random, GPU=2
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.0, training_seed=71, wandb_name=random, GPU=3
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120523-ji1nndrg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ji1nndrg
wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120523-0yr7v7a2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0yr7v7a2
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120524-10jvw406
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/10jvw406
wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120527-e645yyrc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e645yyrc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120525-9bpc3x7i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9bpc3x7i
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120532-45pzfksc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/45pzfksc
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120539-jhttarej
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jhttarej
wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120539-tgdukdx1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tgdukdx1
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120541-usc0ookg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/usc0ookg
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iuuocx91[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120511-iuuocx91/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/t1rjiwtk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120510-t1rjiwtk/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mmrjw52v[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120512-mmrjw52v/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=72, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=73, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=74, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e645yyrc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120527-e645yyrc/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ji1nndrg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120523-ji1nndrg/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0yr7v7a2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120523-0yr7v7a2/logs[0m
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/10jvw406[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120524-10jvw406/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=75, wandb_name=random, GPU=3
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9bpc3x7i[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120525-9bpc3x7i/logs[0m
wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=76, wandb_name=random, GPU=0
wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: / Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.0, training_seed=77, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120616-864r9n0y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/864r9n0y
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120616-vami6pbm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vami6pbm
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/45pzfksc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120532-45pzfksc/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=78, wandb_name=random, GPU=2
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.0, training_seed=79, wandb_name=random, GPU=3
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120619-hv8i6do5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hv8i6do5
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tgdukdx1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120539-tgdukdx1/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=80, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jhttarej[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120539-jhttarej/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=81, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.0, training_seed=82, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/usc0ookg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120541-usc0ookg/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120630-w7br6u39
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/w7br6u39
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120632-vmzedi84
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vmzedi84
wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120629-qzb3pinw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qzb3pinw
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120630-qdel80s5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qdel80s5
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=83, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120635-bhjwbeyf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bhjwbeyf
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120636-tl71kn7k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tl71kn7k
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120639-4eb54hy9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4eb54hy9
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120646-xvks5iqw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xvks5iqw
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120648-3j23jg5u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3j23jg5u
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/864r9n0y[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120616-864r9n0y/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vami6pbm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120616-vami6pbm/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=84, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hv8i6do5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120619-hv8i6do5/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=85, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=86, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120716-h9ajnu8m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h9ajnu8m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120717-z98slv62
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z98slv62
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120720-j2es4vi8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/j2es4vi8
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qzb3pinw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120629-qzb3pinw/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/w7br6u39[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120630-w7br6u39/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vmzedi84[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120632-vmzedi84/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qdel80s5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120630-qdel80s5/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=87, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=88, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tl71kn7k[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120636-tl71kn7k/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bhjwbeyf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120635-bhjwbeyf/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=89, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=90, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=91, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=92, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4eb54hy9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120639-4eb54hy9/logs[0m
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120734-s8p9bmq3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s8p9bmq3
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120734-u1jvbywu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u1jvbywu
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xvks5iqw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120646-xvks5iqw/logs[0m
wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.0, training_seed=93, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120735-sfnh1hmf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sfnh1hmf
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120738-polseccw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/polseccw
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3j23jg5u[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120648-3j23jg5u/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=94, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=95, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120743-vym3zgqx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vym3zgqx
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120745-flqc6t5g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/flqc6t5g
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120752-hbe6dulx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hbe6dulx
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120758-50rd2yei
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/50rd2yei
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120758-dazd1few
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dazd1few
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z98slv62[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120717-z98slv62/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/j2es4vi8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120720-j2es4vi8/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h9ajnu8m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120716-h9ajnu8m/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=96, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=97, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=98, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u1jvbywu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120734-u1jvbywu/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120822-gack6bc1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gack6bc1
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=99, wandb_name=random, GPU=3
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120821-tng5ntxh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tng5ntxh
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s8p9bmq3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120734-s8p9bmq3/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sfnh1hmf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120735-sfnh1hmf/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120824-q4ulbj1a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q4ulbj1a
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/polseccw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120738-polseccw/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=100, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=101, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=102, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vym3zgqx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120743-vym3zgqx/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/flqc6t5g[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120745-flqc6t5g/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hbe6dulx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120752-hbe6dulx/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=103, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=104, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=105, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120838-96l9sly2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/96l9sly2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/50rd2yei[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120758-50rd2yei/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dazd1few[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120758-dazd1few/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120841-ksg1tl8w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ksg1tl8w
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120841-f7mk7ihy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f7mk7ihy
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.0, training_seed=106, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.0, training_seed=107, wandb_name=random, GPU=3
wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120843-03ys36f9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/03ys36f9
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120841-m5j5mvj3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m5j5mvj3
wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120843-jrniruv9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jrniruv9
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120845-ad281epc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ad281epc
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120855-bfz3s85t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bfz3s85t
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120858-tosdta37
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tosdta37
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tng5ntxh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120821-tng5ntxh/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gack6bc1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120822-gack6bc1/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q4ulbj1a[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120824-q4ulbj1a/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=108, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=109, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=110, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120916-ypte5bsg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ypte5bsg
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120922-asovnarl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/asovnarl
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120924-5dfa9ucs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5dfa9ucs
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/96l9sly2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120838-96l9sly2/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=111, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ksg1tl8w[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120841-ksg1tl8w/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f7mk7ihy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120841-f7mk7ihy/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m5j5mvj3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120841-m5j5mvj3/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=112, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=113, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/03ys36f9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120843-03ys36f9/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jrniruv9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120843-jrniruv9/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=114, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ad281epc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120845-ad281epc/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=115, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=116, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120941-85qenraw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/85qenraw
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=117, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120948-mkznx6fq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mkznx6fq
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120950-2vj5yukj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2vj5yukj
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120951-3p3vgvr5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3p3vgvr5
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bfz3s85t[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120855-bfz3s85t/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120953-vi21k544
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vi21k544
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120952-vwrwpd12
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vwrwpd12
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tosdta37[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120858-tosdta37/logs[0m
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.0, training_seed=118, wandb_name=random, GPU=2
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_120954-7cclonyv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7cclonyv
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=119, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5dfa9ucs[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120924-5dfa9ucs/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ypte5bsg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120916-ypte5bsg/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/asovnarl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120922-asovnarl/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.0, training_seed=120, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.0, training_seed=121, wandb_name=random, GPU=1
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121008-tpx5qcj9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tpx5qcj9
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=122, wandb_name=random, GPU=2
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121012-m6mura6b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m6mura6b
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121022-p4cztzc3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p4cztzc3
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121023-0lurev29
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0lurev29
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121023-65v84jzz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/65v84jzz
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/85qenraw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120941-85qenraw/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=123, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mkznx6fq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120948-mkznx6fq/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3p3vgvr5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120951-3p3vgvr5/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2vj5yukj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120950-2vj5yukj/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=124, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vi21k544[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120953-vi21k544/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=125, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=126, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=127, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7cclonyv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120954-7cclonyv/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vwrwpd12[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_120952-vwrwpd12/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.0, training_seed=128, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=129, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121046-b17kz8ak
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b17kz8ak
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121047-ay62wcv5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ay62wcv5
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121047-ya0f8dzv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ya0f8dzv
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121048-fn2myx4h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fn2myx4h
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121047-ciwxz8sc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ciwxz8sc
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tpx5qcj9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121008-tpx5qcj9/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m6mura6b[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121012-m6mura6b/logs[0m
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.0, training_seed=130, wandb_name=random, GPU=2
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121058-yafrf1w8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yafrf1w8
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=131, wandb_name=random, GPU=3
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p4cztzc3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121022-p4cztzc3/logs[0m
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121100-200g88sy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/200g88sy
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=132, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0lurev29[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121023-0lurev29/logs[0m
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/65v84jzz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121023-65v84jzz/logs[0m
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121108-zsce5gd6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zsce5gd6
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=133, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=134, wandb_name=random, GPU=2
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121113-r6zj3ovw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r6zj3ovw
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121117-kzydnsnn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kzydnsnn
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121124-6i2gdo2q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6i2gdo2q
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121128-g0nl3p7o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g0nl3p7o
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ya0f8dzv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121047-ya0f8dzv/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b17kz8ak[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121046-b17kz8ak/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ay62wcv5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121047-ay62wcv5/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ciwxz8sc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121047-ciwxz8sc/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=135, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=136, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fn2myx4h[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121048-fn2myx4h/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=137, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=138, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=139, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121146-13ahnj8h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/13ahnj8h
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121147-u4awdqk8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u4awdqk8
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121146-rekeg9eh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rekeg9eh
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121147-v3tkvmoh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v3tkvmoh
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yafrf1w8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121058-yafrf1w8/logs[0m
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/200g88sy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121100-200g88sy/logs[0m
wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.0, training_seed=140, wandb_name=random, GPU=0
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121150-wppzp7ht
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wppzp7ht
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=141, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121200-s3ucb19m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s3ucb19m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121203-7los5i21
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7los5i21
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zsce5gd6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121108-zsce5gd6/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=142, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r6zj3ovw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121113-r6zj3ovw/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=143, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kzydnsnn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121117-kzydnsnn/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6i2gdo2q[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121124-6i2gdo2q/logs[0m
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121218-0wx9gg77
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0wx9gg77
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=144, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g0nl3p7o[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121128-g0nl3p7o/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=145, wandb_name=random, GPU=1
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121223-0to0f9mx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0to0f9mx
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=146, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u4awdqk8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121147-u4awdqk8/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rekeg9eh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121146-rekeg9eh/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v3tkvmoh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121147-v3tkvmoh/logs[0m
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121233-yf4oyulk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yf4oyulk
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/13ahnj8h[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121146-13ahnj8h/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wppzp7ht[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121150-wppzp7ht/logs[0m
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.0, training_seed=147, wandb_name=random, GPU=3
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.0, training_seed=148, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=149, wandb_name=random, GPU=1
wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=150, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=151, wandb_name=random, GPU=3
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121236-71wmp3wh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/71wmp3wh
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7los5i21[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121203-7los5i21/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s3ucb19m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121200-s3ucb19m/logs[0m
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121240-u9ak5lrb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u9ak5lrb
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=152, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=153, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121249-ripputj6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ripputj6
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121250-4cawj7bu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4cawj7bu
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121250-fhwvatuy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fhwvatuy
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121250-pz6xzjfs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pz6xzjfs
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121251-5qz9et0f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5qz9et0f
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0wx9gg77[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121218-0wx9gg77/logs[0m
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121252-g1ppk2hk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g1ppk2hk
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121253-zu5berar
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zu5berar
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=154, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0to0f9mx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121223-0to0f9mx/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yf4oyulk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121233-yf4oyulk/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=155, wandb_name=random, GPU=3
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.0, training_seed=156, wandb_name=random, GPU=0
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/71wmp3wh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121236-71wmp3wh/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121311-nucyx2vs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nucyx2vs
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=157, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121324-av9fo3kw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/av9fo3kw
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121323-9vsaxqqh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9vsaxqqh
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u9ak5lrb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121240-u9ak5lrb/logs[0m
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121328-qly3cwke
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qly3cwke
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=158, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5qz9et0f[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121251-5qz9et0f/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fhwvatuy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121250-fhwvatuy/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ripputj6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121249-ripputj6/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pz6xzjfs[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121250-pz6xzjfs/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4cawj7bu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121250-4cawj7bu/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zu5berar[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121253-zu5berar/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=159, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g1ppk2hk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121252-g1ppk2hk/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=160, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=161, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=162, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=163, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=164, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=165, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121347-xro283h7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xro283h7
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121349-vfs6u307
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vfs6u307
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: / Waiting for wandb.init()...wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121351-15q358g4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/15q358g4
wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121352-xgak0evz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xgak0evz
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121354-mm5bzbcg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mm5bzbcg
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121355-j8e9wb9k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/j8e9wb9k
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121355-bh38fb2u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bh38fb2u
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121358-ey7vf8dd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ey7vf8dd
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nucyx2vs[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121311-nucyx2vs/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=166, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/av9fo3kw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121324-av9fo3kw/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9vsaxqqh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121323-9vsaxqqh/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=167, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=168, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qly3cwke[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121328-qly3cwke/logs[0m
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121423-2c6g6s9w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2c6g6s9w
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=169, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121433-k9gvtrdl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k9gvtrdl
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121433-s5k625t2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s5k625t2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xro283h7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121347-xro283h7/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/15q358g4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121351-15q358g4/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vfs6u307[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121349-vfs6u307/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=170, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=171, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mm5bzbcg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121354-mm5bzbcg/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/j8e9wb9k[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121355-j8e9wb9k/logs[0m
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xgak0evz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121352-xgak0evz/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=172, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.0, training_seed=173, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bh38fb2u[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121355-bh38fb2u/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=174, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=175, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121447-oa5s699v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oa5s699v
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ey7vf8dd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121358-ey7vf8dd/logs[0m
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121454-gxxmrzua
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gxxmrzua
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.0, training_seed=176, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121455-2ry6cx0a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2ry6cx0a
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121458-9u0vl55n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9u0vl55n
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=177, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121459-um3fjlo4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/um3fjlo4
wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121500-ifjvbcc1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ifjvbcc1
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121502-8zxhnw2g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8zxhnw2g
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2c6g6s9w[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121423-2c6g6s9w/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=178, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121511-i6mq4td2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/i6mq4td2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121513-3jakj0am
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3jakj0am
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k9gvtrdl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121433-k9gvtrdl/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s5k625t2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121433-s5k625t2/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=179, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=180, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121526-pu4jxrky
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pu4jxrky
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121530-wh50fk26
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wh50fk26
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121531-92llq9n4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/92llq9n4
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oa5s699v[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121447-oa5s699v/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gxxmrzua[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121454-gxxmrzua/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2ry6cx0a[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121455-2ry6cx0a/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=181, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=182, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9u0vl55n[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121458-9u0vl55n/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=183, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=184, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/um3fjlo4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121459-um3fjlo4/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121548-oqy5mqm2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oqy5mqm2
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121549-a8kvclyq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a8kvclyq
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ifjvbcc1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121500-ifjvbcc1/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=185, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=186, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121554-8c7qzwb9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8c7qzwb9
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121554-rtguzcxd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rtguzcxd
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8zxhnw2g[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121502-8zxhnw2g/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.0, training_seed=187, wandb_name=random, GPU=3
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121559-v29mopau
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v29mopau
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/i6mq4td2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121511-i6mq4td2/logs[0m
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121604-gyy62901
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gyy62901
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=188, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3jakj0am[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121513-3jakj0am/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121614-rdydjen3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rdydjen3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pu4jxrky[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121526-pu4jxrky/logs[0m
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.0, training_seed=189, wandb_name=random, GPU=1
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121617-6jdinft0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6jdinft0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wh50fk26[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121530-wh50fk26/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=190, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=191, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/92llq9n4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121531-92llq9n4/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=192, wandb_name=random, GPU=0
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121629-7s76vu7k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7s76vu7k
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oqy5mqm2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121548-oqy5mqm2/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121630-keqfnt7a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/keqfnt7a
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a8kvclyq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121549-a8kvclyq/logs[0m
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=193, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=194, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rtguzcxd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121554-rtguzcxd/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8c7qzwb9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121554-8c7qzwb9/logs[0m
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121639-n3j5i65k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n3j5i65k
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=195, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.0, training_seed=196, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121645-srj77xhq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/srj77xhq
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v29mopau[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121559-v29mopau/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gyy62901[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121604-gyy62901/logs[0m
wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.0, training_seed=197, wandb_name=random, GPU=1
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121649-6sklrhof
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6sklrhof
Running with: pruning_method=-1, pruning_rate=0.0, training_seed=198, wandb_name=random, GPU=2
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121651-1vi06bhp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1vi06bhp
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121658-htgh0o96
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/htgh0o96
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rdydjen3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121614-rdydjen3/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121700-ssvz7pde
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ssvz7pde
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121701-iy30ol0r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iy30ol0r
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6jdinft0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121617-6jdinft0/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.0, training_seed=199, wandb_name=random, GPU=3
wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.0, training_seed=200, wandb_name=random, GPU=0
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121703-vz9jb0cg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vz9jb0cg
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7s76vu7k[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121629-7s76vu7k/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=0, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/keqfnt7a[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121630-keqfnt7a/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=1, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121720-37p5fdn7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/37p5fdn7
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n3j5i65k[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121639-n3j5i65k/logs[0m
wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121720-ajpt0edw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.0_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ajpt0edw
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/srj77xhq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121645-srj77xhq/logs[0m
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121721-7xougbx7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7xougbx7
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=2, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=3, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121735-xvbtkewp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xvbtkewp
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1vi06bhp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121651-1vi06bhp/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6sklrhof[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121649-6sklrhof/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121738-4m9go9g2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4m9go9g2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=4, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=5, wandb_name=random, GPU=2
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121741-94qlmvtc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/94qlmvtc
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iy30ol0r[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121701-iy30ol0r/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/htgh0o96[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121658-htgh0o96/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ssvz7pde[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121700-ssvz7pde/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=6, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=7, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=8, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vz9jb0cg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121703-vz9jb0cg/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121753-4gp2jhf2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4gp2jhf2
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=9, wandb_name=random, GPU=2
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121753-vwg1cy8s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vwg1cy8s
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121802-a3d3mglt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a3d3mglt
wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121804-k6tgrdl4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k6tgrdl4
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121803-d4qb32lk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/d4qb32lk
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121804-myzf4cqt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/myzf4cqt
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/37p5fdn7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121720-37p5fdn7/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.0, TrainSize=5875 -> 5875, removed=0.00
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7xougbx7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121721-7xougbx7/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.0_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ajpt0edw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121720-ajpt0edw/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=10, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=11, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=12, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xvbtkewp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121735-xvbtkewp/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4m9go9g2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121738-4m9go9g2/logs[0m
wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=13, wandb_name=random, GPU=2
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121823-ahbcijjo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ahbcijjo
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=14, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121826-pwql4bm7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pwql4bm7
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/94qlmvtc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121741-94qlmvtc/logs[0m
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121830-khb1cvf7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/khb1cvf7
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=15, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121841-gfzvyqam
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gfzvyqam
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vwg1cy8s[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121753-vwg1cy8s/logs[0m
wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121844-ma3gczti
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ma3gczti
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121844-v7ddsypx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v7ddsypx
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4gp2jhf2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121753-4gp2jhf2/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=16, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a3d3mglt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121802-a3d3mglt/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=17, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/d4qb32lk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121803-d4qb32lk/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=18, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=19, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k6tgrdl4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121804-k6tgrdl4/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/myzf4cqt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121804-myzf4cqt/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=20, wandb_name=random, GPU=1
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=21, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121902-zg0g56b6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zg0g56b6
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121905-7o3djaf4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7o3djaf4
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121906-4gj284pt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4gj284pt
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ahbcijjo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121823-ahbcijjo/logs[0m
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pwql4bm7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121826-pwql4bm7/logs[0m
wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=22, wandb_name=random, GPU=3
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121911-u4si0bav
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u4si0bav
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/khb1cvf7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121830-khb1cvf7/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=23, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=24, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121918-rg5q2xwk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rg5q2xwk
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121920-0jz9pdo4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0jz9pdo4
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gfzvyqam[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121841-gfzvyqam/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121924-urxhzmos
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/urxhzmos
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=25, wandb_name=random, GPU=2
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ma3gczti[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121844-ma3gczti/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v7ddsypx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121844-v7ddsypx/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121927-cfqudgpy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cfqudgpy
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=26, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=27, wandb_name=random, GPU=0
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121931-8x5sh0r1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8x5sh0r1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121941-ud9ymigx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ud9ymigx
wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121942-zaxarrru
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zaxarrru
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_121941-lcfn6lyj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lcfn6lyj
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7o3djaf4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121905-7o3djaf4/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zg0g56b6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121902-zg0g56b6/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=28, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=29, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4gj284pt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121906-4gj284pt/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=30, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u4si0bav[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121911-u4si0bav/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=31, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122000-5bk0kkwq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5bk0kkwq
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122001-a451rsg3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a451rsg3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0jz9pdo4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121920-0jz9pdo4/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rg5q2xwk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121918-rg5q2xwk/logs[0m
wandb: / Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=32, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122003-z1bdsvl8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z1bdsvl8
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=33, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/urxhzmos[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121924-urxhzmos/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cfqudgpy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121927-cfqudgpy/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=34, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=35, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122015-hygh4iqb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hygh4iqb
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8x5sh0r1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121931-8x5sh0r1/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122018-7xdd9aze
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7xdd9aze
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122021-ryv3n9vy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ryv3n9vy
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=36, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122026-7jl5sy0w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7jl5sy0w
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122028-bx3vzs3n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bx3vzs3n
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zaxarrru[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121942-zaxarrru/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ud9ymigx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121941-ud9ymigx/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=37, wandb_name=random, GPU=2
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lcfn6lyj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_121941-lcfn6lyj/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122037-14wiyfko
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/14wiyfko
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=38, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=39, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122046-1qvn6ceb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1qvn6ceb
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122050-lp8ewoa3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lp8ewoa3
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122051-0i9anujm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0i9anujm
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a451rsg3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122001-a451rsg3/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5bk0kkwq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122000-5bk0kkwq/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=40, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=41, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z1bdsvl8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122003-z1bdsvl8/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=42, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7xdd9aze[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122018-7xdd9aze/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hygh4iqb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122015-hygh4iqb/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ryv3n9vy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122021-ryv3n9vy/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=43, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=44, wandb_name=random, GPU=1
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=45, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7jl5sy0w[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122026-7jl5sy0w/logs[0m
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bx3vzs3n[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122028-bx3vzs3n/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122112-1hgdejde
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1hgdejde
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=46, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/14wiyfko[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122037-14wiyfko/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=47, wandb_name=random, GPU=0
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122119-mzny4lhn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mzny4lhn
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=48, wandb_name=random, GPU=1
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122119-6zx22dz1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6zx22dz1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122123-wvjx2382
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wvjx2382
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122124-wheqha28
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wheqha28
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122123-tp7uqz7i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tp7uqz7i
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1qvn6ceb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122046-1qvn6ceb/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122129-umct7acv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/umct7acv
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=49, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122133-pntm9tuc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pntm9tuc
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lp8ewoa3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122050-lp8ewoa3/logs[0m
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122134-33zzdntx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/33zzdntx
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0i9anujm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122051-0i9anujm/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=50, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=51, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122146-wef3nttg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wef3nttg
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122150-169sjnv3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/169sjnv3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122154-2lw59keb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2lw59keb
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1hgdejde[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122112-1hgdejde/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mzny4lhn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122119-mzny4lhn/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=52, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6zx22dz1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122119-6zx22dz1/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=53, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wvjx2382[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122123-wvjx2382/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=54, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wheqha28[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122124-wheqha28/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=55, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tp7uqz7i[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122123-tp7uqz7i/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=56, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122214-nq7804a7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nq7804a7
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=57, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/umct7acv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122129-umct7acv/logs[0m
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122217-7uw2uhta
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7uw2uhta
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122219-ogttoxaq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ogttoxaq
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pntm9tuc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122133-pntm9tuc/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=58, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=59, wandb_name=random, GPU=0
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/33zzdntx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122134-33zzdntx/logs[0m
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122223-gfzrg258
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gfzrg258
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=60, wandb_name=random, GPU=1
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122229-irizeiqj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/irizeiqj
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122232-2wsajfso
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2wsajfso
wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122233-jvoz2ozd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jvoz2ozd
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122236-lk8uoocw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lk8uoocw
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/169sjnv3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122150-169sjnv3/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wef3nttg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122146-wef3nttg/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=61, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=62, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122242-296eoe7d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/296eoe7d
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2lw59keb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122154-2lw59keb/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=63, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122258-eb8tm719
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/eb8tm719
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122258-d3pbjzo1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/d3pbjzo1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nq7804a7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122214-nq7804a7/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7uw2uhta[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122217-7uw2uhta/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122306-c8qe80zh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c8qe80zh
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=64, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=65, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gfzrg258[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122223-gfzrg258/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ogttoxaq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122219-ogttoxaq/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=66, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=67, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2wsajfso[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122232-2wsajfso/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/irizeiqj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122229-irizeiqj/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=68, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=69, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lk8uoocw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122236-lk8uoocw/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jvoz2ozd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122233-jvoz2ozd/logs[0m
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122325-useqkbrv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/useqkbrv
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122325-e6yqd8xu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e6yqd8xu
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122325-sw4iebhk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sw4iebhk
wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=70, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=71, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/296eoe7d[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122242-296eoe7d/logs[0m
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122326-4phizbnj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4phizbnj
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=72, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122338-sx5f26pu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sx5f26pu
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122338-2tz6ndpg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2tz6ndpg
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122340-mphklosh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mphklosh
wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122341-twmxthtt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/twmxthtt
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/eb8tm719[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122258-eb8tm719/logs[0m
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122341-jh5quyrg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jh5quyrg
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/d3pbjzo1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122258-d3pbjzo1/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=73, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=74, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c8qe80zh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122306-c8qe80zh/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=75, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122357-8rtronhd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8rtronhd
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122400-9uyfm1qt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9uyfm1qt
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/useqkbrv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122325-useqkbrv/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e6yqd8xu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122325-e6yqd8xu/logs[0m
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4phizbnj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122326-4phizbnj/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=76, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122406-rb5t9u2p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rb5t9u2p
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=77, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=78, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sw4iebhk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122325-sw4iebhk/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=79, wandb_name=random, GPU=0
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122420-ervsnzhn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ervsnzhn
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122420-njr5zthf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/njr5zthf
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122423-2wjjbgsn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2wjjbgsn
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sx5f26pu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122338-sx5f26pu/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mphklosh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122340-mphklosh/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2tz6ndpg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122338-2tz6ndpg/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=80, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=81, wandb_name=random, GPU=2
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122433-q2l0wife
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q2l0wife
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=82, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/twmxthtt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122341-twmxthtt/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=83, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jh5quyrg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122341-jh5quyrg/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=84, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122445-jtfziu29
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jtfziu29
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122445-qijsv97m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qijsv97m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122448-uz5nt4aa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uz5nt4aa
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9uyfm1qt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122400-9uyfm1qt/logs[0m
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122449-zazbg4cx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zazbg4cx
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8rtronhd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122357-8rtronhd/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=85, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=86, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rb5t9u2p[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122406-rb5t9u2p/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=87, wandb_name=random, GPU=0
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122501-5fcfwnmq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5fcfwnmq
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ervsnzhn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122420-ervsnzhn/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/njr5zthf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122420-njr5zthf/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=88, wandb_name=random, GPU=1
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=89, wandb_name=random, GPU=2
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122509-su6kwkaj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/su6kwkaj
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2wjjbgsn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122423-2wjjbgsn/logs[0m
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122511-kq9p758o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kq9p758o
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122512-1g9u9xwb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1g9u9xwb
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=90, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q2l0wife[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122433-q2l0wife/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=91, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122523-dwphtj43
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dwphtj43
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jtfziu29[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122445-jtfziu29/logs[0m
wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122525-kwbvc6aw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kwbvc6aw
wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=92, wandb_name=random, GPU=1
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122527-7vt87k2w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7vt87k2w
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qijsv97m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122445-qijsv97m/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uz5nt4aa[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122448-uz5nt4aa/logs[0m
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zazbg4cx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122449-zazbg4cx/logs[0m
wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=93, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=94, wandb_name=random, GPU=3
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122534-1i4nufnw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1i4nufnw
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=95, wandb_name=random, GPU=0
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5fcfwnmq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122501-5fcfwnmq/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122541-x84xl7r2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x84xl7r2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=96, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/su6kwkaj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122509-su6kwkaj/logs[0m
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122550-xvxepfvi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xvxepfvi
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122552-dc2xmfsk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dc2xmfsk
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1g9u9xwb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122512-1g9u9xwb/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=97, wandb_name=random, GPU=2
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kq9p758o[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122511-kq9p758o/logs[0m
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=98, wandb_name=random, GPU=3
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122555-sb8lbmes
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sb8lbmes
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=99, wandb_name=random, GPU=0
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122556-6dkpvvj5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6dkpvvj5
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dwphtj43[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122523-dwphtj43/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kwbvc6aw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122525-kwbvc6aw/logs[0m
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=100, wandb_name=random, GPU=1
wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122608-ji0ih5i8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ji0ih5i8
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122608-58x5n84w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/58x5n84w
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=101, wandb_name=random, GPU=2
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122612-uee99gf2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uee99gf2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7vt87k2w[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122527-7vt87k2w/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1i4nufnw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122534-1i4nufnw/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=102, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=103, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122626-p8iel74t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p8iel74t
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122625-dwfv47ct
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dwfv47ct
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x84xl7r2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122541-x84xl7r2/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122635-vqp1qimo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vqp1qimo
wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=104, wandb_name=random, GPU=1
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122634-doc7pm04
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/doc7pm04
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dc2xmfsk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122552-dc2xmfsk/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=105, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122648-it8uje4d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/it8uje4d
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sb8lbmes[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122555-sb8lbmes/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6dkpvvj5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122556-6dkpvvj5/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xvxepfvi[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122550-xvxepfvi/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=106, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=107, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=108, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ji0ih5i8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122608-ji0ih5i8/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/58x5n84w[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122608-58x5n84w/logs[0m
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122700-yo0wm0nw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yo0wm0nw
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uee99gf2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122612-uee99gf2/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=109, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=110, wandb_name=random, GPU=3
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122704-vp67wgwz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vp67wgwz
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=111, wandb_name=random, GPU=0
wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122705-2771jhon
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2771jhon
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122705-3eeuuj38
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3eeuuj38
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dwfv47ct[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122625-dwfv47ct/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p8iel74t[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122626-p8iel74t/logs[0m
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=112, wandb_name=random, GPU=1
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=113, wandb_name=random, GPU=2
wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122716-i2r411ik
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/i2r411ik
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vqp1qimo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122635-vqp1qimo/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122719-m05w4mkn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m05w4mkn
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/doc7pm04[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122634-doc7pm04/logs[0m
wandb: / Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=114, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122722-bmesoj7c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bmesoj7c
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=115, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/it8uje4d[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122648-it8uje4d/logs[0m
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122729-m9d0l3vu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m9d0l3vu
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=116, wandb_name=random, GPU=1
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122735-rf8397i7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rf8397i7
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122738-o5uhvell
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o5uhvell
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yo0wm0nw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122700-yo0wm0nw/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122742-mk9iicle
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mk9iicle
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vp67wgwz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122704-vp67wgwz/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=117, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3eeuuj38[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122705-3eeuuj38/logs[0m
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122746-25fcy86b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/25fcy86b
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2771jhon[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122705-2771jhon/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=118, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=119, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=120, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/i2r411ik[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122716-i2r411ik/logs[0m
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122801-63lsb0b3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/63lsb0b3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122802-abi16psb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/abi16psb
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m05w4mkn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122719-m05w4mkn/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bmesoj7c[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122722-bmesoj7c/logs[0m
wandb: / Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=121, wandb_name=random, GPU=2
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122803-tj4a4icn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tj4a4icn
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=122, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=123, wandb_name=random, GPU=0
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122807-3qmgw8ec
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3qmgw8ec
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m9d0l3vu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122729-m9d0l3vu/logs[0m
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122819-th2iqwdy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/th2iqwdy
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=124, wandb_name=random, GPU=1
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122821-ae65nbl6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ae65nbl6
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122821-iexsup2t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iexsup2t
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rf8397i7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122735-rf8397i7/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o5uhvell[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122738-o5uhvell/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=125, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=126, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122834-tokzs85z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tokzs85z
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mk9iicle[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122742-mk9iicle/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/25fcy86b[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122746-25fcy86b/logs[0m
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=127, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=128, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122839-di2jf1f5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/di2jf1f5
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122841-npi560bq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/npi560bq
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/63lsb0b3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122801-63lsb0b3/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/abi16psb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122802-abi16psb/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=129, wandb_name=random, GPU=2
wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tj4a4icn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122803-tj4a4icn/logs[0m
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122855-yomxqan5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yomxqan5
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122854-60zxkixt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/60zxkixt
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3qmgw8ec[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122807-3qmgw8ec/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=130, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=131, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=132, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/th2iqwdy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122819-th2iqwdy/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=133, wandb_name=random, GPU=2
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iexsup2t[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122821-iexsup2t/logs[0m
wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122911-24nvwu7w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/24nvwu7w
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122911-oa4bqebl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oa4bqebl
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ae65nbl6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122821-ae65nbl6/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122911-jtfbea1a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jtfbea1a
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=134, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=135, wandb_name=random, GPU=0
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tokzs85z[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122834-tokzs85z/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122917-c1sy7r95
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c1sy7r95
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=136, wandb_name=random, GPU=1
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/di2jf1f5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122839-di2jf1f5/logs[0m
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122925-0vli6r9q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0vli6r9q
wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122928-d13aqrdy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/d13aqrdy
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/npi560bq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122841-npi560bq/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=137, wandb_name=random, GPU=2
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122928-kef0yhey
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kef0yhey
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=138, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/60zxkixt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122854-60zxkixt/logs[0m
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yomxqan5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122855-yomxqan5/logs[0m
wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=139, wandb_name=random, GPU=0
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122940-aoqvpqk7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/aoqvpqk7
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=140, wandb_name=random, GPU=1
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122944-3dhet8kq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3dhet8kq
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122948-19n6og8w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/19n6og8w
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oa4bqebl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122911-oa4bqebl/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jtfbea1a[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122911-jtfbea1a/logs[0m
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/24nvwu7w[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122911-24nvwu7w/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122956-wsup5nfd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wsup5nfd
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=141, wandb_name=random, GPU=2
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=142, wandb_name=random, GPU=3
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=143, wandb_name=random, GPU=0
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_122958-94a9c627
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/94a9c627
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c1sy7r95[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122917-c1sy7r95/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=144, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0vli6r9q[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122925-0vli6r9q/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/d13aqrdy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122928-d13aqrdy/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kef0yhey[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122928-kef0yhey/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=145, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123013-7pre33cp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7pre33cp
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=146, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=147, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123014-odar0kk8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/odar0kk8
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123015-leno7wfv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/leno7wfv
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123016-fb9bao83
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fb9bao83
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/aoqvpqk7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122940-aoqvpqk7/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=148, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123025-9b9bz79e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9b9bz79e
wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123026-6gstn19m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6gstn19m
wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123027-esc2e56q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/esc2e56q
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3dhet8kq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122944-3dhet8kq/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/19n6og8w[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122948-19n6og8w/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=149, wandb_name=random, GPU=2
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=150, wandb_name=random, GPU=3
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123036-xsbc168k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xsbc168k
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wsup5nfd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122956-wsup5nfd/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=151, wandb_name=random, GPU=0
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123045-p5dwpdaz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p5dwpdaz
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/94a9c627[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_122958-94a9c627/logs[0m
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123050-e3wjogee
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e3wjogee
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=152, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/odar0kk8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123014-odar0kk8/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7pre33cp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123013-7pre33cp/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=153, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fb9bao83[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123016-fb9bao83/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/leno7wfv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123015-leno7wfv/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=154, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=155, wandb_name=random, GPU=0
wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=156, wandb_name=random, GPU=1
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123105-t5yo465b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/t5yo465b
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123112-zrk9srh0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zrk9srh0
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123113-aw3yrm6v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/aw3yrm6v
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123113-6m8hmx6o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6m8hmx6o
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123113-qwedznzf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qwedznzf
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/esc2e56q[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123027-esc2e56q/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6gstn19m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123026-6gstn19m/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9b9bz79e[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123025-9b9bz79e/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=157, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=158, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=159, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xsbc168k[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123036-xsbc168k/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=160, wandb_name=random, GPU=1
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123127-nms8487k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nms8487k
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123132-ghs939yb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ghs939yb
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p5dwpdaz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123045-p5dwpdaz/logs[0m
wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123133-jpd7s2tw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jpd7s2tw
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123133-yl4i4tll
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yl4i4tll
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=161, wandb_name=random, GPU=2
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e3wjogee[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123050-e3wjogee/logs[0m
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123139-jfm7fwsh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jfm7fwsh
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=162, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/t5yo465b[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123105-t5yo465b/logs[0m
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123150-fjiogqmg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fjiogqmg
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=163, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zrk9srh0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123112-zrk9srh0/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=164, wandb_name=random, GPU=1
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/aw3yrm6v[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123113-aw3yrm6v/logs[0m
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123157-sqmral07
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sqmral07
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6m8hmx6o[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123113-6m8hmx6o/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qwedznzf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123113-qwedznzf/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=165, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=166, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=167, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123206-9fk7564c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9fk7564c
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nms8487k[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123127-nms8487k/logs[0m
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123210-ytxx936f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ytxx936f
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=168, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ghs939yb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123132-ghs939yb/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jpd7s2tw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123133-jpd7s2tw/logs[0m
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123218-wp27sgoz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wp27sgoz
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123216-9f2jcior
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9f2jcior
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=169, wandb_name=random, GPU=2
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jfm7fwsh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123139-jfm7fwsh/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yl4i4tll[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123133-yl4i4tll/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123219-0b0ecxg5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0b0ecxg5
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=170, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=171, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=172, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123232-xqm9wkzh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xqm9wkzh
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123234-psam2hd4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/psam2hd4
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fjiogqmg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123150-fjiogqmg/logs[0m
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123237-cgpds8hm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cgpds8hm
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123237-xp9fsqme
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xp9fsqme
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123237-p8a4beki
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p8a4beki
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=173, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sqmral07[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123157-sqmral07/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=174, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9fk7564c[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123206-9fk7564c/logs[0m
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123257-mb4i4bcf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mb4i4bcf
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123258-h709jata
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h709jata
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=175, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ytxx936f[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123210-ytxx936f/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=176, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wp27sgoz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123218-wp27sgoz/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9f2jcior[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123216-9f2jcior/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=177, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0b0ecxg5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123219-0b0ecxg5/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=178, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=179, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123315-tn8apbpk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tn8apbpk
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xqm9wkzh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123232-xqm9wkzh/logs[0m
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=180, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123321-ywtk2gbk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ywtk2gbk
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/psam2hd4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123234-psam2hd4/logs[0m
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123328-fjjk7083
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fjjk7083
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123327-xi0o8ab1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xi0o8ab1
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cgpds8hm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123237-cgpds8hm/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: / Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=181, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p8a4beki[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123237-p8a4beki/logs[0m
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123329-bfndjl8m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bfndjl8m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xp9fsqme[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123237-xp9fsqme/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=182, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=183, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=184, wandb_name=random, GPU=1
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mb4i4bcf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123257-mb4i4bcf/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123338-0fze317v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0fze317v
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=185, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h709jata[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123258-h709jata/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123346-6iz6qjjz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6iz6qjjz
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=186, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123349-sfs2mij0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sfs2mij0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123351-bh2mtdxd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bh2mtdxd
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123352-pr5qoe27
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pr5qoe27
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123353-f4dooy7f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f4dooy7f
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tn8apbpk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123315-tn8apbpk/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=187, wandb_name=random, GPU=0
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ywtk2gbk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123321-ywtk2gbk/logs[0m
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123402-rd44t4d8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rd44t4d8
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=188, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fjjk7083[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123328-fjjk7083/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xi0o8ab1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123327-xi0o8ab1/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bfndjl8m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123329-bfndjl8m/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=189, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=190, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=191, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123418-5m8shvdm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5m8shvdm
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123423-eik6s9ia
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/eik6s9ia
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123427-yjjwehx0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yjjwehx0
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123426-v4qj12bc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v4qj12bc
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sfs2mij0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123349-sfs2mij0/logs[0m
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6iz6qjjz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123346-6iz6qjjz/logs[0m
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123431-hiiqzvkc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hiiqzvkc
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0fze317v[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123338-0fze317v/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pr5qoe27[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123352-pr5qoe27/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=192, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=193, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bh2mtdxd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123351-bh2mtdxd/logs[0m
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=194, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=195, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=196, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f4dooy7f[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123353-f4dooy7f/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=197, wandb_name=random, GPU=2
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rd44t4d8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123402-rd44t4d8/logs[0m
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123447-lmqxnz0y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lmqxnz0y
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123450-iyqyba1b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iyqyba1b
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123449-yzks42hc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yzks42hc
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.3, training_seed=198, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123452-m73ml3oi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m73ml3oi
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123454-p8keyhun
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p8keyhun
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123500-c9s29p5y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c9s29p5y
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5m8shvdm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123418-5m8shvdm/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=199, wandb_name=random, GPU=0
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123508-2nrxlkz4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2nrxlkz4
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/eik6s9ia[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123423-eik6s9ia/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.3, training_seed=200, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v4qj12bc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123426-v4qj12bc/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yjjwehx0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123427-yjjwehx0/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=0, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=1, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hiiqzvkc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123431-hiiqzvkc/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123522-dwtc3e5m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dwtc3e5m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=2, wandb_name=random, GPU=0
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123525-3nelq3un
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.3_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3nelq3un
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123533-e0xx3wnx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e0xx3wnx
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123535-0nvccrbk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0nvccrbk
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123536-hspd59si
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hspd59si
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lmqxnz0y[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123447-lmqxnz0y/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iyqyba1b[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123450-iyqyba1b/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m73ml3oi[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123452-m73ml3oi/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yzks42hc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123449-yzks42hc/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=3, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=4, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=5, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=6, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p8keyhun[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123454-p8keyhun/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c9s29p5y[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123500-c9s29p5y/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=7, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2nrxlkz4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123508-2nrxlkz4/logs[0m
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=8, wandb_name=random, GPU=2
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123555-hy75olp5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hy75olp5
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=9, wandb_name=random, GPU=3
wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123559-3pb86qv2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3pb86qv2
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123602-0fb733ej
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0fb733ej
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123603-cv4mi9nv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cv4mi9nv
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dwtc3e5m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123522-dwtc3e5m/logs[0m
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=10, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123606-dqu3ogf1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dqu3ogf1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.3, TrainSize=5875 -> 4113, removed=0.30
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123608-16ptchn7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/16ptchn7
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.3_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3nelq3un[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123525-3nelq3un/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=11, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e0xx3wnx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123533-e0xx3wnx/logs[0m
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123613-xsxzrklv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xsxzrklv
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=12, wandb_name=random, GPU=2
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123616-m9memitm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m9memitm
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0nvccrbk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123535-0nvccrbk/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=13, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hspd59si[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123536-hspd59si/logs[0m
wandb: / Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123625-67k9af1s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/67k9af1s
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=14, wandb_name=random, GPU=0
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123629-8vcxdn79
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8vcxdn79
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123638-y8xm5a27
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y8xm5a27
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hy75olp5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123555-hy75olp5/logs[0m
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123642-pz6ntszr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pz6ntszr
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3pb86qv2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123559-3pb86qv2/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=15, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=16, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cv4mi9nv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123603-cv4mi9nv/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0fb733ej[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123602-0fb733ej/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=17, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=18, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dqu3ogf1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123606-dqu3ogf1/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/16ptchn7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123608-16ptchn7/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=19, wandb_name=random, GPU=1
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=20, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123657-zrkglqd7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zrkglqd7
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123700-l11ntse7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l11ntse7
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m9memitm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123616-m9memitm/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xsxzrklv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123613-xsxzrklv/logs[0m
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=21, wandb_name=random, GPU=3
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123706-1zh73mz9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1zh73mz9
wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123706-4pz354xy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4pz354xy
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=22, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123709-kkv8wngk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kkv8wngk
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/67k9af1s[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123625-67k9af1s/logs[0m
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123711-5qttik1h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5qttik1h
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=23, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8vcxdn79[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123629-8vcxdn79/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=24, wandb_name=random, GPU=2
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123723-8vslqkzy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8vslqkzy
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123722-81wgt0va
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/81wgt0va
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y8xm5a27[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123638-y8xm5a27/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=25, wandb_name=random, GPU=3
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pz6ntszr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123642-pz6ntszr/logs[0m
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123731-st89bp2o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/st89bp2o
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=26, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123740-5vo9xgw1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5vo9xgw1
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123744-weg25qds
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/weg25qds
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zrkglqd7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123657-zrkglqd7/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=27, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l11ntse7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123700-l11ntse7/logs[0m
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123753-fl8nydiy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fl8nydiy
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kkv8wngk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123709-kkv8wngk/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=28, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4pz354xy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123706-4pz354xy/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1zh73mz9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123706-1zh73mz9/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=29, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5qttik1h[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123711-5qttik1h/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=30, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=31, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=32, wandb_name=random, GPU=2
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/81wgt0va[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123722-81wgt0va/logs[0m
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123804-n9jzyyo7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n9jzyyo7
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8vslqkzy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123723-8vslqkzy/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=33, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=34, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123809-s0zp2a81
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s0zp2a81
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/st89bp2o[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123731-st89bp2o/logs[0m
wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123815-fx0uj4py
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fx0uj4py
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123814-maenzhsc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/maenzhsc
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123818-60h5lc3r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/60h5lc3r
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123819-uxdgkxnc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uxdgkxnc
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=35, wandb_name=random, GPU=1
wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123821-vbhouj8y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vbhouj8y
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123823-yl9k04ym
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yl9k04ym
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5vo9xgw1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123740-5vo9xgw1/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/weg25qds[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123744-weg25qds/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=36, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=37, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123848-isxgbjxs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/isxgbjxs
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123856-qfwlygom
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qfwlygom
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123858-q5bn0c9m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q5bn0c9m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fl8nydiy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123753-fl8nydiy/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=38, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_123943-etdd8cxj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/etdd8cxj
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n9jzyyo7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123804-n9jzyyo7/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=39, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fx0uj4py[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123815-fx0uj4py/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s0zp2a81[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123809-s0zp2a81/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=40, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124015-tuemy72a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tuemy72a
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=41, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/60h5lc3r[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123818-60h5lc3r/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yl9k04ym[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123823-yl9k04ym/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vbhouj8y[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123821-vbhouj8y/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/maenzhsc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123814-maenzhsc/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uxdgkxnc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123819-uxdgkxnc/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124022-i5136mrz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/i5136mrz
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=42, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=43, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=44, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=45, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=46, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124026-m3rx5ahd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m3rx5ahd
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/isxgbjxs[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123848-isxgbjxs/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qfwlygom[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123856-qfwlygom/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q5bn0c9m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123858-q5bn0c9m/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=47, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=48, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124035-cg8gzdkb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cg8gzdkb
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=49, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124036-ism7xba6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ism7xba6
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124036-0pjqtlad
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0pjqtlad
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124036-p2dasawa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p2dasawa
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124037-a9ktb7ia
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a9ktb7ia
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/etdd8cxj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_123943-etdd8cxj/logs[0m
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124046-0yom5y0l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0yom5y0l
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=50, wandb_name=random, GPU=0
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124047-nmqpae5b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nmqpae5b
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124101-8dwbbwjd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8dwbbwjd
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tuemy72a[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124015-tuemy72a/logs[0m
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124109-tcbnp38o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tcbnp38o
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/i5136mrz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124022-i5136mrz/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=51, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=52, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m3rx5ahd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124026-m3rx5ahd/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=53, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124141-l8vdfz9f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l8vdfz9f
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124139-qj3svtis
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qj3svtis
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cg8gzdkb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124035-cg8gzdkb/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124159-8b3npkow
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8b3npkow
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=54, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0pjqtlad[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124036-0pjqtlad/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a9ktb7ia[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124037-a9ktb7ia/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p2dasawa[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124036-p2dasawa/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=55, wandb_name=random, GPU=1
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124225-cyq16zvo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cyq16zvo
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=56, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0yom5y0l[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124046-0yom5y0l/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=57, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ism7xba6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124036-ism7xba6/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=58, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=59, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nmqpae5b[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124047-nmqpae5b/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124238-xr5ribe2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xr5ribe2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=60, wandb_name=random, GPU=2
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124240-52pwwfrh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/52pwwfrh
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124244-cidg9615
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cidg9615
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124244-7s7v71zf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7s7v71zf
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124246-q0s2ohya
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q0s2ohya
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124250-vq1rbntl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vq1rbntl
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8dwbbwjd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124101-8dwbbwjd/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tcbnp38o[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124109-tcbnp38o/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=61, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=62, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124308-8t07pwb0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8t07pwb0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qj3svtis[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124139-qj3svtis/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124312-2iccxq93
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2iccxq93
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l8vdfz9f[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124141-l8vdfz9f/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=63, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=64, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8b3npkow[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124159-8b3npkow/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124326-kqtdjq8y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kqtdjq8y
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cyq16zvo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124225-cyq16zvo/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=65, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124332-kpmjpqi9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kpmjpqi9
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=66, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xr5ribe2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124238-xr5ribe2/logs[0m
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/52pwwfrh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124240-52pwwfrh/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124348-jd7saulb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jd7saulb
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=67, wandb_name=random, GPU=1
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124355-wv471a1x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wv471a1x
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=68, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7s7v71zf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124244-7s7v71zf/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cidg9615[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124244-cidg9615/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=69, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=70, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124411-f3nphya0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f3nphya0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q0s2ohya[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124246-q0s2ohya/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=71, wandb_name=random, GPU=1
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124421-k9n6jnrq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k9n6jnrq
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vq1rbntl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124250-vq1rbntl/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124427-t68wn7m6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/t68wn7m6
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124428-5iz5gqis
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5iz5gqis
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=72, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124438-qx3f9v2k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qx3f9v2k
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124446-s056ia73
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s056ia73
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8t07pwb0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124308-8t07pwb0/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2iccxq93[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124312-2iccxq93/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=73, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=74, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kqtdjq8y[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124326-kqtdjq8y/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124512-3xwtnhb8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3xwtnhb8
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124513-hj6y4ye1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hj6y4ye1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=75, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kpmjpqi9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124332-kpmjpqi9/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124522-3w6lkn6v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3w6lkn6v
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=76, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jd7saulb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124348-jd7saulb/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wv471a1x[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124355-wv471a1x/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=77, wandb_name=random, GPU=3
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124535-f8mpqk2y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f8mpqk2y
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f3nphya0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124411-f3nphya0/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=78, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k9n6jnrq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124421-k9n6jnrq/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=79, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/t68wn7m6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124427-t68wn7m6/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=80, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5iz5gqis[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124428-5iz5gqis/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124549-6r3ubg3u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6r3ubg3u
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=81, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=82, wandb_name=random, GPU=0
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qx3f9v2k[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124438-qx3f9v2k/logs[0m
wandb: / Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s056ia73[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124446-s056ia73/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124555-m4pi9mfs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m4pi9mfs
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=83, wandb_name=random, GPU=1
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124600-di0752uw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/di0752uw
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=84, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124604-evk3d2h2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/evk3d2h2
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124606-rma7lfvz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rma7lfvz
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3xwtnhb8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124512-3xwtnhb8/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hj6y4ye1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124513-hj6y4ye1/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=85, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=86, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3w6lkn6v[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124522-3w6lkn6v/logs[0m
wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124620-akvev825
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/akvev825
wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124621-dqtaroq2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dqtaroq2
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124622-4ydqu13q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4ydqu13q
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=87, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f8mpqk2y[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124535-f8mpqk2y/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=88, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124638-dl0xcist
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dl0xcist
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124639-d5d1a5d9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/d5d1a5d9
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124643-n8jg0ru9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n8jg0ru9
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124700-xs392k4w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xs392k4w
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6r3ubg3u[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124549-6r3ubg3u/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=89, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124735-pere27os
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pere27os
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m4pi9mfs[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124555-m4pi9mfs/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/di0752uw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124600-di0752uw/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=90, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=91, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/evk3d2h2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124604-evk3d2h2/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=92, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124800-hcjcvpuy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hcjcvpuy
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124801-vqbbbxz9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vqbbbxz9
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rma7lfvz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124606-rma7lfvz/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=93, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124810-htzua4zv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/htzua4zv
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/akvev825[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124620-akvev825/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dqtaroq2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124621-dqtaroq2/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4ydqu13q[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124622-4ydqu13q/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=94, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=95, wandb_name=random, GPU=1
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124819-u5rkmw67
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u5rkmw67
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=96, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124827-5yagx0wq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5yagx0wq
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dl0xcist[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124638-dl0xcist/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/d5d1a5d9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124639-d5d1a5d9/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124831-5gz8nk6m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5gz8nk6m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124832-yl5mq5l1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yl5mq5l1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n8jg0ru9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124643-n8jg0ru9/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=97, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xs392k4w[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124700-xs392k4w/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=98, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=99, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=100, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124848-ei3555mo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ei3555mo
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124852-9pj2adl2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9pj2adl2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pere27os[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124735-pere27os/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124856-m63hqaxo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m63hqaxo
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124858-2w68ydl3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2w68ydl3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=101, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124915-2o8wzha8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2o8wzha8
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hcjcvpuy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124800-hcjcvpuy/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vqbbbxz9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124801-vqbbbxz9/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=102, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=103, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/htzua4zv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124810-htzua4zv/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u5rkmw67[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124819-u5rkmw67/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=104, wandb_name=random, GPU=2
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124944-s4f0q24j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s4f0q24j
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=105, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_124950-mq94hqlt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mq94hqlt
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5gz8nk6m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124831-5gz8nk6m/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125004-7d7bi4uy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7d7bi4uy
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5yagx0wq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124827-5yagx0wq/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125005-ezu7ermd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ezu7ermd
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=106, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=107, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yl5mq5l1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124832-yl5mq5l1/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=108, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ei3555mo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124848-ei3555mo/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125025-3r7tlcdb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3r7tlcdb
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125025-drgvcqvk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/drgvcqvk
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=109, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9pj2adl2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124852-9pj2adl2/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m63hqaxo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124856-m63hqaxo/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=110, wandb_name=random, GPU=0
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=111, wandb_name=random, GPU=1
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125034-eygoan8e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/eygoan8e
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2w68ydl3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124858-2w68ydl3/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=112, wandb_name=random, GPU=2
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125043-0xqwm8ef
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0xqwm8ef
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125047-wvadrovs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wvadrovs
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125047-lj1cq5o2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lj1cq5o2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2o8wzha8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124915-2o8wzha8/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125057-iemvchpg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iemvchpg
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=113, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ezu7ermd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125005-ezu7ermd/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s4f0q24j[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124944-s4f0q24j/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7d7bi4uy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125004-7d7bi4uy/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mq94hqlt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_124950-mq94hqlt/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=114, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=115, wandb_name=random, GPU=1
wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=116, wandb_name=random, GPU=2
wandb: / Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=117, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125115-af234t54
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/af234t54
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125128-qspnbo5q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qspnbo5q
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125129-llikm6yr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/llikm6yr
wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125132-jgrj59a0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jgrj59a0
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125131-xh3ldm1x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xh3ldm1x
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/drgvcqvk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125025-drgvcqvk/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3r7tlcdb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125025-3r7tlcdb/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=118, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=119, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/eygoan8e[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125034-eygoan8e/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0xqwm8ef[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125043-0xqwm8ef/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=120, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125203-zlwfss8u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zlwfss8u
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125203-20abl5da
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/20abl5da
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=121, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wvadrovs[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125047-wvadrovs/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125216-n3cbiexl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n3cbiexl
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=122, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lj1cq5o2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125047-lj1cq5o2/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125222-xuqlofnv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xuqlofnv
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=123, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125237-sz7qtyk9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sz7qtyk9
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iemvchpg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125057-iemvchpg/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125247-jqs467la
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jqs467la
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=124, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125300-nz4rp9s5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nz4rp9s5
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/llikm6yr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125129-llikm6yr/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/af234t54[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125115-af234t54/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=125, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=126, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qspnbo5q[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125128-qspnbo5q/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=127, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jgrj59a0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125132-jgrj59a0/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=128, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xh3ldm1x[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125131-xh3ldm1x/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125327-ptkzoeha
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ptkzoeha
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125330-lltuucxx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lltuucxx
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=129, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125332-uuu4llov
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uuu4llov
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/20abl5da[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125203-20abl5da/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zlwfss8u[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125203-zlwfss8u/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125337-wugajg2e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wugajg2e
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=130, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=131, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n3cbiexl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125216-n3cbiexl/logs[0m
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xuqlofnv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125222-xuqlofnv/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125346-k39ir2fp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k39ir2fp
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sz7qtyk9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125237-sz7qtyk9/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=132, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=133, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=134, wandb_name=random, GPU=0
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jqs467la[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125247-jqs467la/logs[0m
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125355-43et6lra
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/43et6lra
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=135, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125359-iv6a30pp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iv6a30pp
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125407-xf2am8tt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xf2am8tt
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nz4rp9s5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125300-nz4rp9s5/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=136, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125412-eft88adq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/eft88adq
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125415-wlz8mpdq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wlz8mpdq
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125418-pmg70ma6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pmg70ma6
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lltuucxx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125330-lltuucxx/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ptkzoeha[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125327-ptkzoeha/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uuu4llov[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125332-uuu4llov/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=137, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=138, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=139, wandb_name=random, GPU=1
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125435-x98ki4qf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x98ki4qf
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wugajg2e[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125337-wugajg2e/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=140, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125453-yg2u89oy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yg2u89oy
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125454-c554dd81
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c554dd81
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125455-gfw74rsp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gfw74rsp
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k39ir2fp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125346-k39ir2fp/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=141, wandb_name=random, GPU=3
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125508-atb1xnn2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/atb1xnn2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/43et6lra[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125355-43et6lra/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=142, wandb_name=random, GPU=0
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125525-x6vdxb0j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x6vdxb0j
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iv6a30pp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125359-iv6a30pp/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=143, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125540-ccavrz8p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ccavrz8p
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/eft88adq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125412-eft88adq/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125552-lq5whj00
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lq5whj00
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=144, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xf2am8tt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125407-xf2am8tt/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=145, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125610-g643nvgb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g643nvgb
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pmg70ma6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125418-pmg70ma6/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125616-7d2on1xo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7d2on1xo
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=146, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wlz8mpdq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125415-wlz8mpdq/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=147, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x98ki4qf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125435-x98ki4qf/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125628-h939az31
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h939az31
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yg2u89oy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125453-yg2u89oy/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=148, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=149, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125634-oqo2mait
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oqo2mait
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c554dd81[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125454-c554dd81/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=150, wandb_name=random, GPU=0
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125644-zueuwz67
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zueuwz67
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gfw74rsp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125455-gfw74rsp/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125645-467iw8rc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/467iw8rc
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x6vdxb0j[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125525-x6vdxb0j/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/atb1xnn2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125508-atb1xnn2/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=151, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=152, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=153, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ccavrz8p[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125540-ccavrz8p/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125700-7q0gfz30
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7q0gfz30
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=154, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125704-d9dw1sq4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/d9dw1sq4
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125704-zvku3puj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zvku3puj
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125709-e3743iyp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e3743iyp
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lq5whj00[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125552-lq5whj00/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=155, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g643nvgb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125610-g643nvgb/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=156, wandb_name=random, GPU=2
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125722-8z3gm8ny
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8z3gm8ny
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7d2on1xo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125616-7d2on1xo/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=157, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h939az31[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125628-h939az31/logs[0m
wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125744-e0ri0pqd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e0ri0pqd
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125747-qk7a09tn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qk7a09tn
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=158, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oqo2mait[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125634-oqo2mait/logs[0m
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125755-z7je8y70
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z7je8y70
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=159, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125805-oyvh5gwc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oyvh5gwc
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125809-vbsy9e9q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vbsy9e9q
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/467iw8rc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125645-467iw8rc/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zueuwz67[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125644-zueuwz67/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=160, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=161, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125838-91d3w9u7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/91d3w9u7
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125843-llxozglw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/llxozglw
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7q0gfz30[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125700-7q0gfz30/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zvku3puj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125704-zvku3puj/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=162, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/d9dw1sq4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125704-d9dw1sq4/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=163, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=164, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e3743iyp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125709-e3743iyp/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=165, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125907-swknayh0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/swknayh0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8z3gm8ny[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125722-8z3gm8ny/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125909-oh87hch0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oh87hch0
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125912-74luxgrn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/74luxgrn
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=166, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e0ri0pqd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125744-e0ri0pqd/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qk7a09tn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125747-qk7a09tn/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z7je8y70[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125755-z7je8y70/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=167, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=168, wandb_name=random, GPU=2
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=169, wandb_name=random, GPU=3
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oyvh5gwc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125805-oyvh5gwc/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vbsy9e9q[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125809-vbsy9e9q/logs[0m
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125922-zwp1270j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zwp1270j
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=170, wandb_name=random, GPU=0
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125927-vc85i3n2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vc85i3n2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=171, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/91d3w9u7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125838-91d3w9u7/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=172, wandb_name=random, GPU=2
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125939-57tm7158
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/57tm7158
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125945-196t22ze
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/196t22ze
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/llxozglw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125843-llxozglw/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125948-0r2kbpu3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0r2kbpu3
wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125949-zp52vp1q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zp52vp1q
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125950-3upv3pla
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3upv3pla
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=173, wandb_name=random, GPU=3
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_125953-a7n0apkc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a7n0apkc
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130014-n4cfx78d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n4cfx78d
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/swknayh0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125907-swknayh0/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=174, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oh87hch0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125909-oh87hch0/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/74luxgrn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125912-74luxgrn/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=175, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=176, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130058-avwrnv7g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/avwrnv7g
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130107-l1sozjwl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l1sozjwl
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130108-ol6sm94v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ol6sm94v
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zwp1270j[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125922-zwp1270j/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=177, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130127-fiy19n2u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fiy19n2u
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vc85i3n2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125927-vc85i3n2/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=178, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/57tm7158[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125939-57tm7158/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/196t22ze[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125945-196t22ze/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0r2kbpu3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125948-0r2kbpu3/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=179, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=180, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=181, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130142-f3hsj2ab
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f3hsj2ab
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3upv3pla[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125950-3upv3pla/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n4cfx78d[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130014-n4cfx78d/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a7n0apkc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125953-a7n0apkc/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130147-iqtrus86
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iqtrus86
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zp52vp1q[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_125949-zp52vp1q/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=182, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130150-wton6fj2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wton6fj2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=183, wandb_name=random, GPU=1
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=184, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=185, wandb_name=random, GPU=3
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130152-rejvlt7a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rejvlt7a
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130204-vt0nl8do
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vt0nl8do
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130207-izcuewtc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/izcuewtc
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130209-ztfzdxag
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ztfzdxag
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130210-9dsanmb1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9dsanmb1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/avwrnv7g[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130058-avwrnv7g/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ol6sm94v[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130108-ol6sm94v/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l1sozjwl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130107-l1sozjwl/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=186, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=187, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=188, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fiy19n2u[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130127-fiy19n2u/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=189, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f3hsj2ab[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130142-f3hsj2ab/logs[0m
wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130240-al7b2b9e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/al7b2b9e
wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130243-rlbdulxb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rlbdulxb
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130244-b3nefver
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b3nefver
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=190, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iqtrus86[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130147-iqtrus86/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=191, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wton6fj2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130150-wton6fj2/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rejvlt7a[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130152-rejvlt7a/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=192, wandb_name=random, GPU=2
wandb: / Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130310-bzb8hf6g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bzb8hf6g
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.5, training_seed=193, wandb_name=random, GPU=3
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130314-riuelwn5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/riuelwn5
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vt0nl8do[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130204-vt0nl8do/logs[0m
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130327-uuf6xb1t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uuf6xb1t
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/izcuewtc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130207-izcuewtc/logs[0m
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130331-pz8ud9pf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pz8ud9pf
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ztfzdxag[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130209-ztfzdxag/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=194, wandb_name=random, GPU=0
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130332-0ifxkkht
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0ifxkkht
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=195, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=196, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9dsanmb1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130210-9dsanmb1/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130350-lg6wcwxw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lg6wcwxw
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=197, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130355-ud50bnxv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ud50bnxv
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130357-s3havhcp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s3havhcp
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130405-yqugn4qs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yqugn4qs
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/al7b2b9e[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130240-al7b2b9e/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b3nefver[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130244-b3nefver/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=198, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=199, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rlbdulxb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130243-rlbdulxb/logs[0m
Running with: pruning_method=-1, pruning_rate=0.5, training_seed=200, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130449-xvifqlz5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xvifqlz5
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bzb8hf6g[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130310-bzb8hf6g/logs[0m
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130452-0n7wwezg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0n7wwezg
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0ifxkkht[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130332-0ifxkkht/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uuf6xb1t[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130327-uuf6xb1t/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/riuelwn5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130314-riuelwn5/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=0, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lg6wcwxw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130350-lg6wcwxw/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=1, wandb_name=random, GPU=0
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130502-etim6oh1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.5_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/etim6oh1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pz8ud9pf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130331-pz8ud9pf/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=2, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=3, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s3havhcp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130357-s3havhcp/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=4, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=5, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ud50bnxv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130355-ud50bnxv/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=6, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=7, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yqugn4qs[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130405-yqugn4qs/logs[0m
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130515-nn6p7a62
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nn6p7a62
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130514-1fb2e4na
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1fb2e4na
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=8, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130522-kldc87kz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kldc87kz
wandb: / Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130521-gpm8k2uf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gpm8k2uf
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130522-4fcfu40t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4fcfu40t
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130523-10ejqg83
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/10ejqg83
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130526-t0m6zxqm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/t0m6zxqm
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130530-xpc0zv8p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xpc0zv8p
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130545-oaeqfraq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oaeqfraq
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xvifqlz5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130449-xvifqlz5/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=9, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130627-qvcm1293
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qvcm1293
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0n7wwezg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130452-0n7wwezg/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.5, TrainSize=5875 -> 2938, removed=0.50
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=10, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.5_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/etim6oh1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130502-etim6oh1/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=11, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130654-egffad88
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/egffad88
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130701-kyv432by
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kyv432by
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nn6p7a62[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130515-nn6p7a62/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1fb2e4na[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130514-1fb2e4na/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=12, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gpm8k2uf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130521-gpm8k2uf/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=13, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kldc87kz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130522-kldc87kz/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=14, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/10ejqg83[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130523-10ejqg83/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=15, wandb_name=random, GPU=2
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4fcfu40t[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130522-4fcfu40t/logs[0m
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130720-oqir64e7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oqir64e7
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=16, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/t0m6zxqm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130526-t0m6zxqm/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xpc0zv8p[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130530-xpc0zv8p/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oaeqfraq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130545-oaeqfraq/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=17, wandb_name=random, GPU=0
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130728-ggddv3qz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ggddv3qz
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=18, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=19, wandb_name=random, GPU=2
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=20, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130728-hjm3xmsx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hjm3xmsx
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130730-fexn7dzk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fexn7dzk
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130734-qusifdif
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qusifdif
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130738-iin3blwq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iin3blwq
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qvcm1293[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130627-qvcm1293/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130743-ow8650dj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ow8650dj
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130744-xer6eubm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xer6eubm
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130744-n6kjk9vo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n6kjk9vo
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=21, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/egffad88[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130654-egffad88/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=22, wandb_name=random, GPU=1
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kyv432by[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130701-kyv432by/logs[0m
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130806-v8yp19zt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v8yp19zt
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=23, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130825-n1ycrfte
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n1ycrfte
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130834-26edwhz2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/26edwhz2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oqir64e7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130720-oqir64e7/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ggddv3qz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130728-ggddv3qz/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=24, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=25, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hjm3xmsx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130728-hjm3xmsx/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fexn7dzk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130730-fexn7dzk/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130907-enhn7y3x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/enhn7y3x
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=26, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130910-7m0ssbuf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7m0ssbuf
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=27, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qusifdif[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130734-qusifdif/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=28, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130929-81g5s2u2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/81g5s2u2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iin3blwq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130738-iin3blwq/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ow8650dj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130743-ow8650dj/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n6kjk9vo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130744-n6kjk9vo/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130934-57kyx2dh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/57kyx2dh
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xer6eubm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130744-xer6eubm/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=29, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=30, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=31, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130939-jq5b1e4s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jq5b1e4s
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=32, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130949-9lo6qmbf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9lo6qmbf
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130949-4wyyzy6i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4wyyzy6i
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130949-ae0e3k34
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ae0e3k34
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_130950-35f8tlas
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/35f8tlas
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v8yp19zt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130806-v8yp19zt/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=33, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n1ycrfte[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130825-n1ycrfte/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/26edwhz2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130834-26edwhz2/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=34, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=35, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/enhn7y3x[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130907-enhn7y3x/logs[0m
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131027-qf0wf5u7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qf0wf5u7
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7m0ssbuf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130910-7m0ssbuf/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=36, wandb_name=random, GPU=3
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131035-8udubxt9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8udubxt9
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=37, wandb_name=random, GPU=0
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/81g5s2u2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130929-81g5s2u2/logs[0m
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/57kyx2dh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130934-57kyx2dh/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131037-jy3zxnaf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jy3zxnaf
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=38, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=39, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jq5b1e4s[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130939-jq5b1e4s/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=40, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ae0e3k34[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130949-ae0e3k34/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/35f8tlas[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130950-35f8tlas/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4wyyzy6i[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130949-4wyyzy6i/logs[0m
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9lo6qmbf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_130949-9lo6qmbf/logs[0m
wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=41, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=42, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=43, wandb_name=random, GPU=2
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131054-3kibu9qa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3kibu9qa
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131056-83kvjvfk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/83kvjvfk
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=44, wandb_name=random, GPU=3
wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131100-x79ofcwi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x79ofcwi
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131103-kv1bmucm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kv1bmucm
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131107-111waqrb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/111waqrb
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131114-pdyh2yzk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pdyh2yzk
wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131114-6ka16mb2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6ka16mb2
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131115-36cek65w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/36cek65w
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131123-glfocnu1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/glfocnu1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qf0wf5u7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131027-qf0wf5u7/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=45, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jy3zxnaf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131037-jy3zxnaf/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=46, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131204-x2aj1eg3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x2aj1eg3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8udubxt9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131035-8udubxt9/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=47, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131221-gqrpf2mp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gqrpf2mp
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131232-swrr38sq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/swrr38sq
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/83kvjvfk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131056-83kvjvfk/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=48, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3kibu9qa[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131054-3kibu9qa/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=49, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6ka16mb2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131114-6ka16mb2/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x79ofcwi[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131100-x79ofcwi/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kv1bmucm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131103-kv1bmucm/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/36cek65w[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131115-36cek65w/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=50, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=51, wandb_name=random, GPU=2
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131309-vywy70ol
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vywy70ol
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=52, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=53, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/glfocnu1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131123-glfocnu1/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pdyh2yzk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131114-pdyh2yzk/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/111waqrb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131107-111waqrb/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=54, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=55, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131316-33p0sqm2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/33p0sqm2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=56, wandb_name=random, GPU=3
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131317-ecizu93l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ecizu93l
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131319-s3kihxx0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s3kihxx0
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131319-oc2no53e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oc2no53e
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131319-k4xi0dpi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k4xi0dpi
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x2aj1eg3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131204-x2aj1eg3/logs[0m
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131326-ykndip98
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ykndip98
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=57, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131328-jv50vlje
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jv50vlje
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gqrpf2mp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131221-gqrpf2mp/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131330-92c9oc4c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/92c9oc4c
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=58, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/swrr38sq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131232-swrr38sq/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=59, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131353-ny46i86z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ny46i86z
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131356-21926vhv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/21926vhv
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131405-sbi1ugvz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sbi1ugvz
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vywy70ol[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131309-vywy70ol/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=60, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k4xi0dpi[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131319-k4xi0dpi/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/33p0sqm2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131316-33p0sqm2/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131434-dkeulqlp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dkeulqlp
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=61, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=62, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ecizu93l[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131317-ecizu93l/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s3kihxx0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131319-s3kihxx0/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=63, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oc2no53e[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131319-oc2no53e/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=64, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131458-4qnusxcq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4qnusxcq
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131500-f0y7zd8g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f0y7zd8g
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=65, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131506-nkuo2o4l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nkuo2o4l
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131510-tsdhrcrb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tsdhrcrb
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ykndip98[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131326-ykndip98/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131517-050pbsfv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/050pbsfv
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jv50vlje[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131328-jv50vlje/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=66, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=67, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/92c9oc4c[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131330-92c9oc4c/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=68, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131532-83zuk32a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/83zuk32a
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131533-v0znjtzy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v0znjtzy
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131541-n3oaf71b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n3oaf71b
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/21926vhv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131356-21926vhv/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ny46i86z[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131353-ny46i86z/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sbi1ugvz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131405-sbi1ugvz/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=69, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=70, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=71, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131601-nmyr62wy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nmyr62wy
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131601-47rkr275
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/47rkr275
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dkeulqlp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131434-dkeulqlp/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=72, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131610-h7p0zwtt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h7p0zwtt
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nkuo2o4l[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131506-nkuo2o4l/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4qnusxcq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131458-4qnusxcq/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tsdhrcrb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131510-tsdhrcrb/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f0y7zd8g[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131500-f0y7zd8g/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=73, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=74, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=75, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=76, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/050pbsfv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131517-050pbsfv/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=77, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131625-dzp45lq5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dzp45lq5
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/83zuk32a[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131532-83zuk32a/logs[0m
wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131634-polfeovx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/polfeovx
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131635-zp9fgdyo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zp9fgdyo
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=78, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v0znjtzy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131533-v0znjtzy/logs[0m
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131640-rfsyjb2r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rfsyjb2r
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131643-pbtwne47
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pbtwne47
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=79, wandb_name=random, GPU=2
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131650-5k9prjbd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5k9prjbd
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131702-525twy30
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/525twy30
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n3oaf71b[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131541-n3oaf71b/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131709-44ped2dx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/44ped2dx
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=80, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nmyr62wy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131601-nmyr62wy/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/47rkr275[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131601-47rkr275/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131728-8xm6hhzi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8xm6hhzi
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=81, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=82, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131747-7lh9tggr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7lh9tggr
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131749-klveu2n9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/klveu2n9
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h7p0zwtt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131610-h7p0zwtt/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=83, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dzp45lq5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131625-dzp45lq5/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131815-mmcuucy3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mmcuucy3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=84, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rfsyjb2r[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131640-rfsyjb2r/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=85, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zp9fgdyo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131635-zp9fgdyo/logs[0m
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/polfeovx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131634-polfeovx/logs[0m
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131831-ks0mhyzy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ks0mhyzy
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pbtwne47[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131643-pbtwne47/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5k9prjbd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131650-5k9prjbd/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=86, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/44ped2dx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131709-44ped2dx/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=87, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=88, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=89, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/525twy30[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131702-525twy30/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8xm6hhzi[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131728-8xm6hhzi/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=90, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131845-r2igas86
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r2igas86
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=91, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=92, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/klveu2n9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131749-klveu2n9/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131857-q9kz45vb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q9kz45vb
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131858-m9pmr5sm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m9pmr5sm
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131858-x4cjy38p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x4cjy38p
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131859-rumcesxx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rumcesxx
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7lh9tggr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131747-7lh9tggr/logs[0m
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=93, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131901-ze5jdrhh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ze5jdrhh
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=94, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131912-4u6q7ar7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4u6q7ar7
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131917-prmdkgdp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/prmdkgdp
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131925-bffnbzts
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bffnbzts
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131930-jqe5drch
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jqe5drch
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mmcuucy3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131815-mmcuucy3/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=95, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_131959-ek3ohzko
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ek3ohzko
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ks0mhyzy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131831-ks0mhyzy/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=96, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r2igas86[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131845-r2igas86/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132032-spuezhi6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/spuezhi6
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=97, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rumcesxx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131859-rumcesxx/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m9pmr5sm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131858-m9pmr5sm/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=98, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=99, wandb_name=random, GPU=2
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132050-l1zjlmvn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l1zjlmvn
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q9kz45vb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131857-q9kz45vb/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x4cjy38p[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131858-x4cjy38p/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132100-hitlq2i1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hitlq2i1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=100, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4u6q7ar7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131912-4u6q7ar7/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=101, wandb_name=random, GPU=0
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132104-fl98r5u8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fl98r5u8
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ze5jdrhh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131901-ze5jdrhh/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=102, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/prmdkgdp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131917-prmdkgdp/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=103, wandb_name=random, GPU=2
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132113-3myujdxh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3myujdxh
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=104, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132121-fqyc2117
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fqyc2117
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132127-361doml3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/361doml3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132131-wb0x8hah
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wb0x8hah
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jqe5drch[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131930-jqe5drch/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bffnbzts[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131925-bffnbzts/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132137-tppb636l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tppb636l
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=105, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=106, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132152-n5diigrg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n5diigrg
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ek3ohzko[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_131959-ek3ohzko/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132158-xp8ymtqq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xp8ymtqq
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=107, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132215-7ptiic2q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7ptiic2q
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/spuezhi6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132032-spuezhi6/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l1zjlmvn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132050-l1zjlmvn/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=108, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=109, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hitlq2i1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132100-hitlq2i1/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=110, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fl98r5u8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132104-fl98r5u8/logs[0m
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132243-3irbqmu9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3irbqmu9
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3myujdxh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132113-3myujdxh/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=111, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=112, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fqyc2117[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132121-fqyc2117/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132251-pjxqhckg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pjxqhckg
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/361doml3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132127-361doml3/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132255-plw7zjzi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/plw7zjzi
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=113, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wb0x8hah[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132131-wb0x8hah/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=114, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tppb636l[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132137-tppb636l/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=115, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=116, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132308-ou3jh7e4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ou3jh7e4
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132309-p1wqy55s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p1wqy55s
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n5diigrg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132152-n5diigrg/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xp8ymtqq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132158-xp8ymtqq/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=117, wandb_name=random, GPU=0
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132321-ktwgugpp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ktwgugpp
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132321-0twuxyx0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0twuxyx0
wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=118, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132323-8tsnaila
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8tsnaila
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132325-u87f9dkl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u87f9dkl
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7ptiic2q[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132215-7ptiic2q/logs[0m
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132342-pasuphq9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pasuphq9
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=119, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132352-fj1le1dn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fj1le1dn
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132410-7zl0pix8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7zl0pix8
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3irbqmu9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132243-3irbqmu9/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=120, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pjxqhckg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132251-pjxqhckg/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/plw7zjzi[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132255-plw7zjzi/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=121, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132444-ebjisx7y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ebjisx7y
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=122, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132457-4gsjdf1n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4gsjdf1n
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ou3jh7e4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132308-ou3jh7e4/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132500-e8sgkhqr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e8sgkhqr
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p1wqy55s[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132309-p1wqy55s/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=123, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8tsnaila[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132323-8tsnaila/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ktwgugpp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132321-ktwgugpp/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=124, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u87f9dkl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132325-u87f9dkl/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=125, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=126, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0twuxyx0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132321-0twuxyx0/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=127, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=128, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pasuphq9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132342-pasuphq9/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132525-ku34mee4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ku34mee4
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132525-kgk1mbnk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kgk1mbnk
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132525-z1g18l8w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z1g18l8w
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132526-kutw4jm7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kutw4jm7
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=129, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132534-xlu0aplz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xlu0aplz
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132538-yvh3c4sr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yvh3c4sr
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fj1le1dn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132352-fj1le1dn/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132547-8iy4jdbd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8iy4jdbd
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=130, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7zl0pix8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132410-7zl0pix8/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=131, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132605-9ohlsh4c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9ohlsh4c
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132616-houjr3w3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/houjr3w3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ebjisx7y[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132444-ebjisx7y/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=132, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4gsjdf1n[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132457-4gsjdf1n/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=133, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e8sgkhqr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132500-e8sgkhqr/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132649-ru0eep0l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ru0eep0l
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=134, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132702-65f11rt5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/65f11rt5
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ku34mee4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132525-ku34mee4/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kutw4jm7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132526-kutw4jm7/logs[0m
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132707-erfal6b4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/erfal6b4
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kgk1mbnk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132525-kgk1mbnk/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=135, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z1g18l8w[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132525-z1g18l8w/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=136, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=137, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xlu0aplz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132534-xlu0aplz/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=138, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yvh3c4sr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132538-yvh3c4sr/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8iy4jdbd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132547-8iy4jdbd/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=139, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132728-mkn3qivt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mkn3qivt
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=140, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=141, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132734-fqfnvh6y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fqfnvh6y
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132734-3w95zzwh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3w95zzwh
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132735-hglyo9t4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hglyo9t4
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9ohlsh4c[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132605-9ohlsh4c/logs[0m
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132740-qrazzvx5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qrazzvx5
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=142, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/houjr3w3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132616-houjr3w3/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132749-or3oo677
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/or3oo677
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=143, wandb_name=random, GPU=2
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132751-kyr0bbxy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kyr0bbxy
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132801-46gcpez8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/46gcpez8
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ru0eep0l[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132649-ru0eep0l/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/65f11rt5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132702-65f11rt5/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=144, wandb_name=random, GPU=3
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=145, wandb_name=random, GPU=0
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132810-dupx3ovg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dupx3ovg
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/erfal6b4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132707-erfal6b4/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=146, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mkn3qivt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132728-mkn3qivt/logs[0m
wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132821-n4advzic
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n4advzic
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=147, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fqfnvh6y[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132734-fqfnvh6y/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hglyo9t4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132735-hglyo9t4/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3w95zzwh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132734-3w95zzwh/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132824-r4xxtb2k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r4xxtb2k
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qrazzvx5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132740-qrazzvx5/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=148, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=149, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=150, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=151, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/or3oo677[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132749-or3oo677/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=152, wandb_name=random, GPU=3
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132836-zxn61ynk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zxn61ynk
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kyr0bbxy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132751-kyr0bbxy/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132839-io3zxlsq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/io3zxlsq
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=153, wandb_name=random, GPU=0
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132841-5o8w7pgu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5o8w7pgu
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/46gcpez8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132801-46gcpez8/logs[0m
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132846-fcihd6jb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fcihd6jb
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132845-myb5ad9v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/myb5ad9v
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=154, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132849-xkiyo4l1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xkiyo4l1
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132851-9xv1ep61
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9xv1ep61
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dupx3ovg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132810-dupx3ovg/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132854-zt3iy1mv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zt3iy1mv
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=155, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n4advzic[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132821-n4advzic/logs[0m
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132903-xpvw7vkl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xpvw7vkl
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=156, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r4xxtb2k[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132824-r4xxtb2k/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=157, wandb_name=random, GPU=0
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132911-lugd4fv3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lugd4fv3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132920-ahmxorwl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ahmxorwl
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zxn61ynk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132836-zxn61ynk/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=158, wandb_name=random, GPU=1
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132927-g3q86agt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g3q86agt
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/io3zxlsq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132839-io3zxlsq/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=159, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5o8w7pgu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132841-5o8w7pgu/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fcihd6jb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132846-fcihd6jb/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=160, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132940-roc9p7wu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/roc9p7wu
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=161, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xkiyo4l1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132849-xkiyo4l1/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/myb5ad9v[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132845-myb5ad9v/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zt3iy1mv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132854-zt3iy1mv/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=162, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=163, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=164, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9xv1ep61[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132851-9xv1ep61/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132949-l7oxgvci
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l7oxgvci
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=165, wandb_name=random, GPU=0
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132953-7ka1hu7z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7ka1hu7z
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_132952-qt0nhd89
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qt0nhd89
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xpvw7vkl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132903-xpvw7vkl/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=166, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lugd4fv3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132911-lugd4fv3/logs[0m
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ahmxorwl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132920-ahmxorwl/logs[0m
wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133004-w7ivjs69
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/w7ivjs69
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=167, wandb_name=random, GPU=2
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133005-jow364m4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jow364m4
wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133006-git376br
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/git376br
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133006-92u39lqk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/92u39lqk
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=168, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g3q86agt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132927-g3q86agt/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=169, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/roc9p7wu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132940-roc9p7wu/logs[0m
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133017-up2ilhh0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/up2ilhh0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=170, wandb_name=random, GPU=1
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133021-uitgxzhw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uitgxzhw
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133023-0fod6qxq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0fod6qxq
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133028-3bagfu5d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3bagfu5d
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l7oxgvci[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132949-l7oxgvci/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=171, wandb_name=random, GPU=2
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7ka1hu7z[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132953-7ka1hu7z/logs[0m
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133037-o8hh00g5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o8hh00g5
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qt0nhd89[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_132952-qt0nhd89/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=172, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=173, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/w7ivjs69[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133004-w7ivjs69/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jow364m4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133005-jow364m4/logs[0m
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/git376br[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133006-git376br/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133050-snpvbguj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/snpvbguj
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=174, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=175, wandb_name=random, GPU=2
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=176, wandb_name=random, GPU=3
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133053-fp7a4a5p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fp7a4a5p
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133053-r5lewr8m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r5lewr8m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/92u39lqk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133006-92u39lqk/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=177, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/up2ilhh0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133017-up2ilhh0/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133102-r2fqbxfe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r2fqbxfe
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=178, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133105-5uibiu8e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5uibiu8e
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133104-hourdvnf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hourdvnf
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uitgxzhw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133021-uitgxzhw/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=179, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0fod6qxq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133023-0fod6qxq/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3bagfu5d[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133028-3bagfu5d/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=180, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=181, wandb_name=random, GPU=0
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133116-mo3gdwyl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mo3gdwyl
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133119-60luvtp1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/60luvtp1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o8hh00g5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133037-o8hh00g5/logs[0m
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=182, wandb_name=random, GPU=1
wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133129-e46x2p62
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e46x2p62
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133128-tafl46ty
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tafl46ty
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/snpvbguj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133050-snpvbguj/logs[0m
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133134-3kia6bmr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3kia6bmr
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=183, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fp7a4a5p[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133053-fp7a4a5p/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r5lewr8m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133053-r5lewr8m/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=184, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=185, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133146-5fa8fqgv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5fa8fqgv
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133149-3sx0gy1m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3sx0gy1m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r2fqbxfe[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133102-r2fqbxfe/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hourdvnf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133104-hourdvnf/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5uibiu8e[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133105-5uibiu8e/logs[0m
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=186, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=187, wandb_name=random, GPU=2
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=188, wandb_name=random, GPU=3
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133158-fkdsyp25
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fkdsyp25
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133203-u8n2q1mw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u8n2q1mw
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mo3gdwyl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133116-mo3gdwyl/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/60luvtp1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133119-60luvtp1/logs[0m
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=189, wandb_name=random, GPU=0
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133209-b89a1uk0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b89a1uk0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133212-c2b6581i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c2b6581i
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=190, wandb_name=random, GPU=1
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133214-i8hk32ih
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/i8hk32ih
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e46x2p62[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133129-e46x2p62/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tafl46ty[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133128-tafl46ty/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3kia6bmr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133134-3kia6bmr/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=191, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=192, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=193, wandb_name=random, GPU=0
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133227-nmbejq6h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nmbejq6h
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133230-w0it8ok7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/w0it8ok7
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133232-53t7mqb1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/53t7mqb1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5fa8fqgv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133146-5fa8fqgv/logs[0m
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3sx0gy1m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133149-3sx0gy1m/logs[0m
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133234-z3sqedyn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z3sqedyn
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=194, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=195, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fkdsyp25[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133158-fkdsyp25/logs[0m
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133241-i73nozg2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/i73nozg2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=196, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u8n2q1mw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133203-u8n2q1mw/logs[0m
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=197, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133248-5fjf4k2f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5fjf4k2f
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b89a1uk0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133209-b89a1uk0/logs[0m
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133250-nh4453mv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nh4453mv
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=198, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c2b6581i[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133212-c2b6581i/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/i8hk32ih[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133214-i8hk32ih/logs[0m
Running with: pruning_method=-1, pruning_rate=0.7, training_seed=199, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.7, training_seed=200, wandb_name=random, GPU=3
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133301-ci6jmakq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ci6jmakq
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133301-0aklrsbo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0aklrsbo
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133310-zpo91iz7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zpo91iz7
wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133312-lxxi653l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lxxi653l
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/w0it8ok7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133230-w0it8ok7/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133315-mu6hyveg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.7_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mu6hyveg
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nmbejq6h[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133227-nmbejq6h/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/53t7mqb1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133232-53t7mqb1/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=0, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=1, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=2, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/i73nozg2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133241-i73nozg2/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z3sqedyn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133234-z3sqedyn/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=3, wandb_name=random, GPU=3
wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=4, wandb_name=random, GPU=0
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133331-fakul7ot
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fakul7ot
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133337-ss4jmy93
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ss4jmy93
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133337-wnzkg6t0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wnzkg6t0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5fjf4k2f[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133248-5fjf4k2f/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nh4453mv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133250-nh4453mv/logs[0m
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133341-b7zqy6sk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b7zqy6sk
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=5, wandb_name=random, GPU=1
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=6, wandb_name=random, GPU=2
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133343-pxdp1rb5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pxdp1rb5
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ci6jmakq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133301-ci6jmakq/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0aklrsbo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133301-0aklrsbo/logs[0m
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133355-s4d1ch56
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s4d1ch56
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133357-fnyn2gbm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fnyn2gbm
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=7, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=8, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mu6hyveg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133315-mu6hyveg/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zpo91iz7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133310-zpo91iz7/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.7, TrainSize=5875 -> 1763, removed=0.70
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.7_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lxxi653l[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133312-lxxi653l/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=9, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=10, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fakul7ot[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133331-fakul7ot/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=11, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=12, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133414-1n1tdwbc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1n1tdwbc
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133414-mup18brm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mup18brm
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ss4jmy93[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133337-ss4jmy93/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133417-2yvtujb0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2yvtujb0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wnzkg6t0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133337-wnzkg6t0/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=13, wandb_name=random, GPU=1
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133417-7al2i0fj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7al2i0fj
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b7zqy6sk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133341-b7zqy6sk/logs[0m
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=14, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pxdp1rb5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133343-pxdp1rb5/logs[0m
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133419-cwnlvtx7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cwnlvtx7
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=15, wandb_name=random, GPU=3
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=16, wandb_name=random, GPU=0
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133423-ijqlgp79
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ijqlgp79
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s4d1ch56[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133355-s4d1ch56/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133432-d62gbse8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/d62gbse8
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fnyn2gbm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133357-fnyn2gbm/logs[0m
wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=17, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133432-gbqk0b9y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gbqk0b9y
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=18, wandb_name=random, GPU=2
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133435-exms1g0w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/exms1g0w
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133438-7g2hs6ux
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7g2hs6ux
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133445-m5168hng
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m5168hng
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mup18brm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133414-mup18brm/logs[0m
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133447-2eaev6a3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2eaev6a3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1n1tdwbc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133414-1n1tdwbc/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=19, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2yvtujb0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133417-2yvtujb0/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=20, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7al2i0fj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133417-7al2i0fj/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=21, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cwnlvtx7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133419-cwnlvtx7/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=22, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ijqlgp79[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133423-ijqlgp79/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=23, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=24, wandb_name=random, GPU=0
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133504-pr4k2pcw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pr4k2pcw
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133506-ooau82ng
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ooau82ng
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/d62gbse8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133432-d62gbse8/logs[0m
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133507-1fcz1637
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1fcz1637
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133507-xdbdeek1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xdbdeek1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gbqk0b9y[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133432-gbqk0b9y/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=25, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/exms1g0w[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133435-exms1g0w/logs[0m
wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=26, wandb_name=random, GPU=2
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133512-brhoz28v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/brhoz28v
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=27, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133514-epqq2ctr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/epqq2ctr
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7g2hs6ux[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133438-7g2hs6ux/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=28, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m5168hng[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133445-m5168hng/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2eaev6a3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133447-2eaev6a3/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133526-tfmmvov1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tfmmvov1
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133526-p1w7uu01
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p1w7uu01
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=29, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=30, wandb_name=random, GPU=2
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133527-wxzarhp0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wxzarhp0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: \ Waiting for wandb.init()...wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133536-az0h8o5i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/az0h8o5i
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133538-xocphyv1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xocphyv1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133543-a64n5n7x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a64n5n7x
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pr4k2pcw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133504-pr4k2pcw/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ooau82ng[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133506-ooau82ng/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1fcz1637[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133507-1fcz1637/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=31, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xdbdeek1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133507-xdbdeek1/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=32, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=33, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=34, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/brhoz28v[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133512-brhoz28v/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/epqq2ctr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133514-epqq2ctr/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=35, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=36, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133602-mrp9dod2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mrp9dod2
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133603-c6nr6r24
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c6nr6r24
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133605-uhajgmpy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uhajgmpy
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133606-4mwdw8b7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4mwdw8b7
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wxzarhp0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133527-wxzarhp0/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p1w7uu01[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133526-p1w7uu01/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tfmmvov1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133526-tfmmvov1/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=37, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=38, wandb_name=random, GPU=2
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=39, wandb_name=random, GPU=3
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/az0h8o5i[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133536-az0h8o5i/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xocphyv1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133538-xocphyv1/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133616-su9rrhsb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/su9rrhsb
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133618-5p59109e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5p59109e
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=40, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=41, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a64n5n7x[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133543-a64n5n7x/logs[0m
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=42, wandb_name=random, GPU=2
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133627-boh0opyv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/boh0opyv
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133627-j9fke6bi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/j9fke6bi
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133627-yyixbei2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yyixbei2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mrp9dod2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133602-mrp9dod2/logs[0m
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133636-mw0n8cz9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mw0n8cz9
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133639-an4pvv33
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/an4pvv33
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c6nr6r24[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133603-c6nr6r24/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uhajgmpy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133605-uhajgmpy/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=43, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4mwdw8b7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133606-4mwdw8b7/logs[0m
wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=44, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=45, wandb_name=random, GPU=1
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133642-6g0cwxal
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6g0cwxal
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=46, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/su9rrhsb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133616-su9rrhsb/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=47, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5p59109e[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133618-5p59109e/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133656-8u5hrs9p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8u5hrs9p
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133656-jk7vbdn2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jk7vbdn2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/j9fke6bi[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133627-j9fke6bi/logs[0m
wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=48, wandb_name=random, GPU=0
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133657-l88n1t27
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l88n1t27
wandb: / Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=49, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133658-u88vi0k5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u88vi0k5
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/boh0opyv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133627-boh0opyv/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yyixbei2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133627-yyixbei2/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=50, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mw0n8cz9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133636-mw0n8cz9/logs[0m
wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133710-4hhyjx0x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4hhyjx0x
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133713-lbli6azo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lbli6azo
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=51, wandb_name=random, GPU=3
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=52, wandb_name=random, GPU=0
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/an4pvv33[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133639-an4pvv33/logs[0m
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133714-852fuzwl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/852fuzwl
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=53, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6g0cwxal[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133642-6g0cwxal/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133726-xy2k9uqt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xy2k9uqt
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133727-hurkz694
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hurkz694
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=54, wandb_name=random, GPU=2
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133728-cx8rv0lk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cx8rv0lk
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133730-s8pyonb9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s8pyonb9
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8u5hrs9p[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133656-8u5hrs9p/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=55, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jk7vbdn2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133656-jk7vbdn2/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=56, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l88n1t27[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133657-l88n1t27/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u88vi0k5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133658-u88vi0k5/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=57, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=58, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lbli6azo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133713-lbli6azo/logs[0m
wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133749-74zau5wf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/74zau5wf
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133750-il2nv6q2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/il2nv6q2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4hhyjx0x[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133710-4hhyjx0x/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/852fuzwl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133714-852fuzwl/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133755-gg4smsbq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gg4smsbq
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=59, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=60, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=61, wandb_name=random, GPU=1
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133756-gu2drg0y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gu2drg0y
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133759-7lnpnem2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7lnpnem2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xy2k9uqt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133726-xy2k9uqt/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hurkz694[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133727-hurkz694/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=62, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=63, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s8pyonb9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133730-s8pyonb9/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cx8rv0lk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133728-cx8rv0lk/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=64, wandb_name=random, GPU=0
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133811-k94zojgi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k94zojgi
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=65, wandb_name=random, GPU=1
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133814-ha0uhdpg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ha0uhdpg
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133814-mc6y6r7b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mc6y6r7b
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133819-mr4pn2m6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mr4pn2m6
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133820-qyl9dj5o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qyl9dj5o
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/74zau5wf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133749-74zau5wf/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/il2nv6q2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133750-il2nv6q2/logs[0m
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133828-6puroble
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6puroble
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gg4smsbq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133755-gg4smsbq/logs[0m
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=66, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=67, wandb_name=random, GPU=3
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133829-4h65tm5g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4h65tm5g
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=68, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gu2drg0y[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133756-gu2drg0y/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7lnpnem2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133759-7lnpnem2/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=69, wandb_name=random, GPU=1
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=70, wandb_name=random, GPU=2
wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133842-gh1crmzj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gh1crmzj
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133848-lp4ba2xw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lp4ba2xw
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133846-wd7oji8g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wd7oji8g
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k94zojgi[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133811-k94zojgi/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mc6y6r7b[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133814-mc6y6r7b/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ha0uhdpg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133814-ha0uhdpg/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=71, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=72, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=73, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qyl9dj5o[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133820-qyl9dj5o/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mr4pn2m6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133819-mr4pn2m6/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=74, wandb_name=random, GPU=2
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133858-b63lwu99
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b63lwu99
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=75, wandb_name=random, GPU=3
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133900-3tbb8t7d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3tbb8t7d
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133903-o7fwfkt2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o7fwfkt2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6puroble[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133828-6puroble/logs[0m
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=76, wandb_name=random, GPU=0
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133905-zn8790ro
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zn8790ro
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133905-dgydyjc2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dgydyjc2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4h65tm5g[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133829-4h65tm5g/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=77, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133914-34ulbg1e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/34ulbg1e
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133914-btrsy7kh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/btrsy7kh
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gh1crmzj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133842-gh1crmzj/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wd7oji8g[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133846-wd7oji8g/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lp4ba2xw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133848-lp4ba2xw/logs[0m
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133920-w2g2d2y0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/w2g2d2y0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=78, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=79, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=80, wandb_name=random, GPU=0
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133927-cfk0j7pv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cfk0j7pv
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b63lwu99[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133858-b63lwu99/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3tbb8t7d[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133900-3tbb8t7d/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133938-veka7z3z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/veka7z3z
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=81, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133938-glnfv6sn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/glnfv6sn
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=82, wandb_name=random, GPU=2
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133939-xx2wjjf6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xx2wjjf6
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o7fwfkt2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133903-o7fwfkt2/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=83, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zn8790ro[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133905-zn8790ro/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dgydyjc2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133905-dgydyjc2/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=84, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/34ulbg1e[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133914-34ulbg1e/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=85, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=86, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/btrsy7kh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133914-btrsy7kh/logs[0m
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133956-li41di84
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/li41di84
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_133956-pezdah8z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pezdah8z
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=87, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: \ Waiting for wandb.init()...wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134002-mnkkb7st
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mnkkb7st
wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134002-xy5lzhak
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xy5lzhak
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/w2g2d2y0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133920-w2g2d2y0/logs[0m
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134004-qtzjyv3s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qtzjyv3s
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cfk0j7pv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133927-cfk0j7pv/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=88, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=89, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134012-gpaon0au
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gpaon0au
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134013-c98pzs81
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c98pzs81
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/glnfv6sn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133938-glnfv6sn/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/veka7z3z[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133938-veka7z3z/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=90, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xx2wjjf6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133939-xx2wjjf6/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=91, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=92, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134023-ji0ylsj5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ji0ylsj5
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134026-ov5ho753
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ov5ho753
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pezdah8z[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133956-pezdah8z/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/li41di84[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_133956-li41di84/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=93, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=94, wandb_name=random, GPU=2
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134037-ryrwr884
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ryrwr884
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mnkkb7st[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134002-mnkkb7st/logs[0m
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xy5lzhak[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134002-xy5lzhak/logs[0m
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134037-3w5tx39r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3w5tx39r
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134040-km6x2k8y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/km6x2k8y
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=95, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=96, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qtzjyv3s[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134004-qtzjyv3s/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gpaon0au[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134012-gpaon0au/logs[0m
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=97, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c98pzs81[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134013-c98pzs81/logs[0m
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134045-fffitdqm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fffitdqm
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134046-ffkev16k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ffkev16k
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=98, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=99, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134055-xl38ijxe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xl38ijxe
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134056-54p42q9d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/54p42q9d
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ov5ho753[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134026-ov5ho753/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ji0ylsj5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134023-ji0ylsj5/logs[0m
wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134100-zzpupp3r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zzpupp3r
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134059-3zydw217
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3zydw217
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134100-5g2mm06d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5g2mm06d
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=100, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=101, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ryrwr884[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134037-ryrwr884/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3w5tx39r[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134037-3w5tx39r/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/km6x2k8y[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134040-km6x2k8y/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=102, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=103, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=104, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134120-ispw7pa5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ispw7pa5
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134119-6utvun95
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6utvun95
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fffitdqm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134045-fffitdqm/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ffkev16k[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134046-ffkev16k/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134130-oxmitxie
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oxmitxie
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134131-e2dlp93c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e2dlp93c
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134132-c6w8sjie
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c6w8sjie
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=105, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=106, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xl38ijxe[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134055-xl38ijxe/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=107, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/54p42q9d[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134056-54p42q9d/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=108, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134152-o3dg4s0s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o3dg4s0s
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134152-tdqpow36
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tdqpow36
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134153-53z5jvgc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/53z5jvgc
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3zydw217[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134059-3zydw217/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zzpupp3r[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134100-zzpupp3r/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5g2mm06d[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134100-5g2mm06d/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=109, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=110, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=111, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134208-m4fsuxbe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m4fsuxbe
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134217-g9ilwyp6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g9ilwyp6
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134217-9yu4ed96
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9yu4ed96
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134222-l8y1oh4e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l8y1oh4e
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ispw7pa5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134120-ispw7pa5/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6utvun95[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134119-6utvun95/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oxmitxie[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134130-oxmitxie/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=112, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=113, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e2dlp93c[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134131-e2dlp93c/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=114, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c6w8sjie[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134132-c6w8sjie/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=115, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=116, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134256-epypw0l2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/epypw0l2
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134257-ie014y76
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ie014y76
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o3dg4s0s[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134152-o3dg4s0s/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/53z5jvgc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134153-53z5jvgc/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134300-rpyjz0se
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rpyjz0se
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tdqpow36[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134152-tdqpow36/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=117, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=118, wandb_name=random, GPU=2
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=119, wandb_name=random, GPU=3
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134305-o6uqgdwu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o6uqgdwu
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9yu4ed96[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134217-9yu4ed96/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m4fsuxbe[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134208-m4fsuxbe/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134314-5ldsftu6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5ldsftu6
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=120, wandb_name=random, GPU=0
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134314-cpt1t0ot
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cpt1t0ot
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g9ilwyp6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134217-g9ilwyp6/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=121, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l8y1oh4e[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134222-l8y1oh4e/logs[0m
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134316-ksbojm61
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ksbojm61
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=122, wandb_name=random, GPU=2
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134322-2p3rmf9w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2p3rmf9w
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=123, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134327-u69kctjd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u69kctjd
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134334-qiyi6jvp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qiyi6jvp
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134337-9ej78bj6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9ej78bj6
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134339-r12c3rk8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r12c3rk8
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rpyjz0se[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134300-rpyjz0se/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/epypw0l2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134256-epypw0l2/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=124, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=125, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ie014y76[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134257-ie014y76/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=126, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o6uqgdwu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134305-o6uqgdwu/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5ldsftu6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134314-5ldsftu6/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=127, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cpt1t0ot[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134314-cpt1t0ot/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=128, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=129, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ksbojm61[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134316-ksbojm61/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2p3rmf9w[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134322-2p3rmf9w/logs[0m
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134407-wk68z979
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wk68z979
wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=130, wandb_name=random, GPU=2
wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134410-6a8cpmpo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6a8cpmpo
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=131, wandb_name=random, GPU=3
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u69kctjd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134327-u69kctjd/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134411-hk9vz8rk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hk9vz8rk
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=132, wandb_name=random, GPU=0
wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134418-1kuqykw3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1kuqykw3
wandb: / Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134419-aaehpamt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/aaehpamt
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qiyi6jvp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134334-qiyi6jvp/logs[0m
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9ej78bj6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134337-9ej78bj6/logs[0m
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134424-jkvx52z0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jkvx52z0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=133, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r12c3rk8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134339-r12c3rk8/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=134, wandb_name=random, GPU=2
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134428-2ql9slbk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2ql9slbk
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134431-kufrk24u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kufrk24u
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=135, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134433-5lr3y1yq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5lr3y1yq
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134445-dm2yxxz4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dm2yxxz4
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134446-oxr2a8p7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oxr2a8p7
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134450-ve0k6672
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ve0k6672
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wk68z979[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134407-wk68z979/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hk9vz8rk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134411-hk9vz8rk/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6a8cpmpo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134410-6a8cpmpo/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=136, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=137, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1kuqykw3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134418-1kuqykw3/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=138, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=139, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jkvx52z0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134424-jkvx52z0/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/aaehpamt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134419-aaehpamt/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=140, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=141, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134517-kgnl51uf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kgnl51uf
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134521-4lcpfy2u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4lcpfy2u
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2ql9slbk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134428-2ql9slbk/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5lr3y1yq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134433-5lr3y1yq/logs[0m
wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134524-dkt9an4d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dkt9an4d
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134523-gjwtw23d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gjwtw23d
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=142, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=143, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kufrk24u[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134431-kufrk24u/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134535-1hanq0uh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1hanq0uh
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=144, wandb_name=random, GPU=0
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134540-b41ub85f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b41ub85f
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oxr2a8p7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134446-oxr2a8p7/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dm2yxxz4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134445-dm2yxxz4/logs[0m
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134549-v6wejf73
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v6wejf73
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134548-4u4ruuz9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4u4ruuz9
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=145, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=146, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ve0k6672[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134450-ve0k6672/logs[0m
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134555-raikfdfr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/raikfdfr
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=147, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134607-ndaulq1p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ndaulq1p
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134607-r33z3go9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r33z3go9
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134618-ed1m44js
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ed1m44js
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4lcpfy2u[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134521-4lcpfy2u/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kgnl51uf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134517-kgnl51uf/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=148, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=149, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dkt9an4d[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134524-dkt9an4d/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gjwtw23d[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134523-gjwtw23d/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1hanq0uh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134535-1hanq0uh/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=150, wandb_name=random, GPU=2
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134649-r7a7gmwn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r7a7gmwn
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=151, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=152, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b41ub85f[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134540-b41ub85f/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134652-knkm4a5f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/knkm4a5f
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=153, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v6wejf73[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134549-v6wejf73/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4u4ruuz9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134548-4u4ruuz9/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134700-4d6vtwz0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4d6vtwz0
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134700-izta5y40
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/izta5y40
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134700-38yflvxx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/38yflvxx
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=154, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/raikfdfr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134555-raikfdfr/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=155, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r33z3go9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134607-r33z3go9/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=156, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ndaulq1p[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134607-ndaulq1p/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=157, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134712-1jg2blwe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1jg2blwe
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=158, wandb_name=random, GPU=2
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134714-l9j7vfkw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l9j7vfkw
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ed1m44js[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134618-ed1m44js/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134719-3dg2d1sp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3dg2d1sp
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=159, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134724-9wnzoh4v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9wnzoh4v
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134735-r1ho1a39
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r1ho1a39
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r7a7gmwn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134649-r7a7gmwn/logs[0m
wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134736-gsyhiy8p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gsyhiy8p
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=160, wandb_name=random, GPU=0
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134740-1b0w85k9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1b0w85k9
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/knkm4a5f[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134652-knkm4a5f/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4d6vtwz0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134700-4d6vtwz0/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=161, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/38yflvxx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134700-38yflvxx/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/izta5y40[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134700-izta5y40/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=162, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=163, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=164, wandb_name=random, GPU=0
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1jg2blwe[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134712-1jg2blwe/logs[0m
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134759-5o5clubb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5o5clubb
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=165, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3dg2d1sp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134719-3dg2d1sp/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l9j7vfkw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134714-l9j7vfkw/logs[0m
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=166, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134809-uoo7n5jz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uoo7n5jz
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=167, wandb_name=random, GPU=3
wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9wnzoh4v[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134724-9wnzoh4v/logs[0m
wandb: / Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134811-u99209xp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u99209xp
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134812-59yd72dr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/59yd72dr
wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134814-94pr039l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/94pr039l
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134814-tkv9kf73
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tkv9kf73
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=168, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r1ho1a39[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134735-r1ho1a39/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=169, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gsyhiy8p[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134736-gsyhiy8p/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=170, wandb_name=random, GPU=2
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134826-qyk0lwzf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qyk0lwzf
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1b0w85k9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134740-1b0w85k9/logs[0m
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134829-qzsbl63d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qzsbl63d
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=171, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134839-5qcvlnpp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5qcvlnpp
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134839-hrcgco9g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hrcgco9g
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5o5clubb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134759-5o5clubb/logs[0m
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134842-7ue5j840
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7ue5j840
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=172, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134853-4mmkwgd5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4mmkwgd5
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/59yd72dr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134812-59yd72dr/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uoo7n5jz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134809-uoo7n5jz/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/94pr039l[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134814-94pr039l/logs[0m
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=173, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=174, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tkv9kf73[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134814-tkv9kf73/logs[0m
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134901-njvhnb09
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/njvhnb09
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u99209xp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134811-u99209xp/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=175, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=176, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=177, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qyk0lwzf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134826-qyk0lwzf/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134916-6asd770m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6asd770m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=178, wandb_name=random, GPU=2
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134919-o793o4k0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o793o4k0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qzsbl63d[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134829-qzsbl63d/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134926-3xqxs57g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3xqxs57g
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=179, wandb_name=random, GPU=3
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134928-upx1h7id
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/upx1h7id
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134927-am9i94e4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/am9i94e4
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hrcgco9g[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134839-hrcgco9g/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5qcvlnpp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134839-5qcvlnpp/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=180, wandb_name=random, GPU=0
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134939-3k9h80of
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3k9h80of
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=181, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7ue5j840[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134842-7ue5j840/logs[0m
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134946-sp93wltt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sp93wltt
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134951-bwmyf6u7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bwmyf6u7
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=182, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4mmkwgd5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134853-4mmkwgd5/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=183, wandb_name=random, GPU=3
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_134958-rzmeh7p3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rzmeh7p3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/njvhnb09[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134901-njvhnb09/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_135009-rppqszof
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rppqszof
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=184, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_135015-lznf4cxg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lznf4cxg
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6asd770m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134916-6asd770m/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_135025-wxzqn4m9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wxzqn4m9
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o793o4k0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134919-o793o4k0/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=185, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=186, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/am9i94e4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134927-am9i94e4/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3xqxs57g[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134926-3xqxs57g/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=187, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_135044-33f1pg84
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/33f1pg84
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=188, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3k9h80of[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134939-3k9h80of/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/upx1h7id[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134928-upx1h7id/logs[0m
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=189, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_135047-he6sb9il
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/he6sb9il
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bwmyf6u7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134951-bwmyf6u7/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sp93wltt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134946-sp93wltt/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=190, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=191, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=192, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_135103-m1cduak1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m1cduak1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rzmeh7p3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_134958-rzmeh7p3/logs[0m
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_135106-isajixyk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/isajixyk
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rppqszof[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_135009-rppqszof/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_135109-81a76f6w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/81a76f6w
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=193, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=194, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lznf4cxg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_135015-lznf4cxg/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_135119-yvlwo9je
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yvlwo9je
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_135121-w791q7ag
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/w791q7ag
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_135122-p0jfem3r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p0jfem3r
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=195, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wxzqn4m9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_135025-wxzqn4m9/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=196, wandb_name=random, GPU=0
wandb: / Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_135131-s9itmv0t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s9itmv0t
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/he6sb9il[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_135047-he6sb9il/logs[0m
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_135136-qej45rec
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qej45rec
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: / Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/33f1pg84[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_135044-33f1pg84/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_135138-nqk04bgc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nqk04bgc
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=197, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=198, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_135149-cwc05v8v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cwc05v8v
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m1cduak1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_135103-m1cduak1/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/isajixyk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_135106-isajixyk/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=199, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=200, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/81a76f6w[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_135109-81a76f6w/logs[0m
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_135201-5e9j8gkz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5e9j8gkz
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_135203-qkwqmwkt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qkwqmwkt
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yvlwo9je[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_135119-yvlwo9je/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/w791q7ag[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_135121-w791q7ag/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p0jfem3r[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_135122-p0jfem3r/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_135214-5gqsl818
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5gqsl818
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/s9itmv0t[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_135131-s9itmv0t/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qej45rec[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_135136-qej45rec/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nqk04bgc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_135138-nqk04bgc/logs[0m
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250205_135221-mznqv8dl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: üöÄ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mznqv8dl
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cwc05v8v[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_135149-cwc05v8v/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5e9j8gkz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_135201-5e9j8gkz/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5gqsl818[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_135214-5gqsl818/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qkwqmwkt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_135203-qkwqmwkt/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mznqv8dl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250205_135221-mznqv8dl/logs[0m
All tasks completed.
