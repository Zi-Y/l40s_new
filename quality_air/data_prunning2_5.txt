nohup: ignoring input
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=0, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=1, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=2, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=3, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=4, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=5, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=6, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=7, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=8, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=9, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=10, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=11, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181604-a1avd2wk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a1avd2wk
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: \ Waiting for wandb.init()...wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181603-uvtrcy43
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uvtrcy43
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181604-mlt3kqfq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mlt3kqfq
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181603-2kp5jx74
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2kp5jx74
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181604-1dpoxps2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1dpoxps2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181605-uzeh0xtl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uzeh0xtl
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181606-c330dgou
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c330dgou
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181606-cmkn61mu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cmkn61mu
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181606-j81uvh3h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/j81uvh3h
wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181606-2r7kx8wt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2r7kx8wt
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181606-keppcjdi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/keppcjdi
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181608-a34c5561
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a34c5561
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a1avd2wk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181604-a1avd2wk/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=12, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mlt3kqfq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181604-mlt3kqfq/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1dpoxps2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181604-1dpoxps2/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/j81uvh3h[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181606-j81uvh3h/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2kp5jx74[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181603-2kp5jx74/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cmkn61mu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181606-cmkn61mu/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c330dgou[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181606-c330dgou/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uvtrcy43[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181603-uvtrcy43/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=13, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=14, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=15, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=16, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=17, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=18, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uzeh0xtl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181605-uzeh0xtl/logs[0m
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=19, wandb_name=random, GPU=3
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2r7kx8wt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181606-2r7kx8wt/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a34c5561[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181608-a34c5561/logs[0m
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/keppcjdi[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181606-keppcjdi/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=20, wandb_name=random, GPU=0
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181639-ezjxa9db
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ezjxa9db
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=21, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=22, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=23, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181647-usjtl147
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/usjtl147
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181648-984agkgx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/984agkgx
wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181648-6alxnwsn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6alxnwsn
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181648-b3t0q1hc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b3t0q1hc
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181649-bom47otx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bom47otx
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181649-wa38jsal
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wa38jsal
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181650-h9gwyrsk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h9gwyrsk
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181652-1z1gxl3z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1z1gxl3z
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181653-8emoinzg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8emoinzg
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181654-6yhs2dwh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6yhs2dwh
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181653-tii9a9xr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tii9a9xr
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ezjxa9db[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181639-ezjxa9db/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/984agkgx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181648-984agkgx/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6alxnwsn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181648-6alxnwsn/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/usjtl147[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181647-usjtl147/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=24, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b3t0q1hc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181648-b3t0q1hc/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wa38jsal[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181649-wa38jsal/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bom47otx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181649-bom47otx/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1z1gxl3z[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181652-1z1gxl3z/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=25, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=26, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8emoinzg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181653-8emoinzg/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=27, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h9gwyrsk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181650-h9gwyrsk/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=28, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=29, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=30, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6yhs2dwh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181654-6yhs2dwh/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tii9a9xr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181653-tii9a9xr/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=31, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=32, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=33, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=34, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=35, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181730-o7tv8ugz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o7tv8ugz
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181730-c1l4gwy5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c1l4gwy5
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181731-7sf7auhd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7sf7auhd
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181731-xtxv3j0o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xtxv3j0o
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181730-ybazkry8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ybazkry8
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181731-fjg0iigc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fjg0iigc
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181731-d73j1x2u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/d73j1x2u
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181732-so74ofey
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/so74ofey
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181731-jq7opt4q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jq7opt4q
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181740-wrjzeq8x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wrjzeq8x
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181741-bviwtv3a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bviwtv3a
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181742-ded208qa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ded208qa
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c1l4gwy5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181730-c1l4gwy5/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7sf7auhd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181731-7sf7auhd/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o7tv8ugz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181730-o7tv8ugz/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fjg0iigc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181731-fjg0iigc/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ybazkry8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181730-ybazkry8/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/d73j1x2u[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181731-d73j1x2u/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=36, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jq7opt4q[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181731-jq7opt4q/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/so74ofey[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181732-so74ofey/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=37, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=38, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xtxv3j0o[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181731-xtxv3j0o/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=39, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=40, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=41, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=42, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=43, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=44, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181813-y19rs182
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y19rs182
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bviwtv3a[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181741-bviwtv3a/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181814-e41zgj7d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e41zgj7d
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181814-t9gblufd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/t9gblufd
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wrjzeq8x[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181740-wrjzeq8x/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181816-4fgngyru
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4fgngyru
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ded208qa[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181742-ded208qa/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=45, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181818-iz2f2nhu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iz2f2nhu
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=46, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=47, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181820-bty9albj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bty9albj
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181820-9fa27qyi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9fa27qyi
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181821-30r6hi92
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/30r6hi92
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181820-wy0zhp2i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wy0zhp2i
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181828-38vu5eb6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/38vu5eb6
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181830-ca57w0ax
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ca57w0ax
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181830-ji5r6lti
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ji5r6lti
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e41zgj7d[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181814-e41zgj7d/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4fgngyru[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181816-4fgngyru/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y19rs182[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181813-y19rs182/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=48, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=49, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iz2f2nhu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181818-iz2f2nhu/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=50, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/t9gblufd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181814-t9gblufd/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=51, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=52, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/30r6hi92[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181821-30r6hi92/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bty9albj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181820-bty9albj/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9fa27qyi[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181820-9fa27qyi/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=53, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=54, wandb_name=random, GPU=2
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181857-n6xz5f6s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n6xz5f6s
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=55, wandb_name=random, GPU=3
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181857-yxxow0jg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yxxow0jg
wandb: | Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181858-5wzkhc6j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5wzkhc6j
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181857-rhhasx08
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rhhasx08
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/38vu5eb6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181828-38vu5eb6/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wy0zhp2i[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181820-wy0zhp2i/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ca57w0ax[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181830-ca57w0ax/logs[0m
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=56, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ji5r6lti[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181830-ji5r6lti/logs[0m
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181902-xzurou4j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xzurou4j
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=57, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=58, wandb_name=random, GPU=2
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=59, wandb_name=random, GPU=3
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181906-pdz1gbqs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pdz1gbqs
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181906-nqu0a9nk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nqu0a9nk
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181908-sq5creoc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sq5creoc
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181915-vqac6pth
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vqac6pth
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181914-zjhexoc2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zjhexoc2
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181915-olf7hj65
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/olf7hj65
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181915-22l30gys
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/22l30gys
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rhhasx08[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181857-rhhasx08/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yxxow0jg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181857-yxxow0jg/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/n6xz5f6s[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181857-n6xz5f6s/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5wzkhc6j[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181858-5wzkhc6j/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xzurou4j[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181902-xzurou4j/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=60, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=61, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=62, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=63, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pdz1gbqs[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181906-pdz1gbqs/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=64, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nqu0a9nk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181906-nqu0a9nk/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=65, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sq5creoc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181908-sq5creoc/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=66, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=67, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181941-ru1nlexp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ru1nlexp
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181941-dlrwtyvd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dlrwtyvd
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181942-59wdph0y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/59wdph0y
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181942-1wlj7y3d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1wlj7y3d
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vqac6pth[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181915-vqac6pth/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zjhexoc2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181914-zjhexoc2/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/olf7hj65[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181915-olf7hj65/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181943-tk6y2ntb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tk6y2ntb
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/22l30gys[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181915-22l30gys/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=68, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=69, wandb_name=random, GPU=1
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181944-hk7z463v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hk7z463v
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=70, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=71, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181953-3zkvamu3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3zkvamu3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181953-x8ktgup3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x8ktgup3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181955-ldieqisu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ldieqisu
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181956-dnyaayfu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dnyaayfu
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181956-re722tss
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/re722tss
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_181958-j3xho8r6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/j3xho8r6
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ru1nlexp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181941-ru1nlexp/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=72, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dlrwtyvd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181941-dlrwtyvd/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1wlj7y3d[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181942-1wlj7y3d/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/59wdph0y[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181942-59wdph0y/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tk6y2ntb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181943-tk6y2ntb/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hk7z463v[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181944-hk7z463v/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=73, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=74, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=75, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=76, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=77, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182025-q4g4ql11
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q4g4ql11
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182025-7a1isqgs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7a1isqgs
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182026-8yst70ax
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8yst70ax
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182026-mxasprzq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mxasprzq
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182027-pp3ovi9s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pp3ovi9s
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3zkvamu3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181953-3zkvamu3/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182029-53skk177
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/53skk177
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dnyaayfu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181956-dnyaayfu/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/re722tss[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181956-re722tss/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ldieqisu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181955-ldieqisu/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/j3xho8r6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181958-j3xho8r6/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x8ktgup3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_181953-x8ktgup3/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=78, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=79, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=80, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=81, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=82, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=83, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182042-a27d33k5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a27d33k5
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182043-qo2ld787
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qo2ld787
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182044-g20qz6d5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g20qz6d5
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182044-yd6xkpv3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yd6xkpv3
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182044-jz9sifty
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jz9sifty
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182049-i2mtypyy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/i2mtypyy
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q4g4ql11[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182025-q4g4ql11/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7a1isqgs[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182025-7a1isqgs/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=84, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8yst70ax[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182026-8yst70ax/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mxasprzq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182026-mxasprzq/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=85, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=86, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=87, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/53skk177[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182029-53skk177/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pp3ovi9s[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182027-pp3ovi9s/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=88, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=89, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182105-7g1d930h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7g1d930h
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182108-w5poroft
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/w5poroft
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182108-azusrkk7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/azusrkk7
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182111-iawjisfm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iawjisfm
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182112-vfkkjihd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vfkkjihd
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182111-z6afj1ja
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z6afj1ja
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a27d33k5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182042-a27d33k5/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yd6xkpv3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182044-yd6xkpv3/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qo2ld787[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182043-qo2ld787/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g20qz6d5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182044-g20qz6d5/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jz9sifty[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182044-jz9sifty/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=90, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=91, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=92, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=93, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=94, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/i2mtypyy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182049-i2mtypyy/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=95, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182127-cg8qc2ix
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cg8qc2ix
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182129-ru6xphq4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ru6xphq4
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182130-t8wgwpak
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/t8wgwpak
wandb: / Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182129-akhioi7u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/akhioi7u
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182129-xdkd2hz0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xdkd2hz0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7g1d930h[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182105-7g1d930h/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/w5poroft[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182108-w5poroft/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=96, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=97, wandb_name=random, GPU=1
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182137-aa566b8p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/aa566b8p
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iawjisfm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182111-iawjisfm/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z6afj1ja[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182111-z6afj1ja/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/azusrkk7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182108-azusrkk7/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vfkkjihd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182112-vfkkjihd/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=98, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=99, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=100, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=101, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182151-i7n70yxw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/i7n70yxw
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182151-6a94flbc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6a94flbc
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cg8qc2ix[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182127-cg8qc2ix/logs[0m
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=102, wandb_name=random, GPU=2
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182156-i2mu4zw7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/i2mu4zw7
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182156-ehradpin
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ehradpin
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182157-sek27e6e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sek27e6e
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ru6xphq4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182129-ru6xphq4/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xdkd2hz0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182129-xdkd2hz0/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/t8wgwpak[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182130-t8wgwpak/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/akhioi7u[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182129-akhioi7u/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182201-384b3vgy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/384b3vgy
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=103, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=104, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=105, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=106, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/aa566b8p[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182137-aa566b8p/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=107, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182210-vbgi9uk3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vbgi9uk3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182213-hcdje2hh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hcdje2hh
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182212-yvbp4xo4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yvbp4xo4
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182212-007rp8vn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/007rp8vn
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182213-r4pbw6gx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r4pbw6gx
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/i7n70yxw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182151-i7n70yxw/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6a94flbc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182151-6a94flbc/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=108, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=109, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182224-mbobs6kc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mbobs6kc
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ehradpin[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182156-ehradpin/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sek27e6e[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182157-sek27e6e/logs[0m
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182230-7cvjw9qh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7cvjw9qh
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/i2mu4zw7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182156-i2mu4zw7/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/384b3vgy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182201-384b3vgy/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=110, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=111, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=112, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=113, wandb_name=random, GPU=1
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182233-bkpzklt1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bkpzklt1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182240-tgmejjxp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tgmejjxp
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182241-fr5l8kko
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fr5l8kko
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yvbp4xo4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182212-yvbp4xo4/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vbgi9uk3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182210-vbgi9uk3/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182243-ohrijawp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ohrijawp
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hcdje2hh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182213-hcdje2hh/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/007rp8vn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182212-007rp8vn/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r4pbw6gx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182213-r4pbw6gx/logs[0m
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182244-qk3h10uy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qk3h10uy
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=114, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=115, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=116, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=117, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=118, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mbobs6kc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182224-mbobs6kc/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=119, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182258-5zvoazus
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5zvoazus
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182259-jb6chrga
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jb6chrga
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7cvjw9qh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182230-7cvjw9qh/logs[0m
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182259-otvl2kum
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/otvl2kum
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182259-xkkyxj0v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xkkyxj0v
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182259-7k1tjbtz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7k1tjbtz
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bkpzklt1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182233-bkpzklt1/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=120, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=121, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fr5l8kko[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182241-fr5l8kko/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182310-2mm79q7w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2mm79q7w
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182312-yg5btc7u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yg5btc7u
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ohrijawp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182243-ohrijawp/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=122, wandb_name=random, GPU=2
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qk3h10uy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182244-qk3h10uy/logs[0m
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182313-laqszntr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/laqszntr
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=123, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=124, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tgmejjxp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182240-tgmejjxp/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=125, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182326-wlh72t0q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wlh72t0q
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182326-12wzak4z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/12wzak4z
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182327-ysu2g5b0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ysu2g5b0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5zvoazus[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182258-5zvoazus/logs[0m
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182329-sslso0v8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sslso0v8
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jb6chrga[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182259-jb6chrga/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/otvl2kum[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182259-otvl2kum/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xkkyxj0v[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182259-xkkyxj0v/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7k1tjbtz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182259-7k1tjbtz/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=126, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=127, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=128, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=129, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=130, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yg5btc7u[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182312-yg5btc7u/logs[0m
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182343-7nj2god1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7nj2god1
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182343-5kl0rlt6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5kl0rlt6
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182344-pw7h3f90
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pw7h3f90
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182343-7p7kw1xj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7p7kw1xj
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/laqszntr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182313-laqszntr/logs[0m
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=131, wandb_name=random, GPU=3
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182345-l5vwjstc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l5vwjstc
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2mm79q7w[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182310-2mm79q7w/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=132, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=133, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/12wzak4z[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182326-12wzak4z/logs[0m
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sslso0v8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182329-sslso0v8/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ysu2g5b0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182327-ysu2g5b0/logs[0m
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182359-zyfhevxu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zyfhevxu
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182359-iv7mfs8s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iv7mfs8s
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182359-bwbh1947
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bwbh1947
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wlh72t0q[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182326-wlh72t0q/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=134, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=135, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=136, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=137, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182410-iwfaknly
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iwfaknly
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182411-d7pgpnmr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/d7pgpnmr
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182412-zmg6s6ps
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zmg6s6ps
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182412-4mwmcc0d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4mwmcc0d
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5kl0rlt6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182343-5kl0rlt6/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7p7kw1xj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182343-7p7kw1xj/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7nj2god1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182343-7nj2god1/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pw7h3f90[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182344-pw7h3f90/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l5vwjstc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182345-l5vwjstc/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=138, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=139, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=140, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=141, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=142, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182427-jpja0220
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jpja0220
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182426-kvytyqi4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kvytyqi4
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182428-olrnuxac
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/olrnuxac
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iv7mfs8s[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182359-iv7mfs8s/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bwbh1947[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182359-bwbh1947/logs[0m
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zyfhevxu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182359-zyfhevxu/logs[0m
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182429-90t2f0gq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/90t2f0gq
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182430-kdezwdh8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kdezwdh8
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=143, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=144, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=145, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182442-6in5wv3e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6in5wv3e
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iwfaknly[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182410-iwfaknly/logs[0m
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/d7pgpnmr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182411-d7pgpnmr/logs[0m
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182444-joubl81j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/joubl81j
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182445-nsr6xbnf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nsr6xbnf
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zmg6s6ps[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182412-zmg6s6ps/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4mwmcc0d[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182412-4mwmcc0d/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=146, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=147, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=148, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=149, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182456-kxr3ime7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kxr3ime7
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182457-o2ttbox6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o2ttbox6
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182458-15r5rnpx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/15r5rnpx
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kvytyqi4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182426-kvytyqi4/logs[0m
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182459-nrw0sds6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nrw0sds6
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/olrnuxac[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182428-olrnuxac/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jpja0220[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182427-jpja0220/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=150, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kdezwdh8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182430-kdezwdh8/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/90t2f0gq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182429-90t2f0gq/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=151, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=152, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=153, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=154, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182512-73ahe80u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/73ahe80u
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182512-ao6vo7iu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ao6vo7iu
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182513-svz0vhod
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/svz0vhod
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182513-fyv21u63
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fyv21u63
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6in5wv3e[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182442-6in5wv3e/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/joubl81j[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182444-joubl81j/logs[0m
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nsr6xbnf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182445-nsr6xbnf/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=155, wandb_name=random, GPU=3
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182515-ro9usjnt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ro9usjnt
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=156, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=157, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kxr3ime7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182456-kxr3ime7/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=158, wandb_name=random, GPU=2
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182526-74lxzv0c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/74lxzv0c
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182526-q1vjm7af
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q1vjm7af
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182526-5ew5qs7t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5ew5qs7t
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nrw0sds6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182459-nrw0sds6/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/15r5rnpx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182458-15r5rnpx/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=159, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=160, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o2ttbox6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182457-o2ttbox6/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=161, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182540-gy1izugg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gy1izugg
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182541-xf49if1m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xf49if1m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182541-6a4j708v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6a4j708v
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182543-ihv9x70o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ihv9x70o
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/svz0vhod[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182513-svz0vhod/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ao6vo7iu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182512-ao6vo7iu/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fyv21u63[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182513-fyv21u63/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/73ahe80u[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182512-73ahe80u/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ro9usjnt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182515-ro9usjnt/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=162, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=163, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=164, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=165, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=166, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182556-x424xkys
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x424xkys
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182556-c3j42fyq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c3j42fyq
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182557-kf75hf7x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kf75hf7x
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182557-jdtz8a7o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jdtz8a7o
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182558-obbsu7wv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/obbsu7wv
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q1vjm7af[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182526-q1vjm7af/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/74lxzv0c[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182526-74lxzv0c/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5ew5qs7t[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182526-5ew5qs7t/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=167, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=168, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=169, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182611-cbkyzkkj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cbkyzkkj
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182612-m0urnmt0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m0urnmt0
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gy1izugg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182540-gy1izugg/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xf49if1m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182541-xf49if1m/logs[0m
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ihv9x70o[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182543-ihv9x70o/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6a4j708v[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182541-6a4j708v/logs[0m
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182613-7qehlhel
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7qehlhel
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=170, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=171, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=172, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=173, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182626-8e5j4yd1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8e5j4yd1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182628-rxs50bn3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rxs50bn3
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x424xkys[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182556-x424xkys/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jdtz8a7o[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182557-jdtz8a7o/logs[0m
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/obbsu7wv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182558-obbsu7wv/logs[0m
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182628-1xrso3nx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1xrso3nx
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c3j42fyq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182556-c3j42fyq/logs[0m
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182629-sn4e4kwp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sn4e4kwp
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kf75hf7x[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182557-kf75hf7x/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=174, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=175, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=176, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=177, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=178, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182641-bbecneyp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bbecneyp
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182641-b88q04n7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b88q04n7
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182642-yjyzk5ej
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yjyzk5ej
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182641-9muvlkp5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9muvlkp5
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7qehlhel[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182613-7qehlhel/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cbkyzkkj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182611-cbkyzkkj/logs[0m
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182642-7rxz9d91
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7rxz9d91
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=179, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=180, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m0urnmt0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182612-m0urnmt0/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=181, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182656-2mrtc8pu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2mrtc8pu
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182656-48iscb36
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/48iscb36
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8e5j4yd1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182626-8e5j4yd1/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rxs50bn3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182628-rxs50bn3/logs[0m
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182658-ns2nanku
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ns2nanku
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1xrso3nx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182628-1xrso3nx/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sn4e4kwp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182629-sn4e4kwp/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=182, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=183, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=184, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=185, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182707-yvf959gm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yvf959gm
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182712-7ldl8m0n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7ldl8m0n
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182713-nenskmbc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nenskmbc
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bbecneyp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182641-bbecneyp/logs[0m
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b88q04n7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182641-b88q04n7/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7rxz9d91[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182642-7rxz9d91/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yjyzk5ej[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182642-yjyzk5ej/logs[0m
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182713-5beecvey
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5beecvey
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=186, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=187, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=188, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=189, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9muvlkp5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182641-9muvlkp5/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=190, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182727-2497od3p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2497od3p
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182726-6z0cbdxi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6z0cbdxi
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182727-sf1eeblj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sf1eeblj
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182727-zdgtugqn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zdgtugqn
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/48iscb36[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182656-48iscb36/logs[0m
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ns2nanku[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182658-ns2nanku/logs[0m
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182730-olfay136
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/olfay136
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=191, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2mrtc8pu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182656-2mrtc8pu/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=192, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=193, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yvf959gm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182707-yvf959gm/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=194, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182741-uwy6e5dh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uwy6e5dh
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182743-x6nodj9n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x6nodj9n
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5beecvey[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182713-5beecvey/logs[0m
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182743-f54kl49f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f54kl49f
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nenskmbc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182713-nenskmbc/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7ldl8m0n[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182712-7ldl8m0n/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=195, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=196, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=197, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182752-z2cve1xm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z2cve1xm
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182754-rrub932v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rrub932v
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182758-sk6rgxan
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sk6rgxan
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182758-1cr1bndj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1cr1bndj
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zdgtugqn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182727-zdgtugqn/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2497od3p[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182727-2497od3p/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/olfay136[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182730-olfay136/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=198, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=199, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sf1eeblj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182727-sf1eeblj/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6z0cbdxi[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182726-6z0cbdxi/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=200, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=201, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=202, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182811-vqj3fsw3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vqj3fsw3
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182812-imlpfkp6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/imlpfkp6
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182812-442n5qi1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/442n5qi1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f54kl49f[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182743-f54kl49f/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x6nodj9n[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182743-x6nodj9n/logs[0m
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uwy6e5dh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182741-uwy6e5dh/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182813-iy4ggd9c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iy4ggd9c
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=203, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=204, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=205, wandb_name=random, GPU=1
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182814-1xauzqu7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1xauzqu7
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z2cve1xm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182752-z2cve1xm/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=206, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182826-ukiaq056
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ukiaq056
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182826-z2233hiw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z2233hiw
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182826-0gbbvqj3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0gbbvqj3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sk6rgxan[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182758-sk6rgxan/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1cr1bndj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182758-1cr1bndj/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rrub932v[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182754-rrub932v/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=207, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=208, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=209, wandb_name=random, GPU=1
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182832-58zxr966
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/58zxr966
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182841-1cfhw9ou
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1cfhw9ou
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182843-xf5c9i58
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xf5c9i58
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182842-ikt8g6qw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ikt8g6qw
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/442n5qi1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182812-442n5qi1/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iy4ggd9c[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182813-iy4ggd9c/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vqj3fsw3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182811-vqj3fsw3/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1xauzqu7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182814-1xauzqu7/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=210, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/imlpfkp6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182812-imlpfkp6/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=211, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=212, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=213, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=214, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182855-q2uoigbw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q2uoigbw
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ukiaq056[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182826-ukiaq056/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182858-nffz8g3y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nffz8g3y
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z2233hiw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182826-z2233hiw/logs[0m
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182859-ecj02tuw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ecj02tuw
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=215, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=216, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182900-p3zpq0wr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p3zpq0wr
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0gbbvqj3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182826-0gbbvqj3/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/58zxr966[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182832-58zxr966/logs[0m
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182900-h90pnrii
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h90pnrii
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=217, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=218, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182911-tldeh7li
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tldeh7li
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182912-h4v9fg60
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h4v9fg60
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ikt8g6qw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182842-ikt8g6qw/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xf5c9i58[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182843-xf5c9i58/logs[0m
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182913-4cdweowp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4cdweowp
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1cfhw9ou[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182841-1cfhw9ou/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=219, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=220, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=221, wandb_name=random, GPU=1
wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182917-ck93qyms
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ck93qyms
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182925-4eem0b1f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4eem0b1f
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182925-rnc5bxjb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rnc5bxjb
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182929-u3kahj10
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u3kahj10
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nffz8g3y[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182858-nffz8g3y/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/p3zpq0wr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182900-p3zpq0wr/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ecj02tuw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182859-ecj02tuw/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=222, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q2uoigbw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182855-q2uoigbw/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=223, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=224, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=225, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182939-9r0fhhfz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9r0fhhfz
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182939-aekoqtt1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/aekoqtt1
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182940-fislqsl8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fislqsl8
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tldeh7li[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182911-tldeh7li/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h4v9fg60[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182912-h4v9fg60/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4cdweowp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182913-4cdweowp/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ck93qyms[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182917-ck93qyms/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182945-54s5dkwb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/54s5dkwb
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=226, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=227, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=228, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=229, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182952-o1d57f45
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o1d57f45
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182953-quccbcxa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/quccbcxa
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182954-g2aknrt1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g2aknrt1
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_182954-cis10inp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cis10inp
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u3kahj10[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182929-u3kahj10/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rnc5bxjb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182925-rnc5bxjb/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=230, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=231, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4eem0b1f[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182925-4eem0b1f/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=232, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183007-sjxn2lbb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sjxn2lbb
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183008-tpuaohwn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tpuaohwn
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183012-gpkspoih
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gpkspoih
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/54s5dkwb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182945-54s5dkwb/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/aekoqtt1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182939-aekoqtt1/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o1d57f45[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182952-o1d57f45/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=233, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9r0fhhfz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182939-9r0fhhfz/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=234, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=235, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fislqsl8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182940-fislqsl8/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/quccbcxa[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182953-quccbcxa/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g2aknrt1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182954-g2aknrt1/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=236, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=237, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cis10inp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182954-cis10inp/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183021-yllgd799
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yllgd799
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=238, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=239, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=240, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183023-j3ck7g5h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/j3ck7g5h
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183024-c3v51cxm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c3v51cxm
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183024-aj0z5afc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/aj0z5afc
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183024-5pcbgdzu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5pcbgdzu
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183027-qj8511i7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qj8511i7
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183027-g2wmew7e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g2wmew7e
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183028-uesp1wzh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uesp1wzh
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sjxn2lbb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183007-sjxn2lbb/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=241, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gpkspoih[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183012-gpkspoih/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tpuaohwn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183008-tpuaohwn/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=242, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=243, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183037-marz3pb5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/marz3pb5
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183040-fmnbf6u1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fmnbf6u1
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183040-ezn755i0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ezn755i0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/j3ck7g5h[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183023-j3ck7g5h/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c3v51cxm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183024-c3v51cxm/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5pcbgdzu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183024-5pcbgdzu/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/aj0z5afc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183024-aj0z5afc/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=244, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=245, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qj8511i7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183027-qj8511i7/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g2wmew7e[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183027-g2wmew7e/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=246, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=247, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=248, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=249, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183054-86wmsidt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/86wmsidt
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183056-bdfdllrp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bdfdllrp
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183056-a2vq70nw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a2vq70nw
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183056-fj1zcasx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fj1zcasx
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183056-v0uwfqph
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v0uwfqph
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183058-164jdzv8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/164jdzv8
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/marz3pb5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183037-marz3pb5/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ezn755i0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183040-ezn755i0/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=250, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=251, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183109-wlhotog8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wlhotog8
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183110-onxt4x4u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/onxt4x4u
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fj1zcasx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183056-fj1zcasx/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/v0uwfqph[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183056-v0uwfqph/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bdfdllrp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183056-bdfdllrp/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a2vq70nw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183056-a2vq70nw/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/164jdzv8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183058-164jdzv8/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=252, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=253, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=254, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=255, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/86wmsidt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183054-86wmsidt/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=256, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=257, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183122-u3m1hpj8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u3m1hpj8
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183122-4y2nyyii
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4y2nyyii
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183122-pd3ayarj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pd3ayarj
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183123-mkfwm75l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mkfwm75l
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183123-y948htng
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y948htng
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183125-vi2488c2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vi2488c2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/onxt4x4u[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183110-onxt4x4u/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=258, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wlhotog8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183109-wlhotog8/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yllgd799[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183021-yllgd799/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fmnbf6u1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183040-fmnbf6u1/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=259, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h90pnrii[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_182900-h90pnrii/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=260, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=261, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=262, wandb_name=random, GPU=2
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183138-clkvtdbd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/clkvtdbd
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183139-vhvvh48c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vhvvh48c
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183139-hsi2l5so
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hsi2l5so
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183141-wgtqjxlw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wgtqjxlw
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183142-aca5eszb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/aca5eszb
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u3m1hpj8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183122-u3m1hpj8/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pd3ayarj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183122-pd3ayarj/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4y2nyyii[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183122-4y2nyyii/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mkfwm75l[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183123-mkfwm75l/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=263, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=264, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=265, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=266, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vi2488c2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183125-vi2488c2/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=267, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y948htng[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183123-y948htng/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183152-hq6xsgmn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hq6xsgmn
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183152-9ktwcohp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9ktwcohp
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183152-udh5bbwp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/udh5bbwp
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=268, wandb_name=random, GPU=0
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183153-uecx3f9t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uecx3f9t
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183156-vqw5m21u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vqw5m21u
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wgtqjxlw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183141-wgtqjxlw/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183200-c8lemcjv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c8lemcjv
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/aca5eszb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183142-aca5eszb/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/clkvtdbd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183138-clkvtdbd/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=269, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=270, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=271, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hsi2l5so[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183139-hsi2l5so/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vhvvh48c[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183139-vhvvh48c/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=272, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=273, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183206-imb71zir
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/imb71zir
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183208-j5qsnzdf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/j5qsnzdf
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183209-ubvgocjq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ubvgocjq
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183213-fcbyp1z1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fcbyp1z1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hq6xsgmn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183152-hq6xsgmn/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183213-mplp65e9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mplp65e9
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9ktwcohp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183152-9ktwcohp/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/udh5bbwp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183152-udh5bbwp/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=274, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vqw5m21u[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183156-vqw5m21u/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=275, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uecx3f9t[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183153-uecx3f9t/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=276, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/c8lemcjv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183200-c8lemcjv/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=277, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183220-9gl4xuv2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9gl4xuv2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=278, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=279, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183222-3pyp876k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3pyp876k
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183223-my91p1jd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/my91p1jd
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183226-l10xagm8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l10xagm8
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183226-gsewf8id
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gsewf8id
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183227-sb56mnhc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sb56mnhc
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/imb71zir[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183206-imb71zir/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=280, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/j5qsnzdf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183208-j5qsnzdf/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ubvgocjq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183209-ubvgocjq/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=281, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=282, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183236-4z45f91r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4z45f91r
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183239-qn8atgbo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qn8atgbo
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183241-2lyqbs0f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2lyqbs0f
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mplp65e9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183213-mplp65e9/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fcbyp1z1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183213-fcbyp1z1/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3pyp876k[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183222-3pyp876k/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=283, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=284, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=285, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183252-q3wmrpsz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q3wmrpsz
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183253-vkneb911
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vkneb911
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183253-raq0mf2j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/raq0mf2j
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4z45f91r[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183236-4z45f91r/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2lyqbs0f[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183241-2lyqbs0f/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qn8atgbo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183239-qn8atgbo/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=286, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=287, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=288, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sb56mnhc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183227-sb56mnhc/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/l10xagm8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183226-l10xagm8/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/my91p1jd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183223-my91p1jd/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gsewf8id[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183226-gsewf8id/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=289, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=290, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=291, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=292, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183310-ddalofy7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ddalofy7
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183309-7vpqzhg1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7vpqzhg1
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183310-oxqsndjs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oxqsndjs
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183313-z87mpkrc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z87mpkrc
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183313-7032o8dy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7032o8dy
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183313-bjfw5f43
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bjfw5f43
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183313-ty8rc0jo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ty8rc0jo
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vkneb911[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183253-vkneb911/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/q3wmrpsz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183252-q3wmrpsz/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/raq0mf2j[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183253-raq0mf2j/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=293, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=294, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=295, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183322-6gggdpdn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6gggdpdn
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183323-r0ydr1gb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r0ydr1gb
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183324-u0f8wn0r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u0f8wn0r
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oxqsndjs[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183310-oxqsndjs/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ddalofy7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183310-ddalofy7/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7vpqzhg1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183309-7vpqzhg1/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=296, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7032o8dy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183313-7032o8dy/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=297, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=298, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ty8rc0jo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183313-ty8rc0jo/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z87mpkrc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183313-z87mpkrc/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=299, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bjfw5f43[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183313-bjfw5f43/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=300, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=301, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=302, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183339-iywjjfr4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iywjjfr4
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183340-o9wi4trj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o9wi4trj
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183341-coygidev
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/coygidev
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183341-wtse48ul
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wtse48ul
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183343-k5fk4z13
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k5fk4z13
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183343-oo5ocn7n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oo5ocn7n
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183345-20jvjz06
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/20jvjz06
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6gggdpdn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183322-6gggdpdn/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r0ydr1gb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183323-r0ydr1gb/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=303, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=304, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9gl4xuv2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183220-9gl4xuv2/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u0f8wn0r[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183324-u0f8wn0r/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=305, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=306, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183352-mxhwbi5w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mxhwbi5w
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183352-pukytrpi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pukytrpi
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183356-cttdsv4n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cttdsv4n
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183356-w3jucl8x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/w3jucl8x
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wtse48ul[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183341-wtse48ul/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/coygidev[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183341-coygidev/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iywjjfr4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183339-iywjjfr4/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=307, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oo5ocn7n[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183343-oo5ocn7n/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=308, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=309, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=310, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183407-logynnt6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/logynnt6
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183410-mjdcuhzx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mjdcuhzx
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183410-f0caooxr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f0caooxr
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183411-im3knkqf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/im3knkqf
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cttdsv4n[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183356-cttdsv4n/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mxhwbi5w[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183352-mxhwbi5w/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/w3jucl8x[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183356-w3jucl8x/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pukytrpi[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183352-pukytrpi/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k5fk4z13[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183343-k5fk4z13/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=311, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=312, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=313, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=314, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=315, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183420-u1h08xcg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u1h08xcg
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/20jvjz06[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183345-20jvjz06/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183422-u3ai92f5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u3ai92f5
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=316, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183422-8pp4v63t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8pp4v63t
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183422-acxiemy0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/acxiemy0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183426-lhm9v6rk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lhm9v6rk
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183428-gqjfhqix
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gqjfhqix
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/im3knkqf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183411-im3knkqf/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/o9wi4trj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183340-o9wi4trj/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=317, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/logynnt6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183407-logynnt6/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=318, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mjdcuhzx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183410-mjdcuhzx/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=319, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/f0caooxr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183410-f0caooxr/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=320, wandb_name=random, GPU=0
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183435-nmq5tvet
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nmq5tvet
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=321, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u1h08xcg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183420-u1h08xcg/logs[0m
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183439-surztsj4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/surztsj4
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183440-8sc4nvws
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8sc4nvws
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=322, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183442-yjt12b1e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yjt12b1e
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183443-8fr71c3i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8fr71c3i
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/acxiemy0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183422-acxiemy0/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8pp4v63t[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183422-8pp4v63t/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u3ai92f5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183422-u3ai92f5/logs[0m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183446-wva92mwc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wva92mwc
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=323, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lhm9v6rk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183426-lhm9v6rk/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=324, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=325, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gqjfhqix[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183428-gqjfhqix/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=326, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=327, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183450-t2w9dnez
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/t2w9dnez
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183452-lmu40c2w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lmu40c2w
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183452-ksvqmg52
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ksvqmg52
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183453-z61ahnx5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z61ahnx5
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183454-dqf5n8vt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dqf5n8vt
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nmq5tvet[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183435-nmq5tvet/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yjt12b1e[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183442-yjt12b1e/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=328, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8fr71c3i[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183443-8fr71c3i/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8sc4nvws[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183440-8sc4nvws/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/surztsj4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183439-surztsj4/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=329, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=330, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=331, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=332, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wva92mwc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183446-wva92mwc/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=333, wandb_name=random, GPU=1
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183508-ag646cvp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ag646cvp
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183512-lciwdz6j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lciwdz6j
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183512-5uoccos3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5uoccos3
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183512-apgmmnmv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/apgmmnmv
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183512-0pshq8md
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0pshq8md
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ksvqmg52[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183452-ksvqmg52/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/t2w9dnez[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183450-t2w9dnez/logs[0m
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183514-vih2qrnz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vih2qrnz
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=334, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dqf5n8vt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183454-dqf5n8vt/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/z61ahnx5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183453-z61ahnx5/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=335, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lmu40c2w[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183452-lmu40c2w/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=336, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=337, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=338, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183522-yovjzrkg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yovjzrkg
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183522-yezh0hhu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yezh0hhu
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183527-uoibej6p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uoibej6p
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183528-kb146arx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kb146arx
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183528-fxx4mcwz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fxx4mcwz
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ag646cvp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183508-ag646cvp/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=339, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/apgmmnmv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183512-apgmmnmv/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lciwdz6j[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183512-lciwdz6j/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0pshq8md[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183512-0pshq8md/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5uoccos3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183512-5uoccos3/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vih2qrnz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183514-vih2qrnz/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=340, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=341, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183540-57gosqjx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/57gosqjx
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=342, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=343, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=344, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183545-wjlultsb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wjlultsb
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183545-evk3tij4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/evk3tij4
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183547-403naxva
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/403naxva
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183547-h050a7oj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h050a7oj
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183548-kguknwc4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kguknwc4
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yovjzrkg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183522-yovjzrkg/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yezh0hhu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183522-yezh0hhu/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=345, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=346, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183558-h4si0r8y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h4si0r8y
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uesp1wzh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183028-uesp1wzh/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kb146arx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183528-kb146arx/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183559-cm9sdr8i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cm9sdr8i
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=347, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=348, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/57gosqjx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183540-57gosqjx/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fxx4mcwz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183528-fxx4mcwz/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/uoibej6p[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183527-uoibej6p/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wjlultsb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183545-wjlultsb/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=349, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=350, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=351, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=352, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/evk3tij4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183545-evk3tij4/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183608-d377vcxt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/d377vcxt
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=353, wandb_name=random, GPU=1
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183609-2gi9vn20
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2gi9vn20
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183613-13uqh3pi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/13uqh3pi
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183614-udylab3k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/udylab3k
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183614-cxd83d0t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cxd83d0t
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h050a7oj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183547-h050a7oj/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/403naxva[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183547-403naxva/logs[0m
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183615-cpoaxtca
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cpoaxtca
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kguknwc4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183548-kguknwc4/logs[0m
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183616-2lmeme2b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2lmeme2b
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=354, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=355, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=356, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cm9sdr8i[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183559-cm9sdr8i/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h4si0r8y[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183558-h4si0r8y/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=357, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=358, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183625-88q4jm3t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/88q4jm3t
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183626-7lgxhqiv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7lgxhqiv
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183628-b1nzh9sn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b1nzh9sn
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/d377vcxt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183608-d377vcxt/logs[0m
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183631-lxhn3aez
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lxhn3aez
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=359, wandb_name=random, GPU=3
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183633-tt7pliqc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tt7pliqc
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2gi9vn20[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183609-2gi9vn20/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=360, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/13uqh3pi[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183613-13uqh3pi/logs[0m
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183640-7v9dv43z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7v9dv43z
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=361, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cxd83d0t[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183614-cxd83d0t/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cpoaxtca[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183615-cpoaxtca/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/2lmeme2b[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183616-2lmeme2b/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=362, wandb_name=random, GPU=2
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=363, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=364, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/udylab3k[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183614-udylab3k/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183647-qt00co05
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qt00co05
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=365, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183651-tz2p7jkc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tz2p7jkc
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183652-9d18t34m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9d18t34m
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183653-sihqygt3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sihqygt3
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183653-dxr6qgda
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dxr6qgda
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/88q4jm3t[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183625-88q4jm3t/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/b1nzh9sn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183628-b1nzh9sn/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=366, wandb_name=random, GPU=2
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183657-ijue9yjh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ijue9yjh
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=367, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tt7pliqc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183633-tt7pliqc/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7lgxhqiv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183626-7lgxhqiv/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=368, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lxhn3aez[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183631-lxhn3aez/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183704-e5ltqcu9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e5ltqcu9
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=369, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=370, wandb_name=random, GPU=2
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7v9dv43z[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183640-7v9dv43z/logs[0m
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183704-8zqjkwsi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8zqjkwsi
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=371, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183709-00asjv7y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/00asjv7y
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/qt00co05[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183647-qt00co05/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183714-r13pxeg2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r13pxeg2
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tz2p7jkc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183651-tz2p7jkc/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183715-7c47715t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7c47715t
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9d18t34m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183652-9d18t34m/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sihqygt3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183653-sihqygt3/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=372, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=373, wandb_name=random, GPU=1
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=374, wandb_name=random, GPU=2
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183717-rnu3ob40
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rnu3ob40
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=375, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dxr6qgda[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183653-dxr6qgda/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=376, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ijue9yjh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183657-ijue9yjh/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=377, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183726-dk2avb7k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dk2avb7k
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183727-mug5gcxv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mug5gcxv
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183727-xkq4knld
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xkq4knld
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183727-ng69oxr9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ng69oxr9
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8zqjkwsi[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183704-8zqjkwsi/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e5ltqcu9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183704-e5ltqcu9/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=378, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/00asjv7y[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183709-00asjv7y/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183732-m2psa0tm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m2psa0tm
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=379, wandb_name=random, GPU=3
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183733-syd5zhjz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/syd5zhjz
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=380, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r13pxeg2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183714-r13pxeg2/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183741-zgy7kyib
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zgy7kyib
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183742-ao37pfcc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ao37pfcc
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=381, wandb_name=random, GPU=1
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183742-fo7llg6x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fo7llg6x
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/rnu3ob40[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183717-rnu3ob40/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=382, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7c47715t[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183715-7c47715t/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=383, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183753-srg4yw1y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/srg4yw1y
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183754-e0hv7am2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e0hv7am2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dk2avb7k[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183726-dk2avb7k/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=384, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mug5gcxv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183727-mug5gcxv/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ng69oxr9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183727-ng69oxr9/logs[0m
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/m2psa0tm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183732-m2psa0tm/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xkq4knld[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183727-xkq4knld/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183759-w5k8r3j3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/w5k8r3j3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=385, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/syd5zhjz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183733-syd5zhjz/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=386, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=387, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=388, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=389, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183806-nbuh4vya
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nbuh4vya
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183808-1xdsf8c5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1xdsf8c5
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183808-5sipxy72
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5sipxy72
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183809-kicr8vqo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kicr8vqo
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183812-kvwite2t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kvwite2t
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/srg4yw1y[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183753-srg4yw1y/logs[0m
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183814-yjisfzr1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yjisfzr1
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fo7llg6x[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183742-fo7llg6x/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zgy7kyib[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183741-zgy7kyib/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ao37pfcc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183742-ao37pfcc/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=390, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e0hv7am2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183754-e0hv7am2/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=391, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=392, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=393, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=394, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183826-h904mpn6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h904mpn6
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183826-06gljs2y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/06gljs2y
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183827-1f51wpxo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1f51wpxo
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183827-mzrdp9es
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mzrdp9es
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183829-nyjhp948
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nyjhp948
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nbuh4vya[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183806-nbuh4vya/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1xdsf8c5[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183808-1xdsf8c5/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/w5k8r3j3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183759-w5k8r3j3/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=395, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/5sipxy72[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183808-5sipxy72/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kicr8vqo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183809-kicr8vqo/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=396, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=397, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=398, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=399, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yjisfzr1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183814-yjisfzr1/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kvwite2t[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183812-kvwite2t/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=400, wandb_name=random, GPU=0
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=401, wandb_name=random, GPU=1
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183843-07qqbkz4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/07qqbkz4
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183845-279tqhhy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/279tqhhy
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183846-xy4c48ur
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xy4c48ur
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183847-3wkdphav
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3wkdphav
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183846-0em4tp1t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0em4tp1t
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183852-1smcs2vd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1smcs2vd
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183852-py02xxzk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/py02xxzk
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nyjhp948[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183829-nyjhp948/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mzrdp9es[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183827-mzrdp9es/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=402, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=403, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/06gljs2y[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183826-06gljs2y/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/h904mpn6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183826-h904mpn6/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1f51wpxo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183827-1f51wpxo/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=404, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=405, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=406, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183909-r8qc812i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r8qc812i
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183908-sbfttusw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sbfttusw
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183913-27k7bh8n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/27k7bh8n
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183913-t3cdq1hl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/t3cdq1hl
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0em4tp1t[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183846-0em4tp1t/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3wkdphav[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183847-3wkdphav/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183914-sq58vkej
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sq58vkej
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/07qqbkz4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183843-07qqbkz4/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/279tqhhy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183845-279tqhhy/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xy4c48ur[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183846-xy4c48ur/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=407, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=408, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=409, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1smcs2vd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183852-1smcs2vd/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=410, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=411, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/py02xxzk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183852-py02xxzk/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=412, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=413, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183925-sntdftmi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sntdftmi
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183925-bjs7udh1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bjs7udh1
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183925-oesjmo84
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oesjmo84
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183925-zdanxkmr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zdanxkmr
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183925-3oybumdv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3oybumdv
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183926-gdcpveuz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gdcpveuz
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183931-nxpawrkb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nxpawrkb
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/r8qc812i[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183909-r8qc812i/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sbfttusw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183908-sbfttusw/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=414, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=415, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/27k7bh8n[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183913-27k7bh8n/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=416, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183943-kjzyo9ki
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kjzyo9ki
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sq58vkej[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183914-sq58vkej/logs[0m
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183946-utg2je35
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/utg2je35
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/t3cdq1hl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183913-t3cdq1hl/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=417, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=418, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183952-wbcghkzh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wbcghkzh
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3oybumdv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183925-3oybumdv/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bjs7udh1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183925-bjs7udh1/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=419, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=420, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_183959-7b5d6ui3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7b5d6ui3
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nxpawrkb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183931-nxpawrkb/logs[0m
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184000-16zsozwo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/16zsozwo
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/sntdftmi[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183925-sntdftmi/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/oesjmo84[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183925-oesjmo84/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zdanxkmr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183925-zdanxkmr/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=421, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/gdcpveuz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183926-gdcpveuz/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=422, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=423, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=424, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=425, wandb_name=random, GPU=1
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184005-t6mcphcv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/t6mcphcv
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184007-fd60050e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fd60050e
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184010-1wyao9ed
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1wyao9ed
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184011-fv2fgbw4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fv2fgbw4
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184012-1danfufc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1danfufc
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/utg2je35[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183946-utg2je35/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kjzyo9ki[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183943-kjzyo9ki/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184015-zhps7tlo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zhps7tlo
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=426, wandb_name=random, GPU=2
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=427, wandb_name=random, GPU=3
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wbcghkzh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183952-wbcghkzh/logs[0m
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184016-pnfsc52n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pnfsc52n
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=428, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184025-yp2f0b3k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yp2f0b3k
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184026-dd6jw3em
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dd6jw3em
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184027-igx1i81n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/igx1i81n
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/16zsozwo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184000-16zsozwo/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7b5d6ui3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_183959-7b5d6ui3/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fd60050e[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184007-fd60050e/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/t6mcphcv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184005-t6mcphcv/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=429, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=430, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=431, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=432, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1wyao9ed[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184010-1wyao9ed/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/fv2fgbw4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184011-fv2fgbw4/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=433, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1danfufc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184012-1danfufc/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=434, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=435, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184042-bpkbh8es
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bpkbh8es
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184042-e8skw3jd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e8skw3jd
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/zhps7tlo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184015-zhps7tlo/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pnfsc52n[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184016-pnfsc52n/logs[0m
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184043-1hwsad1j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1hwsad1j
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184043-3poi33uy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3poi33uy
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=436, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=437, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yp2f0b3k[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184025-yp2f0b3k/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184052-a1tpl4wj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a1tpl4wj
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=438, wandb_name=random, GPU=2
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184053-usdm7ias
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/usdm7ias
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184053-ue4tin21
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ue4tin21
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dd6jw3em[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184026-dd6jw3em/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184055-wov31iwm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wov31iwm
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=439, wandb_name=random, GPU=3
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184057-iidhikwx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iidhikwx
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/igx1i81n[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184027-igx1i81n/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=440, wandb_name=random, GPU=0
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184101-hyegzi4t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hyegzi4t
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184108-lo8nqxyh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lo8nqxyh
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184110-g9ekluc9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g9ekluc9
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/e8skw3jd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184042-e8skw3jd/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1hwsad1j[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184043-1hwsad1j/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bpkbh8es[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184042-bpkbh8es/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3poi33uy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184043-3poi33uy/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=441, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=442, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=443, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=444, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/a1tpl4wj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184052-a1tpl4wj/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=445, wandb_name=random, GPU=1
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/usdm7ias[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184053-usdm7ias/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ue4tin21[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184053-ue4tin21/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=446, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184127-tkcv2d3q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tkcv2d3q
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=447, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184127-bh9bymmq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bh9bymmq
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184127-dqbspg36
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dqbspg36
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184127-toc6dkt7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/toc6dkt7
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iidhikwx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184057-iidhikwx/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/hyegzi4t[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184101-hyegzi4t/logs[0m
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=448, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wov31iwm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184055-wov31iwm/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=449, wandb_name=random, GPU=1
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184132-mkcf2a12
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mkcf2a12
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/lo8nqxyh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184108-lo8nqxyh/logs[0m
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=450, wandb_name=random, GPU=2
wandb: | Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184135-vauyqt83
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vauyqt83
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=451, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184139-pkwyuv6j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pkwyuv6j
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/g9ekluc9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184110-g9ekluc9/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184142-u1vu5vzr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u1vu5vzr
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=452, wandb_name=random, GPU=0
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184145-xmsff4gw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xmsff4gw
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184144-1j3tt1sj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1j3tt1sj
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184151-x6jecvup
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x6jecvup
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/dqbspg36[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184127-dqbspg36/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bh9bymmq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184127-bh9bymmq/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184155-smd22928
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/smd22928
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/tkcv2d3q[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184127-tkcv2d3q/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=453, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=454, wandb_name=random, GPU=2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mkcf2a12[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184132-mkcf2a12/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/toc6dkt7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184127-toc6dkt7/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=455, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=456, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vauyqt83[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184135-vauyqt83/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=457, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=458, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184206-iz5jux0f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iz5jux0f
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184207-89u08hrl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/89u08hrl
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pkwyuv6j[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184139-pkwyuv6j/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184209-xh5xtr8f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xh5xtr8f
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184209-d9v33bvp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/d9v33bvp
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=459, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184211-vhv60b8s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vhv60b8s
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/u1vu5vzr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184142-u1vu5vzr/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xmsff4gw[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184145-xmsff4gw/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=460, wandb_name=random, GPU=0
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1j3tt1sj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184144-1j3tt1sj/logs[0m
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=461, wandb_name=random, GPU=1
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184216-k46i9lid
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k46i9lid
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=462, wandb_name=random, GPU=2
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184220-323eczkc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/323eczkc
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/x6jecvup[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184151-x6jecvup/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/smd22928[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184155-smd22928/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184225-1vmu0cax
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1vmu0cax
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=463, wandb_name=random, GPU=3
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184228-ywmc7pl9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ywmc7pl9
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=464, wandb_name=random, GPU=0
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184229-0j0vvo6d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0j0vvo6d
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iz5jux0f[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184206-iz5jux0f/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/d9v33bvp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184209-d9v33bvp/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=465, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/89u08hrl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184207-89u08hrl/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xh5xtr8f[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184209-xh5xtr8f/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=466, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=467, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=468, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184239-au86ts0s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/au86ts0s
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184240-9k3hf9as
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9k3hf9as
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/k46i9lid[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184216-k46i9lid/logs[0m
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=469, wandb_name=random, GPU=1
wandb: | Waiting for wandb.init()...wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184246-aqnk7f2o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/aqnk7f2o
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vhv60b8s[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184211-vhv60b8s/logs[0m
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184248-8hkloxpo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8hkloxpo
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/323eczkc[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184220-323eczkc/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184250-3kkqelxa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3kkqelxa
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=470, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=471, wandb_name=random, GPU=3
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184250-68qh7mh7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/68qh7mh7
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ywmc7pl9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184228-ywmc7pl9/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/1vmu0cax[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184225-1vmu0cax/logs[0m
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184255-bycv1565
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bycv1565
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=472, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=473, wandb_name=random, GPU=1
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/0j0vvo6d[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184229-0j0vvo6d/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184300-ks857l11
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ks857l11
wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=474, wandb_name=random, GPU=2
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184300-6qkhm6wl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6qkhm6wl
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/au86ts0s[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184239-au86ts0s/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9k3hf9as[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184240-9k3hf9as/logs[0m
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=475, wandb_name=random, GPU=3
wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184308-7fmmfg4d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7fmmfg4d
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184309-y49mt7j2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y49mt7j2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=476, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184312-yb3oq909
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yb3oq909
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/8hkloxpo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184248-8hkloxpo/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/aqnk7f2o[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184246-aqnk7f2o/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=477, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=478, wandb_name=random, GPU=2
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/3kkqelxa[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184250-3kkqelxa/logs[0m
wandb: | Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184318-nbkvgwhr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nbkvgwhr
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/68qh7mh7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184250-68qh7mh7/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=479, wandb_name=random, GPU=3
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=480, wandb_name=random, GPU=0
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184323-woc3azs6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/woc3azs6
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/bycv1565[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184255-bycv1565/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=481, wandb_name=random, GPU=1
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ks857l11[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184300-ks857l11/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6qkhm6wl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184300-6qkhm6wl/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184330-kh8s0f72
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kh8s0f72
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=482, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=483, wandb_name=random, GPU=3
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184330-4ymz8sz4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4ymz8sz4
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184331-pm2ewj81
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pm2ewj81
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184331-6m0ltiz2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6m0ltiz2
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7fmmfg4d[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184308-7fmmfg4d/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y49mt7j2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184309-y49mt7j2/logs[0m
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=484, wandb_name=random, GPU=0
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=485, wandb_name=random, GPU=1
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184339-jspc1li7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jspc1li7
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yb3oq909[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184312-yb3oq909/logs[0m
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=486, wandb_name=random, GPU=2
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184342-4fbti4da
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4fbti4da
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184342-9wx07gbt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9wx07gbt
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/nbkvgwhr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184318-nbkvgwhr/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=487, wandb_name=random, GPU=3
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184347-wyqr214e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wyqr214e
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/woc3azs6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184323-woc3azs6/logs[0m
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184352-pjoh3p7i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pjoh3p7i
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=488, wandb_name=random, GPU=0
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184354-xyluw56m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xyluw56m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184357-9lgkxzhx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9lgkxzhx
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pm2ewj81[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184331-pm2ewj81/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/kh8s0f72[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184330-kh8s0f72/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/6m0ltiz2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184331-6m0ltiz2/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4ymz8sz4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184330-4ymz8sz4/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=489, wandb_name=random, GPU=1
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=490, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=491, wandb_name=random, GPU=3
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=492, wandb_name=random, GPU=0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184406-mgr2ayp0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mgr2ayp0
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/jspc1li7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184339-jspc1li7/logs[0m
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184410-iwec2rdm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iwec2rdm
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=493, wandb_name=random, GPU=1
wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184411-7195jrus
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7195jrus
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4fbti4da[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184342-4fbti4da/logs[0m
wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184411-yaxgwgtk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yaxgwgtk
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184412-mvpx2bio
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mvpx2bio
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9wx07gbt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184342-9wx07gbt/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=494, wandb_name=random, GPU=2
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=495, wandb_name=random, GPU=3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/wyqr214e[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184347-wyqr214e/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/pjoh3p7i[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184352-pjoh3p7i/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: - Waiting for wandb.init()...[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/xyluw56m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184354-xyluw56m/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=496, wandb_name=random, GPU=0
wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=497, wandb_name=random, GPU=1
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184421-4qalp8xx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4qalp8xx
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=498, wandb_name=random, GPU=2
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184427-mte5jk8f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mte5jk8f
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184429-ce1xva1q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ce1xva1q
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9lgkxzhx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184357-9lgkxzhx/logs[0m
wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184430-9x32kyo4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9x32kyo4
wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...Running with: pruning_method=-1, pruning_rate=0.9, training_seed=499, wandb_name=random, GPU=3
wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184431-cc0ke09o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cc0ke09o
wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184432-y7dgrbd3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y7dgrbd3
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mgr2ayp0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184406-mgr2ayp0/logs[0m
Running with: pruning_method=-1, pruning_rate=0.9, training_seed=500, wandb_name=random, GPU=0
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/iwec2rdm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184410-iwec2rdm/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/yaxgwgtk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184411-yaxgwgtk/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184442-7aws3f1r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7aws3f1r
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mvpx2bio[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184412-mvpx2bio/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7195jrus[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184411-7195jrus/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/4qalp8xx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184421-4qalp8xx/logs[0m
wandb: Currently logged in as: ziyang1 (hpi-deep-learning). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.19.4
wandb: Run data is saved locally in /home/zi/research_project/quality_air/wandb/run-20250204_184452-vglzk7dv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run random_prune0.9_lr0.01_bs1024_dr0.1_pm-1
wandb: â­ï¸ View project at https://wandb.ai/hpi-deep-learning/air_quality_drop
wandb: ðŸš€ View run at https://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vglzk7dv
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/mte5jk8f[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184427-mte5jk8f/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/9x32kyo4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184430-9x32kyo4/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/ce1xva1q[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184429-ce1xva1q/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/cc0ke09o[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184431-cc0ke09o/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/y7dgrbd3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184432-y7dgrbd3/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/7aws3f1r[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184442-7aws3f1r/logs[0m
Loading dataset ...
Starting hyperparameter optimization...
set seed for metric calculation: 0
Parameters: {'learning_rate': 0.01, 'batch_size': 1024, 'dropout_rate': 0.1}
Seed=0, pruning_rate=0.9, TrainSize=5875 -> 588, removed=0.90
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mrandom_prune0.9_lr0.01_bs1024_dr0.1_pm-1[0m at: [34mhttps://wandb.ai/hpi-deep-learning/air_quality_drop/runs/vglzk7dv[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250204_184452-vglzk7dv/logs[0m
All tasks completed.
